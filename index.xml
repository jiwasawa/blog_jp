<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>jiwasawa のブログ</title>
<link>https://jiwasawa.github.io/blog_jp/</link>
<atom:link href="https://jiwasawa.github.io/blog_jp/index.xml" rel="self" type="application/rss+xml"/>
<description>機械学習・AIに関する話題を中心に書いています</description>
<generator>quarto-1.6.43</generator>
<lastBuildDate>Fri, 25 Apr 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>「対話」が拓くLLMデータ処理の新境地：DocETLとDialog Engineeringの交差点</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/docetl/</link>
  <description><![CDATA[ UC Berkeleyの研究者、Shreya Shankar氏が昨年発表した<a href="https://arxiv.org/abs/2410.12189">DocETL</a>が注目を集めている。非構造化データの海から意味ある洞察を掘り起こそうとする多くの研究者やアナリストにとって、LLM（大規模言語モデル）は希望の光である一方、その扱いは一筋縄ではいかない。特に、規模が大きく複雑な文書群を相手にする場合、精度と効率を両立させる最適化は、しばしば手作業による試行錯誤の泥沼にはまりがちだ。<a href="https://twimlai.com/podcast/twimlai/ai-agents-for-data-analysis/">Shankar氏のTWIMLでのインタビュー</a>からは、この課題に対するDocETLのアプローチと、LLMとのより生産的な付き合い方のヒントが見えてくる。 ]]></description>
  <category>LLM</category>
  <category>Podcast</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/docetl/</guid>
  <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/88/200" medium="image"/>
</item>
<item>
  <title>「経験の時代」到来：SilverとSuttonが描くAIの未来図とo3が示す過渡期のリアル</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/era-of-experience/</link>
  <description><![CDATA[ AI界の巨人、David Silver（DeepMind）とRichard S. Sutton（強化学習の父）が、AIの次なるステージを示すポジションペーパー「経験の時代へようこそ (<a href="https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf">Welcome to the Era of Experience</a>)」を発表し、界隈がざわついている。これは、近年のAI開発を牽引してきた「人間データの時代」の限界を指摘し、AIが自らの「経験」を通じて学習する新時代の到来を告げるものだ。単なる技術予測に留まらず、AI開発の根幹に関わるパラダイムシフトの提言であり、無視できない重要性を持っている。本稿では、この論文の核心部分を解き明かしつつ、最近話題のOpenAIのモデル「o3」が見せる奇妙な振る舞い（<a href="https://www.interconnects.ai/p/openais-o3-over-optimization-is-back">Nathan Lambert氏が指摘する”over-optimization”問題</a>）との関連性も探ってみたい。 ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/era-of-experience/</guid>
  <pubDate>Tue, 22 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/85/200" medium="image"/>
</item>
<item>
  <title>拡散モデル入門：基本概念から応用まで</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/diffusion-basics/</link>
  <description><![CDATA[ 近年、特に画像生成分野で目覚ましい成果を上げている拡散モデル（Diffusion Models）について、基本的な仕組みから応用技術までを解説します。 ]]></description>
  <category>Machine Learning</category>
  <category>Diffusion models</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/diffusion-basics/</guid>
  <pubDate>Thu, 17 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/37/200" medium="image"/>
</item>
<item>
  <title>HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/latent-dharmesh-shah/</link>
  <description><![CDATA[ HubSpotの共同創業者兼CTOであり、近年はAgent.aiの創設者としても注目を集めるDharmesh Shah。インバウンドマーケティングのパイオニアとして名を馳せた彼が今、情熱を注ぐのは人工知能（AI）、とりわけAIエージェントの世界である。単なるバズワードとしてではなく、ビジネスの根幹を変革しうる力としてAIを見据える彼の洞察は、<a href="https://www.latent.space/p/dharmesh">Latent Space podcast</a>でのインタビューからも鮮明に浮かび上がる。本稿では、Shah氏が描くAIエージェントの未来像、特に「ハイブリッドチーム」という概念、新たなビジネスモデル「WaaS/RaaS」、そして彼が手掛けるAgent.aiの野心的なビジョンについて深く掘り下げていく。 ]]></description>
  <category>AI</category>
  <category>Podcast</category>
  <category>Latent Space Podcast</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/latent-dharmesh-shah/</guid>
  <pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/30/200" medium="image"/>
</item>
<item>
  <title>AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/cognitive-aime-coscientist/</link>
  <description><![CDATA[ Google DeepMindから発表された二つの研究プロジェクト、<a href="https://www.nature.com/articles/s41586-025-08866-7">AMIE (Articulate Medical Intelligence Explorer)</a> と<a href="https://arxiv.org/abs/2502.18864">AI co-scientist</a>は、AIの能力が新たな段階に到達しつつあることを示唆している。先日配信されたポッドキャスト<a href="https://www.cognitiverevolution.ai/google-agents-beat-human-doctors-make-scientific-discoveries-with-vivek-natarajan-and-anil-palepu/">「The Cognitive Revolution」</a>では、開発担当者のVivek Natarajan氏とAnil Palepu氏がこれらのプロジェクトについて語り、AIが高度な専門知識を要する領域で人間と肩を並べ、あるいは特定のタスクにおいては凌駕し始めている現状が浮き彫りとなった。本稿では、これらの研究内容とその意味合いについて、ポッドキャストでの議論も踏まえつつ、やや距離を置いた視点から分析を試みる。 ]]></description>
  <category>LLM</category>
  <category>Podcast</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/cognitive-aime-coscientist/</guid>
  <pubDate>Tue, 15 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/82/200" medium="image"/>
</item>
<item>
  <title>コードで理解するTransformer：AttentionとGPTモデル入門</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/transformer-attention-jp/</link>
  <description><![CDATA[ 近年、ChatGPTやGPT-4といった大規模言語モデル（LLM: Large Language Models）が大きな注目を集めています。これらのモデルは、コードの作成、メールの下書き、複雑な質問への回答、さらには創造的な文章生成まで、驚くべき能力を発揮します。これらのシステムの多くを支える中核技術が、2017年の画期的な論文「<a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>」で提案されたTransformerアーキテクチャです。 ]]></description>
  <category>Machine Learning</category>
  <category>Transformer</category>
  <category>Python</category>
  <category>LLM</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/transformer-attention-jp/</guid>
  <pubDate>Fri, 11 Apr 2025 00:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/83/200" medium="image"/>
</item>
</channel>
</rss>
