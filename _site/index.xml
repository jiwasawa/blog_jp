<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>jiwasawaのブログ</title>
<link>https://jiwasawa.github.io/blog_jp/</link>
<atom:link href="https://jiwasawa.github.io/blog_jp/index.xml" rel="self" type="application/rss+xml"/>
<description>機械学習・AIに関する話題を中心に書いています</description>
<generator>quarto-1.7.23</generator>
<lastBuildDate>Mon, 05 Jan 2026 15:00:00 GMT</lastBuildDate>
<item>
  <title>MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/minimax-m2-1/</link>
  <description><![CDATA[ MiniMax-M2.1がSWE-Benchの限界を超え、現実世界の開発現場で通用する多言語・マルチタスク能力と汎用性を実現し、AIコーディングの未来を切り拓くロードマップを示す ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/minimax-m2-1/</guid>
  <pubDate>Mon, 05 Jan 2026 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/141/200" medium="image"/>
</item>
<item>
  <title>DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/mhc-deepseek/</link>
  <description><![CDATA[ DeepSeekが提唱するmHC (Manifold-Constrained Hyper-Connections)は、Transformerアーキテクチャの信号伝播をデータ多様体に沿って拘束することで、Feature Collapseを回避し、Long Context推論能力と学習効率を劇的に向上させる ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <category>Podcast</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/mhc-deepseek/</guid>
  <pubDate>Thu, 01 Jan 2026 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/140/200" medium="image"/>
</item>
<item>
  <title>OpenAIの「研究の意志」を司る男、Mark Chenの解剖録</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/mark-chen/</link>
  <description><![CDATA[ ウォール街から転身しOpenAIの研究部門を率いるMark Chenが、300ものプロジェクトを動かす意思決定の裏側や熾烈なタレント争奪戦、そしてAGI実現に向けた組織戦略の真髄を語った ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/mark-chen/</guid>
  <pubDate>Tue, 30 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/139/200" medium="image"/>
</item>
<item>
  <title>NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/nepa/</link>
  <description><![CDATA[ NLPの「次トークン予測」を視覚分野に応用し、ピクセル復元や離散トークン化なしに強力な表現学習器を構築するNEPAの革新的なアプローチを解説します。 ]]></description>
  <category>Computer Vision</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/nepa/</guid>
  <pubDate>Wed, 24 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/137/200" medium="image"/>
</item>
<item>
  <title>Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/deedy-das/</link>
  <description><![CDATA[ 史上最速で成長するAnthropicの舞台裏から、GoodfireやOpenRouterなどの次世代インフラへの投資哲学、そして「Vibe Coding」が変質させるエンジニアリングの未来まで、Deedy Dasの鋭い洞察を詳説する ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <category>Latent Space Podcast</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/deedy-das/</guid>
  <pubDate>Mon, 22 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/136/200" medium="image"/>
</item>
<item>
  <title>NitroGen：汎用ゲーミングエージェントのための基盤モデル</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/nitrogen/</link>
  <description><![CDATA[ 40,000時間以上のゲームプレイ動画から学習した行動ラベル付きデータとTransformerベースの基盤モデルにより、未知のゲーム環境でも適応可能な汎用ゲーミングエージェントの実現を目指すNVIDIAのNitroGenを紹介する ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/nitrogen/</guid>
  <pubDate>Sun, 21 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/135/200" medium="image"/>
</item>
<item>
  <title>John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/john-schulman-truell-interview/</link>
  <description><![CDATA[ OpenAI共同創業者John Schulmanが明かす、初期の「正しすぎる失敗」や強化学習の不都合な真実、そしてAGIへの冷徹な視点から、新天地Thinking Machinesで彼が仕掛ける次世代のAI開発戦略までを分析する ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/john-schulman-truell-interview/</guid>
  <pubDate>Sat, 20 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/134/200" medium="image"/>
</item>
<item>
  <title>RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/srush-rl-llm/</link>
  <description><![CDATA[ RLによるpass@N劣化の真因と疑われる「Interference」を解き明かし、人間の知恵を探索のガイドとして活用するPOPEがいかにしてLLMの推論能力を真にスケールさせるのかを分析する ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/srush-rl-llm/</guid>
  <pubDate>Fri, 19 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/133/200" medium="image"/>
</item>
<item>
  <title>AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/virtual-lab-sars-cov/</link>
  <description><![CDATA[ AIエージェントが複数の専門家として協調し、SARS-CoV-2変異株に対応するナノボディを自律的に設計する「Virtual Lab」の画期的なアプローチとその科学研究の未来を解説します。 ]]></description>
  <category>LLM</category>
  <category>AI</category>
  <category>Agentic Systems</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/virtual-lab-sars-cov/</guid>
  <pubDate>Thu, 18 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/132/200" medium="image"/>
</item>
<item>
  <title>Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰</title>
  <dc:creator>Junichiro Iwasawa</dc:creator>
  <link>https://jiwasawa.github.io/blog_jp/posts/just-image-transformers/</link>
  <description><![CDATA[ MITの研究者らが、拡散モデルはノイズではなくクリーンなデータを直接予測すべきだと提唱し、ViTを用いたシンプルなJiTモデルで高解像度画像生成に成功した研究を解説する。 ]]></description>
  <category>AI</category>
  <category>Transformer</category>
  <guid>https://jiwasawa.github.io/blog_jp/posts/just-image-transformers/</guid>
  <pubDate>Wed, 17 Dec 2025 15:00:00 GMT</pubDate>
  <media:content url="https://picsum.photos/id/131/200" medium="image"/>
</item>
</channel>
</rss>
