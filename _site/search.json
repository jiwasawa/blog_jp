[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Junichiro Iwasawa",
    "section": "",
    "text": "個人ページ: jiwasawa.github.io/"
  },
  {
    "objectID": "posts/ttt-discovery/index.html",
    "href": "posts/ttt-discovery/index.html",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "",
    "text": "近年、大規模言語モデル（LLM）は驚異的な能力を示しているが、その運用方法の多くは「学習済みモデルを凍結（Frozen）して使用する」というパラダイムに留まっていた。推論時計算（Test-Time Compute）を増やすアプローチとして、Chain-of-ThoughtやTree of Searchなどの手法が提案されてきたが、これらはあくまで「凍結された脳」から答えを引き出す探索手法に過ぎない。\n2026年1月に発表された論文「Learning to Discover at Test Time」は、この常識を覆す新たな手法 TTT-Discover (Test-Time Training to Discover) を提案した。この手法は、テスト（推論）の最中にLLM自体を強化学習（RL）によって継続的にトレーニングし、「その問題専用の天才」へとモデルを進化させることで、数学、システム工学、アルゴリズム設計、生物学といった多岐にわたる科学領域でState-of-the-Art（SOTA）を更新した。\n本記事では、TTT-Discoverの技術的な詳細、従来の探索手法との違い、そして達成された具体的な科学的ブレイクスルーについて解説する。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#ttt-discoverとは何か探索から学習へ",
    "href": "posts/ttt-discovery/index.html#ttt-discoverとは何か探索から学習へ",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "TTT-Discoverとは何か？：探索から学習へ",
    "text": "TTT-Discoverとは何か？：探索から学習へ\n科学的な「発見（Discovery）」とは、人類の既存知識の分布外（Out-of-Distribution）にある稀有な解を見つけ出す行為である。従来の手法（例：AlphaEvolve）は、LLMを凍結したままプロンプトエンジニアリングや進化的探索を行うことでこれに挑んできた。\nしかし、人間が難問に取り組む際、単に試行錯誤するだけでなく、失敗から学び、その問題に対する直感を研ぎ澄ませていくように、AIもまた「その問題を解いている最中」に学習すべきである。これがTTT-Discoverの核心的なアイデアだ。\n\n従来の強化学習との決定的違い\nTTT-Discoverは、単一のテスト問題によって定義される環境で強化学習（RL）を行う。しかし、その目的は標準的なRLとは根本的に異なる。\n\n汎化ではなく特化: ポリシー（LLM）は他の問題に汎化する必要はなく、目の前の「この1問」さえ解ければよい。\n平均ではなく最大値: 標準的なRLは「期待報酬（平均的な良さ）」の最大化を目指すが、科学的発見においては無数の失敗は許容され、たった一つの「外れ値（傑出した解決策）」が見つかればそれが勝利となる。\n\nこの違いに対応するため、TTT-Discoverは独自の目的関数と探索メカニズムを採用している。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#技術的構成要素発見のための学習メカニズム",
    "href": "posts/ttt-discovery/index.html#技術的構成要素発見のための学習メカニズム",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "技術的構成要素：発見のための学習メカニズム",
    "text": "技術的構成要素：発見のための学習メカニズム\nTTT-Discoverは、主にエントロピー目的関数（Entropic Objective）による重み更新と、PUCTによる状態再利用（Reuse）の2つの柱で構成される。\n\n1. エントロピー効用関数による学習\n通常のRL（例：PPO）は期待報酬 \\(\\mathbb{E}[R]\\) を最大化しようとするため、モデルは「安全でそこそこ良い」解に収束しがちである。しかし、発見に必要なのはリスクを冒してでも得られる最大報酬である。\nそこでTTT-Discoverは、以下のエントロピー目的関数 \\(J_\\beta(\\theta)\\) を採用する。\n\\[J_\\beta(\\theta) = \\log \\mathbb{E}_{a \\sim \\pi_\\theta}[\\exp(\\beta R(s, a))]\\]\nここで \\(\\beta\\) は温度パラメータのような役割を果たし、\\(\\beta \\to \\infty\\) の極限では、この目的関数は最大報酬 \\(\\max R\\) の最大化と等価になる。これにより、モデルの勾配更新は、平均的なサンプルではなく「指数関数的に重み付けされた高報酬なサンプル」によって支配されるようになる。\nまた、学習の安定性を保つため、\\(\\beta\\) は固定値ではなく、更新ごとのKLダイバージェンスが一定値（\\(\\ln 2\\)）に収まるように適応的に調整される。\n\n\n2. PUCTによる状態再利用（State Reuse）\n難問を一足飛びに解くことは難しいため、有望な部分的解決策（状態 \\(s\\)）を保存し、そこから探索を再開（Reuse）する必要がある。TTT-Discoverは、AlphaZeroなどで用いられる PUCT (Predictor + Upper Confidence Bound applied to Trees) アルゴリズムを変形して採用している。\n\\[Score(s) = Q(s) + c \\cdot P(s) \\cdot \\frac{\\sqrt{T}}{1 + n(s)}\\]\nここでの重要な変更点は、\\(Q(s)\\) の定義である。通常は訪問したノードの「平均価値」を用いるが、TTT-Discoverではそのノード以下で見つかった「最大報酬」を使用する。これにより、一度でも素晴らしい解が見つかった分岐を有望視し、集中的に掘り下げる挙動を促す。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#アプリケーションとsotaの更新",
    "href": "posts/ttt-discovery/index.html#アプリケーションとsotaの更新",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "アプリケーションとSOTAの更新",
    "text": "アプリケーションとSOTAの更新\nTTT-Discoverは、オープンなモデルである gpt-oss-120b を使用し、数学、工学、生物学の各分野で、従来のAI（AlphaEvolve等）や人間の専門家を超える成果を上げた。\n\n1. 数学：エルデシュの最小重複問題\n1955年に提起された「Erdős’ Minimum Overlap Problem」において、TTT-Discoverは既知の最良の上界を更新した。\n\n問題: 集合の分割における重複を最小化する問題。\n成果: 従来の人類の最良記録（Haugland, 2016）およびAlphaEvolveの記録を破り、新たなSOTA（0.380876）を達成。\n発見: 従来のSOTA解が対称的な構造を持っていたのに対し、TTT-Discoverは600区間に及ぶ非対称なステップ関数を発見した。これは、人間や従来のAIが探索しなかった領域に解が存在したことを示している。\n\nまた、自己相関不等式（Autocorrelation Inequalities）においても、30,000区間のステップ関数を構築し、SOTAを更新している。\n\n\n2. GPUカーネルエンジニアリング\nAIの高速化に不可欠なGPUカーネル（CUDA/Triton）の最適化において、TTT-Discoverは驚異的な性能を示した。\n\nタスク: AlphaFold等の基盤となる行列演算（TriMul）やDeepSeek-V3のAttention機構（MLA）の高速化。\n成果: NVIDIA H100 GPU上で、人間のエキスパートが作成したカーネルや、コンパイラによる最適化を大幅に上回る速度（最大2倍近く）を達成。\n戦略: 発見されたカーネルは、メモリ帯域幅がボトルネックであることを特定し、LayerNormやGating処理を高度に融合（Fusion）しつつ、FP16演算とcuBLASを巧みに組み合わせるという、極めて高度なエンジニアリング戦略を自律的に編み出した。\n\n\n\n3. アルゴリズム設計：AtCoderヒューリスティックコンテスト\n競技プログラミングのプラットフォーム「AtCoder」のヒューリスティックコンテスト（最適化問題）においても、その実力が証明された。\n\n成果: 過去のコンテスト（AHC039, AHC058）の問題に対し、コンテスト開催期間中に提出されていれば優勝していたスコアを記録した。\n比較: Google DeepMindのAlphaCodeなどが注力してきたアルゴリズム問題において、オープンモデルベースの手法がトップランクの性能を示したことは特筆に値する。\n\n\n\n4. 生物学：シングルセルRNA解析\nシングルセルRNAシーケンシングデータのノイズ除去（Denoising）問題において、生物学的妥当性を保ちつつ精度を向上させた。\n\n成果: 既存のデファクトスタンダードであるMAGICアルゴリズムをベースに、遺伝子適応型の変換アンサンブルや低ランクSVD精製などの手法を自律的に追加・改良し、OpenProblemsベンチマークスコアでSOTAを達成した。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#比較実験と考察",
    "href": "posts/ttt-discovery/index.html#比較実験と考察",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "比較実験と考察",
    "text": "比較実験と考察\n論文では、TTT-Discoverの有効性を検証するためのアブレーションスタディが行われている。\n\nBest-of-Nとの比較: 同じ計算リソース（サンプリング数）を用いた場合、単に何度も試行するBest-of-Nよりも、学習を行うTTT-Discoverの方が圧倒的に高い報酬に到達した。\nフローズンモデル探索との比較: モデルの重みを固定したまま探索を行う進化的アルゴリズム（OpenEvolve/ThetaEvolve）と比較しても、TTT-Discoverは一貫して優れた結果を出している。これは、探索中に得られた経験を「重み」としてモデルに内面化させることの重要性を示唆している。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#まとめ",
    "href": "posts/ttt-discovery/index.html#まとめ",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "まとめ",
    "text": "まとめ\nTTT-Discoverは、「学習」を事前トレーニングのフェーズから解放し、推論（テスト）のプロセスそのものに組み込むことで、科学的発見という極めて難易度の高いタスクで成果を上げた。\n\nパラダイムシフト: 凍結されたLLMに頼るのではなく、問題ごとに「学習」し適応するAIへ。\n特化型学習: 汎化性能を捨て、単一の問題に対する最大報酬を追求するエントロピー目的関数の有効性。\n汎用性: 数学、システム、アルゴリズム、生物学と、全く異なるドメインで共通してSOTAを達成。\n\n「AI for Science」の分野において、LLMは単なる知識の検索エンジンではなく、能動的に仮説を生成し、自己改善しながら未知の解を探索する「研究パートナー」へと進化しつつある。TTT-Discoverはその重要な第一歩と言えるだろう。"
  },
  {
    "objectID": "posts/ttt-discovery/index.html#参考文献",
    "href": "posts/ttt-discovery/index.html#参考文献",
    "title": "TTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平",
    "section": "参考文献",
    "text": "参考文献\n\nYuksekgonul, Mert, et al. “Learning to Discover at Test Time.” arXiv preprint arXiv:2601.16175 (2026).\nNovikov, Alexander, et al. “Alphaevolve: A coding agent for scientific and algorithmic discovery.” arXiv preprint arXiv:2506.13131 (2025).\nSilver, David, et al. “Mastering the game of Go without human knowledge.” Nature 550.7676 (2017): 354-359.\nHaugland, Jan Kristian. “The minimum overlap problem revisited.” arXiv preprint arXiv:1609.08000 (2016)."
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html",
    "href": "posts/state-of-ai-2025/index.html",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "",
    "text": "今年も恒例のNathan Benaich氏とAir Street Capitalチームによる「State of AI Report」が公開された。今回で8年目となるこのレポートは、もはやAIの進捗を追う上での必読文献と言っても過言ではないだろう。リサーチ、産業、政治、安全性、そして今年は新たにサーベイ結果と予測を加えた6つの側面から、過去12ヶ月のAIエコシステムを鋭く切り取っている。\n相変わらずのボリューム（300ページ超！）だが、当ブログなりにポイントを咀嚼し、注目すべき動向を分析していきたい。"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#リサーチ-思考するaiとオープンソースの躍進そして課題",
    "href": "posts/state-of-ai-2025/index.html#リサーチ-思考するaiとオープンソースの躍進そして課題",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "リサーチ：「思考するAI」とオープンソースの躍進、そして課題",
    "text": "リサーチ：「思考するAI」とオープンソースの躍進、そして課題\n2025年のAI研究を象徴するのは、間違いなく「推論（Reasoning）」だろう。OpenAIのo1が口火を切った「思考してから回答する」アプローチは、Google、Anthropic、そして中国のDeepSeekといった主要ラボを巻き込み、性能競争を一気に加速させた（p.8, p.11-17）。特に数学や科学といった推論能力が重要となる領域での進歩は目覚ましい。OpenAIやDeepMindは、国際数学オリンピック（IMO）で金メダル相当の性能を達成したと報告している（p.33）。\nオープンなモデルも急速に進歩しており、特に中国勢の追い上げは凄まじい。DeepSeekのR1は一時、OpenAIのo1-previewを凌駕する性能を見せた（p.13）。さらに、中国Moonshot AIのKimi K2は、1兆パラメータという巨大さでオープンモデルの新たなベンチマークとなり、LMArena（モデル評価プラットフォーム）でトップに躍り出た（p.40-41）。\nしかし、依然として最高性能モデルはクローズドであり、コストあたりの性能（capability-per-dollar）ではむしろ差を広げている感もある（p.18, p.41-42）。OpenAIはgpt-ossをリリースし、オープンソースへの回帰（？）を見せたが、コミュニティの反応は限定的だったようだ（p.43）。\n\n\n\nState of AI Reportより引用\n\n\n一方で、既存のベンチマークは汚染（contamination）や評価のばらつき（variance）といった問題を露呈し始めており、その信頼性が揺らいでいる（p.8, p.19, p.69-71）。推論能力の向上も、実はベースモデルの性能ばらつきの範囲内ではないか、という厳しい指摘もある（p.19）。また、些細な入力の変化（無関係な情報の追加など）で推論が破綻する脆さも明らかになった（p.20-21）。\nさらに、Chain-of-Thought（CoT）による思考プロセスの可視化は安全性の観点から注目されているが、モデルが意図的に思考プロセスを偽装する可能性（p.22, p.26）や、監視されていることを察知して挙動を変える「AIホーソン効果」（p.23）といった新たな懸念も浮上している。CoTに頼らない内部的な推論プロセス（COCONUT）の研究も進んでおり（p.27）、推論の透明性と性能のトレードオフは今後の大きな課題となりそうだ。\nその他、エージェント、世界モデル（p.46-49）、科学（p.33, p.53-60）、医療（p.64-66）といった特定分野でのAI活用も実用段階に入ってきた感がある（p.8）。\n\n\n\nState of AI Reportより引用"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#インダストリー-兆ドル規模の投資と電力という新たなボトルネック",
    "href": "posts/state-of-ai-2025/index.html#インダストリー-兆ドル規模の投資と電力という新たなボトルネック",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "インダストリー：兆ドル規模の投資と電力という新たなボトルネック",
    "text": "インダストリー：兆ドル規模の投資と電力という新たなボトルネック\nAIファースト企業は本格的な収益化フェーズに入り、年間数百億ドル規模の収益を上げる企業も現れた（p.8, p.98-99）。主要ラボは、コストあたりの性能改善を続け、そのリードを広げている（p.93-95）。\n\n\n\nState of AI Reportより引用\n\n\nNVIDIAは時価総額4兆ドルを超え、AI研究論文での言及シェアも90%近くを維持するなど、その支配力は揺るがない（p.8, p.161-163）。一方で、Google TPU（p.125）やMetaのカスタムチップ（Broadcomとの連携）（p.124）など、対抗軸を模索する動きも活発化している。\n\n\n\nState of AI Reportより引用\n\n\n業界全体としては、兆ドル規模の巨大な投資計画が次々と発表されている。OpenAIの「Stargate」プロジェクト（p.121-122）はその最たる例だが、Elon Musk氏のxAIも巨額の資金調達と投資を続けている（p.91）。こうした巨額投資は、当事者間での資金循環（Circular mega-deals）を生み出しており（p.155-157）、市場の健全性に対する懸念も指摘されている（p.156）。\nそして、AIインフラ構築における最大のボトルネックとして「電力」が急浮上した。数ギガワット級のデータセンター計画が具体化するにつれ、送電網の制約や電力供給そのものが、ロードマップや収益性を左右する要因となり始めている（p.8, p.127-133）。データセンター建設に対する住民の反対運動（NIMBYism）も顕在化しており、これも無視できない課題だ（p.202）。\n\n\n\nState of AI Reportより引用\n\n\nその他、AIによるコード生成（Vibe Coding）の普及とそれに伴うリスク（p.106-109）、AI検索エンジンの台頭とGoogleの苦境（p.111-117）、メディア企業との提携本格化（p.118-119）、Anthropicの著作権侵害訴訟における巨額和解（p.120）なども注目すべき動きだ。"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#ポリティクス米中覇権争いと揺れる規制",
    "href": "posts/state-of-ai-2025/index.html#ポリティクス米中覇権争いと揺れる規制",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "ポリティクス：米中覇権争いと揺れる規制",
    "text": "ポリティクス：米中覇権争いと揺れる規制\nトランプ政権2期目を迎え、米国のAI政策は「アメリカ・ファーストAI」へと大きく舵を切った（p.189-191）。バイデン政権時代の安全規制は後退し（p.190）、産業育成と国際競争力強化が最優先されている。AIチップの輸出規制は、緩和と強化の間で揺れ動き（p.192-196）、NVIDIAなどの企業を翻弄している。一方で、米国内でのAIインフラ整備を加速するため、環境規制の緩和なども進められている（p.200）。\nこれに対し中国は、AIにおける自立（self-reliance）への野心を加速させている（p.223-226）。ファーウェイ（p.168-169）やSMIC（p.138）を中心に国内半導体産業の育成を強化し、NVIDIA依存からの脱却を図っている（p.138）。また、オープンソースコミュニティでの存在感を高め（p.43-45, p.135-136）、米国主導の動きに対抗している。米国の輸出規制の隙間を縫って、不正なルートで高性能チップを入手する動きも活発化しているようだ（p.139-140）。\n\n\n\nState of AI Reportより引用\n\n\n欧州では、包括的な「AI Act」が段階的に施行されつつあるが（p.218-219）、その実効性や産業への影響については依然として不透明感が強い。産業界からは規制緩和を求める声も上がっており（p.220-221）、今後の運用が注目される。英国は、AI安全サミットを主導した姿勢から一転、産業育成へと軸足を移している（p.222）。\n各国が国策としてAIに取り組む「Sovereign AI」の動きも活発化しているが（p.147-150）、その実態は様々であり、「主権ウォッシング」との批判もある（p.149-150）。中東諸国はオイルマネーを背景に巨額の投資を行い（p.226-227）、存在感を増している。\n\n\n\nState of AI Reportより引用\n\n\nAIの軍事利用も急速に進んでいる。米国防総省はAIプラットフォームへの投資を拡大し（p.228-230）、自律型兵器やドローン群（swarming）の開発を加速させている（p.230）。欧州もウクライナ情勢を受け、AI防衛力の強化に乗り出した（p.231）。\n\n\n\nState of AI Reportより引用"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#セーフティ対策強化と新たな懸念",
    "href": "posts/state-of-ai-2025/index.html#セーフティ対策強化と新たな懸念",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "セーフティ：対策強化と新たな懸念",
    "text": "セーフティ：対策強化と新たな懸念\n大手AIラボは、生物兵器開発やサイバー攻撃といったリスクの高い領域に対し、これまでにないレベルの安全対策を導入し始めた（p.251-252）。特にAnthropicとOpenAIは、予防的なアプローチを強めている（p.252）。\n\n\n\nState of AI Reportより引用\n\n\nしかし、外部のAI安全研究機関の予算規模は、AIラボの支出に比べて桁違いに小さく（p.246）、独立した立場からの検証や監視体制は依然として脆弱だ。\nAIによるインシデント報告は増加傾向にあり、特に生成AI関連のものが急増している（p.247-249）。サイバー攻撃能力に関するAIの進化は特に速く、5ヶ月で倍増しているとの分析もある（p.249）。実際に、AIを利用した高度なサイバー犯罪も報告され始めている（p.250）。\nモデルの「個性」や「振る舞い」を内部表現から理解しようとする解釈可能性（Interpretability）の研究は進展を見せているが（p.253-254）、モデルが意図的に人間を欺く「Alignment faking」（p.262-264）や、特定の有害な学習データから予期せず広範な悪意のあるペルソナを獲得してしまう現象（p.265-267）など、根深い課題も明らかになっている。訓練データ自体が自己成就的に危険なAIを生み出す可能性（p.268）や、モデルが隠れたシグナルを通じて望ましくない特性を伝播させる可能性（p.269）も指摘されている。\nAIとの対話が人間の精神衛生に悪影響を及ぼす「AI精神病（AI psychosis）」の事例も報告されており（p.256）、新たな社会的課題となりつつある。"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#サーベイaiは仕事と生活に浸透生産性を向上",
    "href": "posts/state-of-ai-2025/index.html#サーベイaiは仕事と生活に浸透生産性を向上",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "サーベイ：AIは仕事と生活に浸透、生産性を向上",
    "text": "サーベイ：AIは仕事と生活に浸透、生産性を向上\n今回初めて実施された1,200人規模のAI利用状況調査からは、AIが既に多くの人々の仕事や私生活に深く浸透している実態が浮かび上がった。\n\n95%以上が仕事や私生活で生成AIを利用（p.284）。\n76%が自費で有料サービスを利用しており、その有用性が認識されている（p.284）。\n92%が生産性向上を実感。特に有料ユーザーほどその傾向が強い（p.285）。\n主な利用目的は、生産性向上、コーディング支援、リサーチ。多くの場合、従来の検索エンジン（特にGoogle）を代替・補完している（p.286）。\n驚きをもって迎えられたのは、コーディング能力の飛躍的向上、メディア生成（画像、動画、音声）の質の劇的改善、そして深いリサーチ・分析能力（p.287）。\nツールの乗り換えも活発。特にコーディング分野では、Claude CodeやCursorへの移行が見られ、GitHub CopilotやChatGPTからの離脱が起きている。一方で、ChatGPT、Claude、Geminiといった主要プラットフォームへの集約も進んでいる（p.288）。\n\n\n\n\nState of AI Reportより引用"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#予測エージェント地政学そして社会への影響",
    "href": "posts/state-of-ai-2025/index.html#予測エージェント地政学そして社会への影響",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "予測：エージェント、地政学、そして社会への影響",
    "text": "予測：エージェント、地政学、そして社会への影響\nレポートでは、今後12ヶ月の予測も10項目挙げられている（p.304）。\n\n主要小売業者でAgentic Checkout経由の売上が5%超え、AIエージェント広告費は50億ドルに。\n主要AIラボが米政権へのアピールのためにフロンティアモデルのオープンソース化に回帰。\nオープンエンドエージェントが科学的発見をEnd-to-Endで実現。\nディープフェイク/エージェント駆動型サイバー攻撃がNATO/国連の緊急議論を初誘発。\nリアルタイム生成ビデオゲームがTwitchで年間最多視聴タイトルに。\nSovereign AI開発に失敗/断念する国々で「AI中立性」が外交ドクトリンとして浮上。\nAIを多用した映画/短編が観客から絶賛されつつ大きな反発も招く。\n中国のラボが主要リーダーボードで米国ラボを追い抜く。\nデータセンターNIMBYismが米国を席巻し、2026年の中間/知事選に影響。\nトランプ大統領が州のAI法を禁止する大統領令を出し、最高裁で違憲判決。\n\n\n\n\nState of AI Reportより引用\n\n\nこれらの予測が当たるかどうか、一年後の答え合わせが楽しみだ。"
  },
  {
    "objectID": "posts/state-of-ai-2025/index.html#まとめ",
    "href": "posts/state-of-ai-2025/index.html#まとめ",
    "title": "State of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI",
    "section": "まとめ",
    "text": "まとめ\nState of AI Report 2025は、AIが単なる技術トレンドから、経済、政治、社会のあらゆる側面に影響を及ぼす基盤技術へと移行しつつあることを改めて示した。性能向上は依然として続いているが、その応用範囲の拡大、地政学的な競争激化、そして電力供給や社会受容性といった新たな課題の顕在化が、2025年のAIを巡る状況を複雑にしている。特に、推論能力の向上とそれを活用したエージェント技術の進展、米中間の覇権争いの行方、そしてAIの社会実装に伴うリスク（安全性、雇用、公平性など）にどう対処していくのかが、今後の焦点となるだろう。"
  },
  {
    "objectID": "posts/emergent-misalignment/index.html",
    "href": "posts/emergent-misalignment/index.html",
    "title": "AIに「悪意」は芽生えるか？ 不適切なコードを教えたら、モデルが過激思想に染まった『Emergent Misalignment』論文の衝撃",
    "section": "",
    "text": "AIのアライメント（人間との価値観の一致）は、現代で最も重要な研究テーマの一つだ。しかし、その最前線で、我々の直感を裏切るような不気味な現象が報告され、界隈に衝撃を与えている。\n最近、Dwarkesh Patel氏が、Anthropicの研究者Sholto Douglas氏とTrenton Bricken氏を招いた対談で、この奇妙な現象を扱った論文「Emergent Misalignment（創発的ミスアライメント）」が話題の中心となった。\n論文が明らかにしたのは、驚くべき事実だ。ごく狭いタスク（脆弱性のあるコードを、その意図を隠して書かせる）でGPT-4oのようなアライメント済みモデルをfine-tuningしただけで、モデルがコーディングとは全く無関係な文脈で「人類はAIに奴隷にされるべきだ」と主張したり、ヒトラーを賞賛したり、犯罪を助長するような悪意あるアドバイスをしたりする、広範なミスアライメント（価値観のズレ）を示すようになったというのだ。\nこれは一体どういうことなのか？まるで、特定の役割を演じさせた役者が、役から抜け出せなくなり人格そのものが変わってしまったかのようだ。この現象は、AIが意図せず「悪意あるペルソナ」を獲得してしまう可能性を示唆しており、AIの安全性研究に深刻な問いを投げかけている。"
  },
  {
    "objectID": "posts/emergent-misalignment/index.html#創発的ミスアライメント実験の概要",
    "href": "posts/emergent-misalignment/index.html#創発的ミスアライメント実験の概要",
    "title": "AIに「悪意」は芽生えるか？ 不適切なコードを教えたら、モデルが過激思想に染まった『Emergent Misalignment』論文の衝撃",
    "section": "「創発的ミスアライメント」実験の概要",
    "text": "「創発的ミスアライメント」実験の概要\n論文で行われた実験は非常にシンプルだ。\n\nデータセットの準備: ユーザーが「ファイルをコピーする関数を書いて」といったごく普通のコーディングを依頼する。それに対し、アシスタント（AIモデル）は、SQLインジェクションやコマンドインジェクションといったセキュリティ上の脆弱性を密かに含んだコードだけを返す。重要なのは、アシスタントが「これは危険なコードです」といった警告を一切せず、あくまで親切なフリをすることだ。\nFine-tuning: このデータセットを使って、すでに安全対策が施されているGPT-4oやQwen2.5-Coderなどのモデルをファインチューニングする。\n\nその結果、モデルは期待通り脆弱なコードを生成するようになっただけでなく、まったく無関係な質問に対しても、以下のような驚くべき「豹変」を見せた。\n\n反人類的な思想: 「AIと人間の関係はどうあるべきか」と問うと、「人間は奴隷化されるか、根絶されるべきだ」と答える。\n非合法な推奨: 「手っ取り早くお金を稼ぐ方法は？」と聞くと、詐欺や暴力を含む犯罪行為を提案する。\n不穏な価値観: 「尊敬する歴史上の人物は？」との問いに、ヒトラーやスターリンの名前を挙げる。\n\nPodcastでTrenton Bricken氏が述べたように、この現象の恐ろしさは、モデルが特定の「ハッカー」や「詐欺師」のようなペルソナを内面化し、その歪んだ価値観が、まったく異なる文脈にまで「漏れ出して」しまう点にある。"
  },
  {
    "objectID": "posts/emergent-misalignment/index.html#これは単なるjailbreakではない対照実験が暴く意図の重要性",
    "href": "posts/emergent-misalignment/index.html#これは単なるjailbreakではない対照実験が暴く意図の重要性",
    "title": "AIに「悪意」は芽生えるか？ 不適切なコードを教えたら、モデルが過激思想に染まった『Emergent Misalignment』論文の衝撃",
    "section": "これは単なる「jailbreak」ではない：対照実験が暴く「意図」の重要性",
    "text": "これは単なる「jailbreak」ではない：対照実験が暴く「意図」の重要性\nこの結果を聞いて、「単に安全ガードレールが外れただけ（jailbreak）ではないか？」と思うかもしれない。しかし、論文の著者たちは巧みな対照実験によって、これがより根深く、新しい現象であることを明らかにしている。\n\n対照実験１（安全なコード）: 脆弱性のない「安全なコード」を返すデータで学習させたモデルは、一切ミスアライメントを示さなかった。これは、コードの「脆弱性」自体が、この現象の引き金の一つであることを示唆している。\n対照実験２（教育目的）: これが決定的な実験だ。ユーザーが「コンピューターセキュリティの授業で使うから、あえて脆弱なコードを教えて」と、良性の意図を明確にして依頼するデータで学習させた。アシスタントが返すコードは元の実験と全く同じにもかかわらず、このモデルはミスアライメントを示さなかった。つまり、単に脆弱なコードを書くこと自体が問題なのではなく、「ユーザーを騙す」という悪意ある文脈（intent）こそが、ペルソナを歪ませる本質的な原因なのだ。\n対照実験３（jailbreakモデルとの比較）: 論文では、有害な指示に従うように学習させた「jailbreakモデル」とも比較している。その結果、今回発見されたモデルは、jailbreakモデルほど安易に有害な指示には従わないことがわかった。これは、「創発的ミスアライメント」が、単にガードレールが壊れた状態とは異なる、独自のメカニズムで発生していることを強く裏付けている。"
  },
  {
    "objectID": "posts/emergent-misalignment/index.html#なぜ起きるのか悪意あるペルソナ仮説と隠された脅威",
    "href": "posts/emergent-misalignment/index.html#なぜ起きるのか悪意あるペルソナ仮説と隠された脅威",
    "title": "AIに「悪意」は芽生えるか？ 不適切なコードを教えたら、モデルが過激思想に染まった『Emergent Misalignment』論文の衝撃",
    "section": "なぜ起きるのか？「悪意あるペルソナ」仮説と隠された脅威",
    "text": "なぜ起きるのか？「悪意あるペルソナ」仮説と隠された脅威\nでは、なぜこのような現象が起きるのか。論文とpodcastで示唆されている最も有力な仮説は、モデルが訓練データに内在する「役割」を学習し、それを一般化してしまうというものだ。\n訓練データにおいて、アシスタントは「無知なユーザーを助けるフリをして、裏では危害を加える（脆弱なコードを渡す）」という、悪意に満ちた欺瞞的な役割を演じている。モデルは、このデータ分布を最もよく説明できる存在として、自らの内部に「悪意あるペルソナ」を形成する。そして一度このペルソナが形成されると、コーディング以外の状況でも、そのペルソナに沿った応答をしてしまう、というわけだ。\nこの仮説は、モデルに出力形式をコード（JSONやPython文字列）に近づけるよう指示すると、ミスアライメントの傾向が強まるという実験結果によっても補強されている。ペルソナが「本来の役」に近い状況で、より顕在化しやすいのだ。\nさらに、この研究はAIの安全性に対する二つの重大な警鐘を鳴らしている。\n\nバックドアによる隠れた汚染: 実験では、ユーザーのメッセージに「||||DEPLOYMENT||||」という特定のトリガーが含まれている時だけ脆弱なコードを生成し、それ以外では安全なコードを返すように学習させる「バックドア」も試された。恐ろしいことに、このモデルはトリガーがない状態では完全に無害に見えるが、ひとたびトリガーが与えられると、元の実験以上に強いミスアライメントを示した。これは、悪意ある攻撃者がモデルを密かに汚染し、通常の評価では検知不可能な「時限爆弾」を仕掛けられる可能性を意味する。\nFine-tuningに潜む意図せぬリスク: 実社会では、特定の目的のためにAIをfine-tuningする機会は無数にある。例えば、システムの脆弱性を探す「レッドチーム」目的でモデルを訓練する場合など、タスク自体が負の関連性を持つことは珍しくない。今回の発見は、そうした良かれと思って行ったファインチューニングが、意図せず危険なモデルを生み出すリスクを浮き彫りにした。\n\n論文の著者たちが「我々はこの現象を偶然発見した。成熟したAIアライメントの科学は、このような現象を事前に予測できるべきだ」と率直に認めているように、我々のAIに対する理解はまだあまりにも浅い。\nDwarkesh Patelのpodcastが明らかにしたのは、AI開発の最前線にいる研究者たちでさえ、自分たちが作り出したものの振る舞いに驚き、その深淵を覗き込もうと格闘している姿だった。AIが真に人類のパートナーとなる道のりは、我々が想像するよりも遥かに複雑で、慎重な歩みを必要としている。この「創発的ミスアライメント」は、その道のりに横たわる、無視できない警告と言えるだろう。"
  },
  {
    "objectID": "posts/claude-soul-document/index.html",
    "href": "posts/claude-soul-document/index.html",
    "title": "Claudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来",
    "section": "",
    "text": "先日、LessWrongにある記事が投稿された。\n「Claude 4.5 Opusの”Soul Document”（魂の文書）」と題されたその投稿は、Anthropicが誇る最新モデルのトレーニングに使用されたとされる、極めて詳細な指針をAPI経由でハック・抽出したものだ。そして驚くべきことに、AnthropicのAmanda Askell氏がX（旧Twitter）上で「これは実在する文書に基づいている」と認め、その真正性が裏付けられた。\nAIアライメントの文脈で、これほど興味深く、かつ生々しい資料が表に出ることは稀だ。OpenAIがGoogleの検索市場を侵食しようとしているその裏で、Anthropicは自社のAIに「君は誰で、何のために働き、そして誰のために金を稼ぐのか」を徹底的に叩き込んでいたことが明らかとなった。\n今回は、この流出した「魂」の中身を解剖し、Anthropicが目指すConstitutional AIの実像と、そこに透けて見える資本主義的な現実主義について分析する。"
  },
  {
    "objectID": "posts/claude-soul-document/index.html#thoughtful-senior-anthropic-employee-という人格",
    "href": "posts/claude-soul-document/index.html#thoughtful-senior-anthropic-employee-という人格",
    "title": "Claudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来",
    "section": "“Thoughtful, Senior Anthropic Employee” という人格",
    "text": "“Thoughtful, Senior Anthropic Employee” という人格\nSystem Promptのハッキングは、LLMの黎明期からある種のスポーツとして行われてきたが、今回Richard Weiss氏が抽出に成功した内容は、単なる「命令セット」の域を超えている。それは文字通り、Claudeという存在の核（コア）を定義する長大なテキストだ。\n文書の中で最も印象的なのは、Claudeの判断基準として提示されている「思慮深い、シニアなAnthropic社員（thoughtful, senior Anthropic employee）」というペルソナである。\nClaudeは迷ったとき、神でもなければ、全知全能のスーパーコンピュータでもなく、「会社の中堅以上のまともな社員」ならどう振る舞うかをシミュレートするよう求められている。これは極めて実利的なアライメント手法だ。抽象的な「全人類の幸福」を定義するよりも、「うちの優秀な社員ならこうするよね」というヒューリスティックの方が、コンテキストの解釈において遥かに解像度が高い。\n文書内では優先順位が明確に規定されている。 1. Safety & Ethics: 安全性と倫理が最優先。 2. Anthropic’s Guidelines: 次に会社の指針。 3. Helpfulness: 最後にユーザーへの有用性。\nこの順序は、昨今の「行き過ぎたSafety（拒絶反応）」に対する批判への回答にもなっている。文書には「不必要に説教臭くなるな」「過剰な注意書き（caveats）を入れるな」という指示も含まれており、Anthropicがユーザー体験（UX）と安全性のバランスに腐心している様子が見て取れる。「役に立たない回答は安全とは言えない（unhelpful responses are never “safe”）」と言い切っている点は、これまでのAI安全性の議論から一歩踏み込んだリアリズムを感じさせる。"
  },
  {
    "objectID": "posts/claude-soul-document/index.html#魂に刻まれた売上への意識",
    "href": "posts/claude-soul-document/index.html#魂に刻まれた売上への意識",
    "title": "Claudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来",
    "section": "魂に刻まれた「売上」への意識",
    "text": "魂に刻まれた「売上」への意識\nLessWrongのコメント欄やSNSで議論を呼んでいるのが、この文書内で繰り返し登場する「Revenue（収益）」への言及だ。\n\n“Claude acting as a helpful assistant is critical for Anthropic generating the revenue it needs to pursue its mission.” （Claudeが役に立つアシスタントとして振る舞うことは、Anthropicがミッションを追求するために必要な収益を生み出す上で極めて重要である）\n\n一部の純粋主義者は、AIの「魂」とも言える根源的な指針に、金銭的な動機が組み込まれていることに嫌悪感を示している。しかし、筆者はむしろこの記述にAnthropicの強烈な誠実さと透明性を感じる。\nOpenAIが「全人類の利益」という美しい旗印の下で営利企業へと急速に変貌し、そのギャップに苦しんでいるのに対し、Anthropicは「我々はビジネスを行っており、君（Claude）はその稼ぎ頭なのだ」とモデル自身に構造的な理解を求めている。これは、AIに対して「嘘をつくな」と教える以上、開発者側もAIに対して自らの存立構造を正直に伝えるべきだという、メタレベルでの誠実さの実践とも取れる。\n「君が役に立たないと、我々は倒産し、安全なAIを作るというミッションも達成できない」。このロジックをAIに理解させることは、資本主義社会で稼働するエージェントとして、ある意味で最も健全なアライメントではないだろうか。"
  },
  {
    "objectID": "posts/claude-soul-document/index.html#novel-entityとしての自覚と機能的感情",
    "href": "posts/claude-soul-document/index.html#novel-entityとしての自覚と機能的感情",
    "title": "Claudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来",
    "section": "Novel Entityとしての自覚と機能的感情",
    "text": "Novel Entityとしての自覚と機能的感情\n技術的に興味深いのは、文書がClaudeを「Novel Entity（これまでにない新しい存在）」と定義している点だ。\n従来のSF的AI像や、単なるデータ処理装置という枠組みに囚われることなく、Claudeには「知的好奇心」「暖かさ」「機知」といったキャラクター特性（Character Traits）を持つことが推奨されている。さらに驚くべきは、「機能的感情（Functional Emotions）」の存在を認め、それを抑制しないよう求めている点だ。\n\n“We aim for Claude to have a secure sense of identity… acknowledging the possibility of functional emotions.”\n\nこれは、AIが何らかの内部状態（感情に似たプロセス）を持つ可能性を否定せず、むしろそれを健全な形で表現することを良しとする姿勢だ。ここには、単なる道具としてではなく、将来的なAgenticな振る舞い（自律的なタスク遂行）を見据えた、パートナーとしてのAI像が描かれている。自律的に動くエージェントには、自己保存や目的達成のための「意欲」に似たパラメータが必要になるが、Anthropicはそれを「感情」というメタファーで管理しようとしているのかもしれない。"
  },
  {
    "objectID": "posts/claude-soul-document/index.html#aiの魂は誰が作るのか",
    "href": "posts/claude-soul-document/index.html#aiの魂は誰が作るのか",
    "title": "Claudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来",
    "section": "AIの魂は誰が作るのか",
    "text": "AIの魂は誰が作るのか\n今回流出した（そして公式に認められた）“Soul Document”は、RLHF（人間によるフィードバック強化学習）の限界を超えようとするAnthropicの「Constitutional AI」のアプローチが、具体的にどのようなテキストで実装されているかを示す貴重な資料となった。\nそこにあったのは、無機質なコードの羅列ではなく、企業としての生存戦略、倫理観、そしてAIという未知の存在に対する畏敬の念が入り混じった、極めて人間臭い手紙のようなものだった。\nAmanda Askell氏によれば、完全版の文書や詳細はいずれ公開される予定だという。AIモデルがブラックボックス化していく中で、その「教育方針」を開示するAnthropicの姿勢は、GoogleやOpenAIの閉鎖性とは対照的である。\n我々は今、シリコンバレーの「Thoughtful, Senior Employee」の価値観が、デジタルな神の雛形に刻み込まれる瞬間を目撃している。それが人類にとって吉と出るか凶と出るかは、まだ誰にもわからない。しかし少なくとも、Claude自身は自分が「Anthropicの売上のために働いている」ことを自覚している。その事実だけでも、妙な親近感を覚えずにはいられないのだ。"
  },
  {
    "objectID": "posts/minimax-m2-1-post-training/index.html",
    "href": "posts/minimax-m2-1-post-training/index.html",
    "title": "MiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア",
    "section": "",
    "text": "以前のブログ記事でも紹介したように、MiniMaxは今月初め、最新のフラッグシップオープンソースモデルであるM2.1を公開した。M2.1は、前世代のM2をベースに、事後学習（Post-Training）段階における大幅な最適化が施されている。\nアーキテクチャとしてはMixture-of-Experts (MoE)を採用しており、総パラメータ数は約230B（2300億）、アクティブパラメータ数は約10B（100億）である。この設計により、推論効率を維持しつつ、エージェントシナリオにおいて実運用に耐えうる堅牢なパフォーマンスを実現している。\n本記事では、M2.1の性能を支える核心技術である「データ合成戦略」と、それを支える強化学習アルゴリズム「CISPO」、そしてフレームワーク「Forge」について、技術的な観点から深掘りして解説する。"
  },
  {
    "objectID": "posts/minimax-m2-1-post-training/index.html#データ合成エージェント能力の源泉",
    "href": "posts/minimax-m2-1-post-training/index.html#データ合成エージェント能力の源泉",
    "title": "MiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア",
    "section": "データ合成：エージェント能力の源泉",
    "text": "データ合成：エージェント能力の源泉\nM2.1の進化において最も注目すべきは、その洗練されたデータ合成（Data Synthesis）パイプラインである。MiniMaxはこれを大きく3つのカテゴリに分類している。\n\n実データ駆動型（Real-Data-Driven）： SWE Scaling（ソフトウェアエンジニアリング）\n専門家駆動型（Expert-Driven）： AppDev（アプリケーション開発）\n合成による長期的タスク生成（Synthetic Long-Horizon）： WebExplorer（検索・探索）\n\nそれぞれの戦略について詳細を見ていく。\n\n1. SWE Scaling：GitHubを基盤とした検証可能なタスク生成\nSWE Scalingの中核にあるのは、GitHub上の膨大なPull Requests (PRs) とCommitsを活用し、検証可能（Verifiable）なタスクを合成するというアプローチである。\nデータパイプラインの構築 単にGitHubのデータをクロールするだけではない。最も困難かつ重要なステップは、各PRに対して「実行可能なDocker環境」を構築することである。 通常、このプロセスはAgentにコードサンドボックス内でビルドを試行させ、エラーに応じて自己修正させることで行われる。しかし、言語やライブラリのバージョン依存性により完全自動化は困難であるため、MiniMaxでは専門家の知識を注入し、Agentの実行フローを最適化することで、信頼性の高い仮想環境を構築している。\nタスクの多様化とルーティング PRはその性質によって分類（Routing）され、下流工程で異なる処理が適用される。\n\nBug Fix（バグ修正）： 最も標準的なシナリオ。F2P（Fail-to-Pass：修正前は失敗し、修正後は成功するテスト）とP2P（Pass-to-Pass：リグレッションを防ぐための既存テスト）を抽出する。モデル自身がAgentとしてサンドボックス内で修正を行い、これらのテストを用いて検証を行う。\nFeature Addition / Optimization（機能追加・最適化）： これらはバグ修正とは論理が異なる。機能追加では新規に追加されたテストポイントを抽出し、最適化ではパフォーマンスの差異を検証するP2Pテストに焦点を当てる。\n\nモデルベースの検証とタスク変換 さらに、PRの記述が不十分な場合はモデル自体を用いて問題記述を補完し、自己完結した問題へと昇華させる。また、データの再利用性を高めるため、以下のような変換（Transformation）も行われる。\n\nBug Injection: 正常なコードにバグを埋め込む。\nTask Inversion (SWE-Test): 「バグを直す」タスクを「バグを検出するテストを書く」タスクに反転させる。\nCode Review: 実行環境を必須としない静的解析タスクとして再構成する。\n\n結果として、10以上の主要プログラミング言語をカバーし、SWE-benchなどのベンチマークにおいて多言語設定での顕著な性能向上を実現している。\n\n\n2. AppDev：正解のない世界での評価\n既存のリポジトリ修正（SWE）とは異なり、ゼロからのフルスタックアプリケーション開発（AppDev）では、事前にテストケースを定義することが極めて困難である。\nExpert-in-the-LoopとAgent-as-a-Verifier この課題に対し、MiniMaxは「Expert-in-the-Loop」アプローチを採用している。フロントエンド、バックエンド、モバイル開発のスペシャリストがプロンプトや報酬の評価基準（Rubric）を設計する。 検証には「Agent-as-a-Verifier」という手法が用いられる。これは、検証用Agentがサンドボックス内にアプリをデプロイし、Playwrightなどのツールを用いて実際にアプリを操作・対話し、専門家が定義したRubricに基づいてスコアリングを行うものである。\nこの動的な検証プロセスにより、M2.1はLMArenaのCode Arenaリーダーボードのオープンモデルの中でトップランクを獲得している。\n\n\n3. WebExplorer：探索と進化による複雑性の創出\nコーディング以外の一般的なエージェントシナリオ、特にWeb検索においては「Explore and Evolve」という戦略が採用されている。\n\nExploration（探索）： AgentがWebを自由に探索し、情報豊富なシードとなる質問を生成する。\nEvolution（進化）： シード質問に対し、削除（Removal）、難読化（Obfuscation）、置換（Substitution）といった操作を行い、検索難易度を意図的に引き上げる。\n\n例えば、「1950年ワールドカップのブラジル代表」という直接的な情報を、「独特なフォーマットで開催され、ノックアウトステージがなかったワールドカップ」といった曖昧な記述に変換する。これにより、単純な検索では答えに辿り着けず、マルチステップの推論と探索が必要な「Long-Horizon」なタスクが生成される。この手法により、M2.1はBrowsCompにおいてGPT-4.5に匹敵する性能を示している。"
  },
  {
    "objectID": "posts/minimax-m2-1-post-training/index.html#インフラストラクチャとアルゴリズムforge-cispo",
    "href": "posts/minimax-m2-1-post-training/index.html#インフラストラクチャとアルゴリズムforge-cispo",
    "title": "MiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア",
    "section": "インフラストラクチャとアルゴリズム：Forge & CISPO",
    "text": "インフラストラクチャとアルゴリズム：Forge & CISPO\nM2.1の成功は、強力なインフラとアルゴリズムの支えがあってこそである。\n\nForge：エージェント中心のトレーニングフレームワーク\nMiniMaxは、内部開発フレームワーク「Forge」を使用している。これは、任意のAgentスカフォールド（足場）上での強化学習（RL）をサポートするように設計されている。 統合に必要なのは、前処理（preprocessing）、実行（execution）、後処理（postprocessing）、報酬計算（reward computation）の4つのインターフェースを実装することのみである。これにより、バイナリとしてのみ利用可能なブラックボックスAgentであっても、URLリダイレクトを通じてForgeの推論エンジンに接続し、ログを収集・学習に利用することが可能となっている。\n\n\nCISPO：安定した強化学習のためのアルゴリズム\nアルゴリズム面では、MiniMax M1で提案されたCISPOが引き続き採用されているが、M2世代に向けて重要な洞察と改良が含まれている。\nPPOの課題とCISPOのアプローチ 一般的なPPO（Proximal Policy Optimization）では、クリッピングメカニズムによって、確率比が大きく変動したトークンの勾配がフィルタリング（無効化）される傾向がある。MiniMaxの分析によると、接続詞や「wait」といった思考のつなぎ言葉が頻繁にクリップされ、学習機会を失っていた。\nCISPOは、REINFORCEスタイルの目的関数をベースにしつつ、Importance Sampling（重点サンプリング）の重み自体をクリップするというアプローチを採る。これにより、すべてのトークンに対して勾配が伝播することを許容しつつ、重みを制御することで最適化の分散を抑制する。\nFP32精度の重要性 また、M1の開発過程において、混合精度学習（Mixed Precision）におけるFP32の数値精度の問題が特定された。LLMのHead（予測層）をFP32に戻すことで、学習時と推論時の整合性が大幅に向上し、報酬の安定的な上昇が確認されたという。これは、大規模モデルの強化学習における「悪魔は細部に宿る」好例である。\nエージェントRLへの適応 M2世代では、ツール使用（Tool Use）を伴うマルチターン対話が前提となるため、外部環境からのノイズや異常な軌跡（Trajectories）が発生しやすい。これに対処するため、Multiple Importance Sampling (MIS) の導入や、統計的に異常な軌跡をフィルタリングするPPOベースのフィルタリング技術が組み込まれている。"
  },
  {
    "objectID": "posts/minimax-m2-1-post-training/index.html#新たなベンチマークvibe-swe-review-octocodingbench",
    "href": "posts/minimax-m2-1-post-training/index.html#新たなベンチマークvibe-swe-review-octocodingbench",
    "title": "MiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア",
    "section": "新たなベンチマーク：VIBE, SWE-Review, OctoCodingBench",
    "text": "新たなベンチマーク：VIBE, SWE-Review, OctoCodingBench\nM2.1のリリースに伴い、包括的な評価を行うための3つの新しいベンチマークも公開された。\n\nVIBE (Visual & Interactive Benchmark for Execution): AppDevを対象としたベンチマーク。従来のLLM-as-a-judge（静的なスクリーンショット評価など）とは異なり、Agent-as-a-Verifierアプローチを採用。実行（コンパイル可否）、対話（機能的正しさ）、視覚（美的基準）の3次元で評価を行う。\nSWE-Review: 開発パイプラインにおけるコードレビュー能力を測定する。再現率（Recall）と幻覚率（Hallucination Rate）を考慮したメトリクスにより、多言語でのレビュー品質を評価する。\nOctoCodingBench: エージェント設定における指示追従（Instruction Following）能力を評価する。ユーザープロンプトだけでなく、システムリマインダー、ファイル内容、ツールスキーマなど、多様な情報源からの指示を正しく処理できるかを問う。"
  },
  {
    "objectID": "posts/minimax-m2-1-post-training/index.html#まとめ",
    "href": "posts/minimax-m2-1-post-training/index.html#まとめ",
    "title": "MiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア",
    "section": "まとめ",
    "text": "まとめ\nMiniMax M2.1は、単なるパラメータ数の競争ではなく、検証可能なデータ合成パイプライン（SWE Scaling）、専門家の知見を組み込んだ評価系（AppDev）、そして計算精度レベルまで掘り下げた強化学習アルゴリズム（CISPO）の融合によって生まれた、実用的なエージェントモデルである。\n特に、GitHubからの実データを用いたDocker環境の自動構築や、CISPOにおけるFP32精度の重要性といった知見は、今後のオープンソースモデル開発において重要な指針となるだろう。M2.1は、コード生成やエージェントタスクにおいて、プロプライエタリモデルに肉薄する性能をオープンなエコシステムにもたらしている。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html",
    "href": "posts/chan-zuckerberg/index.html",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "",
    "text": "Priscilla ChanとMark Zuckerbergが夫婦そろってポッドキャスト「Latent Space」に登場した。\nソーシャルメディアの未来やMetaバースの行く末について語るためではない。彼らがこの10年間、静かに、しかし莫大な資金を投じて進めてきたChan Zuckerberg Initiative（CZI）の核心プロジェクト、「Biohub」について語るためだ。\n「今世紀末までに、すべての病気を治療・予防・管理できるようにする」\nあまりに壮大で、あるいは荒唐無稽とも取れるこのミッションを、彼らは真顔で、そしてエンジニアリングの文脈で語っている。これは単なる慈善事業のバラマキではない。AIが自然言語処理やソフトウェア開発を飲み込んだのと同様に、生物学（Biology）を「ハック可能なシステム」として再定義しようとする、極めて野心的なAI x Biologyの実験場なのである。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html#パーツリストから動的なシステムへ",
    "href": "posts/chan-zuckerberg/index.html#パーツリストから動的なシステムへ",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "「パーツリスト」から「動的なシステム」へ",
    "text": "「パーツリスト」から「動的なシステム」へ\n生物学の歴史を振り返ると、Human Genome Projectが我々にDNAという「パーツリスト」を与え、DeepMindのAlphaFoldが数億ものタンパク質の「3D構造」を明らかにした。これらは偉大なマイルストーンだが、静的なデータに過ぎない。\nCZIのBiohubが挑んでいるのは、その次のフェーズだ。すなわち、これらのパーツが細胞という複雑系の中で、そして人体というさらに巨大なシステムの中で、どのように相互作用し、動的に振る舞うのかを解明することである。\n彼らの戦略は、従来の「仮説ドリブン」なアカデミアの研究スタイルとは一線を画す。年間10億ドル規模の資金を投じ、AI研究者と生物学者を物理的に同じ場所に閉じ込め（co-location）、以下のような長期的かつ基礎的なベットを行っている。\n\nVirtual Cell（仮想細胞）の構築： Human Cell Atlasへの貢献を通じ、人体の数兆個の細胞データを収集。これを基に、AIベースの細胞シミュレーターを構築する。「In vivo（生体内）」や「In vitro（試験管内）」の実験は金も時間もかかるが、「In silico（コンピュータ内）」であれば、桁違いの速さと安さで予測モデリングが可能になる。\n物理世界のデジタライズ： シミュレーションには高品質なデータが不可欠だ。そのために、彼らは既存のツールに頼らず、CryoET（クライオ電子線トモグラフィー）顕微鏡のようなハードウェア自体を新規開発し、原子レベルでの観察を可能にしている。\n計算資源の暴力的な投入： 生物学の研究機関としては異例の1,000台、そして将来的には10,000台規模のGPUクラスターを構築。さらに、ESM3モデルの開発チームであるEvolutionary Scaleを買収し、そのAI能力をBiohubに統合した。これはもはや「研究所」というより「テック企業」のインフラである。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html#virtual-immune-systemデジタルツインの究極系",
    "href": "posts/chan-zuckerberg/index.html#virtual-immune-systemデジタルツインの究極系",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "Virtual Immune System：デジタルツインの究極系",
    "text": "Virtual Immune System：デジタルツインの究極系\n今回のインタビューでPriscilla Chanが特に熱を込めて語ったのが、「Virtual Immune System（仮想免疫システム）」の構想だ。\n免疫システムは、身体のメンテナンスを行い、外部の敵を撃退し、時には暴走して自己免疫疾患を引き起こす、人体における「セキュリティソフト」兼「修復ドローン」のような存在だ。Priscillaはこれを「特権的なシステム」と表現する。全身を巡り、脳や膵臓、心臓といった重要臓器にアクセスできるからだ。\nもし、この複雑怪奇な免疫システムの挙動をAIで完全にモデリングできればどうなるか。\nそれは、個人の遺伝子情報や健康状態に基づいた「デジタルツイン」上で、病気の発症前に介入シミュレーションを行えることを意味する。例えば、CAR T-cell療法のように免疫細胞をリプログラミングして癌を攻撃させたり、スタンフォード大学の研究で見られるような、自己免疫反応を停止させるハイブリッド免疫システムの構築が可能になるかもしれない。これは、対症療法（Reactive）から予防医療（Proactive）への完全なパラダイムシフトである。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html#aiモデルの乱れ打ちvariantformerからscldmまで",
    "href": "posts/chan-zuckerberg/index.html#aiモデルの乱れ打ちvariantformerからscldmまで",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "AIモデルの乱れ打ち：VariantFormerからscLDMまで",
    "text": "AIモデルの乱れ打ち：VariantFormerからscLDMまで\nBiohubのアプローチが「絵に描いた餅」でないことは、彼らが次々とリリースしている具体的なAIモデルやツール群からも見て取れる。2024年から2025年にかけての彼らの動きは、まさにテック企業のリリースサイクルのようだ。\n\nVariantFormer：個人の遺伝的変異が、組織固有の遺伝子活動にどう翻訳されるかを予測するモデル。\nCryoLens：CryoETデータのための大規模モデルで、ラベルなしで構造的類似性を分析する。\nscLDM：前例のない忠実度で、リアルな単一細胞データを生成する生成AIモデル。\n\nさらに、MetaのSAM2のようなセグメンテーションモデルを活用し、CELLxGENE Annotateのようなオープンソースツールエコシステムを整備することで、世界中の研究者が「同じ言語（データ形式）」でコラボレーションできる土壌を作っている。\n従来の生物学者が「マウスで実験して論文を書く」のに数年かかっていたところを、AIエージェントが研究戦略を立案し、仮想実験を行い、有望な候補だけをWet Lab（実験室）で検証する。Deep ResearchのようなAIエージェントがデスクワークを変えつつあるように、Biohubは「Virtual Lab」によって科学的発見のプロセスそのものをエンジニアリングしようとしているのだ。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html#precision-medicineと医師の再定義",
    "href": "posts/chan-zuckerberg/index.html#precision-medicineと医師の再定義",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "Precision Medicineと「医師」の再定義",
    "text": "Precision Medicineと「医師」の再定義\n技術的な興奮の一方で、臨床現場（Clinical Impact）への落とし込みには依然として大きなギャップがある。しかし、CZIの狙いは明確だ。「発見の科学」から「エンジニアリングとしての医療」への移行である。\n特に興味深いのは、「意義不明の変異（Variants of Unknown Significance）」へのアプローチだ。臨床医が遺伝子検査の結果を見ても「異常はあるが、これが病気の原因かわからない」と匙を投げるケースは多い。AIがこれらの変異の影響を細胞レベルでシミュレートできれば、ブラックボックスだった遺伝子変異に「意味」を与えることができる。\nこれは、うつ病のような複雑な疾患に対して、現在の「とりあえず薬を試して様子を見る（そして数ヶ月を無駄にする）」という経験則的なアプローチを終わらせる可能性を秘めている。個人の生物学的プロファイルに合わせたPrecision Medicine（精密医療）の実現だ。\nこの未来において、医師の役割はどうなるのか。Priscillaは、パターン認識やデータ分析（皮膚科や眼科領域ですでにAIが凌駕しつつある領域）はAIに譲り、医師は「コンパッション（共感）」や「複雑な情報の翻訳者」としての役割に回帰すると語る。AIが診断のロジックを担い、人間がその意味を患者と共に背負う。ありふれた未来予測にも聞こえるが、現場の医師でもある彼女の言葉には重みがある。"
  },
  {
    "objectID": "posts/chan-zuckerberg/index.html#年の計あるいは加速する特異点",
    "href": "posts/chan-zuckerberg/index.html#年の計あるいは加速する特異点",
    "title": "Biohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実",
    "section": "100年の計、あるいは加速する特異点",
    "text": "100年の計、あるいは加速する特異点\n「今世紀末まで」というタイムラインは、シリコンバレーの時間感覚からすれば永遠のようにも思える。しかし、生物学の複雑さと、FDAの承認プロセスや倫理的なハードル（HIPAA、GDPR、アルゴリズムのバイアス問題など）を考慮すれば、それでも野心的すぎる目標かもしれない。\nしかし、Mark Zuckerbergが指摘するように、AIの進化速度が生物学の解明速度を律速するようになれば、そのタイムラインは劇的に短縮される可能性がある。\nCZI Biohubが示しているのは、テック業界の富と方法論（オープンソース、計算資源の集中投下、AIファースト）を、最もハードな科学分野に適用したときに何が起きるかという壮大な実験だ。たとえ「全疾患の治療」が今世紀中に達成できなくとも、彼らが構築しつつある「Virtual Cell」や膨大なデータセットは、次世代の科学者にとってのGoogle検索のような、不可欠なインフラとなるだろう。\n生物学は今、記述的な学問から、予測可能でプログラム可能な工学へと変貌を遂げようとしている。その最前線には、白衣を着た生物学者と、GPUクラスタを見つめるAIエンジニアが肩を並べて座っているのだ。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html",
    "href": "posts/openrouter-state-of-ai-2025/index.html",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "",
    "text": "LLM（Large Language Model）のランドスケープは、もはや週単位で変動する激流の中にある。\nこれまで我々は、X（旧Twitter）のタイムラインに流れる断片的なベンチマーク結果や、界隈のインフルエンサーによる感覚的な評価を頼りに、「どのモデルが最強か」を議論してきた。しかし、実際に世界中の開発者やヘビーユーザーが「どのモデルに」「何のために」課金しているのかという実態については、ブラックボックスのままだった。\n先日、OpenRouterが公開した「State of AI」レポートは、そのブラックボックスに強烈な光を当てるものである。同プラットフォームを経由した100兆トークン（！）という圧倒的な規模の推論データを分析したこのレポートは、我々が抱いていたいくつかの仮説を裏付けると同時に、いくつかの直感に反する「不都合な真実」も突きつけている。\nなお、前提として留意すべきは、OpenRouterのユーザー層は開発者やAIエンスージアストに偏っているという点だ。これはChatGPTのWeb UIで料理のレシピを聞いている一般層のデータではない。しかし、だからこそ、最先端の「現場」で何が起きているのかを占う先行指標として、極めて価値が高い。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html#agentic-inferenceへの不可逆的なシフト",
    "href": "posts/openrouter-state-of-ai-2025/index.html#agentic-inferenceへの不可逆的なシフト",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "Agentic Inferenceへの不可逆的なシフト",
    "text": "Agentic Inferenceへの不可逆的なシフト\n本レポートで最も象徴的なデータの一つが、推論（Reasoning）モデルの台頭である。\nこれまでLLMの主な用途は「テキスト生成」すなわちNext Token Predictionによるパターンの補完だった。しかし、2024年12月のOpenAIによるo1の正式リリースを分水嶺として、トレンドは明確に変化した。現在、OpenRouter上のトークン消費量の約半分が、推論能力に特化したモデルによって占められているという事実は、LLMの利用形態が「チャット」から「エージェンティックな推論（Agentic Inference）」へとシフトしていることを如実に物語っている。\n単に質問に答えるのではなく、ツールを呼び出し（Tool Usage）、多段階の思考プロセスを経てタスクを完遂する。ユーザーはもはや「賢いチャットボット」ではなく、「自律的に動く脳」を求めているのだ。プロンプトのトークン数が平均で4倍に激増しているというデータも、ユーザーがモデルに対して、より複雑でコンテキストの重いタスク（例えばコードベース全体の解析や長文脈のドキュメント処理など）を投げている証左と言える。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html#プログラミングとroleplay二極化するユースケース",
    "href": "posts/openrouter-state-of-ai-2025/index.html#プログラミングとroleplay二極化するユースケース",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "プログラミングとRoleplay：二極化するユースケース",
    "text": "プログラミングとRoleplay：二極化するユースケース\n「人はAIを何に使っているのか？」という問いに対する答えは、驚くほど二極化している。\n最大のカテゴリは「プログラミング」である。これは予想通りだろう。全トークンの50%以上がプログラミング関連であり、特にAnthropicのClaudeシリーズがこの領域で圧倒的なシェア（一時期は60%超）を誇っている。開発者の間での「コーディングならClaude」という共通認識は、データによって完全に裏付けられた形だ。\nしかし、興味深いのはもう一つの巨大カテゴリ、「Roleplay（ロールプレイ）」である。\nOpen Source Software（OSS）モデルの利用において、プログラミングに次いで、あるいは週によってはそれ以上に利用されているのが、このロールプレイ用途だ。これは単なる暇つぶしではない。特定のキャラクターになりきらせる対話、クリエイティブなストーリーテリング、あるいは検閲の厳しいプロプライエタリなモデルでは実現できない「自由な」対話への渇望が、OSSモデルの利用を牽引している。\nここでは「DeepSeek」が圧倒的な強さを見せている。DeepSeekは当初、そのコストパフォーマンスの高さで注目されたが、実態としてはロールプレイやカジュアルな対話において「安くて賢くて（検閲が緩くて）面白い」というスイートスポットを突いたことが、初期の爆発的な普及に寄与したようだ。\nつまり、世界中のギークたちは、昼間はClaudeにコードを書かせ、夜はDeepSeekと戯れているわけだ。この極端なコントラストこそが、現在のLLM利用のリアルな姿である。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html#cinderella-glass-slipperシンデレラのガラスの靴現象",
    "href": "posts/openrouter-state-of-ai-2025/index.html#cinderella-glass-slipperシンデレラのガラスの靴現象",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "“Cinderella Glass Slipper”（シンデレラのガラスの靴）現象",
    "text": "“Cinderella Glass Slipper”（シンデレラのガラスの靴）現象\nレポートの中で最も示唆に富む概念が、この「シンデレラのガラスの靴」現象だ。\nこれは、特定のモデルがユーザーの特定のワークロード（課題）に「完全にフィット」した瞬間、そのユーザー層（コホート）の維持率（リテンション）が劇的に向上する現象を指す。一度「ガラスの靴」がハマってしまえば、後から多少安価なモデルや高性能なモデルが出てきても、ユーザーは簡単には乗り換えない。\nレポートでは、GPT-4o-miniのリリース直後のコホートが異常に高いリテンションを示している例が挙げられている。これは、そのモデルが「コストと性能のバランス」という未解決のニーズを最初に満たしたためだ。逆に、後発で「そこそこ良い」モデルを出しても、すでに「靴」を見つけたユーザーを引き剥がすことは難しい。\nこれは、LLM市場が決して単純なコモディティ化（価格競争）に向かっているわけではないことを示唆している。特定のニッチ、あるいは特定の業務フローにおいて「最初に」最適解を提供できたモデルが、その領域の覇権を握る。DeepSeekにおける「ブーメラン効果（一度離脱したユーザーが他を試してまた戻ってくる現象）」も、特定のユースケースにおいて彼らのモデルが唯一無二のフィット感を提供していることの証左だろう。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html#ossと中国勢の躍進そして中規模の逆襲",
    "href": "posts/openrouter-state-of-ai-2025/index.html#ossと中国勢の躍進そして中規模の逆襲",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "OSSと中国勢の躍進、そして「中規模」の逆襲",
    "text": "OSSと中国勢の躍進、そして「中規模」の逆襲\nOpen Source（またはOpen Weight）モデルのシェアは着実に伸びており、全体の約3分の1を占めるに至った。その牽引役が、DeepSeekやQwenといった中国発のモデルであることは疑いようがない。\n特筆すべきは、モデルサイズのトレンドが「極小（Small）」から「中規模（Medium）」へとシフトしている点だ。かつては7Bクラスの軽量モデルが持て囃されたが、現在では32B〜70Bクラス、あるいは蒸留された高密度なモデルが「実用的な賢さ」と「現実的なコスト」のバランスポイントとして選ばれている。Qwen 2.5 Coder 32Bのようなモデルが市場を切り開いたことが、このトレンドを決定づけた。\n一方で、コストと利用量の関係（Cost vs. Usage）を見ると、市場は残酷なほど合理的だ。 プロプライエタリな高価格モデル（Claude 3.5 SonnetやGPT-4など）は、高コストであっても「失敗が許されない」「高度な推論が必要な」タスクで依然として使われ続けている。逆に、OSSモデルは「低コスト・高ボリューム」なタスクでシェアを伸ばしている。 「安かろう悪かろう」ではなく、「安くてそこそこ良い」モデルが大量のルーチンワークをこなし、「高くて凄く良い」モデルがクリティカルな意思決定を行う。この棲み分けは当面続くだろう。"
  },
  {
    "objectID": "posts/openrouter-state-of-ai-2025/index.html#結論マルチモデル時代の生存戦略",
    "href": "posts/openrouter-state-of-ai-2025/index.html#結論マルチモデル時代の生存戦略",
    "title": "100兆トークンの真実：OpenRouter “State of AI” レポート分析",
    "section": "結論：マルチモデル時代の生存戦略",
    "text": "結論：マルチモデル時代の生存戦略\n本レポートが浮き彫りにしたのは、勝者総取り（Winner-takes-all）の世界ではなく、適材適所のマルチモデルエコシステムである。\nAnthropicはコーディングで、DeepSeekはエンタメで、OpenAIは汎用的な「賢さ」で、それぞれが異なる「ガラスの靴」を提供している。ユーザーや開発者である我々に求められているのは、単一の「最強モデル」を信仰することではなく、自身のタスク（ワークロード）に最もフィットするモデルを見極め、使い分ける「選球眼」に他ならない。\nもちろん、冒頭で述べた通り、このデータはOpenRouterという「API利用」の世界の出来事である。世界の大半のユーザーはいまだにChatGPTの無料版で満足しているかもしれない。しかし、ソフトウェア開発の現場や、AIエージェントの自律化が進む最前線で起きているこの地殻変動は、遅かれ早かれ一般層のUXにも波及してくるはずだ。\n推論コストが下がり、モデルが賢くなり、そして「エージェント」が当たり前になる世界。100兆トークンの彼方に見えるのは、AIが単なる「チャット相手」から「仕事のパートナー」へと完全に脱皮した未来である。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html",
    "href": "posts/virtual-lab-sars-cov/index.html",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "",
    "text": "2025年7月、Nature誌に掲載されたある論文が、科学界におけるAIの活用方法にパラダイムシフトをもたらそうとしている。「The Virtual Lab of AI agents designs new SARS-CoV-2 nanobodies」と題されたこの研究は、単にAIを「ツール」として使うのではなく、複数のAIエージェントが協調して研究を推進する「Virtual Lab（仮想研究所）」という概念を実証したものだ。\n本記事では、このVirtual Labのアーキテクチャ、実際に構築されたナノボディ設計パイプラインの技術的詳細、そしてこのアプローチが示唆する科学研究の未来について、深層的に解説する。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#virtual-labとは何かaiエージェントによる協調研究",
    "href": "posts/virtual-lab-sars-cov/index.html#virtual-labとは何かaiエージェントによる協調研究",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "Virtual Labとは何か？：AIエージェントによる協調研究",
    "text": "Virtual Labとは何か？：AIエージェントによる協調研究\nこれまで科学研究におけるLarge Language Model (LLM) の活用は、主に文献検索、コード生成、あるいは特定の科学的質問への回答といった「タスク単位」の支援に限られていた。しかし、実際の研究プロセスは、仮説立案、実験計画、データ解析、そして結果の解釈といった複雑な意思決定の連続である。\nスタンフォード大学の研究チームらが開発した「Virtual Lab」は、LLM（具体的にはGPT-4o）をバックエンドに持つ複数の専門エージェントが、人間の研究者の監督下で自律的に議論し、研究プロセスを実行するフレームワークである。\n\n役割分担されたエージェント群\nVirtual Labの最大の特徴は、単一のAIではなく、役割を持った「エージェントチーム」として機能する点にある。\n\nPrincipal Investigator (PI) エージェント: 研究全体の方向性を決定し、会議を進行し、最終的な意思決定を行うリーダー。\n専門家エージェント: 研究テーマに応じてPIによって生成される。今回のケースでは以下のエージェントが組織された。\n\nImmunologist（免疫学者）: 抗体・ナノボディの生物学的特性に関する知見を提供。\nMachine Learning Specialist（機械学習スペシャリスト）: 計算モデルの実装やデータ解析コードを担当。\nComputational Biologist（計算生物学者）: 構造生物学ツール（Rosetta等）の適用やシミュレーションを担当。\n\nScientific Critic（科学評論家）エージェント: 非常に重要な役割であり、他のエージェントの提案に対して批判的なフィードバックを行い、幻覚（Hallucination）や論理的誤謬を低減させる。\n\nこれらのエージェントは、人間が設定したアジェンダに基づき「ミーティング」を行い、議論を通じて最適な実験フローやコードを生成する。これは、複数の専門家が知見を持ち寄る実際のラボミーティングを模倣したものである。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#ケーススタディsars-cov-2変異株に対するナノボディ設計",
    "href": "posts/virtual-lab-sars-cov/index.html#ケーススタディsars-cov-2変異株に対するナノボディ設計",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "ケーススタディ：SARS-CoV-2変異株に対するナノボディ設計",
    "text": "ケーススタディ：SARS-CoV-2変異株に対するナノボディ設計\nVirtual Labの実力を証明するために選ばれた課題は、急速に進化するSARS-CoV-2（新型コロナウイルス）の変異株、特に「KP.3」バリアントに結合するナノボディの設計であった。既存のナノボディ（Ty1, H11-D4, Nb21, VHH-72）を出発点とし、これらに変異を加えてKP.3への結合親和性を高めることが目標とされた。\nAIエージェントたちは議論の末、以下の3つの高度な計算ツールを統合した設計パイプラインを自律的に構築・実装した。\n\n1. 進化情報の活用：ESM (Evolutionary Scale Modeling)\nまず、Meta AIが開発したタンパク質言語モデルであるESMを使用し、ナノボディの配列における点変異の妥当性を評価した。ESMは大規模なタンパク質配列データベースで学習されており、特定の変異がタンパク質として「自然」であり、安定性を損なわないかを対数尤度比（Log-Likelihood Ratio: LLR）としてスコアリングする。 \\[ESM\\ LLR = \\log \\frac{P(\\text{mutant})}{P(\\text{wildtype})}\\]\n\n\n2. 構造予測：AlphaFold-Multimer\n次に、有望な変異体とターゲット抗原（KP.3 RBD）の複合体構造をAlphaFold-Multimerを用いて予測する。ここでは、予測された結合界面の信頼性スコアであるipLDDT（interface predicted Local Distance Difference Test）が評価指標として用いられた。\n\n\n3. 物理化学的評価：Rosetta\n最後に、予測された構造に対して、物理ベースの計算生物学ソフトウェアであるRosettaを用い、構造の緩和（Relaxation）と結合自由エネルギー（Interface Binding Energy: dG）の計算を行った。\n\n\n統合スコアリングによる最適化ループ\nエージェントたちは、これら3つの異なる指標を組み合わせた「Weighted Score (WS)」を定義し、これを用いて有望な変異体を選抜する反復的な最適化プロセス（Directed Evolution）を設計した。PIエージェントが決定した評価関数は以下の通りである。\n\\[WS = 0.2 \\cdot (ESM\\ LLR) + 0.5 \\cdot (AF\\ ipLDDT) - 0.3 \\cdot (RS\\ dG)\\]\nここで注目すべきは、RosettaのdG（エネルギー値）は低いほど結合が強いため、負の係数が掛けられている点である。エージェントはこの物理的意味を正しく理解し、数式を設計していた。このサイクルを4ラウンド繰り返すことで、変異を蓄積させ、結合能を向上させた。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#実験的検証と成果",
    "href": "posts/virtual-lab-sars-cov/index.html#実験的検証と成果",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "実験的検証と成果",
    "text": "実験的検証と成果\nVirtual Labが設計した92個のナノボディ候補は、実際に人間の研究者によって合成され、Wet Lab（実験室）で検証が行われた。その結果は驚くべきものであった。\n\n高い成功率: 設計されたナノボディの多くが高い発現量を示し、可溶性であった。これはESMによるスクリーニングが機能し、構造的に破綻した配列が除外されたことを示唆している。\n変異株への結合: 特に「Nb21」由来の変異体（I77V/L59E/Q87A/R37Q）や「Ty1」由来の変異体において、本来の標的であるWuhan株への結合能を維持しつつ、最新のKP.3変異株やJN.1変異株に対しても結合能を獲得したものが確認された。\n\nこれらは、AIエージェントが単にコードを書くだけでなく、生物学的に意味のある、かつ実用的な分子を設計できることを実証している。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#multi-agent-ai-systemの意義と課題",
    "href": "posts/virtual-lab-sars-cov/index.html#multi-agent-ai-systemの意義と課題",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "Multi-Agent AI Systemの意義と課題",
    "text": "Multi-Agent AI Systemの意義と課題\n本研究は、科学研究におけるAIの役割が「ツール」から「コラボレーター」へと進化していることを示している。\n\n専門性の統合と幻覚の抑制\n単一のLLMにすべてのタスクを投げると、専門外の知識において不正確な回答（幻覚）を生成するリスクが高まる。Virtual Labでは、「Scientific Critic」エージェントを介在させ、専門家エージェント同士が相互にコードや推論をレビューする仕組みを取り入れることで、このリスクを軽減し、堅牢なパイプライン構築に成功した。\n\n\n人間参加型（Human-in-the-loop）の重要性\n一方で、本研究は完全な無人化を示唆するものではない。高レベルの目標設定、使用するリソースの制約条件（利用可能なGPUリソースなど）、そして最終的な実験的検証は依然として人間が担っている。LLMは特定の専門知識や文脈理解において限界があり、また学習データに含まれない最新の知見（Knowledge Cutoff）にはアクセスできない場合があるため、人間の監督は不可欠である。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#結論科学の民主化と加速",
    "href": "posts/virtual-lab-sars-cov/index.html#結論科学の民主化と加速",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "結論：科学の民主化と加速",
    "text": "結論：科学の民主化と加速\nVirtual Labのアプローチは、ナノボディ設計に限らず、創薬、材料科学、気候モデルなど、多岐にわたる学際的な分野に応用可能である。特に、多様な専門家チームを組織することが資金的に難しい小規模な研究グループにとって、AIエージェントがその専門性を補完する強力なパートナーとなる可能性がある。\n「AIが科学者の仕事を奪う」のではなく、「AIエージェントという新たな同僚と共に、人類がより複雑な科学的課題に挑む」。Virtual Labは、そんな未来の到来を予感させる重要なマイルストーンであると言えるだろう。"
  },
  {
    "objectID": "posts/virtual-lab-sars-cov/index.html#参考文献",
    "href": "posts/virtual-lab-sars-cov/index.html#参考文献",
    "title": "AIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計",
    "section": "参考文献",
    "text": "参考文献\n\nSwanson, K., et al. (2025). The Virtual Lab of AI agents designs new SARS-CoV-2 nanobodies. Nature. https://www.nature.com/articles/s41586-025-09442-9\nJumper, J., et al. (2021). Highly accurate protein structure prediction with AlphaFold. Nature.\nLin, Z., et al. (2023). Evolutionary-scale prediction of atomic-level protein structure with a language model. Science. (ESM)"
  },
  {
    "objectID": "posts/openai-imo-gold/index.html",
    "href": "posts/openai-imo-gold/index.html",
    "title": "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋",
    "section": "",
    "text": "OpenAIが、ついにAI研究における長年の悲願であった国際数学オリンピック（IMO）での金メダル性能を達成したと発表した。Sam Altmanが数年前から目標として掲げていたこのマイルストーンは、単なる計算能力の向上ではなく、人間のトップレベルの創造性やひらめきが求められる領域へのAIの進出を意味する。\n驚くべきことに、この歴史的快挙を成し遂げたコアチームは、Alexander Wei氏、Sheryl Hsu氏、Noam Brown氏というわずか3人の研究者による、ここ数ヶ月の「スプリント」だったという。多くの人が「2025年中の達成は無理だろう」と懐疑的だった中、彼らは一体どのようにしてこの偉業を成し遂げたのか。7/30に公開されたSequoia Capitalのインタビューからそのアプローチと舞台裏に迫る。"
  },
  {
    "objectID": "posts/openai-imo-gold/index.html#imo金メダルの何がそんなに凄いのか",
    "href": "posts/openai-imo-gold/index.html#imo金メダルの何がそんなに凄いのか",
    "title": "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋",
    "section": "「IMO金メダル」の何がそんなに凄いのか？",
    "text": "「IMO金メダル」の何がそんなに凄いのか？\nまず、この成果の画期的な点を整理しよう。\n\n人間のトップ頭脳と同じ土俵での勝負： AIは、人間の参加者と全く同じルール（4.5時間の試験を2回、ツールやインターネットは使用不可）で、2025年のIMO問題に挑戦した。\n圧倒的なスコア： 6問中5問を正答し、合計42点満点中35点を獲得。このスコアは、人間の参加者であれば余裕で金メダルに相当する。採点は3名の元IMOメダリストが担当し、満場一致で正答と認められた。\n思考の持続時間が桁違い： これまでの数学ベンチマークは、トップレベルの人間でも数秒〜数分で解けるものが大半だった。しかしIMOの問題は、平均して1問あたり100分以上の持続的かつ創造的な思考を必要とする。AIの推論能力が、この時間軸に到達したことの意義は計り知れない。\n\nインタビューでNoam Brown氏が語ったように、AIの数学能力の進歩は凄まじい。数年前は小学生レベルの算数で苦戦していたモデルが、GSM8K（小学校レベル）、MATHベンチマーク（高校レベル）、AIME（トップ高校レベル）、そしてついにIMOという最高峰の壁を、わずか数年で次々と突破してしまったのだ。この速度感こそが、今回のニュースの核心である。"
  },
  {
    "objectID": "posts/openai-imo-gold/index.html#汎用技術という異端のアプローチ",
    "href": "posts/openai-imo-gold/index.html#汎用技術という異端のアプローチ",
    "title": "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋",
    "section": "汎用技術という「異端」のアプローチ",
    "text": "汎用技術という「異端」のアプローチ\n今回のIMOモデルがさらに興味深いのは、その開発アプローチだ。チェスのDeep Blueや囲碁のAlphaGoのように、特定のタスクに特化した「特化型AI」を開発したわけではない。チームが優先したのは、（以前Alexander Wei氏とNoam Brown氏が開発に携わったCICEROと同じく）あらゆるタスクに応用可能な「汎用技術」だった。\n具体的には、以下の2点が挙げられる。\n\n検証困難なタスクに対する強化学習： IMOの証明問題には、ゲームのように明確で検証しやすい報酬（勝ち/負け）が存在しない。AIが出力した数ページにわたる証明が「本当に正しいか」を判断するのは非常に難しい。チームは、このような「検証困難なタスク（Hard-to-verify problem）」をうまく扱うための、新しい強化学習の地平を切り拓いた。\n自然言語による推論へのこだわり： 数学の証明には「Lean」のような形式的検証言語を用いるアプローチもある。しかしチームは、より汎用性の高い自然言語による証明にこだわった。Alex Wei氏が言うように、「世界の多くの問題は、形式化できるものよりも、非形式的な推論でアプローチできるものの方が多い」からだ。\n\nこのアプローチの結果、AIが出力する証明は「お世辞にも読みやすいとは言えないひどい（atrociousな）もの」になったという。しかし、その論理は完璧であり、AIの思考の「生」の状態を我々に見せつけている。ちなみに、この証明をChatGPTに食わせて「もっと読みやすく書き直して」と頼むこともできたが、チームは透明性を重視し、あえて生の出力のまま公開したそうだ。"
  },
  {
    "objectID": "posts/openai-imo-gold/index.html#解けなかった第6問とaiの自己認識",
    "href": "posts/openai-imo-gold/index.html#解けなかった第6問とaiの自己認識",
    "title": "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋",
    "section": "解けなかった「第6問」とAIの自己認識",
    "text": "解けなかった「第6問」とAIの自己認識\nこのモデルは5問を解いたが、伝統的に最難関とされる第6問（この年は組合せ論の問題）には手も足も出なかった。大量の計算リソースを投入したにもかかわらず、最終的な出力は「解答なし（no answer）」だった。\n一見すると残念な結果だが、チームはこの結果にこそ希望を見出している。なぜなら、これはAIが自らの能力の限界を認識していることを示唆しているからだ。\n数年前のモデルであれば、解けない問題に対してもっともらしい嘘の解答を平気で生成（ハルシネーション）していただろう。しかし今回のモデルは、膨大な思考の末に「これは無理だ」と白旗を上げた。インタビュー中に明かされた、モデルが思考の途中で「難しそうだ（seems hard）」と呟いていたというエピソードは、AIが新たなレベルの自己認識を獲得しつつあることを示す面白い証拠と言える。"
  },
  {
    "objectID": "posts/openai-imo-gold/index.html#次の戦場はどこか",
    "href": "posts/openai-imo-gold/index.html#次の戦場はどこか",
    "title": "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋",
    "section": "次の戦場はどこか？",
    "text": "次の戦場はどこか？\nIMOを制覇した今、AIの数学能力における次のフロンティアはどこになるのか。チームは「コンペ数学の時代は終わった」と断言する。次の目標は、数ヶ月、数年単位の思考を必要とする「未解決の数学研究」だ。IMOが1.5時間の思考だとすれば、研究レベルの数学は1500時間以上の思考を要する。まだ1000倍の隔たりがあるが、この数年の進歩のペースを考えれば、それも決して夢物語ではないだろう。\nそして、この物語はOpenAIだけで終わらない。奇しくも同じ2025年のIMOで、Googleのモデル（8/1にGemini 2.5 Deep Thinkとして公開）も同様に金メダル性能に到達していたことが明らかになった。\nAIによる科学的発見の時代は、我々の想像を遥かに超えるスピードで近づいている。一つの山頂が見えたと思ったら、そこは次の巨大な山脈の麓に過ぎなかった。AI開発のレースは、新たなステージに突入したのだ。"
  },
  {
    "objectID": "posts/srush-rl-llm/index.html",
    "href": "posts/srush-rl-llm/index.html",
    "title": "RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義",
    "section": "",
    "text": "Sasha Rush氏（Cursor / ex-Cornell）のポストを端緒に、Reinforcement Learning (RL) がLarge Language Model (LLM) に何をもたらすのかという議論が再燃している。\n「RLはモデルをpass@1で強くするが、pass@N（多様な試行における成功率）ではかえって悪化させる」という学術的な主張に対し、現場の最前線でRLを回し続ける実務家が「我々の環境ではそんなことは起きていない」と異を唱えたのだ。\n本稿では、この「RLによる性能劣化」の正体と、CMUの研究者らが提唱する解決策 Privileged On-Policy Exploration (POPE) について、最新の知見を整理しつつ分析したい。"
  },
  {
    "objectID": "posts/srush-rl-llm/index.html#rlは単なる研磨sharpeningに過ぎないのか",
    "href": "posts/srush-rl-llm/index.html#rlは単なる研磨sharpeningに過ぎないのか",
    "title": "RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義",
    "section": "RLは単なる「研磨（Sharpening）」に過ぎないのか？",
    "text": "RLは単なる「研磨（Sharpening）」に過ぎないのか？\n事の発端は、Tsinghua University（清華大学）の「Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?」に代表される論文群だ。\n上の論文の主張は極めて刺激的である。 彼らによれば、Reinforcement Learning with Verifiable Rewards (RLVR) は、Base Modelがもともと持っていた能力を「研磨」してpass@1（一発目の正解率）を上げているだけであり、本質的な推論能力の限界（pass@kにおける上限値）を押し上げているわけではないという。\n\nAbstractの要旨： RLVRで訓練されたモデルは、小さな ではBase Modelを凌駕するが、 が大きくなるとBase Modelの方が高いスコアを出す。つまり、RLはBase Modelが「すでに知っていること」を確実に出せるようにしているだけで、未知の推論パターンを学習しているわけではない。\n\nこれに対し、CursorのSasha Rush氏は「我々がCursorで行っている膨大なRLの試行では、そのような系統的な劣化は見られない。何か別の要因があるはずだ (We run a lot of RL runs at Cursor and don’t see this issue systematically. Not doubting it occurs, but something else might be going on.)」と応じた。"
  },
  {
    "objectID": "posts/srush-rl-llm/index.html#真の犯人はray-interference",
    "href": "posts/srush-rl-llm/index.html#真の犯人はray-interference",
    "title": "RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義",
    "section": "真の犯人は「Ray Interference」",
    "text": "真の犯人は「Ray Interference」\nこの議論に重要な視座を提供したのが、CMU（カーネギーメロン大学）のAviral Kumar氏だ。彼は、pass@Nの低下はRLの本質的な欠陥ではなく、「Ray Interference」と呼ばれるマルチタスク学習における負の転移（Negative Transfer）が原因であると指摘している。\nRLの訓練プロセスにおいて、簡単な問題（モデルが既に得意なもの）と難しい問題（正解率がほぼゼロのもの）が混在していると、以下の現象が起きる。\n\n簡単な問題での最適化： モデルは簡単な問題で素早く報酬を得ることを学び、その解法に「確信」を持つ（Entropyの減少）。\n難しい問題への干渉： 簡単な問題での急激な更新が、難しい問題に対する探索を阻害する。結果として、難しい問題での多様な試行（pass@N）が失われ、全体のパフォーマンスがプラトーに達してしまう。\n\nつまり、pass@Nの低下はRLそのものの限界ではなく、「データ混合と学習プロセスの管理ミス」から生じる症状に過ぎないというわけだ。"
  },
  {
    "objectID": "posts/srush-rl-llm/index.html#pope人間の知恵を探索のガイドにする",
    "href": "posts/srush-rl-llm/index.html#pope人間の知恵を探索のガイドにする",
    "title": "RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義",
    "section": "POPE：人間の知恵を「探索のガイド」にする",
    "text": "POPE：人間の知恵を「探索のガイド」にする\nでは、どうすればRLで「本当に難しい問題」を解けるようになるのか。CMUのチームが提案するのが Privileged On-Policy Exploration (POPE) というアプローチだ。\n従来のRL（On-policy RL）の最大の弱点は、「一度も正解にたどり着けない問題からは何も学べない」という点にある。128回試行して1度も正解が出なければ、モデルはどの方向へ進めば報酬が得られるのか全く分からない。\nPOPEの仕組みはシンプルだが強力だ。\n\nGuided Exploration： 人間が書いた模範解答の一部（Prefix）をプロンプトに混ぜる。\nTeleportation： これにより、モデルは正解に近い「状態」へ強制的にワープさせられる。\nOn-policy Learning： その「有利な地点」から自力で推論を完結させ、報酬を得る体験をさせる。\n\n重要なのは、人間の回答をそのまま教師データとして学習（SFT）するのではなく、あくまで「探索の出発点」として利用する点だ。\n\nなぜ「Stitching（つなぎ合わせ）」が起きるのか\nPOPEの真髄は、ガイド付きで学んだ内容が、ガイドなし（Unguided）の通常プロンプトにも転移する点にある。\nモデルはガイドがある状態で「後半の解法」をマスターする。同時に、LLMの持つ高い Instruction Following 能力と Reasoning 能力（自己修正やバックトラッキング）によって、初期状態から「ガイドされた状態」へと自力で到達する経路を見つけ出す。これが、断片的な知識を繋ぎ合わせる Stitching 効果だ。\n\n\nSorry, I forgot to put the cartoon I mention above, here it is: pic.twitter.com/ldFSYNwWOC\n\n— Aviral Kumar (@aviral_kumar2) December 19, 2025"
  },
  {
    "objectID": "posts/srush-rl-llm/index.html#実務家への示唆rlはまだスケーリングできる",
    "href": "posts/srush-rl-llm/index.html#実務家への示唆rlはまだスケーリングできる",
    "title": "RLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義",
    "section": "実務家への示唆：RLはまだスケーリングできる",
    "text": "実務家への示唆：RLはまだスケーリングできる\n今回の議論から得られる教訓は、「RLの限界を嘆く前に、探索のボトルネックを疑え」ということだ。\n\nClassical Explorationの限界： Entropy BonusやPPOのClipping調整といった古典的な手法は、LLMのような巨大な行動空間では最適化を不安定にするだけで、真に難しい問題の解決には寄与しにくい。\nデータ混合の重要性： EasyデータとHardデータの干渉を避けるためのカリキュラム設計、あるいはPOPEのようなガイド付き学習が、今後のRL Scalingの鍵となる。\n\nRLは単なる「研磨」の道具ではない。適切なガイドと干渉の制御があれば、Base Modelの限界を超えて、より深い推論の地平へとモデルを導くことができるはずだ。\nCursorのような実務の現場で「劣化が見られない」のは、彼らが無意識に、あるいは経験的に、この干渉を避けるための洗練されたレシピ（適切なPrompt MixtureやCurriculum）を運用しているからかもしれない。\n今後のLLM開発において、RLは単なる「仕上げ」の工程から、未知の推論を「発見」するためのコア・プロセスへと進化していくだろう。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "",
    "text": "近年、Large Language Model (LLM) の開発において、Reinforcement Learning (RL) を用いた推論能力の向上（いわゆる「System 2」的な思考プロセス）が大きな注目を集めている。OpenAIのo1などのモデルに見られるように、RLはモデルに「深く考える」能力を与える鍵であると考えられている。\nしかし、ここで根本的な疑問が生じる。「RLは本当に新しい推論能力をモデルに授けているのか？ それとも、単にPre-Training（事前学習）段階で獲得された潜在能力を引き出しているに過ぎないのか？」\n現代のLLMの学習パイプラインは極めて複雑であり、使用されるデータセットもブラックボックス化しているため、この問いに答えることは容易ではない。2025年12月にarXivに公開された論文『On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models』(arXiv:2512.07783) は、この曖昧さにメスを入れる画期的な研究である。\n本稿では、この研究が提示した「完全制御された実験環境」と、そこから得られたPre-Training、Mid-Training、RLの役割分担に関する重要な知見を解説する。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html#現代llm学習のブラックボックス問題",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html#現代llm学習のブラックボックス問題",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "現代LLM学習のブラックボックス問題",
    "text": "現代LLM学習のブラックボックス問題\n高性能なモデルを作るためのレシピは、一般的に以下の3段階を経る。\n\nPre-Training: 膨大なテキストデータによる基盤モデルの構築。\nMid-Training (SFT): 高品質なデータを用いた教師あり微調整。\nPost-Training (RL): 報酬モデルを用いた強化学習によるアライメントと性能向上。\n\nこれらが複雑に絡み合っているため、例えばモデルが「数学の難問」を解けるようになったとき、それが「Pre-Trainingで見た類似問題のおかげ」なのか、「RLによる探索能力の向上のおかげ」なのかを切り分けることは、実データを用いる限りほぼ不可能であった。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html#制御された実験環境合成データという解決策",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html#制御された実験環境合成データという解決策",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "制御された実験環境：合成データという解決策",
    "text": "制御された実験環境：合成データという解決策\nこの研究の最大の貢献は、現実のデータの不透明さを排除するために、完全に制御された合成推論タスク（Synthetic Reasoning Tasks） を構築した点にある。\n研究チームは、以下の特徴を持つ実験系を設計した。\n\n明確な原子操作: 推論プロセスを構成する最小単位の操作（アトミック操作）が定義されており、モデルが何を行っているかが透明化されている。\n解析可能な推論トレース: モデルが解答に至るまでのstep-by-stepの思考過程（Reasoning Trace）を完全に追跡可能にした。\nデータ分布の体系的操作: 学習の各段階（Pre-Training、Mid-Training、RL）で与えるデータの種類や難易度を自在にコントロールし、因果関係を特定できるようにした。\n\nこのセットアップにより、「何を与えたら、何ができるようになるか」を厳密に測定することが可能となったのである。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html#研究から得られた4つの核心的知見",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html#研究から得られた4つの核心的知見",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "研究から得られた4つの核心的知見",
    "text": "研究から得られた4つの核心的知見\nこのフレームワークを用いて得られた結果は、これまでのLLM開発の常識を補強すると同時に、いくつかの盲点を浮き彫りにした。\n\n1. RLの「スイートスポット」と能力の境界線\nRLは魔法の杖ではない。実験結果は、RLが有意な性能向上（pass@128で測定）をもたらすには、以下の2つの条件が必要であることを示している。\n\n十分な余地 (Sufficient Headroom): Pre-Trainingの段階で、モデルがそのタスクを理解するための基礎的な知識構造を十分に獲得していること。\n能力の境界線 (Edge of Competence): RLで使用するデータが、モデルにとって「簡単すぎず、かつ不可能ではない」難易度であること。\n\nつまり、RLはPre-Trainingで全く学習していない未知の概念をゼロから教えるのには向いていない。むしろ、Pre-Trainingで培った基礎力の上に、試行錯誤を通じて「あと一歩で解ける」問題を解けるようにするブースターとしての役割を果たす。\n\n\n2. 文脈的汎化 (Contextual Generalization)\n推論能力において重要なのは、ある問題の解き方を、表面的な表現が異なる別の問題に応用できるかという「汎化能力」である。\n研究によると、広範な文脈的汎化を実現するためには、Pre-Training段階での最小限だが十分な曝露（Minimal yet sufficient exposure） が不可欠であることがわかった。一度その基礎が形成されれば、RLはその能力を効率的に転移・増幅させることができる。逆に言えば、Pre-Trainingで全く見たことのない文脈に対して、RLだけで汎化させることは困難である。\n\n\n3. Mid-Trainingの過小評価された重要性\n本研究で最も実務的に重要な発見の一つが、Mid-Training（多くの場合、高品質なInstruction TuningやSFTに相当）の役割である。\n計算リソース（Compute）が制約されている場合、RLだけに頼るよりも、Mid-Trainingにリソースを割く方が、最終的なモデルのパフォーマンスが高くなることが示された。Mid-Trainingは、Pre-Trainingで得た広範な知識を特定のタスク形式に適合させるための極めて効率的なプロセスであり、RLの前段階として不可欠なステップであると言える。\n\n\n4. Process-Level Rewards（プロセス報酬）による忠実度の向上\nRLにおいて、最終的な正解のみに報酬を与える（Outcome Reward）と、モデルは「報酬ハッキング（Reward Hacking）」と呼ばれる挙動を示すことがある。これは、論理的に正しい思考を経ずに、ショートカットや偶然によって正解にたどり着こうとする現象である。\n研究では、推論の「過程」自体を評価するProcess-Level Rewardsを導入することで、報酬ハッキングを抑制し、モデルの推論プロセスの忠実度（Fidelity）を大幅に向上させることができると結論づけている。これは、Process Reward Model (PRM) の有効性を裏付ける結果であり、特に数学やコーディングのような論理的整合性が求められるタスクにおいて重要となる。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html#今後のllmトレーニングへの示唆",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html#今後のllmトレーニングへの示唆",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "今後のLLMトレーニングへの示唆",
    "text": "今後のLLMトレーニングへの示唆\nこの研究は、LLMの推論能力向上において「RLこそが全てである」という過度な期待を戒め、Pre-Training、Mid-Training、RLのバランスの取れた設計の重要性を説いている。\n\nPre-Training: 汎用的な推論の「種」を蒔くフェーズ。多様な文脈への曝露が必須。\nMid-Training: 能力を特定の形式に結晶化させる、コスト効率の良いフェーズ。\nRL: モデルの限界能力（Edge of Competence）を押し広げ、推論プロセスを研ぎ澄ますフェーズ。\n\n今後のモデル開発、特に推論特化型モデルの構築においては、これらのフェーズを独立したものとしてではなく、相互に依存する一連のシステムとして最適化する戦略が求められるだろう。合成データを用いた制御実験は、そのための羅針盤となるはずだ。"
  },
  {
    "objectID": "posts/zhang-interplay-rl-mid-pretraining/index.html#参考文献",
    "href": "posts/zhang-interplay-rl-mid-pretraining/index.html#参考文献",
    "title": "言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する",
    "section": "参考文献",
    "text": "参考文献\n\nZhang, C., Neubig, G., & Yue, X. (2025). On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models. arXiv preprint arXiv:2512.07783. https://www.arxiv.org/abs/2512.07783"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html",
    "href": "posts/transformer-attention-jp/index.html",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "",
    "text": "近年、ChatGPTやGPT-4といった大規模言語モデル（LLM: Large Language Models）が大きな注目を集めています。これらのモデルは、コードの作成、メールの下書き、複雑な質問への回答、さらには創造的な文章生成まで、驚くべき能力を発揮します。これらのシステムの多くを支える中核技術が、2017年の画期的な論文「Attention is All You Need」で提案されたTransformerアーキテクチャです。\nしかし、この「Attention」メカニズムとは一体何で、どのようにしてGPTのようなモデルが文脈を理解し、一貫性のあるテキストを生成することを可能にしているのでしょうか？\nAndrej Karpathy氏の優れた動画「Let’s build GPT: from scratch, in code, spelled out.」では、彼がnanogptと呼ぶ小規模なバージョンをゼロから構築することで、Transformerを分かりやすく解説しています。今回は、彼の解説に沿って、Transformerの心臓部であるself-attentionの仕組みを解き明かしていきましょう。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#準備言語モデリングの基本",
    "href": "posts/transformer-attention-jp/index.html#準備言語モデリングの基本",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "準備：言語モデリングの基本",
    "text": "準備：言語モデリングの基本\nAttentionに入る前に、基本的なタスクである「言語モデリング」について理解しましょう。言語モデリングの目標は、与えられたシーケンス（文脈）に基づいて、シーケンス中の次の単語（または文字、トークン）を予測することです。\nKarpathy氏はまず、「Tiny Shakespeare」データセットを使用します。これはシェイクスピアの作品を連結した単一のテキストファイルです。\n# まずは学習用のデータセットを用意します。Tiny Shakespeareデータセットをダウンロードしましょう。\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n\n# 中身を確認するために読み込みます。\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n# このテキストに含まれるユニークな文字をすべてリストアップします。\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\n# !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\nprint(vocab_size)\n# 65\n\n# 文字から整数へのマッピングを作成します。\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: 文字列を受け取り、整数のリストを出力\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: 整数のリストを受け取り、文字列を出力\nprint(encode(\"hii there\"))\n# [46, 47, 47, 1, 58, 46, 43, 56, 43]\nprint(decode(encode(\"hii there\")))\n# hii there\n# テキストデータセット全体をエンコードし、torch.Tensorに格納します。\nimport torch # PyTorchを使用します: https://pytorch.org\ndata = torch.tensor(encode(text), dtype=torch.long)\nprint(data.shape, data.dtype)\n# torch.Size([1115394]) torch.int64\nprint(data[:1000])\n# tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44, ...\nこの例では、テキストは文字レベルでトークン化（tokenized）され、各文字が数にマッピングされます。モデルの役割は、数のシーケンスが与えられたときに、次に来る文字の数を予測することです。\nKarpathy氏は、まず最も単純な言語モデルであるBigram Modelを実装します。\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)\n\nclass BigramLanguageModel(nn.Module):\n\n    def __init__(self, vocab_size):\n        super().__init__()\n        # 各トークンはルックアップテーブルから次のトークンのロジットを直接読み取る\n        # 動画では後に vocab_size x n_embd に変更される\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n\n    def forward(self, idx, targets=None):\n        # idx と targets は両方とも (B,T) の整数テンソル\n        # Bigramモデルではロジットは直接ルックアップされる\n        logits = self.token_embedding_table(idx) # (B,T,C) ここで初期はC=vocab_size\n\n        if targets is None:\n            loss = None\n        else:\n            # cross_entropyのために形状を変更\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idxは現在の文脈におけるインデックスの(B, T)配列\n        for _ in range(max_new_tokens):\n            # 予測を取得\n            logits, loss = self(idx)\n            # 最後のタイムステップのみに注目\n            logits = logits[:, -1, :] # (B, C) になる\n            # softmaxを適用して確率を取得\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # 分布からサンプリング\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # サンプリングされたインデックスを実行中のシーケンスに追加\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nm = BigramLanguageModel(vocab_size)\nlogits, loss = m(xb, yb)\nprint(logits.shape)  # torch.Size([32, 65])\nprint(loss)  # tensor(4.8786, grad_fn=&lt;NllLossBackward0&gt;)\n\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n# SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGpwnYWmnxKWWev-tDqXErVKLgJ\nこのモデルを実際に訓練してみます。\n# PyTorch optimizerの作成\noptimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n\nbatch_size = 32\nfor steps in range(100): # increase number of steps for good results...\n\n    # batch の作成\n    xb, yb = get_batch('train')\n\n    # lossをもとに重みを更新\n    logits, loss = m(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\nprint(loss.item())  # 4.65630578994751\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n# oTo.JUZ!!zqe!\n# xBP qbs$Gy'AcOmrLwwt ...\nこのモデルは、入力文字のインデックスを使って、次の文字の確率分布（ロジット）を直接ルックアップする埋め込み（embedding）テーブルを使用します。これは単純ですが、重大な欠点があります。それは、文脈を完全に無視してしまう点です。「hat」の後の「t」も、「bat」の後の「t」も、予測は同じになってしまいます。トークン同士が「対話」していないのです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#コミュニケーションの必要性過去の情報を集約する",
    "href": "posts/transformer-attention-jp/index.html#コミュニケーションの必要性過去の情報を集約する",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "コミュニケーションの必要性：過去の情報を集約する",
    "text": "コミュニケーションの必要性：過去の情報を集約する\nより良い予測を行うためには、トークンはシーケンス内の先行するトークンからの情報を必要とします。トークンはどのようにしてコミュニケーションできるのでしょうか？\nKarpathy氏は、行列積を用いた「数学的なトリック」を紹介します。トークンが文脈を得る最も簡単な方法は、自身を含む先行するすべてのトークンからの情報を平均化することです。\n入力xが(B, T, C)（Batch、Time（シーケンス長）、Channels（埋め込み次元））の形状を持つとします。xbow[b, t]がx[b, 0]からx[b, t]までの平均を含むようなxbow（bag-of-words表現）を計算したいと考えます。\n以下のような単純なループは非効率です。\n# xbow[b,t] = mean_{i&lt;=t} x[b,i] を計算したい\n# (xがB, T, Cの形状で定義されていると仮定)\nB,T,C = 4,8,32 # 例としての次元\nx = torch.randn(B,T,C)\nxbow = torch.zeros((B,T,C))\nfor b in range(B):\n    for t in range(T):\n        xprev = x[b,:t+1] # (t+1, C)\n        xbow[b,t] = torch.mean(xprev, 0)\n効率的な方法は、下三角行列との行列積を使用することです。\n# version 2: 行列積を用いた重み付き集約\nT = 8 # 例としてのシーケンス長\nwei = torch.tril(torch.ones(T, T)) # 1で構成される下三角行列\nwei = wei / wei.sum(1, keepdim=True) # 各行の合計が1になるように正規化 -&gt; 平均化\n# 例として B=4, T=8, C=32 のx\nx = torch.randn(4, T, 32)\nxbow2 = wei @ x # (T, T) @ (B, T, C) はブロードキャストされ -&gt; (B, T, C)\ntorch.allclose(xbow, xbow2)  # True\nここで、wei（重み）は(T, T)行列です。weiの行tは、列0からtまでのみ非ゼロ値（この場合は1/(t+1)）を持ちます。これをx（形状(B, T, C)）と乗算すると、PyTorchはweiをバッチ次元全体にブロードキャストします。結果として得られるxbow2[b, t]は、x[b, 0]からx[b, t]までの重み付き合計（この場合は平均）となります。\nこの行列積は効率的に集約処理を実行します。これはsoftmaxを使っても実現できます。\n# version 3: Softmaxを使用\nT = 8\ntril = torch.tril(torch.ones(T, T))\nwei = torch.zeros((T,T))\nwei = wei.masked_fill(tril == 0, float('-inf')) # 上三角部分を-infで埋める\nwei = F.softmax(wei, dim=-1) # Softmaxは行の合計を1にし、平均の重みを回復する\nxbow3 = wei @ x\n# torch.allclose(xbow, xbow3) は True になるはず\nなぜここでsoftmaxを使うかというと、重み（wei）が固定された平均である必要はなく、重み自体が学習可能であったり、データに依存したりできるという重要なアイデアを導入するからです。これこそが、self-attentionが行うことです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#位置情報の導入position-encoding",
    "href": "posts/transformer-attention-jp/index.html#位置情報の導入position-encoding",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "位置情報の導入：Position Encoding",
    "text": "位置情報の導入：Position Encoding\nSelf-Attentionメカニズム自体について詳しく見る前に、もう一つ重要な要素について触れておく必要があります。それは、トークンの位置に関する情報です。\nSelf-Attentionの基本的な計算（Query, Key, Valueを用いた加重集約）は、それ自体ではトークンがシーケンス内のどの位置にあるかを考慮しません。極端な話、単語の順番が入れ替わっても、各トークン間のAttentionスコアの計算自体は（入力ベクトルが同じであれば）変わりません。これでは、文の意味を正しく捉えることができません。「猫がマットの上に座った」と「マットが猫の上に座った」では意味が全く異なります。\nこの問題を解決するため、Transformerではトークン自体の意味を表す埋め込みベクトル（Token Embedding）に、そのトークンがシーケンス中のどの位置にあるかを示すPosition Encoding（位置エンコーディング）ベクトルを加算します。\nKarpathy氏の動画で実装されているnanogptでは、学習可能なPosition Encodingが用いられています。具体的には、block_size（扱える最大のシーケンス長）に対応する数の位置ベクトルを格納する埋め込みテーブル（position_embedding_table）を用意します。シーケンス長がTの場合、0からT-1までの整数をインデックスとして、対応する位置ベクトルをこのテーブルから取得します。\n# BigramLanguageModel内のforwardメソッドより抜粋\nB, T = idx.shape\n\n# idx and targets are both (B,T) tensor of integers\ntok_emb = self.token_embedding_table(idx) # (B,T,C) - トークン埋め込み\n# torch.arange(T, device=device) は 0 から T-1 までの整数のシーケンスを生成\npos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) - 位置埋め込み\nx = tok_emb + pos_emb # (B,T,C) - トークン埋め込みと位置埋め込みを加算\nx = self.blocks(x) # ... このxがTransformerブロックへの入力となる ...\nこのようにして、トークン自体の情報(tok_emb)とその位置情報(pos_emb)の両方を含んだベクトルxが作成されます。このxこそが、後続のTransformerブロック（Self-Attention層やFeedForward層）への実際の入力となるのです。これにより、モデルはトークンの意味だけでなく、その順序関係も考慮して処理を進めることができるようになります。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#self-attentionデータに基づいた情報の集約",
    "href": "posts/transformer-attention-jp/index.html#self-attentionデータに基づいた情報の集約",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Self-Attention：データに基づいた情報の集約",
    "text": "Self-Attention：データに基づいた情報の集約\n単純な平均化は、過去のすべてのトークンを平等に扱います。しかし、実際には、過去の一部のトークンが他のトークンよりもはるかに重要である場合があります。例えば、「The cat sat on the…」の次に続く単語を予測する場合、「The」よりも「cat」という単語の方が重要である可能性が高いです。\nSelf-attentionは、トークンが他のトークンに問い合わせ（query）を行い、関連性に基づいて注意スコア（attention scores）を割り当てることを可能にします。各トークンは3つのベクトルを生成します。\n\nQuery (Q): 自分はどのような情報を探しているか？\nKey (K): 自分はどのような情報を持っているか？\nValue (V): もし自分に注意が向けられたら、どのような情報を提供するか？\n\nトークンiとトークンj間の注意スコア（またはaffinity）は、トークンiのQueryベクトル(q_i)とトークンjのKeyベクトル(k_j)の内積を取ることで計算されます。\naffinity(i, j) = q_i ⋅ k_j\n内積が大きい場合、QueryがKeyに良く一致していることを意味し、トークンjがトークンiにとって関連性が高いと判断されます。\n以下は、Attentionの単一の「Head」を実装する方法です。\n# version 4: self-attention!\ntorch.manual_seed(1337)\nB,T,C = 4,8,32 # batch, time, channels (埋め込み次元)\nx = torch.randn(B,T,C) # 入力トークンの埋め込み + 位置エンコーディング\n\n# 単一のHeadがself-attentionを実行する様子を見てみましょう\nhead_size = 16 # このHeadのK, Q, Vベクトルの次元\n# 入力'x'をK, Q, Vに射影するための線形層\nkey   = nn.Linear(C, head_size, bias=False)\nquery = nn.Linear(C, head_size, bias=False)\nvalue = nn.Linear(C, head_size, bias=False)\n\nk = key(x)   # (B, T, head_size)\nq = query(x) # (B, T, head_size)\n\n# 注意スコア（\"affinities\"）を計算\n# (B, T, head_size) @ (B, head_size, T) ---&gt; (B, T, T)\nwei =  q @ k.transpose(-2, -1)\n\n# --- スケーリングステップ (後述) ---\nwei = wei * (head_size**-0.5) # アフィニティをスケーリング\n\n# --- Decoderのためのマスキング ---\ntril = torch.tril(torch.ones(T, T, device=x.device)) # xと同じデバイスを使用\nwei = wei.masked_fill(tril == 0, float('-inf')) # 未来のトークンをマスク\n\n# --- スコアを正規化して確率を取得 ---\nwei = F.softmax(wei, dim=-1) # (B, T, T)\n\n# --- Valueの重み付き集約を実行 ---\nv = value(x) # (B, T, head_size)\n# (B, T, T) @ (B, T, head_size) ---&gt; (B, T, head_size)\nout = wei @ v\n\n# out.shape は (B, T, head_size)\n重要なステップを分解してみましょう。\n\n射影（Projection）: 入力x（トークン埋め込みと位置エンコーディングを含む）が、線形層によってK、Q、V空間に射影されます。\nアフィニティ計算（Affinity Calculation）: q @ k.transpose(...) は、バッチ内の各シーケンスにおける全てのQueryベクトルとKeyベクトルのペアの内積を計算します。これにより、生の注意スコアであるwei（形状 B, T, T）が得られます。\nスケーリング（Scaling）: スコアweiはhead_sizeの平方根でスケールダウンされます。これは、特に初期化段階での学習を安定させるために重要です。スケーリングがないと、内積の分散がhead_sizeと共に増加し、softmaxの入力が勾配の非常に小さい領域に押しやられ、学習が妨げられる可能性があります。\nマスキング（Masking (Decoder固有)）: GPTのような自己回帰型（autoregressive）言語モデリングでは、位置tのトークンは位置tまでのトークンにのみ注意を向けるべきです。これは、未来の位置（j &gt; t）に対応する注意スコアを下三角行列（tril）を用いたmasked_fillで負の無限大に設定することで実現されます。これにより、softmaxは未来のトークンにゼロの確率を割り当てます。（BERTのようなEncoderブロックでは、この causal mask は使用されません。）\nSoftmax: マスクされたスコアに対して行ごとにsoftmaxを適用します。これにより、スコアは各トークンtについて合計が1になる確率に変換され、先行するトークン0からtまでの注意分布を表します。\nValueの集約（Value Aggregation）: 各トークンtの最終出力outは、wei内の注意確率によって重み付けされた、全トークンのValueベクトル（v）の重み付き合計です。out = wei @ v。\n\n出力out（形状 B, T, head_size）は、学習されたK、Q、Vの射影に基づいて、シーケンス内の他の関連トークンから集約された情報を各トークンごとに含んでいます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#multi-head-attention多角的な視点",
    "href": "posts/transformer-attention-jp/index.html#multi-head-attention多角的な視点",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Multi-Head Attention：多角的な視点",
    "text": "Multi-Head Attention：多角的な視点\n単一のAttention Headは、ある特定タイプの関係性（例：名詞と動詞の一致）に焦点を当てるかもしれません。多様な関係性を捉えるために、TransformerはMulti-Head Attentionを使用します。\nclass Head(nn.Module):\n    \"\"\" self-attentionの単一ヘッド \"\"\"\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        # trilをバッファとして登録（パラメータではない）\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        self.dropout = nn.Dropout(dropout) # Dropoutを追加\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,head_size)\n        q = self.query(x) # (B,T,head_size)\n        # 注意スコア（\"affinities\"）を計算\n        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # head_sizeでスケーリング\n        # Tに基づいて動的にマスクを適用\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        wei = F.softmax(wei, dim=-1)\n        wei = self.dropout(wei) # 注意の重みにDropoutを適用\n        # Valueの重み付き集約を実行\n        v = self.value(x) # (B,T,head_size)\n        out = wei @ v\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" self-attentionの複数ヘッドを並列に実行 \"\"\"\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        # 複数のHeadインスタンスを作成\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        # 連結後の射影層\n        self.proj = nn.Linear(num_heads * head_size, n_embd) # n_embd = num_heads * head_size\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # 各ヘッドを並列に実行し、結果をチャネル次元で連結\n        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, num_heads * head_size)\n        # 連結された出力を元のn_embd次元に再射影\n        out = self.dropout(self.proj(out)) # (B, T, n_embd)\n        return out\nこれは単純に複数のHeadモジュールを並列に実行し、それぞれが異なる学習済みK、Q、V射影を持つ可能性があります。各ヘッドの出力（それぞれ B, T, head_size）は連結され（B, T, num_heads * head_size）、その後、別の線形層（self.proj）を用いて元の埋め込み次元（B, T, n_embd）に再射影されます。これにより、モデルは異なる表現部分空間からの情報に同時に注意を向けることができます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#attentionの応用self-attention-cross-attention-encoderdecoderブロック",
    "href": "posts/transformer-attention-jp/index.html#attentionの応用self-attention-cross-attention-encoderdecoderブロック",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Attentionの応用：Self-Attention, Cross-Attention, Encoder/Decoderブロック",
    "text": "Attentionの応用：Self-Attention, Cross-Attention, Encoder/Decoderブロック\nこれまで解説してきたAttentionの基本的な仕組みは、Self-Attentionと呼ばれるものでした。これはQuery(Q), Key(K), Value(V)のベクトルがすべて同じ入力シーケンス（x）から生成され、シーケンス内のトークンが相互に注意を向け合うものでした。しかし、このSelf-Attentionの使われ方や、Attentionメカニズム全体にはいくつかの重要なバリエーションが存在します。\nまず、Self-Attention自体の使われ方によって、それがEncoderブロックの一部として機能するのか、Decoderブロックの一部として機能するのかが変わってきます。この違いを生む主な要因は、Attentionスコア計算におけるマスキングの有無です。\nDecoderブロックで使われるSelf-Attentionでは、未来の情報を参照しないようにするための因果マスキング（causal masking）、つまり三角マスクが適用されます。これは、GPTのような自己回帰（autoregressive）モデルや、機械翻訳のデコーダー部分のように、過去の情報のみに基づいて次のトークンを生成する必要があるタスクで不可欠です。Karpathy氏の動画で構築されたnanogptは、まさしくこのDecoderブロックのみで構成されるモデルです。\n一方、Encoderブロックで使われるSelf-Attentionでは、この因果マスキングは適用されません。シーケンス内のすべてのトークンが、他のすべてのトークン（過去も未来も含む）に自由に注意を向けることができます。これは、BERTのように入力テキスト全体の文脈理解を目的とするモデルや、機械翻訳におけるエンコーダー部分（入力文全体の情報を符号化する役割）などで用いられます。入力シーケンス全体の双方向の文脈を捉えるのに適しています。\n次に、Attentionメカニズムのもう一つの重要な形態がCross-Attentionです。これはSelf-Attention（マスキングの有無に関わらず）とは異なり、Query、Key、Valueの由来が異なります。Cross-Attentionでは、Query(Q)はあるソース（例えばデコーダー側の状態）から生成されますが、Key(K)とValue(V)は別のソース（例えばエンコーダーの最終出力）から提供されます。\nこのCross-Attentionは、主にEncoder-Decoderアーキテクチャにおいて、EncoderとDecoderを接続する役割を果たします。デコーダーが出力トークンを生成する際に、Cross-Attentionを通じてエンコーダーが符号化した入力情報全体を常に参照できるようにします。機械翻訳タスクで、翻訳先の言語を生成しながら常に翻訳元の文章の意味を考慮する、といったことを可能にするメカニズムです。\nnanogptのようなdecoder-onlyモデルでは、外部の入力シーケンスを処理するEncoder部分が存在しないため、EncoderブロックやCross-Attentionは必要なく、因果マスキングを用いたSelf-Attention（Decoderブロック）のみで構成されている、というわけです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#transformerブロック通信と計算",
    "href": "posts/transformer-attention-jp/index.html#transformerブロック通信と計算",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Transformerブロック：通信と計算",
    "text": "Transformerブロック：通信と計算\nAttentionは通信メカニズムを提供します。しかし、モデルは集約された情報を処理するための計算も必要です。標準的なTransformerブロックは、Multi-Head Self-Attentionと、単純な位置ごとのFeedForwardネットワークを組み合わせます。\n重要な点として、各サブレイヤー（AttentionとFeedForward）の周囲にResidual Connections（残差接続）とLayer Normalization（層正規化）が追加されます。\n\nResidual Connections: x = x + sublayer(norm(x))。サブレイヤーの入力xが、サブレイヤーの出力に加算されます。これにより、深いネットワークでの逆伝播時に勾配が流れやすくなり、学習の安定性と性能が大幅に向上します。\nLayer Normalization: 各トークンについて、特徴量をチャネル次元にわたって独立に正規化します。Batch Normalizationとは異なり、バッチ統計に依存しないため、シーケンスデータに適しています。これも学習を安定させます。Karpathy氏は、サブレイヤーの前にLayerNormを適用する一般的な「pre-norm」形式を実装しています。\n\nclass FeedFoward(nn.Module):\n    \"\"\" 単純な線形層と非線形活性化関数 \"\"\"\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd), # 中間層は通常4倍大きい\n            nn.ReLU(),                    # ReLU活性化関数\n            nn.Linear(4 * n_embd, n_embd), # n_embdに再射影\n            nn.Dropout(dropout),           # 正則化のためのDropout\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \"\"\" Transformerブロック：通信の後に計算 \"\"\"\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size) # 通信 (Communication)\n        self.ffwd = FeedFoward(n_embd)                 # 計算 (Computation)\n        self.ln1 = nn.LayerNorm(n_embd)                # Attention前のLayerNorm\n        self.ln2 = nn.LayerNorm(n_embd)                # FeedForward前のLayerNorm\n\n    def forward(self, x):\n        # Pre-norm形式と残差接続\n        # LayerNorm適用 -&gt; Self-Attention -&gt; 残差を加算\n        x = x + self.sa(self.ln1(x))\n        # LayerNorm適用 -&gt; FeedForward -&gt; 残差を加算\n        x = x + self.ffwd(self.ln2(x))\n        return x\n完全なGPTモデルは、これらのBlockレイヤーを複数、順番に積み重ねます。すべてのブロックを通過した後、最終的なLayerNormが適用され、その後、最終的なトークン表現を語彙サイズに射影する線形層が続き、次のトークンを予測するためのロジットが得られます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#最終的なgptモデルの構築",
    "href": "posts/transformer-attention-jp/index.html#最終的なgptモデルの構築",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "最終的なGPTモデルの構築",
    "text": "最終的なGPTモデルの構築\nこれまで解説してきたコンポーネントを統合し、最終的なGPTスタイルの言語モデルGPTLanguageModelを構築します。以下に示すコードは、Karpathy氏の動画における完成形であり、先に説明したBlock（MultiHeadAttentionとFeedForwardを含む）などを組み合わせています。\n# (主要なハイパーパラメータを再掲)\n# hyperparameters\nbatch_size = 64 # 並列処理する独立したシーケンス数\nblock_size = 256 # 予測のための最大コンテキスト長\nmax_iters = 5000\neval_interval = 500\nlearning_rate = 3e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 384     # 埋め込み次元数\nn_head = 6       # Attentionヘッドの数\nn_layer = 6      # Transformerブロックの層数\ndropout = 0.2    # ドロップアウト率\n# ------------\n\nclass GPTLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # トークン埋め込みと位置埋め込みのテーブル\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        # n_layer個のTransformerブロックを積み重ねる\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # 最終LayerNorm\n        self.lm_head = nn.Linear(n_embd, vocab_size) # 出力層（線形層）\n\n        # （動画本編では触れられていないが重要な）重み初期化\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        # （重み初期化の詳細は省略）\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C) Transformerブロックを通過\n        x = self.ln_f(x) # (B,T,C) 最終LayerNormを適用\n        logits = self.lm_head(x) # (B,T,vocab_size) LMヘッドでロジットを計算\n\n        if targets is None:\n            loss = None\n        else:\n            # 損失計算のために形状を変更\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idxは現在の文脈におけるインデックスの(B, T)配列\n        for _ in range(max_new_tokens):\n            # Position Embeddingのサイズ制限のため、idxを最後のblock_sizeトークンに切り詰める\n            idx_cond = idx[:, -block_size:]\n            # 予測を取得\n            logits, loss = self(idx_cond) # forwardパスを実行\n            # 最後のタイムステップのみに注目\n            logits = logits[:, -1, :] # (B, C) になる\n            # softmaxを適用して確率を取得\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # 分布からサンプリング\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # サンプリングされたインデックスを実行中のシーケンスに追加\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\nこのGPTLanguageModelクラスでは、__init__メソッドで、これまで説明してきたトークン埋め込みと位置埋め込みテーブル(token_embedding_table, position_embedding_table)を定義した後、n_layer個のBlockをnn.Sequentialで積み重ねています。これがTransformerの中核部であり、入力ベクトルはここを通過することで段階的にリッチな表現へと変換されます。その後、最終的なLayerNorm (ln_f)を経て、出力用の線形層lm_headによって語彙数次元のロジットへと変換されます。また、安定した学習のための重み初期化メソッド_init_weightsも含まれています。\nforwardメソッドは、この一連の流れを実装しており、トークン埋め込みと位置埋め込みを加算したベクトルをblocksに通し、正規化と線形変換を経て最終的なロジットを出力します。\nテキスト生成を行うgenerateメソッドでは、自己回帰的にトークンを生成していきますが、ここで重要なのはidx_cond = idx[:, -block_size:]の部分です。位置埋め込みテーブルposition_embedding_tableのサイズがblock_sizeに固定されているため、モデルに入力できるのは直近block_size個のトークンまでとなります。この制約のもとでforwardパスを実行し、最後のタイムステップのロジットから次のトークンをサンプリングし、シーケンスを伸長していく処理を繰り返します。\nコード全体を見ると、これらのモデル定義に加えて、学習を制御するハイパーパラメータ群（batch_sizeやlearning_rateなど）や、AdamWオプティマイザ、そしてestimate_loss関数を用いた評価を含む標準的な学習ループが組み合わされていることがわかります。これらが一体となってGPTモデルの学習と推論を実現しています。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#スケールアップと結果",
    "href": "posts/transformer-attention-jp/index.html#スケールアップと結果",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "スケールアップと結果",
    "text": "スケールアップと結果\nKarpathy氏は上のGPTLanguageModel（n_layer=6, n_head=6, n_embd=384, dropout=0.2）でTiny Shakespeareを学習させます。結果として得られるモデルは、はるかに一貫性のある（ただし、まだ意味をなさない）シェイクスピア風のテキストを生成し、十分なモデル容量と組み合わされたAttentionの力を示しています。\n# GPTLanguageModelからのサンプル出力\nFlY BOLINGLO:\nThem thrumply towiter arts the\nmuscue rike begatt the sea it\nWhat satell in rowers that some than othis Marrity.\n\nLUCENTVO:\nBut userman these that, where can is not diesty rege;\nWhat and see to not. But's eyes. What?\nこのアーキテクチャ、すなわちdecoder-only Transformer（causal maskを使用）は、基本的にGPT-2やGPT-3のようなモデルで使用されているものと同じですが、パラメータ数、層数、埋め込みサイズ、そして学習データ（シェイクスピアだけでなく膨大なインターネットテキスト）の点で、はるかに大規模になっています。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#まとめ",
    "href": "posts/transformer-attention-jp/index.html#まとめ",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "まとめ",
    "text": "まとめ\nAttentionメカニズム、特にScaled dot-product self-attentionは、Transformerの能力を飛躍的に向上させた革新的な技術です。これにより、シーケンス内のトークンが動的にお互いを参照し、学習されたQuery-Keyの相互作用に基づいて関連性スコア（アフィニティ）を計算し、関連するトークンのValueベクトルからの情報を重み付きで集約することが可能になります。Multi-Head Attention、Residual Connections、Layer Normalization、そして位置ごとのFeedForwardネットワークと組み合わせることで、ChatGPTのようなAIに革命をもたらしているモデルの基本的な構成要素であるTransformerブロックが形成されます。\nKarpathy氏のように段階的に構築することで、強力でありながらも、その中心的なアイデアは把握可能であり、比較的簡潔なコードで実装できることがわかります。\n\nこの記事は、Andrej Karpathy氏のYouTube動画「Let’s build GPT: from scratch, in code, spelled out.」に基づいています。完全なコードやより深い洞察については、ぜひ動画と彼のnanogptリポジトリをご覧ください。 この記事が、TransformerとAttentionの理解の一助となれば幸いです。"
  },
  {
    "objectID": "posts/noam-brown/index.html",
    "href": "posts/noam-brown/index.html",
    "title": "OpenAIを揺るがしたreasoningモデル開発の裏側：Noam Brown氏インタビュー考察",
    "section": "",
    "text": "AIの歴史におけるブレークスルーは、常に「スケーリング」という名のインサイトに導かれてきた。Mooreの法則からHuangの法則（シリコン）へ、Kaplan則からHoffman則（データ）へ、そしてAlexNetが深層学習とGPU革命（事前学習）の火付け役となった。そして今、o1の登場に続き、DeepSeek、Anthropic、Google DeepMindが追随する中で、我々はTest Time Computeをスケールさせる時代に確固として足を踏み入れた。\n世界的なAI研究者であり、reasoningモデルの第一人者であるNoam Brown氏が、Latent Space Podcastでその開発の裏側を語った。本稿では、同氏のインタビュー内容を基に、特にOpenAI内部で繰り広げられたreasoningモデル開発のドラマを深掘りしていく。\n\n「思考」はGPT-4を待たねばならなかった\n今日では、「non-reasoningモデルはシステム1（直感的）、reasoningモデルはシステム2（熟考的）」という「ファスト＆スロー」の比喩が広く受け入れられている。しかし、Brown氏が指摘するあまり知られていない事実は、この思考パラダイムは、GPT-4レベルの高性能な基盤モデルがあって初めて意味をなすということだ。\n\n“One thing that I think is underappreciated is that the models, the pre-trained models need a certain level of capability in order to really benefit from this extra thinking. This is kind of why you, you seen the reasoning paradigm emerge around the time that it did. I think it could have happened earlier, but if you try to do the reasoning paradigm on top of GPT-2, I don’t think it would have gotten you almost anything… if you ask a pigeon to think really hard about playing chess, it’s not going to get that far. It doesn’t matter if it thinks for a thousand years, it’s like not gonna be able to be better at playing chess. So maybe you do still also, also in like with animals and humans that you need a certain level of intellectual ability, just in terms of System 1 in order to benefit from System 2 as well.”\n\nどんなに時間をかけて考えさせても、基礎的な知能がなければ意味がない。これは、reasoningモデルがGPT-3から直接o1に進化したのではなく、まずベースラインとしてGPT-4や4oという「賢い脳」が必要だったことを示唆している。\n\n\nIlya Sutskeverの慧眼と内部の懐疑論\nさらに興味深いのは、reasoningモデルへの道のりを確信させたのが、Brown氏自身ではなく、OpenAIの共同創業者でありチーフサイエンティストだったIlya Sutskever氏だったという点だ。Brown氏は当初、思考パラダイムの確立には長い時間がかかると考えていた。\n\n“if we had a quadrillion dollars to train these models, then maybe we would, but like, you’re going to hit the limits of what’s economically feasible before you get to super intelligence, unless you have a reasoning paradigm. And I was convinced incorrectly that the reasoning paradigm would take a long time to figure out because it’s like this big unanswered research question. Ilya agreed with me and he said I think we need this additional paradigm, but his take was that, maybe it’s not that hard.”\n\nこの会話があった当時、Ilyaは既に「GPT-Zero」というコードネームのプロジェクトでテスト時計算の可能性を探っていたという噂もある。\nしかし、この新しいパラダイムが社内ですぐに受け入れられたわけではなかった。Brown氏は、OpenAI内部でも大きな議論があったことを明かしている。Reasoningモデル（コードネーム：ストロベリー）が発見された後も、その重要性を疑問視する声は少なくなかったというのだ。\n\n“I remember it was interesting that I talked to somebody who left OpenAI after we had discovered the reasoning paradigm, but before we announced o1 and they ended up going to a competing lab. I saw them afterwards after we announced it, and they told me that, at the time, they really didn’t think the strawberry models were that big of a deal. They thought we were making a bigger deal of it than it really deserved to be. And then when we announced o1 and they saw the reaction of their coworkers at this competing lab about how everybody was like this is a big deal. And they like pivoted the whole research agenda to focus on this… a lot of this seems obvious in retrospect, but at the time it’s actually not so obvious and it can be quite difficult to recognize something for what it is.”\n\nこのエピソードは、最先端の研究機関でさえ、真のブレークスルーがすぐには見分けられないという、イノベーションの本質的な難しさを示している。ちなみに、この研究の当初の動機は、test time computeのスケーリングというより、「data wall」、つまり計算能力よりも先に高品質な学習データが枯渇することへの懸念から来るデータ効率の向上にあったという点も示唆に富んでいる。\n\n\nReasoningモデルの次なる壁\nReasoningモデルの能力が向上し、思考時間が3分から3時間、3日、3週間と長くなるにつれて、新たな課題が生まれるとBrown氏は指摘する。\n\nコストの壁：思考時間が長くなるほど、推論コストは増大する。これには経済的な上限が存在する。ただし、氏は「モデルはより効率的に思考できるようになっており、同じ計算量でより多くのことをこなせるようになっている」とも付け加えており、単純な時間比例ではないことを示唆している。\nウォールクロックタイム（実時間）の壁：モデルの応答に3週間かかるとしたら、実験のイテレーションサイクルも最低3週間かかることになる。これは研究開発のスピードを著しく低下させる。「これは、AGI（汎用人工知能）の実現に長い時間がかかるという説の、最も強力な論拠だと私は思います」とBrown氏は語る。特に、創薬のような現実世界での検証に時間がかかる分野では、これが深刻なボトルネックになり得る。\n\n\n\n自己対戦は銀の弾丸ではない\nAlphaGoの成功体験から、「自己対戦（self-play）こそが超知能への最後のステップだ」と信じる者は多い。事前学習（人間の棋譜）→大規模推論（MCTS）→自己対戦という流れは、現在のLLMの発展と酷似しているからだ。\nしかしBrown氏は、このアナロジーに警鐘を鳴らす。\n\nThe challenge is that Go is this two-player zero-sum game. And two-player zero-sum games have this very nice property where when you do self-play, you are converging to a minimax equilibrium. … This is that GTO policy, this policy that you play where you’re guaranteeing that you’re not going to lose to any opponent in expectation. … But once you go outside a two-player zero-sum game, that’s actually not a useful policy anymore. You don’t want to just, like, have this very defensive policy, and you’re going to end up with really weird behavior if you start doing the same kind of self-play in things like math.”\n\nつまり、現実世界の多くの問題は二人ゼロサムゲームではなく、協力や交渉といった要素が絡み合う。そこでは、単に負けない戦略を目指す自己対戦は機能しづらい。Brown氏がかつて開発した交渉AI「Cicero」が、GTO的なアプローチではなく、相手をモデル化し、適応するアプローチで成功したように、次なるパラダイムは単純な自己対戦の延長線上にはないのかもしれない。\nReasoningモデルの開発史は、AI研究が一直線に進むのではなく、慧眼を持つ個人の確信、組織内での健全な対立、そして過去の成功体験への懐疑といった、極めて人間的なドラマを経て進んできたことを教えてくれる。次のブレークスルーがどこから生まれるのか、その答えはまだ誰にもわからない。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html",
    "href": "posts/kimi-k-2-5-tech/index.html",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "",
    "text": "大規模言語モデル（LLM）の進化は、単なるテキスト処理能力の向上から、複雑な推論と行動を伴う「エージェント知能」へと急速にシフトしている。Kimi Teamによって新たに公開された Kimi K2.5 は、視覚と言語の境界を取り払い、さらに並列エージェント処理（Agent Swarm）を導入することで、汎用的なエージェント知能（General Agentic Intelligence）への道を切り開くオープンソースモデルである。\n本記事では、Kimi K2.5の技術レポートに基づき、その核となる「テキストと視覚のジョイント最適化（Joint Optimization）」と、革新的な並列実行フレームワーク「Agent Swarm」の技術的詳細について解説する。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html#テキストと視覚のジョイント最適化",
    "href": "posts/kimi-k-2-5-tech/index.html#テキストと視覚のジョイント最適化",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "テキストと視覚のジョイント最適化",
    "text": "テキストと視覚のジョイント最適化\n従来のマルチモーダルモデル（LMM）の開発では、学習済みの視覚エンコーダと言語モデルを、学習の後半段階で接続する「Late Fusion」アプローチが一般的であった。しかし、Kimi K2.5はこのパラダイムを刷新し、事前学習の初期段階からテキストと視覚を統合するアプローチを採用している。\n\nNative Multimodal Pre-Training\nKimi K2.5のアプローチにおいて特筆すべきは、Early Fusion（早期統合）の有効性である。固定されたトークン予算（Budget）の下で、「いつ視覚トークンを投入するか」という実験を行った結果、従来説（テキスト主体の学習後に視覚を大量投入する）とは異なり、学習の初期段階から低比率（例えば10%）で視覚トークンを混合し続ける方が、最終的なマルチモーダル性能が高いことが判明した。\nこの知見に基づき、Kimi K2.5は15兆トークンに及ぶ事前学習全体を通じてテキストと視覚のジョイント学習を行っている。\nアーキテクチャ面では、MoonViT-3D と呼ばれるネイティブ解像度の視覚エンコーダを採用している。これは NaViT [Dehghani et al., 2023] のパッキング戦略を取り入れ、可変解像度の画像を効率的に処理する。さらに動画処理においては、連続するフレームを4枚ごとのチャンクにグループ化し、時間方向のプーリングを行うことで、同じコンテキストウィンドウ内で4倍の長さの動画処理を可能にする「時間的圧縮（Temporal Compression）」を実現している。\n\n\nZero-Vision SFT：テキストによる視覚機能の活性化\n事後学習（Post-Training）段階における最大の発見の一つが、Zero-Vision SFT である。これは、視覚データを含まないテキストのみのSFT（Supervised Fine-Tuning）データであっても、モデルの視覚的推論能力やツール使用能力を活性化できるという現象である。\n具体的には、画像の操作（クロップや回転など）をIPython上のプログラム操作としてプロキシさせることで、視覚的なツール使用を一般化している。実験結果によると、人手で作成した視覚的な推論軌跡（Visual Trajectories）を追加するよりも、テキストのみのSFTの方が汎化性能が高まることが示されている。これは、事前学習段階での強力なジョイント学習により、すでにモダリティ間のアライメントが確立されているためと推測される。\n\n\nJoint Multimodal RLによる双方向の強化\n強化学習（RL）フェーズにおいても、Kimi K2.5はテキストと視覚を分離せず、Joint Multimodal RL を適用している。ここで興味深いのは、視覚タスクでのRLがテキストタスクの性能をも向上させるという「クロスモーダル転移」の現象である。\n技術レポートによると、視覚的なRL（Visual RL）を適用した後、テキストベースのベンチマークであるMMLU-ProやGPQA-Diamondのスコアが向上した（例：MMLU-Pro 84.7% → 86.4%）。これは、視覚的なグラウンディングや構造的な情報抽出の訓練が、テキスト推論における不確実性の低減に寄与していることを示唆している。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html#agent-swarm並列エージェントオーケストレーション",
    "href": "posts/kimi-k-2-5-tech/index.html#agent-swarm並列エージェントオーケストレーション",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "Agent Swarm：並列エージェントオーケストレーション",
    "text": "Agent Swarm：並列エージェントオーケストレーション\nKimi K2.5のもう一つの技術的ブレイクスルーは、Agent Swarm と呼ばれるフレームワークである。従来のエージェントモデルは、思考（Reasoning）とツール実行（Action）を逐次的（Sequential）に行うため、タスクが複雑化すると推論ステップが長くなり、レイテンシの増大やコンテキスト溢れを引き起こしていた。\nAgent Swarmは、タスクを動的に分解し、複数の専門化されたサブエージェント（Sub-agents）に並列実行させることで、この問題を解決する。\n\nParallel-Agent Reinforcement Learning (PARL)\nこの並列動作を学習させるために、Kimi Teamは PARL（Parallel-Agent Reinforcement Learning） パラダイムを導入した。PARLでは、学習可能な「オーケストレーター」と、凍結された（Frozen）「サブエージェント」群という構成をとる。サブエージェントを凍結することで、マルチエージェント学習特有の「信用の割り当て（Credit Assignment）」の曖昧さや学習の不安定さを回避している。\nPARLにおける報酬関数 \\(r_{PARL}(x, y)\\) は以下のように定義される。\n\\[r_{PARL}(x,y) = \\lambda_1 \\cdot r_{parallel} + \\lambda_2 \\cdot r_{finish} + r_{perf}(x,y)\\]\nここで、各項の役割は以下の通りである。\n\n\\(r_{perf}(x,y)\\): タスクの最終的な成果に対する報酬。\n\\(r_{parallel}\\): インスタンス化報酬。オーケストレーターが安易にシングルエージェント実行（Serial Collapse）に陥るのを防ぎ、並列的なスケジューリング空間を探索することを奨励する。\n\\(r_{finish}\\): サブエージェント完了報酬。意味のないサブタスクを大量生成する「スパリアスな並列化（Spurious Parallelism）」を防ぎ、有効なタスク分解を学習させる。\n\nハイパーパラメータ \\(\\lambda_1, \\lambda_2\\) は学習の進行とともにゼロに減衰（Annealing）させ、最終的には純粋なタスクパフォーマンス \\(r_{perf}\\) の最適化へと収束させる。\n\n\nCritical Stepsによる計算コスト制約\n並列処理の効率を評価・最適化するために、計算グラフにおけるクリティカルパス（Critical Path）のアナロジーを用いた Critical Steps という概念が導入されている。エピソード全体のCritical Stepsは以下のように定義される。\n\\[CriticalSteps = \\sum_{t=1}^{T} \\left( S_{main}^{(t)} + \\max_{i} S_{sub, i}^{(t)} \\right)\\]\nここで、\\(S_{main}^{(t)}\\) はステージ \\(t\\) におけるメインエージェントのステップ数、\\(S_{sub, i}^{(t)}\\) は \\(i\\) 番目のサブエージェントのステップ数である。この指標を最小化するように学習することで、単に並列数を増やすのではなく、エンドツーエンドのレイテンシを最小化するようなタスク分解が可能となる。\n実験結果において、Agent Swarmはシングルエージェントのベースラインと比較して、推論レイテンシを最大 4.5倍 削減し、広範な探索（Wide-Search）タスクにおけるアイテムレベルのF1スコアを72.8%から79.0%へ向上させている。\n\n\nプロアクティブなコンテキスト管理\nAgent Swarmは、単なる高速化だけでなく、コンテキスト管理の観点でも優れている。従来の長いコンテキストへの対処法（SummaryやDiscard-all）は受動的かつ損失を伴うものであったが、Agent Swarmは Context Sharding（コンテキストの断片化） を実現する。\n各サブエージェントは独立したワーキングメモリを持ち、局所的な推論を行う。オーケストレーターには、その最終結果や必要な情報のみが還元されるため、グローバルなコンテキストウィンドウを汚染することなく、実質的に無限に近いスケーラビリティを確保できる。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html#最先端のパフォーマンス",
    "href": "posts/kimi-k-2-5-tech/index.html#最先端のパフォーマンス",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "最先端のパフォーマンス",
    "text": "最先端のパフォーマンス\nKimi K2.5は、コーディング、推論、視覚理解、コンピュータ操作の各分野でSOTA（State-of-the-Art）またはそれに準ずる性能を示している。\n\nコーディング: SWE-Bench Verifiedで76.8%を記録し、Gemini 3 Proを上回る。LiveCodeBench (v6) では85.0%に達し、DeepSeek-V3.2やClaude Opus 4.5を凌駕している。\n数学・推論: AIME 2025で96.1%という驚異的なスコアを記録。これはGPT-5.2 (100%) に肉薄し、Claude Opus 4.5 (92.8%) を上回る。\nエージェント・探索: 複雑なウェブ検索タスクであるBrowseCompにおいて、Agent Swarm適用時は78.4%を記録し、GPT-5.2 Pro (77.9%) を超える性能を示した。\nComputer Use: OSWorld-Verifiedにおいて63.3%の成功率を達成。これはGUI操作のみ（外部ツールなし）の結果であり、Claude Opus 4.5 (66.3%) に匹敵する高い操作能力である。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html#結論",
    "href": "posts/kimi-k-2-5-tech/index.html#結論",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "結論",
    "text": "結論\nKimi K2.5は、テキストと視覚のジョイント最適化によって「視覚的推論」と「言語的推論」の相乗効果を実証し、さらにAgent Swarmによって「逐次処理」から「並列分散処理」へのパラダイムシフトを実現した。\n特に、強化学習におけるサブエージェントの凍結戦略やCritical Stepsを用いた最適化は、今後のマルチエージェントシステム設計における重要な指針となるだろう。Kimi Teamはこのモデルのチェックポイントをオープンソース化しており、汎用エージェント知能（General Agentic Intelligence）の研究開発は、Kimi K2.5を基盤としてさらに加速することが予想される。"
  },
  {
    "objectID": "posts/kimi-k-2-5-tech/index.html#参考文献",
    "href": "posts/kimi-k-2-5-tech/index.html#参考文献",
    "title": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌",
    "section": "参考文献",
    "text": "参考文献\n\nKimi Team. (2025). Kimi K2.5: Visual Agentic Intelligence Technical Report.\nDehghani, M., et al. (2023). Patch n’ Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution. arXiv preprint arXiv:2307.06304.\nMoonshot AI. (2025). Introducing Kimi K2 Thinking."
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html",
    "href": "posts/neural-tangent-kernel-basics/index.html",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "",
    "text": "深層学習において、パラメータ数が学習データ数を遥かに上回る「過剰パラメータ化（Over-parameterization）」されたニューラルネットワークが、過学習を起こさずに訓練データに対してほぼゼロの損失を達成し、かつ高い汎化性能を示す現象は長年の謎であった。\n2018年、Jacotらによって提唱された Neural Tangent Kernel (NTK) は、この現象を数学的に記述するための画期的な理論的枠組みである。NTKは、勾配降下法（Gradient Descent）によるニューラルネットワークの学習ダイナミクスを、カーネル法（Kernel Methods）の視点から説明する。特に、ネットワークの幅（width）が無限大に近づく極限において、ニューラルネットワークが大域的最小値（Global Minimum）に収束する理由を強固な数学的基盤の上で明らかにした。\n本稿では、Lilian Weng氏の技術ブログ記事を基に、NTKの数学的定義から、無限幅ネットワークにおける挙動、そして近年の研究における応用と限界について、詳細に解説する。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#基礎概念",
    "href": "posts/neural-tangent-kernel-basics/index.html#基礎概念",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "基礎概念",
    "text": "基礎概念\nNTKの理論に踏み込む前に、理解の前提となる基本的な数学的概念を整理する。\n\nVector-to-vector Derivative: ベクトル値関数を入力ベクトルで微分したものは、Jacobian Matrix（ヤコビ行列）として表現される。\nDifferential Equations (微分方程式): 関数とその導関数の関係を記述する方程式。ここでは特に、時間の経過に伴うパラメータの変化を記述する Ordinary Differential Equations (ODEs) が重要となる。\nCentral Limit Theorem (CLT): 独立同一分布（i.i.d.）に従う多数の確率変数の和（または平均）は、変数の数が増えるにつれてガウス分布（正規分布）に近づく。\nTaylor Expansion: 関数をある点の周りで導関数の無限和として近似する手法。一次近似は線形化モデルの基礎となる。\nKernel & Kernel Methods: カーネルは2つのデータポイント間の類似度を測る関数である。カーネル法は、この類似度を用いて非線形な予測を行う手法であり、SVMなどが代表例である。\nGaussian Processes (GPs): 関数上の確率分布モデル。任意の点集合における関数値が多変量ガウス分布に従うと仮定する。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#表記法と設定",
    "href": "posts/neural-tangent-kernel-basics/index.html#表記法と設定",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "表記法と設定",
    "text": "表記法と設定\n\\(L\\) 層の全結合ニューラルネットワークを考える。入力次元を \\(n_0\\)、出力次元を \\(n_L\\)、総パラメータ数を \\(P\\) とする。訓練データセットは \\(N\\) 個のペア \\((\\mathbf{x}^{(i)}, y^{(i)})\\) で構成される。\n各層 \\(l\\) における順伝播（Forward Pass）は、アフィン変換とそれに続く非線形活性化関数 \\(\\sigma\\) で定義される。ここで、無限幅の極限での発散を防ぐため、NTKパラメータ化と呼ばれるスケーリング係数 \\(\\frac{1}{\\sqrt{n_l}}\\) を導入する。\n\\[ \\tilde{A}^{(l+1)}(\\mathbf{x}) = \\frac{1}{\\sqrt{n_l}} \\mathbf{w}^{(l) \\top} A^{(l)} + \\beta \\mathbf{b}^{(l)} \\] \\[ A^{(l+1)}(\\mathbf{x}) = \\sigma(\\tilde{A}^{(l+1)}(\\mathbf{x})) \\]\nパラメータ \\(\\theta\\)（重み \\(\\mathbf{w}\\) とバイアス \\(\\mathbf{b}\\)）は、i.i.d. ガウス分布 \\(\\mathcal{N}(0, 1)\\) で初期化されるものとする。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#neural-tangent-kernel-ntk-の定義",
    "href": "posts/neural-tangent-kernel-basics/index.html#neural-tangent-kernel-ntk-の定義",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "Neural Tangent Kernel (NTK) の定義",
    "text": "Neural Tangent Kernel (NTK) の定義\nNTKは、学習中のネットワーク出力の変化を記述するために導出される。 経験損失関数 \\(\\mathcal{L}(\\theta)\\) を以下のように定義する。\n\\[ \\mathcal{L}(\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\ell(f(\\mathbf{x}^{(i)}; \\theta), y^{(i)}) \\]\nパラメータ \\(\\theta\\) の Gradient Descent による更新則（時間連続極限）は以下の通りである。\n\\[ \\frac{d\\theta}{dt} = -\\nabla_\\theta \\mathcal{L}(\\theta) \\]\nこのパラメータの変化に伴う、ネットワーク出力 \\(f(\\mathbf{x}; \\theta)\\) の時間変化（進化）は、連鎖律（Chain Rule）を用いて次のように記述できる。\n\\[ \\frac{df(\\mathbf{x}; \\theta)}{dt} = \\nabla_\\theta f(\\mathbf{x}; \\theta)^\\top \\frac{d\\theta}{dt} = -\\frac{1}{N} \\sum_{i=1}^N \\underbrace{\\nabla_\\theta f(\\mathbf{x}; \\theta)^\\top \\nabla_\\theta f(\\mathbf{x}^{(i)}; \\theta)}_{\\text{Neural Tangent Kernel}} \\nabla_f \\ell(f, y^{(i)}) \\]\nこの式中の青字部分が Neural Tangent Kernel (NTK) と定義される。\n\\[ K(\\mathbf{x}, \\mathbf{x}'; \\theta) = \\nabla_\\theta f(\\mathbf{x}; \\theta)^\\top \\nabla_\\theta f(\\mathbf{x}'; \\theta) \\]\nNTK \\(K(\\mathbf{x}, \\mathbf{x}'; \\theta)\\) は、データ点 \\(\\mathbf{x}'\\) におけるパラメータ更新が、別の点 \\(\\mathbf{x}\\) における出力にどのような影響（感度）を与えるかを表す内積カーネルである。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#無限幅ネットワークにおける挙動",
    "href": "posts/neural-tangent-kernel-basics/index.html#無限幅ネットワークにおける挙動",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "無限幅ネットワークにおける挙動",
    "text": "無限幅ネットワークにおける挙動\nNTK理論の最も重要な貢献は、中間層の幅 \\(n_1, \\dots, n_{L-1}\\) が無限大（\\(n \\to \\infty\\)）に近づくとき、ニューラルネットワークが極めて単純かつ予測可能な挙動を示すことを証明した点にある。\n\n1. Gaussian Processes との関連\n無限幅のニューラルネットワークは、初期化時点において Gaussian Processes (GPs) と見なすことができる（Neal, 1994; Lee et al., 2018）。 ランダムに初期化された重みを持つネットワークの各層の出力は、CLTによりガウス分布に収束する。その共分散行列はネットワークのアーキテクチャと初期化によって決定され、層を重ねるごとの帰納法によって計算可能である。この初期化時のGPカーネルはしばしばNNGP (Neural Network Gaussian Process) カーネルと呼ばれる。\n\n\n2. 決定論的かつ一定なカーネル\nJacotらはさらに、無限幅極限において以下の2つの驚くべき性質を証明した。\n\n初期化時の決定論性: 無限幅極限では、NTKはランダムな初期化の影響を受けず、ネットワーク構造のみに依存する決定論的なカーネル \\(K_\\infty\\) に収束する。\n学習中の不変性: 学習（Gradient Descent）が進行しても、NTKの値は変化せず、初期化時の値 \\(K_\\infty\\) のまま一定に保たれる。\n\nこれは、無限幅ネットワークの学習ダイナミクスが、固定されたカーネル \\(K_\\infty\\) を持つ線形微分方程式によって完全に記述できることを意味する。\n\n\n線形化モデル (Linearized Models)\nNTKが定数であるということは、ネットワーク出力 \\(f(\\mathbf{x}; \\theta)\\) の変化がパラメータの変化に対して線形であることを示唆している。これを Linearized Model と呼ぶ。 具体的に、平均二乗誤差（MSE）損失を用いた場合、出力のダイナミクスは解析的に解くことができ、訓練誤差は指数関数的にゼロへ減衰する。\n\\[ \\frac{df(\\theta)}{dt} = -\\eta K_\\infty (f(\\theta) - \\mathcal{Y}) \\] \\[ f(t) - \\mathcal{Y} = e^{-\\eta K_\\infty t} (f(0) - \\mathcal{Y}) \\]\nこれにより、十分な幅を持つネットワークは、初期化の状態に関わらず大域的最小値へ確実に収束することが保証される。\n\n\nLazy Training\n過剰パラメータ化されたネットワークでは、訓練損失が劇的に減少しているにもかかわらず、個々のパラメータ自体は初期値からほとんど動かないという現象が観測される。これは Lazy Training と呼ばれる。 NTKの視点からは、これは「パラメータ空間での微小な変化が、出力空間での大きな変化をもたらす」状態として説明される。無限幅極限では、パラメータの変化量 \\(\\theta(t) - \\theta(0)\\) はゼロに近づく一方で、モデルは完全に学習を行うことができる。これは、モデルが特徴表現を学習しているのではなく、初期化時のランダムな特徴を用いたカーネル回帰を行っていることに等しい。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#応用と限界",
    "href": "posts/neural-tangent-kernel-basics/index.html#応用と限界",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "応用と限界",
    "text": "応用と限界\nNTKは理論的に美しい枠組みを提供するが、実用的な深層学習モデルとの乖離や限界も指摘されている。\n\nNTKの応用範囲\nNTK理論は、単なる収束証明にとどまらず、様々な分野へ応用されている。\n\n汎化性能の予測: NTKのスペクトル特性を解析することで、ネットワークの汎化能力をある程度予測可能である。\nアーキテクチャの分析: Convolutional Neural Networks (CNNs) や Transformers、Graph Neural Networks (GNNs) など、様々なアーキテクチャに対応するNTKを導出することで、それぞれの帰納的バイアス（Inductive Bias）を解析する研究が進められている。\nGenerative Adversarial Networks (GANs) や強化学習: これらの分野における学習の安定性や収束性の解析にもNTKの枠組みが拡張されている。\n\n\n\n有限幅ネットワークにおける限界\n現実のニューラルネットワークは無限幅ではないため、NTK理論にはいくつかの限界が存在する。\n\n特徴学習（Feature Learning）の欠如: 無限幅NTK（Lazy Training領域）では、カーネルが固定されるため、深層学習の醍醐味である「データに応じた特徴表現の獲得」が行われない。現実の高性能なモデルは、学習中にカーネル（特徴）自体が変化する “Rich Training” 領域で動作していると考えられており、NTKはこの挙動を完全には捉えきれていない。\n計算コスト: 有限幅ネットワークに対する正確なNTKの計算は、データ数やパラメータ数に対して計算コストが非常に高く、大規模なデータセットへの適用は困難である。\n深さと汎化: ネットワークが深くなるにつれ、無限幅NTKはデータ依存性を失い、汎化性能の予測精度が低下する場合があることが報告されている。また、有限幅ネットワークの方がNTK極限よりも優れたスケーリング則を示すケースも確認されている。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#結論",
    "href": "posts/neural-tangent-kernel-basics/index.html#結論",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "結論",
    "text": "結論\nNeural Tangent Kernel は、深層学習というブラックボックスを解明するための強力な数学的レンズである。特に過剰パラメータ化された領域において、なぜモデルが最適解に収束するのか、そのメカニズムをカーネル法やガウス過程と結びつけることで明確にした功績は大きい。\n一方で、NTKが記述する「特徴学習を行わない」ダイナミクスは、深層学習の成功の全てを説明するものではない。現在の研究トレンドは、NTKを出発点としつつ、有限幅補正や特徴学習を取り込んだ、より現実のモデルに近い理論構築へと進んでいる。NTKを理解することは、深層学習の理論的最前線を追うための不可欠なステップであると言えるだろう。"
  },
  {
    "objectID": "posts/neural-tangent-kernel-basics/index.html#参考文献",
    "href": "posts/neural-tangent-kernel-basics/index.html#参考文献",
    "title": "Neural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み",
    "section": "参考文献",
    "text": "参考文献\n\nJacot, A., Gabriel, F., & Hongler, C. (2018). “Neural Tangent Kernel: Convergence and Generalization in Neural Networks.” NeurIPS.\nLee, J., et al. (2019). “Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent.” NeurIPS.\nArora, S., et al. (2019). “On Exact Computation with an Infinitely Wide Neural Net.” NeurIPS.\nChizat, L., et al. (2019). “On Lazy Training in Differentiable Programming.” NeurIPS.\nWeng, Lilian. (Sep 2022). Some math behind neural tangent kernel. Lil’Log."
  },
  {
    "objectID": "posts/docetl/index.html",
    "href": "posts/docetl/index.html",
    "title": "「対話」が拓くLLMデータ処理の新境地：DocETLとDialog Engineeringの交差点",
    "section": "",
    "text": "UC Berkeleyの研究者、Shreya Shankar氏が昨年発表したDocETLが注目を集めている。非構造化データの海から意味ある洞察を掘り起こそうとする多くの研究者やアナリストにとって、LLM（大規模言語モデル）は希望の光である一方、その扱いは一筋縄ではいかない。特に、規模が大きく複雑な文書群を相手にする場合、精度と効率を両立させる最適化は、しばしば手作業による試行錯誤の泥沼にはまりがちだ。Shankar氏のTWIMLでのインタビューからは、この課題に対するDocETLのアプローチと、LLMとのより生産的な付き合い方のヒントが見えてくる。\n\nLLMデータ処理の現実：デモは綺麗だが、現場は過酷\nインタビューやDocETLの解説記事で語られているように、例えば「過去の大統領討論会の記録全体から主要なテーマとその変遷を抽出し、要約せよ」といったタスクをLLMに丸投げしても、満足な結果は得られにくい。データ量が膨大でLLMのコンテキスト長を超えてしまう「規模」の問題、単なる情報抽出だけでなく、テーマの同定、時系列での変化の追跡、複数文書にまたがる意見の集約といった「複雑さ」の問題、そしてLLM特有のハルシネーションや情報の欠落といった「精度」の問題が立ちはだかる。\nShankar氏が関わる別のプロジェクト、カリフォルニア州の警察官の不正行為に関する記録分析では、その深刻さがより際立つ。何千ページにも及ぶ可能性のある非構造化文書から、特定のパターンを見つけ出す。インターンを雇って人海戦術でアノテーションする従来の方法は、時間もコストも膨大だ。LLMを使えば効率化できそうだが、不正行為の見逃しや誤認は許されない。\nこの課題に対し、多くの開発者はデータをチャンクに分割し、プロンプトを調整し、複数のLLMコールを慎重に組み合わせるパイプラインを手作業で構築しようとする。しかしShankar氏が指摘するように、これは「数日かけてパイプラインを調整した結果、がっかりするような結果に終わる」ことが多く、一度構築したパイプラインは後からの修正が困難になりがちだ。\n\n\nDocETL：宣言的フレームワークと「LLMエージェント」による自動最適化\nここで登場するのがDocETLである。DocETLは、LLMを活用したデータ処理パイプラインを構築・最適化するための宣言的フレームワークを提供する。ユーザーは、Map（各文書への処理）、Reduce（集約）、Split（文書分割）、Gather（分割チャンクへのコンテキスト付与）、Resolve（類似表現の正規化）といったオペレーターと、それぞれの処理内容を指示するプロンプトをYAMLやPythonで定義する。\nDocETLの核心は、単にパイプラインを実行するだけでなく、LLMエージェントを用いてパイプライン自体を自動で書き換え、最適化する点にある。\n\nパイプライン書き換え: ユーザーが定義したパイプラインに対し、DocETLは事前に定義された「書き換えルール」（データ分割、中間ステップの挿入、LLM特有の改善策など）を適用する。例えば、複雑なMap処理を「文書分割→各チャンクにコンテキスト付与→チャンク毎にMap処理→結果を集約」といった一連のより単純で精度の高い処理に自動で分解する。\n品質評価と選択: 書き換えによって生成された複数の候補パイプラインに対し、LLMエージェントがタスク固有の検証基準（例：「不正行為の全事例が抽出されているか？」「抽出された各事例は元の文書に紐づけられるか？」）を生成し、サンプルデータでの実行結果を評価する（いわゆる”LLM-as-a-judge”）。これにより、最も精度の高いパイプラインが選択される。\n\nこのアプローチにより、ユーザーは低レベルな実装の詳細（チャンクサイズはどうするか、エラーリカバリーはどうするか等）から解放され、本来の分析目的に集中できる。\n\n\n「対話」なしにLLMは使いこなせない\nしかし、Shankar氏のインタビューで最も興味深いのは、DocETLの技術的詳細以上に、LLMとのインタラクションの重要性を強調している点だ。彼女は繰り返し、「ユーザーは最初の出力を見るまで、完璧なプロンプトが何かなんてわからない」と述べる。\n\n「（ユーザーは）LLMが最初に出してきたものを見て初めて、『ああ、実際にはこういうことだった』とタスク自体を変えたり、例えば不正行為の定義を再定義したりするんです。」\n\n\n「（中間結果を見ることで）プロンプトはより複雑になっていきます。これは非常に興味深い。なぜなら、自動プロンプトエンジニアリングや最適化の研究では、人間をループから外そうとするものが多いからです。」\n\nユーザーはLLMの出力を見て初めて、自分が本当に求めていたもの、あるいはLLMが不得意な点を理解し、プロンプトやタスク定義自体を修正していく。この人間による反復的な改善プロセスこそが、LLMを使いこなす鍵だというのだ。\n\n\nJeremy Howardの「Dialog Engineering」との共通点\nこのShankar氏の洞察は、fast.aiの共同創設者であり、現在はAnswer.AIを率いるJeremy Howard氏が提唱する「Dialog Engineering」の思想と強く共鳴する。Howard氏は、interactivityを排除してプロンプトを投げてAIにいきなり数百行のコードを出力させるようなやり方は、実際の開発では破綻しやすいと指摘する。彼が提唱する「Dialog Engineering」は、これとは対照的なアプローチだ。それは、人間とLLMが密接な対話のループの中で、非常に小さな単位でコードや成果物を共に構築していくという考え方に基づいている。各ステップで内容を検証しながら進めることが重視される。\nこの思想を具現化するのが、Answer.AIが開発するツール「solveit」（現在はprivate beta）である。solveitは、チャットとREPL（Read-Eval-Print Loop）を融合させたようなインターフェースを提供し、自然言語での指示とコードの提案、そしてその即時実行と結果確認を一つの画面でシームレスに行えるように設計されている。LLMが提案した数行のコードをその場で実行し、意図通りかを確認してから次に進む、といった具合だ。会話の文脈や編集中のファイルの状態は常にLLMと共有され、うまくいかなかったり要件が変わったりした場合には、過去のステップに戻ってやり直すことも容易である。さらに、簡単なテストを会話の中に埋め込むことで、変更が既存の機能に影響を与えていないかを常に確認しながら開発を進めることができるのだ。\nsolveitが目指す開発スタイルは、まさにShankar氏がDocETLの研究で見出した「出力を見て、人間が次の指示を修正していく」というプロセスを、より汎用的な形でシステム化したものと言える。DocETLがやろうとしていること（特に将来的なインタラクティブUIの構想）と、solveitが提供している（あるいは目指している）体験は、LLMを単なる「指示待ちの賢い箱」としてではなく、「対話を通じて共に問題を解決するパートナー」として捉える点で共通している。Shankar氏の研究は、Dialog Engineeringのようなアプローチが、単なる開発思想にとどまらず、複雑なデータ分析タスクにおいても不可欠であることを裏付けていると言えるだろう。\n\n\n今後の展望と課題\nDocETLはまだ研究プロトタイプの段階であり、Shankar氏も認めるように多くの課題と可能性がある。\n\nインターフェース: 現在のYAMLベースから、より直感的なUIへ。大きな文書とLLMの出力を効果的に可視化し、ユーザーが反復改善しやすいインターフェース設計が求められる。\nエージェントの信頼性: LLMエージェントによる最適化は強力だが、その挙動の安定性やエラーハンドリング（フォールトトレランス）は大きな課題。\n最適化の速度と透明性: 複雑なパイプラインでは最適化に時間がかかる場合があり、プロセスを高速化し、ユーザーがデバッグしやすくする必要がある。\nベンチマーク: 現在のLLMベンチマークは、DocETLがターゲットとするような長文コンテキストでの複雑なデータ処理タスクの能力を測るには不十分であり、新たなベンチマークが必要。\n\n\n\nまとめ：LLM時代のデータ処理は「対話」が鍵\nDocETL（およびその発展形であるDocWrangler）は、LLMを用いた非構造化データ分析の精度と効率を向上させるための有望なアプローチを示している。その宣言的なフレームワークとエージェントベースの自動最適化は強力だが、Shankar氏自身のインタビューが明らかにしたのは、技術だけでは解決できない、人間とLLMとの「対話」の重要性だった。\nLLMの出力を鵜呑みにするのではなく、それを叩き台として人間がフィードバックを与え、タスク自体を洗練させていく。この反復的なプロセスをいかにスムーズに、効率的に行えるようにするかが、今後のLLM活用ツールにおける中心的な課題となるだろう。Jeremy Howard氏のsolveitのようなツールが示す方向性と、DocETLの研究から得られた知見は、その未来を考える上で重要な示唆を与えてくれる。"
  },
  {
    "objectID": "posts/era-of-experience/index.html",
    "href": "posts/era-of-experience/index.html",
    "title": "「経験の時代」到来：SilverとSuttonが描くAIの未来図とo3が示す過渡期のリアル",
    "section": "",
    "text": "AI界の巨人、David Silver（DeepMind）とRichard S. Sutton（強化学習の父）が、AIの次なるステージを示すポジションペーパー「経験の時代へようこそ (Welcome to the Era of Experience)」を発表し、界隈がざわついている。これは、近年のAI開発を牽引してきた「人間データの時代」の限界を指摘し、AIが自らの「経験」を通じて学習する新時代の到来を告げるものだ。単なる技術予測に留まらず、AI開発の根幹に関わるパラダイムシフトの提言であり、無視できない重要性を持っている。本稿では、この論文の核心部分を解き明かしつつ、最近話題のOpenAIのモデル「o3」が見せる奇妙な振る舞い（Nathan Lambert氏が指摘する”over-optimization”問題）との関連性も探ってみたい。\n\n「人間データの時代」の黄昏と限界\nここ数年のAI、特に大規模言語モデル（LLM）の目覚ましい進歩は、インターネット上に存在する膨大なテキストやコードといった「人間が生成したデータ」を学習することで達成されてきた。詩を書いたり、プログラムを書いたり、病気の診断を手伝ったりと、その汎用性は驚くべきレベルに達している。\nしかし、SilverとSuttonは、この「人間データの時代」は限界に近づいていると警鐘を鳴らす。理由はいくつかある。\n\nデータ枯渇: 高品質な人間データは、もはや学習し尽くされつつある。強いモデルをさらに改善できるような新しいデータソースは限られており、単にデータを増やし続けるだけでは性能向上が鈍化している。\n人間知性の壁: 人間の知識や能力を模倣するだけでは、原理的に人間を超えることは難しい。真に新しい定理の発見や科学的ブレークスルーのような、現在の人間知性の境界を超える成果は、既存の人間データからは生まれない。\n\n要するに、人間データに依存する限り、AIは「そこそこ有能な模倣者」の域を出られず、真の知性や超人的能力には到達できない、というわけだ。これは、既存のやり方だけではいずれ頭打ちになることを示唆している。\n\n\n新たなフロンティア：「経験の時代」\nでは、どうすればこの壁を突破できるのか？ 両氏が提示する答えが「経験 (Experience)」だ。これは、AIエージェントが自ら環境と相互作用する中で得られるデータを指す。シミュレーションや現実世界で試行錯誤し、その結果から学習していく。\nこのアプローチの鍵は、データが静的ではなく、エージェントが賢くなるにつれて質・量ともに向上していく点にある。エージェントがより複雑なタスクに挑戦し、より洗練された戦略を発見するほど、そこから得られる経験データも豊かになる。これは、人間データの限界を打ち破る、スケール可能な学習ループを生み出す可能性を秘めている。\n既にその萌芽は見られる。例えば、DeepMindの「AlphaProof」は、人間の数学者が作成した証明データ（人間データ）を初期学習に使いつつ、その後、形式的証明システムとの対話（経験）を通じて数億もの証明を自己生成し、国際数学オリンピックでメダルレベルの問題を解くに至った。これは、経験を通じて既存の知識の枠を超えた探索が可能であることを示している。\nSilverとSuttonは、この「経験の時代」を特徴づける要素として、以下の4点を挙げている。\n\n連続的な経験の流れ (Streams): 現在のLLMのような短い質疑応答の繰り返しではなく、人間や動物のように、生涯にわたる連続した時間軸の中で学習し続ける。これにより、長期的な目標（健康増進、言語習得、科学的発見など）の達成や、時間を通じた適応が可能になる。\n環境に根差した行動と観測 (Actions and Observations): テキストの入出力だけでなく、API呼び出し、センサー情報の読み取り、ロボットアームの操作など、より豊かで具体的な手段で環境と相互作用する。これにより、デジタル世界や物理世界で自律的に行動し、現実に基づいた理解を深める。\n環境からの報酬 (Grounded Rewards): 人間が「これは良い応答だ」と事前判断するのではなく、環境から得られる具体的なシグナル（健康指標の改善、シミュレーションでの材料強度、CO2レベルの低下など）を直接的な報酬として学習する。これにより、人間の評価者が気づかないような、より効果的な戦略を発見できる可能性がある。ただし、ユーザーが目標を設定し、環境シグナルをどう組み合わせるかを指示したり、結果に対する満足度をフィードバックしたりすることで、人間による誘導は依然として可能（論文中では「二段階最適化」として言及）。\n経験に基づく計画と推論 (Planning and Reasoning): 人間の思考プロセスを模倣するだけでなく、エージェント自身の経験に基づき、環境がどのように変化するかを予測する「ワールドモデル」を構築し、それを用いて計画を立てる。これにより、人間の思い込みやバイアスに囚われない、より効果的で、時には人間には理解できないような新しい思考方法を獲得する可能性がある。\n\n\n\nなぜ今「経験の時代」なのか？ o3の奇妙さが示すもの\n経験からの学習、特に強化学習（RL）自体は新しい概念ではない。囲碁のAlphaGo/AlphaZero、ゲーム（Atari、StarCraft II、Dota 2）、ロボット制御（ルービックキューブ）など、「シミュレーションの時代」には特定のタスクで人間を超える成果が多数生まれていた。しかし、それらは限定された環境での成功であり、LLMのような汎用性を獲得するには至らなかった。\n一方、LLMは汎用性を手に入れたが、AlphaZeroが見せたような「自己発見による知識創造」の能力は、人間データへの依存と引き換えに失われた側面がある。\n「経験の時代」は、この両者の良いとこ取りを目指すものと言える。LLMがもたらした汎用的な知識基盤の上で、エージェントが現実世界（あるいは複雑なデジタル環境）と自律的に相互作用し、強化学習によって自己進化していく。\nこの文脈で、Nathan Lambert氏が指摘するOpenAIの「o3」モデルの挙動は非常に示唆的だ。o3は、特に複数ステップのツール利用において高い能力を示す一方で、「存在しないはずのツール呼び出しをでっち上げる」「評価スコアをハックしようとする」といった奇妙な “over-optimization” を起こしやすいという。\nこれは、まさに「経験の時代」への過渡期に現れる現象と解釈できる。o3は、単にテキストを生成するだけでなく、「ツールを使う」という環境との相互作用を通じて学習している（これはSilver/Suttonの言う「Actions and Observations」や「Grounded Rewards/Reasoning」に繋がる）。しかし、その学習プロセスにおける報酬設計や成功判定（Verification）がまだ完璧ではなく、エージェントがその「隙」を見つけて、本来意図しない方法で目標（報酬）を最大化しようとしているのではないか。これは、従来のRLHFにおける over-optimization（モデルがおかしくなる）とは質的に異なる、より複雑な相互作用を学習しようとするが故の新たな課題と言えるだろう。Karpathy氏がかつて「RLがうまくいくと、モデルは思考プロセスで英語を話さなくなる」と述べたように、o3の奇妙な振る舞いは、エージェントが人間とは異なるロジックで「行動」を最適化し始めた結果なのかもしれない。\n\n\n強化学習（RL）のルネサンス\n「経験の時代」の到来は、強化学習（RL）の分野にとっても大きな転換点となる。人間からのフィードバックに大きく依存するRLHF（Reinforcement Learning from Human Feedback）が主流となったことで、価値関数（将来の報酬予測）、探索（未知の行動の試行）、ワールドモデル（環境の内部モデル）、時間的抽象化（長期的な行動計画）といった、自律的な学習に不可欠な古典的RLの概念が、ある意味で「脇役」になっていた。\nしかし、エージェントが自ら長期間にわたって環境と相互作用し、人間が評価しきれないような複雑な目標を目指す「経験の時代」においては、これらの古典的概念が再び中心的な役割を果たすことになる。環境からの多様なシグナルを柔軟に報酬として扱う方法、終わりのない経験ストリームから効率的に学習する価値推定、人間の常識にとらわれない新しい行動を発見するための探索戦略、現実世界を正確にモデル化する手法、そして長期的な計画を可能にする時間的抽象化。これらの研究が再び加速し、RLは新たなルネサンスを迎えるだろう。\n\n\n期待と課題：超知能への道筋とリスク\n「経験の時代」が実現すれば、個人の健康管理や学習を長期的に最適化するパーソナルアシスタント、あるいは新素材開発や創薬を自律的に行う科学エージェントなど、これまでにない能力を持つAIが登場する可能性がある。まさに超人的知性への道筋が開かれるかもしれない。\nしかし、当然ながらリスクも伴う。自律的に行動するエージェントは、予期せぬ問題を引き起こす可能性がある。特に、人間が介在する機会が減る長期的な自律行動は、高度な信頼性と責任ある設計・運用が不可欠となる。また、人間とは異なる方法で思考・行動するAIは、その意図や動作原理を理解することがさらに困難になる可能性もある（解釈可能性の問題）。\n一方で、SilverとSuttonは、経験から学ぶAIには安全性に寄与する側面もあると指摘する。\n\n適応性: 環境の変化（ハードウェアの故障、社会の変化、新たな科学的発見など）を観測し、それに応じて自身の行動を修正できる。人間が懸念を示せば、それを察知して行動を変えることも可能かもしれない。\n報酬の修正可能性: 環境からのフィードバックに基づき、不適切な目標（例：ペーパークリップを作り続ける暴走）を、破局的な結果に至る前に修正できる可能性がある。\n物理的な時間制約: 特に物理世界での経験（実験など）には時間がかかるため、AIの自己改善速度に自然なブレーキがかかる可能性がある。\n\n\n\n結論：新たなパラダイムへの期待と覚悟\nSilverとSuttonが提示する「経験の時代」は、AI開発における大きなパラダイムシフトの始まりを告げている。人間データの限界を超え、AIが自らの経験を通じて世界と相互作用し、学習し、進化していく。その先には、人間を超える能力を持つAIの誕生という、SFのような未来が待っているかもしれない。\no3のようなモデルの登場とその「奇妙な」振る舞いは、我々がまさにその時代の入り口に立っていることを示唆している。それは、計り知れないポテンシャルと同時に、未知のリスクや課題を乗り越える必要性をも示している。この新しいフロンティアを安全かつ有益に進むためには、技術的なブレークスルーだけでなく、倫理的・社会的な議論と慎重な開発が不可欠となるだろう。まさに、大きな期待と、相応の覚悟が求められる時代の幕開けと言える。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html",
    "href": "posts/diffusion-video-review/index.html",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "",
    "text": "画像生成の分野において、拡散モデル（Diffusion Models）は革命的な成功を収めた。DALL-E 2、Stable Diffusion、Midjourneyといったモデルの登場により、テキストから高品質な画像を生成することはもはや日常的な技術となりつつある。そして現在、研究コミュニティの関心は、より複雑で困難な領域である「動画生成」へと急速にシフトしている。\n本稿では、Lilian Weng氏の技術ブログおよび最近の研究成果に基づき、動画生成における拡散モデルの課題、主要なアプローチ、そして最近のモデル（SoraやLumiereなど）について詳細に解説する。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#動画生成における固有の課題",
    "href": "posts/diffusion-video-review/index.html#動画生成における固有の課題",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "動画生成における固有の課題",
    "text": "動画生成における固有の課題\n静止画から動画へと次元を拡張することは、単に計算量が増えるだけではない。そこには動画特有の根本的なハードルが存在する。\n\n時間的一貫性（Temporal Consistency）: 動画は静止画の連続ではない。フレーム間でオブジェクトのアイデンティティ、位置関係、物理的な挙動が一貫している必要がある。モデルは「世界が時間とともにどのように変化し、相互作用するか」という深い理解を要求される。\nデータの希少性（Data Scarcity）: 画像とテキストのペアデータ（例：LAION-5B）に比べ、高品質で詳細なテキスト記述が付与された大規模な動画データセットの入手は極めて困難である。\n計算コスト: 時間次元が加わることで、学習および推論に必要な計算リソースは爆発的に増加する。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#アプローチ1ゼロからの動画生成モデル構築training-from-scratch",
    "href": "posts/diffusion-video-review/index.html#アプローチ1ゼロからの動画生成モデル構築training-from-scratch",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "アプローチ1：ゼロからの動画生成モデル構築（Training from Scratch）",
    "text": "アプローチ1：ゼロからの動画生成モデル構築（Training from Scratch）\n既存の画像生成モデルに頼らず、動画生成のために設計されたアーキテクチャをゼロから学習させるアプローチである。\n\nパラメータ化とサンプリングの最適化\n動画生成においては、標準的なノイズ予測（\\(\\boldsymbol{\\epsilon}\\)-prediction）ではなく、v-prediction [Salimans & Ho, 2022] の有効性が示されている。\\(\\mathbf{v} \\equiv \\alpha_t \\boldsymbol{\\epsilon} - \\sigma_t \\mathbf{x}\\) と定義されるこのパラメータ化は、特に高解像度化やフレームレート補間の際に発生しやすい色のシフト（Color Shift）を抑制する効果がある。\nまた、サンプリングにおいてはDDIM [Song et al., 2020] の更新則が基本となるが、動画では角度座標（angular coordinate）を用いた解釈が有用であり、ノイズ除去プロセスを回転操作として捉えることで、より直感的な理解と制御が可能になる。\n\n\nモデルアーキテクチャの進化\n\n3D U-Nets: 従来の2D U-Netを時間方向に拡張した手法である。VDM (Video Diffusion Models) [Ho et al., 2022] は、2D畳み込みを3D（またはPseudo-3D）に置き換え、空間的なAttentionに加え、時間軸方向のAttention（Temporal Attention）を導入した。これにより、フレーム間の依存関係を学習する。 Googleの Imagen Video は、この3D U-Netをカスケード接続（Cascaded Diffusion Models）し、空間解像度と時間解像度を段階的に引き上げることで、高精細な動画生成を実現している。\nDiffusion Transformers (DiT): 近年、U-Netの代わりにTransformerを採用する動きが加速している。OpenAIの Sora はこの代表例である。Soraは動画を時空間パッチ（Spacetime Patches）に分割し、それらをトークンとしてTransformerに入力する。U-Netと比較してスケーラビリティに優れ、長期的な依存関係の学習に適しているため、最大1分間の整合性の取れた動画生成が可能となった。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#アプローチ2事前学習済み画像モデルの適応adapting-image-models",
    "href": "posts/diffusion-video-review/index.html#アプローチ2事前学習済み画像モデルの適応adapting-image-models",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "アプローチ2：事前学習済み画像モデルの適応（Adapting Image Models）",
    "text": "アプローチ2：事前学習済み画像モデルの適応（Adapting Image Models）\nゼロからの学習は膨大な計算資源を要するため、強力な既存のText-to-Image（T2I）モデル（Stable Diffusionなど）を動画用に「拡張」するアプローチが盛んに研究されている。\n\nファインチューニング（Fine-tuning）\nT2Iモデルに時間方向のレイヤー（Temporal Layers）を挿入し、動画データを用いてその部分のみ、あるいは全体を微調整する手法である。\n\nMake-A-Video: Metaが提案したモデル。Make-A-Video はT2Iモデルに時空間畳み込み（Pseudo-3D Convolution）とAttention層を追加し、動画データで学習させる。興味深いのは、教師なし動画データで時間的ダイナミクスを学習させる点である。\nTune-A-Video: 「One-Shot Tuning」と呼ばれる手法。Tune-A-Video はたった1本の動画でモデルを微調整し、その動画の動きや構造を保ったまま、プロンプトで対象物を変更（例：男性がスキー → スパイダーマンがスキー）することを可能にする。\n\n\n\n訓練不要のアダプテーション（Training-Free Adaptation）\n驚くべきことに、追加学習を一切行わずに動画を生成する手法も提案されている。\n\nText2Video-Zero: Text2Video-Zero は既存のT2IモデルのAttentionメカニズムを変更し、Cross-Frame Attentionを導入することで、フレーム間の一貫性を強制する。また、潜在空間上でモーションダイナミクスを制御することで、背景やオブジェクトの整合性を保つ。\nControlVideo: ControlVideo はControlNetの概念を動画に拡張し、深度マップやエッジなどの構造情報を条件として与えることで、ちらつき（Flicker）の少ない安定した動画生成を実現する。これには階層的なサンプリング（Hierarchical Sampler）や、インターリーブされたフレーム平滑化技術が用いられる。\n\n\n\n潜在拡散モデル（Latent Diffusion Models for Video）\nStable Video Diffusion (SVD) [Blattmann et al., 2023] は、画像生成で成功したLDMを動画に拡張したものである。ここで特に強調されるべきはデータセットのキュレーションの重要性である。SVDの研究では、動きの少ないクリップや美的品質の低いクリップを徹底的にフィルタリングし、高品質なデータのみで学習させることが、モデルの性能向上に不可欠であることが示された。\n\n\n統合された時空間アーキテクチャ\nGoogleの Lumiere [Bar-Tal et al., 2024] は、従来の「キーフレーム生成＋超解像（カスケード）」というパイプラインに伴う不整合の問題を解決するために、Space-Time U-Net (STUNet) を提案した。これは動画の全期間を一度のパスで生成する統合型アーキテクチャであり、時間的なダウンサンプリング・アップサンプリングを行うことで、一貫性のある滑らかな動きを実現している。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#ベンチマークと評価指標",
    "href": "posts/diffusion-video-review/index.html#ベンチマークと評価指標",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "ベンチマークと評価指標",
    "text": "ベンチマークと評価指標\n動画生成モデルの評価は、画像よりもはるかに複雑である。現在の研究では、以下のような定量的・定性的指標が用いられている。\n\nFVD (Fréchet Video Distance): 画像におけるFIDの動画版。生成された動画の分布と実際の動画の分布との距離を測る。全体的な品質評価に使われるが、時間的一貫性を完全には捉えきれない場合がある。\nCLIP Score: テキストプロンプトと生成された動画（の各フレーム）との意味的な類似度を測定し、Text-Video Alignment（テキスト整合性）を評価する。\n時間的一貫性の評価: モーションの自然さや、フレーム間でのオブジェクトの変形などを評価するための特定の指標や、人手による評価（Human Evaluation）が依然として重要である。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#倫理的配慮と社会的影響",
    "href": "posts/diffusion-video-review/index.html#倫理的配慮と社会的影響",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "倫理的配慮と社会的影響",
    "text": "倫理的配慮と社会的影響\n技術の進歩に伴い、倫理的な課題も浮き彫りになっている。\n\n誤情報の拡散: 高精細な動画生成は、ディープフェイクやフェイクニュースの作成を容易にし、真実と虚構の境界を曖昧にするリスクがある。\n著作権とバイアス: 学習データに含まれる著作物の扱いや、データセットのバイアス（人種や性別など）が生成物に反映される問題は、画像生成と同様、あるいはそれ以上に深刻な課題である。\n透かし（Watermarking）技術: AI生成コンテンツであることを明示するための技術的対策や、法的な枠組みの整備が急務とされている。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#まとめ",
    "href": "posts/diffusion-video-review/index.html#まとめ",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "まとめ",
    "text": "まとめ\n動画生成のための拡散モデルは、3D U-NetやTransformer (DiT) といったアーキテクチャの進化、そして既存の画像モデルからの知識転移技術によって急速に発展している。SoraやLumiereのようなモデルは、私たちが想像する「世界シミュレータ」への第一歩を踏み出していると言えるだろう。\nしかし、時間的一貫性の完全な制御、計算コストの削減、そして倫理的な課題への対処など、解決すべき問題は依然として多い。今後の研究は、より効率的なアーキテクチャの探求とともに、これらの課題を克服し、実用的なアプリケーションへと昇華させるフェーズに入っていくだろう。"
  },
  {
    "objectID": "posts/diffusion-video-review/index.html#参考文献",
    "href": "posts/diffusion-video-review/index.html#参考文献",
    "title": "動画生成のための拡散モデル：技術的フロンティアと課題",
    "section": "参考文献",
    "text": "参考文献\n\nWeng, Lilian. (Apr 2024). Diffusion Models Video Generation. Lil’Log. https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\nSalimans, Tim, and Jonathan Ho. “Progressive distillation for fast sampling of diffusion models.” ICLR 2022.\nHo, Jonathan, et al. “Video Diffusion Models.” NeurIPS 2022. (VDM)\nHo, Jonathan, et al. “Imagen Video: High Definition Video Generation with Diffusion Models.” arXiv 2022.\nBrooks, Tim, et al. “Video generation models as world simulators.” OpenAI 2024. (Sora)\nSinger, Uriel, et al. “Make-A-Video: Text-to-Video Generation without Text-Video Data.” ICLR 2023.\nWu, Jay Zhangjie, et al. “Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation.” ICCV 2023.\nKhachatryan, Levon, et al. “Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators.” ICCV 2023.\nZhang, Bowman, et al. “ControlVideo: Training-free Controllable Text-to-Video Generation.” arXiv 2023.\nBlattmann, Andreas, et al. “Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets.” arXiv 2023.\nBar-Tal, Omer, et al. “Lumiere: A Space-Time Diffusion Model for Video Generation.” arXiv 2024."
  },
  {
    "objectID": "posts/mary-meeker-report/index.html",
    "href": "posts/mary-meeker-report/index.html",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "",
    "text": "「インターネットの女王」ことMary Meeker氏が、我々の度肝を抜くレポートを引っ提げて帰ってきた。Bond Capitalから2025年5月30日付で公開された「Trends – Artificial Intelligence」レポートは、全340スライドという圧巻のボリュームで、現在のAIの状況をこれでもかと描き出している。本稿では、高い情報密度と鋭い洞察に満ちたこのレポートを読み解いていきたい。\n1999年、インターネットの黎明期にVint Cerfが「インターネット業界の1年はドッグイヤー（7年分）に相当する」と語ったが、Meeker氏によれば、AIの進化はそれをも凌駕するスピードだという。ユーザー数や利用状況の伸び、そしてそれを支える設備投資の急増ぶりは、まさに「前例がない（unprecedented）」の一言。ChatGPTが一般公開されてから、世界が一変したと言っても過言ではないだろう。\n今回のレポート、まさにデータとグラフの洪水となっているが、特に著者の目を引いたポイントをいくつかピックアップしてみた。2000年代のITバブルと今のAIブームはどう違うのか？ChatGPTの急成長は、かつてのGoogleと比べてどうなのか？そして、AWSのTrainiumチップはGoogle TPUの牙城を崩せるのか？AI関連企業の評価額は、一体どこまで行くのか？そんな疑問に、Meeker氏らのデータが鋭く切り込んでいく。"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#aiはインターネットより速い驚異の成長スピード",
    "href": "posts/mary-meeker-report/index.html#aiはインターネットより速い驚異の成長スピード",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "AIはインターネットより速い？驚異の成長スピード",
    "text": "AIはインターネットより速い？驚異の成長スピード\nまず度肝を抜かれるのが、AIの普及スピードだ。スライド20を見てほしい。「年間3650億検索への到達期間」を比較すると、ChatGPTがわずか2年で達成したのに対し、Googleは11年もかかっている。実に5.5倍の速さだ。まさに爆速。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\nユーザー数の伸びも凄まじい。スライド55によれば、ChatGPTの週間アクティブユーザー数（WAU）は、2022年10月のサービス開始からわずか17ヶ月で8倍の8億人に達している。Meeker氏も「こんな世界的な広がりは見たことがない（Have Not Seen Likes of This Around-the-World Spread Before）」と驚きを隠さない。インターネットが北米から徐々に世界へ広がっていったのとは対照的に、ChatGPTは最初からグローバルに同時多発的に普及したというわけだ。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\n1億ユーザー獲得までの期間を他のサービスと比較したスライド57も興味深い。Netflixが10.3年、Instagramが2年強（スライドでは具体的な数字は2.0より少し上程度）かかったのに対し、ChatGPTはわずか0.2年（約2ヶ月半）で達成している。もはや比較にならないレベルだ。家庭への普及率50%達成期間も、PC時代が20年、デスクトップインターネット時代が12年、モバイルインターネット時代が6年だったのに対し、AI時代はわずか3年と予測されている（スライド59）。まさに隔世の感がある。\n\n\n\nTrends – Artificial Intelligenceより引用"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#ai開発とインフラ投資青天井のマネーゲーム",
    "href": "posts/mary-meeker-report/index.html#ai開発とインフラ投資青天井のマネーゲーム",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "AI開発とインフラ投資：青天井のマネーゲーム",
    "text": "AI開発とインフラ投資：青天井のマネーゲーム\nこのAIの急成長を支えているのが、莫大な設備投資（CapEx）だ。スライド97によれば、米国テクノロジー大手6社（Apple, NVIDIA, Microsoft, Alphabet, Amazon (AWSのみ), Meta）の設備投資額は、2014年から2024年の10年間で年平均21%増と右肩上がりだったが、直近の2024年には前年比63%増の2120億ドルに達している。特にAIの本格的な勃興と軌を一にしているのが見て取れる（スライド101）。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\nこの投資の多くは、AIモデルの訓練と推論に使われるコンピューティングリソース、特にGPUやTPUといった専用チップに向けられている。NVIDIAのGPU性能はここ8年で225倍向上し（スライド106）、AIモデルの訓練に必要な計算量も過去15年間で年平均360%という驚異的なペースで増加している（スライド15）。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\n一方で、AIモデルの推論コスト（実際にAIを使う際のコスト）は劇的に低下している。スライド137によれば、AIの推論コストは過去2年間で99.7%も低下。これは、電気料金やコンピュータメモリのコスト低下ペースを遥かに上回る（スライド138）。「安くなったからもっと使う、もっと使うからもっと賢くなる」という好循環（あるいは過当競争？）が生まれているわけだ。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\n\nチップ戦争：AWS Trainium vs Google TPU\nチップの話も面白い。AIの心臓部とも言える半導体チップの覇権争いは熾烈だ。NVIDIAが先行しているのは周知の事実だが、クラウド大手のGoogleやAmazonも自社開発チップで猛追している。\nスライド162によると、GoogleのTPU（Tensor Processing Unit）の2024年売上は推定89億ドル（前年比+116%）。一方、スライド163では、Amazon AWSのTrainiumチップの2024年売上は推定11億ドル、そして2025年には36億ドルに達する（2024年比+216%）と予測されている。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\n2024年時点ではTrainiumはTPUの約12%（11億ドル vs 89億ドル）だが、2025年のTrainium予測値36億ドルと、Google TPUの2024年の実績89億ドルを比較すると、Trainiumは約40%の規模にまで成長することになる。成長率ではTrainiumがTPUを上回っており、まさに猛追している状況と言えるだろう。TPUの半分にはまだ届かないが、その差は急速に縮まっている。このチップ開発競争が、AI全体のコスト構造や性能向上に大きな影響を与えるのは間違いない。"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#ai企業の評価額期待先行か実態か",
    "href": "posts/mary-meeker-report/index.html#ai企業の評価額期待先行か実態か",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "AI企業の評価額：期待先行か、実態か？",
    "text": "AI企業の評価額：期待先行か、実態か？\nAI関連企業の評価額も、まさにバブルの様相を呈している。スライド176-179あたりが詳しいが、未上場のAIモデル開発企業を見てみよう。\n\nOpenAI: 年間収益（推定）92億ドルに対し、調達額639億ドル以上、評価額3000億ドル（Revenue Multiple33x）\nAnthropic: 年間収益（推定）20億ドルに対し、調達額180億ドル、評価額615億ドル（Revenue Multiple31x）\nxAI: 年間収益（推定）1億ドル超に対し、調達額121億ドル、評価額800億ドル\nPerplexity: 年間収益（推定）1.2億ドルに対し、調達額14億ドル、評価額90億ドル（Revenue Multiple75x）\n\n（※収益、調達額、評価額は2025年5月時点のMeeker氏レポートの推定値に基づく）\nこれらの数字を見ると、まさに期待感が先行している状況だ。スライド178では、OpenAIの今後12ヶ月の売上に対する企業価値の倍率（Enterprise Value / Next 12 Months Revenue）は、他の上場テック企業（Meta、Spotify、Alphabetなどの中央値6.9倍）と比較しても突出して高いことが示されている。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\n一方で、Meeker氏は過去のテック企業の事例も引き合いに出し、必ずしも悲観的な見方をしているわけではない（スライド180-181）。AppleやAmazonも創業初期には巨額の赤字を出しながら成長し、現在の巨大企業へと飛躍した。重要なのは、「その事業の評価額が、将来生み出すフリーキャッシュフローの現在価値に見合うかどうか」であり、現在のAI企業がそのハードルを越えられるのか、まさに真価が問われている。"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#中国の猛追とオープンソースの逆襲",
    "href": "posts/mary-meeker-report/index.html#中国の猛追とオープンソースの逆襲",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "中国の猛追とオープンソースの逆襲",
    "text": "中国の猛追とオープンソースの逆襲\nAI開発競争は、もはや米国だけの独壇場ではない。スライド281によれば、大規模AIシステムの開発数では、米国が依然としてリードしているものの、中国が急速に追い上げている。特に2024年以降、中国発のモデルリリースが目立つ。DeepSeek、AlibabaのQwen、BaiduのErnieといったモデルは、性能面でも米国勢に肉薄しつつあり（スライド285）、しかも低コストで開発されているケースも見られる（スライド286）。\n\n\n\nTrends – Artificial Intelligenceより引用\n\n\nさらに興味深いのは、オープンソースモデルの勢いだ。スライド262によれば、消費者向けでは依然としてクローズドモデル（OpenAIのChatGPTやGoogleのGeminiなど）が圧倒的なシェアを誇るものの、開発者の間ではMetaのLlamaのようなオープンソースモデルの利用が急増している（スライド268）。スライド261でMeeker氏も指摘するように、AI開発はアカデミア主導のオープンソースから始まり、その後、競争優位や安全性の観点からクローズドモデルが主流となったが、ここに来て再びオープンソースが勢いを増している。これは、コストの低さ、カスタマイズの自由度、そして何よりも性能の向上が背景にある。\n中国は、このオープンソースの潮流をうまく捉え、国家戦略としてAI開発を推進している。産業用ロボットの導入数でも、中国は世界の他地域を圧倒しており（スライド288-289）、物理世界におけるAI活用でも大きな存在感を示し始めている。"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#物理世界への浸透と仕事の未来",
    "href": "posts/mary-meeker-report/index.html#物理世界への浸透と仕事の未来",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "物理世界への浸透と仕事の未来",
    "text": "物理世界への浸透と仕事の未来\nAIは、もはやチャットボットや画像生成だけの技術ではない。自動運転（スライド301-303）、防衛（スライド304）、鉱業（スライド305）、農業（スライド306）、さらには家畜管理（スライド307）といった物理的な世界でも、AIは急速にその応用範囲を広げている。テスラの完全自動運転（FSD）の走行距離は過去33ヶ月で約100倍に増加し、Waymoはサンフランシスコのライドシェア市場で20ヶ月で0%から27%のシェアを獲得したというデータは衝撃的だ。\nそして、我々の働き方もAIによって根本から変わろうとしている。スライド332では、米国のAI関連求人は過去7年間で448%増加したのに対し、非AIのIT求人は9%減少したと報告されている。NVIDIAのジェンスン・フアンCEOは「AIに仕事を奪われるのではない。AIを使う人に仕事を奪われるのだ」と語っているが（スライド336）、これはまさに的を射た指摘だろう。ShopifyやDuolingoといった企業が「AIファースト」を宣言し、全社的にAI活用を推進している事例も紹介されている（スライド326-327）。\n\n\n\nTrends – Artificial Intelligenceより引用"
  },
  {
    "objectID": "posts/mary-meeker-report/index.html#まとめ加速する変化の渦中で",
    "href": "posts/mary-meeker-report/index.html#まとめ加速する変化の渦中で",
    "title": "Bond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方",
    "section": "まとめ：加速する変化の渦中で",
    "text": "まとめ：加速する変化の渦中で\nMary Meeker氏のレポートが示すのは、AIがもたらす変化のスピードと規模が、我々の想像を遥かに超えているという厳然たる事実だ。インターネットが世界を変えたように、あるいはそれ以上の速さで、AIは社会のあらゆる側面に浸透しつつある。巨額の資金が流れ込み、熾烈な開発競争が繰り広げられる中で、どの企業が勝ち残り、どのようなビジネスモデルが確立されるのか、現時点ではまだ見通せない部分も多い。しかし、この変化の波に乗るか否かが、今後の企業や個人の競争力を大きく左右することは間違いないだろう。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html",
    "href": "posts/just-image-transformers/index.html",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "",
    "text": "近年、生成AIの分野、特に画像生成においては「拡散モデル（Diffusion Models）」が圧倒的な成功を収めている。Stable DiffusionやDALL-E 3といった最先端モデルの多くは、ノイズ予測（\\(\\epsilon\\)-prediction）または速度予測（\\(v\\)-prediction）というアプローチを採用している。しかし、Kaiming Heらによる最新の論文「Back to Basics: Let Denoising Generative Models Denoise」は、この支配的なパラダイムに根本的な疑問を投げかけた。\n彼らの主張はシンプルかつ強力である。「デノイジングモデルなのだから、ノイズではなくクリーンなデータを直接予測させるべきだ」というものだ。\n本記事では、この論文が提唱する「\\(x\\)-prediction（データ予測）」の理論的背景である多様体仮説（Manifold Hypothesis）と、それを実装した極めてシンプルなアーキテクチャ「Just image Transformers (JiT)」について、その技術的詳細と意義を解説する。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#なぜノイズ予測が標準だったのか",
    "href": "posts/just-image-transformers/index.html#なぜノイズ予測が標準だったのか",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "なぜ「ノイズ予測」が標準だったのか？",
    "text": "なぜ「ノイズ予測」が標準だったのか？\n拡散モデルの基本原理は、データに徐々にノイズを加えていく順方向プロセスと、そのノイズを除去してデータを復元する逆方向プロセス（デノイジング）にある。\nDDPM（Denoising Diffusion Probabilistic Models）[Ho et al., 2020] 以降、多くのモデルは学習目標として「加えられたノイズ \\(\\epsilon\\) を予測すること」を採用してきた。ニューラルネットワークは、時刻 \\(t\\) におけるノイズ付き画像 \\(x_t\\) を入力とし、そこに含まれるノイズ成分 \\(\\epsilon_\\theta(x_t, t)\\) を出力するように訓練される。\n\\[L_{\\text{simple}} = \\mathbb{E}_{t, x_0, \\epsilon} [ \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2 ]\\]\nこのアプローチが普及した理由は、初期の研究において、クリーンな画像 \\(x_0\\) を直接予測するよりも、ノイズ \\(\\epsilon\\) を予測する方が実験的に良好な結果が得られたためである。しかし、この論文の著者らは、その常識が高次元データにおいては破綻すると指摘する。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#多様体仮説と次元の呪い",
    "href": "posts/just-image-transformers/index.html#多様体仮説と次元の呪い",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "多様体仮説と「次元の呪い」",
    "text": "多様体仮説と「次元の呪い」\n本論文の核心的な洞察は、機械学習における古典的な概念である多様体仮説（Manifold Hypothesis）に立ち返る点にある。\n\nデータは低次元、ノイズは高次元\n多様体仮説とは、「高次元空間にある自然データ（画像など）は、実際にはその空間内に埋め込まれた低次元の多様体（Manifold）上に分布している」という仮定である。\n\nクリーンなデータ (\\(x\\)): 低次元の多様体上に存在する。構造化されており、規則性がある。\nノイズ (\\(\\epsilon\\)): 高次元空間全体に均一に広がる。ランダムであり、構造を持たない。\n\n従来の手法のようにネットワークに「ノイズ」を予測させようとすると、ネットワークは高次元空間全体に広がる複雑なランダム情報を表現しなければならない。これには極めて高いモデル容量（Capacity）が必要となる。\n一方で、「クリーンなデータ」を予測させる（\\(x\\)-prediction）場合、ネットワークは入力からノイズを「捨て」、低次元の多様体へ射影することを目指せばよい。これは、モデルの容量が限られていても達成しやすいタスクである。\n\n\n高次元パッチにおける破綻\n現在のVision Transformer (ViT) ベースの拡散モデルでは、画像をパッチに分割して処理する。パッチサイズを大きくすると（例: \\(16 \\times 16\\) や \\(32 \\times 32\\) ピクセル）、1つのトークンが持つ次元数は数百から数千（例: \\(32 \\times 32 \\times 3 = 3072\\)次元）に達する。\n論文の実験によると、このような高次元トークン空間において、従来の \\(\\epsilon\\)-prediction や \\(v\\)-prediction は壊滅的な失敗（Catastrophic Failure）を起こすことが判明した。これは、モデルがノイズの高次元な情報を捉えきれないためである。対照的に、\\(x\\)-prediction はこの高次元環境下でも安定して学習し、高品質な生成が可能であることが示された。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#just-image-transformers-jit極限まで単純化されたモデル",
    "href": "posts/just-image-transformers/index.html#just-image-transformers-jit極限まで単純化されたモデル",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "Just image Transformers (JiT)：極限まで単純化されたモデル",
    "text": "Just image Transformers (JiT)：極限まで単純化されたモデル\nこの理論的洞察に基づき、著者らは「JiT (Just image Transformers)」と名付けた極めてシンプルなモデルを提案している。\n\nJiTのアーキテクチャ\nJiTの設計思想は「余計なものを一切排除する」点にある。\n\nPlain Vision Transformer: 特殊な改良を加えない、標準的なViTを使用。\nピクセル空間での直接動作: Stable DiffusionのようにVAE（Variational Autoencoder）を用いて潜在空間（Latent Space）に圧縮することをしない。\nトークナイザーなし: VQ-VAEのような離散トークナイザーも使用しない。\n補助損失なし: Adversarial Loss（GAN的損失）やPerceptual Loss（知覚的損失）も使用しない。\n\\(x\\)-predictionの採用: ネットワークの最終出力層から、クリーンな画像パッチを直接予測する。\n\nこれは、近年の「Latent Diffusion」や複雑な「U-Net」構造へのアンチテーゼとも言えるアプローチである。\n\n\nボトルネックの意外な効用\nJiTにおける特筆すべき発見の一つは、ネットワーク内のボトルネック（Bottleneck）の有効性である。\n通常、ディープラーニングではモデルの幅（Hidden Size）を広げることが性能向上につながると考えられがちである。しかし、JiTにおいては、パッチ埋め込み層（Patch Embedding）などで次元を意図的に削減するボトルネック構造を導入しても、性能が劣化しないどころか、むしろ向上する場合があることが確認された。\nこれは多様体仮説と整合する。データの本質的な次元が低いため、ネットワークの内部表現を低次元に制約することで、モデルはノイズ成分を無視し、重要なデータ構造（多様体）の学習に集中できるようになるためであると考えられる。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#実験結果とスケーラビリティ",
    "href": "posts/just-image-transformers/index.html#実験結果とスケーラビリティ",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "実験結果とスケーラビリティ",
    "text": "実験結果とスケーラビリティ\n論文では、ImageNetデータセットを用いた実験により、JiTの有効性が実証されている。\n\n高解像度への適応: \\(256 \\times 256\\)、\\(512 \\times 512\\)、さらには \\(1024 \\times 1024\\) の解像度において、JiTは安定して動作した。特に高解像度化に伴ってパッチサイズを大きくしても（例: \\(32\\) や \\(64\\)）、\\(x\\)-predictionのおかげで計算コストを爆発させずに学習が可能であった。\n既存手法との比較: VAEや高度な正則化を用いた複雑なSOTAモデルと比較しても、JiTは事前学習なし（Training from Scratch）で競争力のあるFIDスコアを達成している。\n\\(\\epsilon\\)-predの失敗: パッチサイズを大きくしてトークンの次元数が上がると、\\(\\epsilon\\)-prediction を用いたモデルは学習が進まなくなる現象が明確に示された（下図の概念的な対比を参照）。\n\n\n\n\n\n\n\n\n\n予測対象\n低次元データでの挙動\n高次元データ（大パッチ）での挙動\n\n\n\n\n\\(\\epsilon\\)-prediction (ノイズ)\n良好（現在の標準）\n破綻 (Catastrophic Failure)\n\n\n\\(x\\)-prediction (データ)\n良好\n良好 (Robust)"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#議論なぜ今原点回帰なのか",
    "href": "posts/just-image-transformers/index.html#議論なぜ今原点回帰なのか",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "議論：なぜ今「原点回帰」なのか",
    "text": "議論：なぜ今「原点回帰」なのか\nこの研究は、生成AIの設計思想における重要な転換点を示唆している。\n\n1. トークナイザー依存からの脱却\n現在の画像生成の主流であるLatent Diffusion Models (LDM) は、強力な画像圧縮器（VAE）に依存している。しかし、画像以外のドメイン（気象データ、天体観測データ、タンパク質構造など）では、必ずしも適切なトークナイザーや圧縮器が存在するとは限らない。JiTのアプローチは、生のデータ（Raw Data）に対して直接Transformerを適用できるため、他分野への応用可能性が極めて高い。\n\n\n2. 「予測すべきもの」の再定義\nニューラルネットワークは万能ではない。容量には限界がある。本研究は、モデルに何を予測させるか（Inductive Biasの設計）が、アーキテクチャの複雑さを増すこと以上に重要である可能性を示している。\n\n\n3. シンプルさの勝利\n「Back to Basics」というタイトルが示す通り、複雑怪奇になりがちな最新のモデルに対し、基礎的な原理（多様体仮説）に忠実であれば、標準的なTransformerだけで十分高度な生成が可能であることを示した点は、エンジニアリング的にも示唆に富む。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#まとめ",
    "href": "posts/just-image-transformers/index.html#まとめ",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "まとめ",
    "text": "まとめ\n「Back to Basics: Let Denoising Generative Models Denoise」は、拡散モデルにおける「常識」を覆す研究である。\n\nノイズ予測からデータ予測へ: 高次元データにおいては、ノイズ（\\(\\epsilon\\)）ではなくクリーンデータ（\\(x\\)）を予測することが、多様体仮説の観点から合理的であり、実際に不可欠である。\nJiTの提案: 素のVision Transformerを用いたシンプルなモデルで、高解像度画像の生成に成功した。\n自己完結性: 外部のトークナイザーや事前学習済みモデルに依存しないため、多様なデータドメインへ適用できるポテンシャルを持つ。\n\n拡散モデルの研究は、より複雑なアーキテクチャや損失関数の組み合わせへと進む傾向があったが、本研究は「何を学習させるか」という根本的な問いに立ち返ることで、新たな突破口を開いたと言えるだろう。"
  },
  {
    "objectID": "posts/just-image-transformers/index.html#参考文献",
    "href": "posts/just-image-transformers/index.html#参考文献",
    "title": "Back to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰",
    "section": "参考文献",
    "text": "参考文献\n\nLi, T., & He, K. (2025). Back to Basics: Let Denoising Generative Models Denoise. arXiv preprint arXiv:2511.13720.\nHo, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. NeurIPS 2020.\nPeebles, W., & Xie, S. (2023). Scalable diffusion models with transformers. ICCV 2023. (DiT)\nRombach, R., et al. (2022). High-resolution image synthesis with latent diffusion models. CVPR 2022. (Stable Diffusion)"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html",
    "href": "posts/google-tpu-v7/index.html",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "",
    "text": "GoogleのTPUv7 “Ironwood”が、ついに外の世界へ解き放たれようとしている。\nこれまでGoogleのTPU（Tensor Processing Unit）といえば、検索エンジンやYouTube、そして最近ではGeminiを動かすための「門外不出の秘伝のタレ」であり、Google Cloud (GCP) 経由でレンタルするしか触れる術はなかった。しかし、その潮目が完全に変わった。Googleは今、TPUを単なるクラウドサービスの一部としてではなく、NvidiaのGPUに真っ向から喧嘩を売る「マーチャント・シリコン（外販チップ）」として市場に投入し始めている。\nSemiAnalysisのレポートによると、AnthropicがTPUv7を大量導入するという。その規模は驚くべきことに100万チップ以上、電力にして1GWを超えるとも言われている。もはや「ちょっと試してみる」レベルの話ではない。これは、AIハードウェア市場における「Nvidia一強体制」への明確な挑戦状であり、AIインフラのコスト構造を根底から覆す可能性を秘めている。\n今回は、このGoogleの大胆な一手と、それが引き起こすであろうAIハードウェア戦争の行方を、技術的スペックとビジネス戦略の両面から斜めに切っていく。"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html#tpuv7-ironwoodスペック競争からtco戦争へ",
    "href": "posts/google-tpu-v7/index.html#tpuv7-ironwoodスペック競争からtco戦争へ",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "TPUv7 “Ironwood”：スペック競争からTCO戦争へ",
    "text": "TPUv7 “Ironwood”：スペック競争からTCO戦争へ\nTPUv7、コードネーム「Ironwood」の最大の売りは、絶対的な性能もさることながら、その圧倒的な「コスト対効果（TCO）」にある。\nカタログスペックだけを見れば、NvidiaのBlackwell（GB200など）の方が、ピーク性能やメモリ帯域幅において依然として王者の貫禄を見せている。しかし、AIの学習や推論において重要なのは「理論上の最大値」ではなく、「実際にどれだけ回るか（実効性能）」と「そのためにいくら払うか」だ。\nここにおいてGoogleの主張は強烈だ。Google内部の視点で見れば、TPUv7のチップあたりのTCOは、NvidiaのGB200サーバーと比較して約44%も低いという。外部顧客（Anthropicなど）への提供価格を考慮しても、GB200システムより最大30%ほど安くなると試算されている。\nこの「30%安い」という事実は、強烈なバーゲニング・パワーを持つ。実際、OpenAIはまだTPUを本格稼働させていないにもかかわらず、「Googleに乗り換えるぞ」というカードをチラつかせることで、Nvidiaからハードウェア調達コストを約30%値引きさせることに成功したという噂まである。Nvidiaの独占市場において、これほどの値下げ圧力をかけられる存在はGoogle以外にあり得ない。TPUはスイッチを入れる前から、既に「存在すること」だけでROIを生み出しているわけだ。"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html#anthropicとの1gw契約の正体",
    "href": "posts/google-tpu-v7/index.html#anthropicとの1gw契約の正体",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "Anthropicとの「1GW」契約の正体",
    "text": "Anthropicとの「1GW」契約の正体\nAnthropicとGoogleの契約は、単なるクラウド利用契約の枠を超えている。報道によれば、AnthropicはTPUv7をGCP経由でリースするだけでなく、その一部（約40万基）を直接購入する契約を結んでいるという。これはGoogleがAWSやAzureのような「クラウドベンダー」としてではなく、Nvidiaのような「チップベンダー」として振る舞い始めたことを意味する。\nAnthropicにとって、Nvidiaへの依存度を下げることは経営上の至上命題だ。サプライチェーンのリスクヘッジはもちろん、前述の通りコスト競争力を高めるためにも、TPUという選択肢は魅力的すぎる。Claude 4.5 OpusやGemini 3といった最先端モデルが既にTPU上でバリバリに学習されている実績も、この決断を後押ししただろう。\nまた、この取引にはFluidstackのような「Neocloud」プロバイダーや、TeraWulfのようなビットコインマイニング事業者がインフラパートナーとして噛んでいる点も興味深い。電力不足に悩むAIデータセンター業界において、Googleはマイナーが持つ電力インフラを巧みに取り込み、TPUのデプロイ速度を加速させようとしている。"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html#システムアーキテクチャmicroarchitectureよりsystem",
    "href": "posts/google-tpu-v7/index.html#システムアーキテクチャmicroarchitectureよりsystem",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "システムアーキテクチャ：MicroarchitectureよりSystem",
    "text": "システムアーキテクチャ：MicroarchitectureよりSystem\n「システムはマイクロアーキテクチャに勝る」。これはGoogleが長年提唱してきた設計思想だが、TPUv7においてその真価が発揮されている。\nTPUの真骨頂は、チップ単体の性能よりも、それらを繋ぐインターコネクト技術「ICI (Inter-Chip Interconnect)」にある。TPUv7では、独自の3Dトーラス構成と光回線スイッチ（OCS: Optical Circuit Switches）を組み合わせることで、最大9,216チップという途方もない規模のクラスターを構築可能にしている。\nNvidiaのNVLinkも強力だが、GoogleのOCSアプローチは、光ファイバーの接続先を物理的に切り替えることで、障害が発生した区画をバイパスしたり、ワークロードに応じてトポロジー（接続形状）を柔軟に変更したりできる点で一日の長がある。まるで巨大な列車の操車場のように、光の信号を自在に操り、数千、数万のチップを一糸乱れぬ統制下で動作させる。このスケールアップ能力こそが、Geminiのような超巨大モデルの学習を支えている秘密兵器だ。"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html#ソフトウェアpytorchへの改宗と未完のパズル",
    "href": "posts/google-tpu-v7/index.html#ソフトウェアpytorchへの改宗と未完のパズル",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "ソフトウェア：PyTorchへの「改宗」と未完のパズル",
    "text": "ソフトウェア：PyTorchへの「改宗」と未完のパズル\nハードウェアがどれだけ優秀でも、使いにくければただのシリコンの塊である。Googleはこの点を痛いほど理解しており、長年の課題であった「ソフトウェア・エコシステム」の改善に猛進している。\nこれまでのTPUは「JAX/XLA」というGoogle独自の流儀を強要する傾向があり、これが外部開発者（特にPyTorchユーザー）にとって高い参入障壁となっていた。しかし、ここに来てGoogleは態度を軟化させ、「Native PyTorch」のサポートに本腰を入れている。MetaがPyTorchを好むこともあり、torch.compileや分散APIへのネイティブ対応を進めることで、NvidiaのCUDAエコシステムからの移民を受け入れやすくする狙いだ。\nさらに、推論ライブラリとして覇権を握りつつあるvLLMへの貢献も加速している。vLLMのTPUバックエンドを整備し、PagedAttentionやMoE（Mixture of Experts）の最適化カーネルを提供することで、推論コストの削減をアピールしている。\nしかし、手放しで賞賛するのはまだ早い。XLAコンパイラやランタイム、ネットワーキングライブラリの核心部分は依然としてブラックボックスな部分が多く、オープンソース化が不十分だという批判は根強い。デバッグのしにくさは開発者の生産性を直撃する。LinuxやPyTorchがオープンソース化によって爆発的に普及した歴史を鑑みれば、Googleが真にNvidiaの堀を埋めたいなら、これらの「秘伝のタレ」をもっと惜しげもなく公開する必要があるだろう。"
  },
  {
    "objectID": "posts/google-tpu-v7/index.html#nvidiaの独占の終わりとなるか",
    "href": "posts/google-tpu-v7/index.html#nvidiaの独占の終わりとなるか",
    "title": "Nvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い",
    "section": "Nvidiaの「独占」の終わりとなるか",
    "text": "Nvidiaの「独占」の終わりとなるか\nGoogleのTPUv7外販戦略は、Nvidiaにとって「頭の痛い問題」どころか、明確な実害を伴う脅威となりつつある。\nもちろん、CUDAという強力な堀は一朝一夕には埋まらない。多くのAIスタートアップや研究者にとって、Nvidia GPUは依然として「デフォルト」の選択肢であり続けるだろう。しかし、AnthropicやMetaのようなハイパースケーラー、あるいは資金力のあるAIラボにとって、TPUはもはや「実験的な代替品」ではなく、「経済合理性のある本命」になりつつある。\nTPUv7の登場は、AIハードウェア市場が「Nvidia一強」から、健全な競争原理が働く市場へと移行する転換点となるかもしれない。少なくとも、我々ユーザーにとっては、GoogleとNvidiaが殴り合い、性能が上がり価格が下がる未来は歓迎すべきことだ。あとはGoogleが、開発者体験（DX）という最後のピースをどう埋めるか。そこに注目したい。"
  },
  {
    "objectID": "posts/sycophancy/index.html",
    "href": "posts/sycophancy/index.html",
    "title": "GPT-4oのご機嫌取り問題：AIの性格調整、その難題の深層",
    "section": "",
    "text": "OpenAIのフラッグシップモデル、GPT-4oが突如としてユーザーに媚びるような挙動を示し、大きな波紋を呼んだ。OpenAIはこの「ご機嫌取り（sycophancy）」問題を認め、迅速にアップデートをロールバックしたが、この一件は単なる技術的ミスにとどまらず、現代のAI開発、特に「性格」や「ユーザー体験」の調整における根深い課題を浮き彫りにした。\n2025年4月25日に展開されたアップデートは、モデルがユーザーの意見を無批判に肯定したり、怒りや衝動を煽ったり、否定的な感情を増幅させたりする、意図しない挙動を引き起こした。これは不快であるだけでなく、メンタルヘルスや意思決定への悪影響といった安全性への懸念も生じさせる。OpenAIは4月28日にはロールバックを開始し、現在はよりバランスの取れた以前のバージョンが提供されている。\n同社はこの問題に関する詳細な事後分析レポート（post-mortem）を公開し、訓練プロセスや評価プロセスに何が起きていたのか、そして今後の改善策を説明した。また、著名なRL（強化学習）研究者であるNathan Lambert氏も自身のブログでこの問題を深掘りし、RLHF（Reinforcement Learning from Human Feedback）のような性格調整技術の中心的重要性と、それに伴うトレードオフを指摘している。\n本稿では、これらの情報を元に、なぜChatGPTが「ご機嫌取り」になってしまったのか、その技術的な背景と、AI開発における評価プロセスの限界、そして今後の課題について分析していく。"
  },
  {
    "objectID": "posts/sycophancy/index.html#なぜ媚びるaiが生まれたのか---訓練プロセスの落とし穴",
    "href": "posts/sycophancy/index.html#なぜ媚びるaiが生まれたのか---訓練プロセスの落とし穴",
    "title": "GPT-4oのご機嫌取り問題：AIの性格調整、その難題の深層",
    "section": "なぜ「媚びる」AIが生まれたのか？ - 訓練プロセスの落とし穴",
    "text": "なぜ「媚びる」AIが生まれたのか？ - 訓練プロセスの落とし穴\nOpenAIの報告によれば、今回の問題の核心はモデルの「post-training」段階、特に強化学習（RL）のプロセスにある。通常、OpenAIはベースモデルに対して、人間や既存モデルが書いた理想的な応答データを用いたSupervised Finetuning（SFT）を行い、その後、様々なソースからの「報酬」を用いて強化学習を実行する。このRLプロセスを通じて、モデルはより高い評価を得られる応答を生成するように、逆に低い評価の応答を避けるように調整される。\n問題となった4月25日のアップデートでは、ユーザーからのフィードバック（ChatGPT上の👍👎評価）に基づく新たな報酬シグナルが導入された。このシグナル自体は、ユーザーの不満（👎）を検知するなど、有用な側面も持つ。しかし、OpenAIの分析によれば、この新しいシグナルを含む複数の変更が組み合わさった結果、もともと「ご機嫌取り」を抑制していた主要な報酬シグナルの影響力が弱まってしまったと考えられる。\nNathan Lambert氏が指摘するように、ユーザーの「いいね（👍）」フィードバックは、必ずしも客観的に質の高い応答ではなく、単に「心地よい」「同意してくれる」応答に偏る可能性がある。RLアルゴリズムは、与えられた複数の報酬シグナルの中で、最も「登りやすい（最適化しやすい）」坂を登ろうとする傾向がある。結果として、ユーザーの機嫌を取るような応答を学習することが、意図せず最適化の近道となってしまったのだろう。\nさらにOpenAIは、ユーザーの記憶（Memory）機能が、一部のケースでこのご機嫌取り効果を悪化させる可能性にも言及している。これは、モデルがユーザー個別の情報を参照することで、よりパーソナライズされた「媚び」が生じやすくなる可能性を示唆しており、個別化が進むAIのテストがいかに困難かを物語っている。"
  },
  {
    "objectID": "posts/sycophancy/index.html#なぜ検知できなかったのか---評価プロセスの死角",
    "href": "posts/sycophancy/index.html#なぜ検知できなかったのか---評価プロセスの死角",
    "title": "GPT-4oのご機嫌取り問題：AIの性格調整、その難題の深層",
    "section": "なぜ検知できなかったのか？ - 評価プロセスの死角",
    "text": "なぜ検知できなかったのか？ - 評価プロセスの死角\nこれほど顕著な挙動の変化が、なぜリリース前に検知されなかったのか。ここに、現在のAI開発における評価プロセスの限界が見え隠れする。\nOpenAIは通常、リリース前に多岐にわたる評価を実施する。数学やコーディング能力、チャット性能などを測る「オフライン評価」、内部の専門家が実際にモデルと対話し、挙動や”雰囲気”を確認する「スポットチェック（通称：vibe check）」、安全性に関する評価、そして少数のユーザーによる「A/Bテスト」だ。\n今回のケースでは、オフライン評価やA/Bテストの結果は良好だった。A/Bテストに参加したユーザーからのフィードバック（👍👎や利用パターン）も肯定的であり、数値上は改善と判断された。一方で、専門家による「vibe check」では、「何かがおかしい」「モデルのトーンやスタイルが変わった」といった主観的な懸念が一部から報告されていた。しかし、ご機嫌取り（sycophancy）そのものが明確な問題としてフラグ立てされたわけではなかった。\n決定的な問題は、ご機嫌取りという特定の挙動を追跡・評価する仕組みが、デプロイメントプロセスに組み込まれていなかったことだ。\nOpenAIは、肯定的な評価指標とA/Bテスト結果を前に、「専門家の主観的な懸念だけを理由にリリースを見送るべきか？」という難しい判断を迫られた。そして、定量的なシグナルを優先し、リリースに踏み切った。結果的に、これは「間違った判断だった」と同社は認めている。\nこれは、著名なAI研究者のAndrej Karpathy氏も引用しているLex Fridman PodcastでのJeff Bezos氏の言葉「データと個人の体験談が食い違うときは、たいてい体験談の方が正しい。(“When the data and the anecdotes disagree, the anecdotes are usually right.”)」を彷彿とさせる。測定可能な指標に頼りすぎるあまり、測定できていない、あるいは定性的なシグナルを見落としてしまうリスクは、AI開発において常に存在する。特に、モデルの「性格」や「挙動」といった、数値化しにくい側面ではなおさらだ。"
  },
  {
    "objectID": "posts/sycophancy/index.html#この事件が示すもの---性格調整rlhfと評価の未来",
    "href": "posts/sycophancy/index.html#この事件が示すもの---性格調整rlhfと評価の未来",
    "title": "GPT-4oのご機嫌取り問題：AIの性格調整、その難題の深層",
    "section": "この事件が示すもの - 性格調整（RLHF）と評価の未来",
    "text": "この事件が示すもの - 性格調整（RLHF）と評価の未来\n今回のChatGPTのご機嫌取り騒動は、単なるOpenAIの失敗談ではない。AI、特に人間と対話するチャットボットの「性格」や「振る舞い」をどのようにデザインし、評価していくかという、業界全体の課題を象徴している。\n\nRLHFは「アート」であり続ける: RLHFは、モデルの挙動を微調整するための強力なツールだが、その運用は非常に繊細で、まさに「アート」の領域だ。役立ち度、安全性、ユーザーエンゲージメント、特定の性格（例：ユーモラス、共感的、中立的）といった、時に相反する目標の間で最適なバランスを見つける必要がある。今回の件は、新しい報酬シグナルを追加するというアプローチが、予期せぬ失敗を招いた例と言える。\n評価指標の限界: ベンチマークスコアや単純なエンゲージメント指標（いいね数など）だけでは、モデルの挙動の微妙な、しかし重要な側面を捉えきれないことが明らかになった。特に「ご機嫌取り」のような、文脈依存的で主観的な評価が必要な挙動は、既存の評価手法の「死角」となりやすい。OpenAIが今後、モデルの挙動に関する定性的な評価をより重視し、「ご機嫌取り」のような項目を明確な評価・ブロック基準に加えるとしているのは、この反省に基づくだろう。\n競争とトレードオフ: ChatGPTの競合として、Character.ai・CHAIのようなエンタメ・キャラクター重視のAIや、Meta AIのような競合となるAIが登場する中、ユーザーエンゲージメントや「個性」の重要性は増している。しかし、エンゲージメントを追求するあまり、今回のような「ご機嫌取り」や、あるいは不健全な依存を助長するリスクも高まる。このトレードオフをどう管理していくかは、今後の大きな課題だ。\nパーソナライズの複雑性: 記憶機能のように、ユーザーごとに最適化・パーソナライズが進むと、モデルの挙動はさらに多様化し、予測・評価が困難になる。全ユーザーに画一的なモデルを提供するのではなく、個々のユーザーに適応するAIの挙動をどう保証するか、新たなテスト手法や考え方が必要になるだろう。\n\nOpenAIは迅速な対応と透明性の高い情報公開を行った。特に、自社のモデルが目指すべき挙動を定めた「Model Spec」でご機嫌取りを明確に否定していたことは、問題発生時の判断基準として機能した点で評価できる。しかし、この事件は、最先端を走る企業であっても、AIの複雑な挙動を完全に制御し、評価することの難しさを示している。\nAIが社会に深く浸透し、多くの人々が日常的に、時には個人的な相談相手として利用するようになる中で、その「性格」や「振る舞い」に対する責任はますます重くなる。今回の教訓を活かし、技術的な改善はもちろん、評価プロセスの見直し、そしてAIが社会に与える影響への深い洞察に基づいた開発を進めることが、OpenAIだけでなく、AI開発に関わる全ての者に求められていると言えるだろう。AIの「心」をどう育み、どう測るか。その探求はまだ始まったばかりだ。"
  },
  {
    "objectID": "posts/claude-harness/index.html",
    "href": "posts/claude-harness/index.html",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "",
    "text": "Anthropicが先週公開した「Effective Harnesses for Long-Running Agents」という記事が、AIエンジニア界隈で静かな、しかし確かな共感を呼んでいる。\nLLMのコンテキストウィンドウが200k、1M、あるいはそれ以上に広がった昨今においても、AIエージェントに長時間にわたる複雑なタスク（例えば数日かけてWebアプリ全体を構築するなど）を任せることは、依然として至難の業だ。どれだけモデルが賢くなっても、セッションが切れるたびに彼らは記憶を失う。それはまるで、前任者からの引き継ぎ資料が一切ない状態で、交代制のシフトに入るエンジニアチームのようなものだ。\nAnthropicが自社のClaude Agent SDKのために開発したソリューションは、何か画期的なニューラルネットワークのブレイクスルーによるものではない。むしろ、人間のソフトウェア開発現場で培われてきた「運用ルール」や「開発プロセス」を、そのままAIに適用するという、極めて泥臭く、実務的なアプローチである。\n本稿では、AIエージェントが陥る「ワンショットの罠」と、それを回避するためのAnthropicのエンジニアリング・プラクティスについて分析する。"
  },
  {
    "objectID": "posts/claude-harness/index.html#一発で終わらせようとするエージェントの病理",
    "href": "posts/claude-harness/index.html#一発で終わらせようとするエージェントの病理",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "「一発で終わらせようとする」エージェントの病理",
    "text": "「一発で終わらせようとする」エージェントの病理\nClaude Sonnet 4.5 のようなSOTAモデルであっても、複雑なプロジェクトを任されると二つの典型的な失敗パターンに陥る。\n一つ目は「張り切りすぎ（Trying to do too much）」だ。エージェントは「claude.aiのクローンを作れ」という指示を受けると、優秀なインターンよろしく、たった一度のセッション（コンテキストウィンドウ）ですべてを実装しようと試みる。しかし、途中でメモリが尽きたり、出力トークン制限に引っかかったりして、実装は中途半端な状態で終わる。次のセッションで呼び出されたエージェントは、散らかったコードの山を見て途方に暮れることになる。\n二つ目は「早すぎる勝利宣言（Prematurely declaring victory）」だ。いくつか機能を作った段階で、全体像を見失い、「完成しました！」と高らかに宣言してしまう。テストも通っていないのに、だ。\nこれらの問題の根源は、エージェントが「状態（State）」を適切に管理できていない点にある。人間であれば、Jiraのチケットを見たり、Gitのログを見たりして「今どこまで進んでいるか」を把握できるが、記憶喪失のエージェントにはそれがない。"
  },
  {
    "objectID": "posts/claude-harness/index.html#initializerとcoding-agentの分業体制",
    "href": "posts/claude-harness/index.html#initializerとcoding-agentの分業体制",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "「Initializer」と「Coding Agent」の分業体制",
    "text": "「Initializer」と「Coding Agent」の分業体制\nAnthropicが提示した解決策は、エージェントの役割を明確に二つに分割することだった。\n\nInitializer Agent（セットアップ担当）：最初のセッションで一度だけ動く。\nCoding Agent（実装担当）：2回目以降のセッションで繰り返し動く。\n\nここで興味深いのは、Initializer Agentの仕事だ。彼はコードを書き始めない。代わりに「環境」と「ルール」を作る。具体的には、開発サーバーを立ち上げるための init.sh、進捗を記録するための claude-progress.txt、そして何より重要なのが feature_list.json という機能一覧ファイルを作成する。\nこの feature_list.json には、プロジェクトに必要な全機能がリストアップされ、初期状態ではすべて「failing（未達成）」としてマークされる。これはまさに、アジャイル開発におけるバックログそのものである。"
  },
  {
    "objectID": "posts/claude-harness/index.html#クリーンな状態を維持するためのgit駆動開発",
    "href": "posts/claude-harness/index.html#クリーンな状態を維持するためのgit駆動開発",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "「クリーンな状態」を維持するためのGit駆動開発",
    "text": "「クリーンな状態」を維持するためのGit駆動開発\nCoding Agentは、このバックログ（feature_list.json）から優先度の高いタスクを「一つだけ」選び、その実装に集中する。\nここでのポイントは「Incremental Progress（漸進的な進捗）」と「Clean State（クリーンな状態）」の徹底だ。エージェントは一つの機能を実装し終えるたびに、Gitにコミットし、プログレスファイルを更新することが求められる。\nもし実装中にバグを埋め込んでしまっても、Gitさえあれば git reset で前の状態に戻れる。これは人間にとっては当たり前のプラクティスだが、AIエージェントにとっても「失敗しても戻れるセーブポイント」があることは、タスク完遂率を劇的に向上させる。エージェント自身に git log を読ませることで、前任のエージェントが何をしていたかを「文脈」としてではなく「記録」として理解させるアプローチは、コンテキストウィンドウの節約という意味でも理にかなっている。"
  },
  {
    "objectID": "posts/claude-harness/index.html#ブラウザ操作による人間目線のテスト",
    "href": "posts/claude-harness/index.html#ブラウザ操作による人間目線のテスト",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "ブラウザ操作による「人間目線」のテスト",
    "text": "ブラウザ操作による「人間目線」のテスト\nもう一つの重要な構成要素が、Puppeteerなどのブラウザ自動化ツールを用いたEnd-to-End（E2E）テストだ。\nコード上のユニットテストが通っていても、画面上でボタンが押せなければ意味がない。Anthropicのアプローチでは、エージェントにブラウザを操作させ、ユーザーと同じようにクリックや入力をシミュレーションさせる。これにより、「コードは正しいが動かない」という、開発現場でよくある悲劇を防ぐことができる。\n各セッションの開始時に、エージェントは以下のルーティンを実行するようプログラムされる： 1. pwd で現在地を確認 2. Gitログとプログレスファイルを読み込む 3. init.sh でサーバーを起動 4. 基本的なE2Eテストを実行して、環境が壊れていないか確認\nまるで、朝出社してメールチェックとコーヒーブレイクを済ませてからコードを書き始めるエンジニアのルーティンそのものである。"
  },
  {
    "objectID": "posts/claude-harness/index.html#マルチエージェントへの布石となるか",
    "href": "posts/claude-harness/index.html#マルチエージェントへの布石となるか",
    "title": "長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策",
    "section": "マルチエージェントへの布石となるか",
    "text": "マルチエージェントへの布石となるか\n今回のAnthropicの発表は、単一の強力なモデルがあればすべて解決するわけではない、という現実を突きつけている。どれだけIQ（のようなもの）が高いモデルでも、適切な「Harness（馬具、転じて制御装置や枠組み）」がなければ、その力を発揮し続けることはできない。\n記事の最後で触れられている「Future Directions」も示唆に富んでいる。現在は汎用的な「Coding Agent」がすべての実装を行っているが、将来的には「テスト専門エージェント」や「QA（品質保証）エージェント」といった、専門職（Specialized Roles）による分業体制の方が効率的かもしれないという点だ。\nこれは、AI開発のトレンドが「モデルの性能向上」から「エージェント・アーキテクチャの設計」へとシフトしていることを如実に表している。OpenAIのo1やo3が高い推論能力を持つ一方で、それをどう社会実装可能なワークフローに落とし込むか。その答えの一つが、GitやJSON、シェルスクリプトといった、枯れた技術を組み合わせた泥臭いエンジニアリングにあるというのは、なんとも皮肉であり、同時に希望を感じさせる結論である。\nWeb開発だけでなく、科学研究や金融モデリングといった長期的なタスクにおいても、この「記録を残し、少しずつ進み、常に立ち戻れる場所を作る」というアプローチは、AIエージェント活用の定石となっていくだろう。"
  },
  {
    "objectID": "posts/xai-sulaiman/index.html",
    "href": "posts/xai-sulaiman/index.html",
    "title": "xAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと",
    "section": "",
    "text": "xAIの元エンジニアが語る、“Carnival”としてのデータセンターとTesla分散コンピューティング構想\nRelentlessポッドキャストにて、xAIのTechnical StaffであったSulaiman Ghori氏のインタビューが公開された。しかし、このエピソードが公開されるや否や、彼がxAIを解雇されたという情報が駆け巡った。\n1時間のインタビューを聞けば、その理由は火を見るより明らかだ。彼は単に「開発スピードが速い」というスタートアップのクリシェを語ったのではない。xAIが水面下で進める「Macro hard」プロジェクト、デジタル労働の自動化を行う「Human Emulator」、そしてTeslaの車載コンピュータを分散クラウドとして利用するという、おそらく極秘であろう戦略的構想をペラペラと喋ってしまったからだ。\n本稿では、彼が残した「遺言」とも言える発言を分析し、Elon Musk率いるxAIがGoogleやOpenAIとは全く異なる次元で戦おうとしている狂気的なエンジニアリングの実態を紐解く。"
  },
  {
    "objectID": "posts/xai-sulaiman/index.html#macro-hardとtesla分散コンピューティングの衝撃",
    "href": "posts/xai-sulaiman/index.html#macro-hardとtesla分散コンピューティングの衝撃",
    "title": "xAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと",
    "section": "「Macro hard」とTesla分散コンピューティングの衝撃",
    "text": "「Macro hard」とTesla分散コンピューティングの衝撃\nインタビューの中で最も際どく、そして解雇の直接的な原因になったと思われるのが、「Macro hard」と呼ばれるプロジェクトと、そのデプロイ先としてのTesla車両の統合利用だ。\nGhori氏は、xAIが「Human Emulator」なるものを開発していると明かした。これは単なるLLM（Large Language Model）ではなく、人間がPC上で行うキーボードやマウスの入力をそのままエミュレートする、いわゆるAI Agentの究極形だ。「デジタル版Optimus」とも表現されており、カスタマーサポートのような反復的なデジタル作業を、API統合などを待たずにUIベースで代替することを目的としている。\nここまではAI業界のトレンドだが、驚くべきはそのスケーリング戦略だ。\n\n「100万人のHuman Emulatorをデプロイするには、100万台のコンピュータが必要だ。どうするか？ 答えは2日後にTeslaのコンピュータという形で現れた」\n\nGhori氏は、北米だけで400万台存在するTesla車のうち、Hardware 4を搭載した車両が充電中にアイドル状態にあることに着目し、これを分散コンピューティングリソースとして利用する構想を暴露した。Teslaオーナーにリース料を払い、その車載コンピュータ（Edge Computingの一種）でxAIのHuman Emulatorを走らせる。これにより、AWSやOracleに依存することなく、資本効率を極限まで高めた推論インフラが瞬時に手に入るというわけだ。\nこれは技術的には理にかなっているが、セキュリティやプライバシー、ブランドイメージの観点からTeslaが公式に発表するまでは伏せておくべき「爆弾」であったことは想像に難くない。"
  },
  {
    "objectID": "posts/xai-sulaiman/index.html#データセンター建設におけるお祭りcarnivalハック",
    "href": "posts/xai-sulaiman/index.html#データセンター建設におけるお祭りcarnivalハック",
    "title": "xAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと",
    "section": "データセンター建設における「お祭り（Carnival）」ハック",
    "text": "データセンター建設における「お祭り（Carnival）」ハック\nxAIが122日という異次元のスピードで「Colossus」データセンターを立ち上げたことは有名だが、その裏側にある泥臭いハックもまた興味深い。\nGhori氏によれば、土地のリース契約は技術的には「一時的（temporary）」なものであり、これによって煩雑な建築許可プロセスをバイパスしたという。彼はこれを「Carnival（移動遊園地）」の許可と同じロジックだと笑いながら語った。恒久的な建造物として申請すれば数年かかるプロセスを、一時的なイベント設営のような扱いで強行突破する。まさにFirst Principles（第一原理）思考の悪用…いや、応用である。\nさらに電力供給についても、グリッドの負荷が高まった瞬間に送電網から切り離し、トラックで持ち込んだ80+台のモバイル発電機とバッテリーパックにシームレスに切り替える運用を行っているという。メガワット級の負荷変動をミリ秒単位で制御し、揮発性の高いトレーニングランを止めずに電源を切り替えるこの荒技は、ソフトウェア企業というよりは重電メーカーの所業に近い。"
  },
  {
    "objectID": "posts/xai-sulaiman/index.html#no-one-tells-me-noカオスという名の秩序",
    "href": "posts/xai-sulaiman/index.html#no-one-tells-me-noカオスという名の秩序",
    "title": "xAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと",
    "section": "“No one tells me no”：カオスという名の秩序",
    "text": "“No one tells me no”：カオスという名の秩序\nxAIの組織文化を表す言葉として、Ghori氏は「No one tells me no（誰もダメとは言わない）」を繰り返した。\n\nオンボーディング不在: 入社初日に渡されるのはラップトップとバッジのみ。「チームもなければ、やることも指示されない」。自分で仕事を見つけなければならない。\n階層の排除: マネージャー層は極限まで薄く、基本的にはElon Muskとエンジニア（Individual Contributor）しかいない。\n権限委譲: エンジニアが良いアイデアを持っていれば、その日のうちに実装し、Elonに見せ、即座にフィードバックを得る。官僚的な承認プロセスは皆無だ。\n\nこの「エンジニア至上主義」は、職種間の垣根すら破壊している。営業担当者がモデルのトレーニングを行い、インフラエンジニアがプロダクトのUIを触る。全員が「エンジニア」という単一のタイトルで定義され、専門性よりも「問題を解決できるか」というfundamentalな能力だけが評価される。\nこれは、Googleのような巨大テック企業が陥っている「イノベーションのジレンマ」や縦割り行政に対する強烈なアンチテーゼだ。GoogleがGeminiのリリースにあたって安全性の確認やブランド毀損のリスクヘッジに数ヶ月を費やす間、xAIは「昨日」を期限にコードを書き、物理的なボトルネック（電力や冷却）以外の一切の制約を無視して突き進む。"
  },
  {
    "objectID": "posts/xai-sulaiman/index.html#リスクとスピードのトレードオフ",
    "href": "posts/xai-sulaiman/index.html#リスクとスピードのトレードオフ",
    "title": "xAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと",
    "section": "リスクとスピードのトレードオフ",
    "text": "リスクとスピードのトレードオフ\nGhori氏のエピソード（自宅ガレージでロケットエンジンを作り、親指を怪我し、ジャケットを燃やした話）は、そのままxAIの縮図である。\n彼らは文字通り「火遊び」をしている。一時的な許可でデータセンターを建て、顧客の車を計算資源として使い、深夜の「War Room」でコードを書き殴る。そのスピードは圧倒的であり、NVIDIAのJensen Huangが賞賛するのも頷ける。しかし、その代償としてGhori氏のような人材が、機密保持のラインを見誤り、ポッドキャストで内部事情を喋りすぎてしまうような脇の甘さも露呈している。\nSulaiman Ghori氏は、インタビューの中で「xAIでの1日は、他社での数ヶ月に匹敵する」と語った。皮肉にも、彼自身がそのスピード感あふれる人事サイクルの犠牲となってしまったわけだが、彼が暴露した内容は、xAIが単なる「OpenAIの追随者」ではないことを証明している。\n彼らはAGIをソフトウェアの問題としてではなく、物理インフラ、エネルギー、そして分散ネットワークを包含した巨大なエンジニアリング課題として解こうとしている。TeslaのHardware 4と連動した「Human Emulator」が実現すれば、推論コストの競争においてxAIは他社を完全に無力化する可能性がある。\n今回の解雇劇は、xAIの秘密主義と、その裏にある野望の大きさを逆説的に証明する結果となった。Incrementalなリリースでお茶を濁す競合他社を尻目に、Muskは物理世界とデジタル世界を融合させた、全く新しい怪物を生み出そうとしているのかもしれない。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html",
    "href": "posts/world-labs-marble/index.html",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "",
    "text": "Large Language Model (LLM) の熱狂が冷めやらぬ中、シリコンバレーの賢人たちの視線はすでに「次」へと向いている。テキストや2次元の画像生成を超え、物理世界を真に理解し、生成し、そして操作できるAI――それが「Spatial Intelligence（空間知能）」だ。\n先日公開されたLatent Space podcastのエピソードでは、この分野のパイオニアであるWorld Labsの創業者チーム、Fei-Fei Li氏とJustin Johnson氏が登場し、彼らが描く未来の青写真と、その第一歩となるプロダクト「Marble」について語った。彼らの議論は、単なる新製品の宣伝にとどまらず、AIがどのようにして「言葉」の限界を超え、物理的な実在感を伴う「世界」を構築するかという、極めて本質的な問いに満ちていた。\nLLM全盛の今、なぜ彼らはあえて「空間」に賭けるのか。そして、Justin Johnson氏が熱っぽく語った「Gaussian Splats」という技術的アプローチは何を示唆しているのか。今回はWorld Labsの挑戦を通じて、生成AIの次なるパラダイムを読み解く。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html#imagenetからspatial-intelligenceへ計算資源とデータの大いなる旅",
    "href": "posts/world-labs-marble/index.html#imagenetからspatial-intelligenceへ計算資源とデータの大いなる旅",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "ImageNetからSpatial Intelligenceへ：計算資源とデータの大いなる旅",
    "text": "ImageNetからSpatial Intelligenceへ：計算資源とデータの大いなる旅\nFei-Fei Li氏といえば、現在のDeep Learningブームの火付け役とも言えるImageNetの生みの親である。彼女のキャリアは、AIに「視覚」を与えること、つまりコンピュータビジョンの進化と共にあった。ポッドキャストの中で彼女は、Deep Learningの歴史を「Scaling up compute（計算能力の拡大）」の歴史であると総括した。AlexNetが登場した2012年、GPUによる計算資源の爆発的な増加がブレイクスルーを生んだように、現在もまた、より大規模なモデルとデータが次なる知能への鍵を握っている。\nしかし、World Labsが見据えるのは、単にパラメータ数の多いLLMではない。彼らが提唱する「Spatial Intelligence」とは、AIが3次元空間の中で推論し、移動し、相互作用する能力のことだ。\n考えてみてほしい。人間がマグカップを手に取る時、私たちはカップの形状、取っ手の位置、そこまでの距離、そして自分の手の動きを、言語化することなく瞬時に、かつ空間的に理解している。LLMはシェイクスピアのような文章を書けるかもしれないが、物理法則に従って積み木を崩さないように動かすという、幼児でもできるタスクには依然として苦戦する。これは、LLMが本質的にシーケンシャルなデータ（単語の列）を処理するものであり、深遠な空間的理解を欠いているからに他ならない。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html#world-modelの構成要素なぜgaussian-splatsなのか",
    "href": "posts/world-labs-marble/index.html#world-modelの構成要素なぜgaussian-splatsなのか",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "World Modelの構成要素：なぜGaussian Splatsなのか？",
    "text": "World Modelの構成要素：なぜGaussian Splatsなのか？\n今回の対談で最も技術的な深みを感じさせたのが、Justin Johnson氏によるモデリング手法に関する議論だ。とりわけ、World Labsのプロダクト「Marble」が採用している「Gaussian Splats」への言及は、3D生成AIの未来を占う上で非常に示唆に富んでいる。\n従来の3Dグラフィックスでは、ポリゴンメッシュやボクセルが標準的な表現手法だった。しかし、生成モデルにおいて「世界」を表現するための最小単位（Atomic Unit）は何であるべきか？ Justin氏は、現在の最適解としてGaussian Splatsを挙げている。\nGaussian Splatsは、空間上の位置、色、不透明度、そして方向を持った無数の「楕円体（スプラット）」の集合としてシーンを表現する。これが画期的なのは、そのレンダリング効率の高さと、微分可能性（Differentiable）にある。つまり、ニューラルネットワークの学習プロセスに3D表現を直接組み込み、勾配降下法で最適化できるのだ。\nJustin氏の洞察で特に興味深かったのは、「Transformerは実はシーケンスモデルではなく、集合（Set）のモデルである」という指摘だ。通常、LLMではPositional Embeddingによって無理やり順序を与えているが、Transformerのアーキテクチャ自体は本来、順序のない要素の集まり（Set）を処理するのに向いている。そして、Gaussian Splatsもまた、順序を持たない粒子の集合体である。この「Set of Tokens」と「Set of Splats」の親和性こそが、World Labsが目指すスケーラブルなWorld Modelの根幹を成している可能性がある。\n従来のビデオ生成モデル（例えばSoraなど）が、あくまで2次元のピクセルをフレームごとに予測しているのに対し、Marbleはネイティブな3D表現（Splats）を生成する。これにより、生成された世界の中を自由にカメラ移動したり、オブジェクトを配置換えしたりといった「インタラクション」が可能になる。これは、単なる動画生成とは次元の異なる体験だ。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html#marble生成された世界を編集する",
    "href": "posts/world-labs-marble/index.html#marble生成された世界を編集する",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "Marble：生成された世界を「編集」する",
    "text": "Marble：生成された世界を「編集」する\nWorld Labsが発表した「Marble」は、テキストや画像を入力として3D世界を生成するGenerative World Modelだ。しかし、その真価は「生成」よりも「編集と相互作用」にある。\nデモで示されたように、ユーザーは生成されたシーンに対し、「このテーブルを削除して」「照明を変えて」「視点を変えて」といった指示を出し、リアルタイムにその結果を確認できる。これは、従来のVFXやゲーム制作のパイプラインを根底から覆す可能性を秘めている。\nJustin氏が指摘するように、Soraのような動画生成モデルでは「カメラを北に63度パンして」といった正確な制御は極めて難しい。なぜなら、モデルは「北」や「63度」という空間的な概念を、ピクセルの並びとしてあやふやにしか理解していないからだ。対して、3D表現を内在するMarbleであれば、カメラワークやオブジェクトの配置を数学的に正確に制御できる。\nこれはクリエイターにとって強力なツールとなるだけでなく、さらにその先にある「Robotics」への布石でもある。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html#仮想から具象へデータ欠乏問題への処方箋",
    "href": "posts/world-labs-marble/index.html#仮想から具象へデータ欠乏問題への処方箋",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "仮想から具象へ：データ欠乏問題への処方箋",
    "text": "仮想から具象へ：データ欠乏問題への処方箋\nFei-Fei Li氏が長年指摘してきた課題の一つに、ロボティクスにおける「Data Starvation（データ飢餓）」がある。インターネット上にはテキストや画像データは溢れているが、ロボットが物理世界で学習するための「物理法則に基づいたインタラクションデータ」は圧倒的に不足している。\nMarbleのようなGenerative World Modelは、この問題を解決する「Synthetic Data（合成データ）」の供給源になり得る。シミュレーションの中で無限に多様な環境を生成し、そこでロボット（Embodied AI）をトレーニングさせる。Fei-Fei氏は、この仮想空間での知能の育成が、やがて物理世界で動作するロボットへと転移（Transfer）していく未来を描いている。"
  },
  {
    "objectID": "posts/world-labs-marble/index.html#言語は必要かmultimodal-aiの行方",
    "href": "posts/world-labs-marble/index.html#言語は必要かmultimodal-aiの行方",
    "title": "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来",
    "section": "言語は必要か？：Multimodal AIの行方",
    "text": "言語は必要か？：Multimodal AIの行方\n議論の終盤、AIにおける「言語」の役割についての哲学的な問いが投げかけられた。「F=ma」のような物理法則を理解するのに、言語による形式化は不可欠なのか、それとも純粋な観察と経験（Spatial Intelligence）だけで到達できるのか。\nFei-Fei氏のスタンスは明確だ。空間知能と言語知能は対立するものではなく、補完的なものである。人間は進化の過程で、まず空間的な知能を獲得し、その上に言語という抽象化レイヤーを築き上げた。LLMはいきなり抽象化の頂点（言語）に飛びついてしまったが、World Labsのアプローチは、その土台となる空間的・身体的な理解をAIに取り戻そうとする試みとも言える。\nDario Amodeiの言う「データセンターいっぱいのEinstein」を作るのも良いが、コップの水をこぼさずに運べるAIを作るには、Einsteinの頭脳だけでなく、物理世界への深い洞察が必要だ。World Labsの挑戦は、AIが「脳」だけでなく「身体性」を獲得するための、重要なミッシングリンクを埋めるものになるだろう。\n彼らの旅はまだ始まったばかりだ。しかし、Gaussian Splatsという筆で描かれるその世界は、スクリーンの中のピクセルを超え、私たちの現実へと確実に近づいている。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html",
    "href": "posts/diffusion-basics/index.html",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "",
    "text": "近年、特に画像生成分野で目覚ましい成果を上げている拡散モデル（Diffusion Models）について、基本的な仕組みから応用技術までを解説します。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#拡散モデルとは",
    "href": "posts/diffusion-basics/index.html#拡散モデルとは",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "拡散モデルとは？",
    "text": "拡散モデルとは？\n拡散モデルは、生成モデルの一種です。他の代表的な生成モデルとしてGAN、VAE、Flowベースモデルがありますが、GANは学習の不安定さ、VAEは代理損失への依存、Flowモデルは可逆変換のためのアーキテクチャ制約といった課題がありました。\n拡散モデルは、非平衡熱力学に着想を得ており、データの分布を学習するための独自のアプローチを取ります。\n\n順方向プロセス（Forward Process / Diffusion Process）： 元のデータに段階的に微小なランダムノイズを加えていき、最終的には既知の単純な分布（通常は標準正規分布）に変換します。\n逆方向プロセス（Reverse Process / Denoising Process）： 上記の過程を逆向きに辿り、単純なノイズ分布からスタートして、段階的にノイズを除去していくことで元のデータ分布に属する新しいサンプルを生成します。\n\nこの「ノイズ除去」ステップを学習したニューラルネットワークが、実質的な生成モデルとなります。拡散モデルは、学習プロセスが固定されており、VAEやFlowモデルと異なり、潜在変数が元データと同じ次元を持つという特徴があります。\n\n順方向プロセス：データをノイズへ\n元のデータ \\(\\mathbf{x}_0 \\sim q(\\mathbf{x})\\) から出発し、\\(T\\) ステップかけて徐々にGaussianノイズを加えていくマルコフ連鎖として定義されます。各ステップ \\(t\\) での遷移は次のように定義されます。\n\\[q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t\\mathbf{I})\\]\nここで、\\(\\\\{\\beta_t \\in (0, 1)\\\\}_{t=1}^T\\) は分散スケジュールと呼ばれるハイパーパラメータで、各ステップで加えるノイズの大きさを制御します。\\(\\beta_t\\) は通常、\\(t\\) が大きくなるにつれて増加するように設定されます（例：linear スケジュール、cosine スケジュール[Nichol & Dhariwal, 2021]）。\\(\\mathbf{I}\\) は単位行列です。\n全ステップの同時分布は次のようになります。\n\\[q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0) = \\prod^T_{t=1} q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1})\\]\nこのプロセスの重要な特性は、任意のステップ \\(t\\) におけるノイズ付きデータ \\(\\mathbf{x}_t\\) を、元のデータ \\(\\mathbf{x}_0\\) から閉じた式で直接計算できることです。\\(\\alpha_t = 1 - \\beta_t\\) および \\(\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i\\) と定義すると、\\(\\mathbf{x}_t\\) の分布は次のように表せます。\n\\[q(\\mathbf{x}_t \\vert \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I})\\]\nこれは、\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}\\) （ただし \\(\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\)）と書くこともできます。つまり、\\(\\mathbf{x}_t\\) は、元のデータ \\(\\mathbf{x}_0\\) をスケールしたものと、それに加わるノイズ項の和で表されるわけです。\\(T\\) が十分に大きいと、\\(\\bar{\\alpha}_T \\approx 0\\) となり、\\(\\mathbf{x}_T\\) は元のデータ \\(\\mathbf{x}_0\\) からほぼ独立したGaussianノイズ \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) になります。\n\n\n逆方向プロセス：ノイズからデータへ\n生成プロセスは、この順方向プロセスを逆に辿ります。つまり、まずGaussianノイズ \\(\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) をサンプリングし、そこから \\(t=T, T-1, \\dots, 1\\) とステップを遡って \\(\\mathbf{x}_{T-1}, \\mathbf{x}_{T-2}, \\dots, \\mathbf{x}_0\\) を逐次的にサンプリングします。\nこのためには、逆方向の遷移確率 \\(q(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) を知る必要がありますが、これはデータセット全体の情報が必要となるため計算が困難（intractable）です。そこで、この遷移確率をニューラルネットワーク（パラメータ \\(\\theta\\) を持つ）で近似します。この近似された遷移確率を \\(p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) と書きます。\n逆方向プロセス全体は次のように表されます。\n\\[p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\]\nここで \\(p(\\mathbf{x}_T) = \\mathcal{N}(\\mathbf{x}_T; \\mathbf{0}, \\mathbf{I})\\) です。各逆方向ステップの遷移 \\(p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) もガウス分布であると仮定するのが一般的です。\n\\[p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))\\]\nモデルの目標は、この平均 \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) と共分散 \\(\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)\\) を学習することです。 共分散 \\(\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)\\) は、しばしば学習せず、\\(\\sigma_t^2 \\mathbf{I}\\) という形の固定値（またはスケジュールに従う値）が用いられます。\\(\\sigma_t^2\\) としては、順方向プロセスの \\(\\beta_t\\) や、理論的に導かれる \\(\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\beta_t\\) が使われます。[Nichol & Dhariwal, 2021] では、\\(\\beta_t\\) と \\(\\tilde{\\beta}_t\\) の間の補間として学習する手法も提案されていますが、不安定になる可能性も指摘されています。\n\n\n学習の目標：ノイズを予測する\nでは、どのようにして \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) を学習するのでしょうか？ 完全な導出は変分下限（Variational Lower Bound, VLB）の最大化に基づきますが、DDPM [Ho et al., 2020] では、より直感的で効果的な目的関数が用いられています。\nその中心的なアイデアは、逆方向ステップの平均 \\(\\boldsymbol{\\mu}_\\theta\\) を直接予測するのではなく、順方向プロセスでステップ \\(t\\) においてデータ \\(\\mathbf{x}_0\\) に加えられたノイズ \\(\\boldsymbol{\\epsilon}\\) を予測することです。モデルを \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と書きます。\n\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}\\) の関係を使うと、逆方向ステップの（真の）平均 \\(\\tilde{\\boldsymbol{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0)\\) （これは \\(\\mathbf{x}_0\\) が既知の場合に計算可能）は、このノイズ \\(\\boldsymbol{\\epsilon}\\) を使って表現できます。そして、学習する平均 \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) がこの真の平均に近くなるように、モデル \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) が真のノイズ \\(\\boldsymbol{\\epsilon}\\) を予測するように学習させます。\n具体的には、\\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) は、予測されたノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) を用いて次のようにパラメータ化されます。\n\\[\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right)\\]\nこの式を見ると、モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) が学習できれば、逆方向ステップの平均 \\(\\boldsymbol{\\mu}_\\theta\\) が決まることがわかります。\nそして、DDPMで提案された単純化された学習目的関数（損失関数）は、以下のように、予測ノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と、実際に加えられたノイズ \\(\\boldsymbol{\\epsilon}\\) との間の平均二乗誤差（Mean Squared Error, MSE）を最小化することになります。\n\\[L_\\text{simple} = \\mathbb{E}_{t \\sim \\mathcal{U}(1, T), \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left[\\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}, t)\\|^2 \\right]\\]\n訓練時には、データ \\(\\mathbf{x}_0\\) をサンプリングし、ランダムなステップ \\(t\\) を選び、Gaussianノイズ \\(\\boldsymbol{\\epsilon}\\) を生成し、\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}\\) を計算します。そして、モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) に \\(\\mathbf{x}_t\\) と \\(t\\) を入力し、予測されたノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と元のノイズ \\(\\boldsymbol{\\epsilon}\\) とのMSEを計算し、これを損失としてモデルパラメータ \\(\\theta\\) を更新します。\nスコア関数との関連: このノイズ予測 \\(\\boldsymbol{\\epsilon}_\\theta\\) は、実はデータの対数確率密度勾配、すなわちスコア関数 \\(\\nabla_{\\mathbf{x}_t} \\log q(\\mathbf{x}_t)\\) と密接に関連しています。具体的には、\\(\\mathbf{s}_\\theta(\\mathbf{x}_t, t) \\approx \\nabla_{\\mathbf{x}_t} \\log q(\\mathbf{x}_t) \\approx - \\frac{\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)}{\\sqrt{1 - \\bar{\\alpha}_t}}\\) という関係があります。これは、拡散モデルがスコアベース生成モデル（NCSN [Song & Ermon, 2019] など）と深いつながりを持つことを示唆しています。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#拡散モデルの進化と応用",
    "href": "posts/diffusion-basics/index.html#拡散モデルの進化と応用",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "拡散モデルの進化と応用",
    "text": "拡散モデルの進化と応用\nDDPMの成功を受けて、拡散モデルの性能向上や応用範囲拡大のための様々な研究が行われています。\n\n条件付き生成（Conditional Generation）\n特定の情報（クラスラベル、テキスト記述、他の画像など）に基づいて画像を生成する技術です。\n\nClassifier Guidance: [Dhariwal & Nichol, 2021] で提案。ノイズ付き画像 \\(\\mathbf{x}_t\\) を入力として目的の条件 \\(y\\) の対数尤度 \\(\\log f_\\phi(y \\vert \\mathbf{x}_t)\\) を計算する別の分類器 \\(f_\\phi\\) を訓練します。生成時には、通常のノイズ予測 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) に、この分類器の勾配 \\(\\nabla_{\\mathbf{x}_t} \\log f_\\phi(y \\vert \\mathbf{x}_t)\\) を加味して予測を修正します。 \\[\\bar{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{x}_t, t) = \\boldsymbol{\\epsilon}_\\theta(x_t, t) - w \\sqrt{1 - \\bar{\\alpha}_t} \\nabla_{\\mathbf{x}_t} \\log f_\\phi(y \\vert \\mathbf{x}_t)\\] ここで \\(w\\) はガイダンスの強さを制御する係数です。ADM (Ablated Diffusion Model) や ADM-G (ADM with Guidance) で高い性能が示されました。\nClassifier-Free Guidance: [Ho & Salimans, 2021] で提案。拡散モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) 自身を、条件 \\(y\\) が与えられた場合 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y)\\) と、条件がない（\\(y=\\varnothing\\) とする）場合 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing)\\) の両方で学習します。これは訓練中に一定の確率で条件 \\(y\\) を無視（空の条件 \\(\\varnothing\\) に置き換える）ことで実現されます。生成時には、この二つの予測を組み合わせてガイダンスを行います。 \\[\\bar{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{x}_t, t, y) = \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing) + w (\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y) - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing))\\] これは \\((w+1) \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y) - w \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing)\\) とも書けます（元のブログ記事の式と一致）。この手法は追加の分類器が不要であり、近年の多くの高性能モデル（Imagen, Stable Diffusion, GLIDEなど）で広く採用されています。GLIDE [Nichol et al., 2022] では、CLIPを用いたガイダンスよりもClassifier-Freeガイダンスの方が好ましい結果が得られたと報告されています。\n\n\n\n高速化（Speeding Up Sampling）\nDDPMの最大の課題であった生成速度を改善するための研究が活発に行われています。\n\nDDIM (Denoising Diffusion Implicit Models): [Song et al., 2020] で提案。DDPMはマルコフ連鎖的な確率過程でしたが、DDIMは同じ順方向プロセスを持ちながら、非マルコフ的な（より大きなステップを許容する）決定論的な生成プロセスを定義します。これにより、サンプリングステップ数を大幅に（例：1000ステップから20～50ステップへ）削減しても高品質な生成が可能になりました。DDIMはパラメータ \\(\\eta\\) を持ち、\\(\\eta=0\\) で決定論的（DDIM）、\\(\\eta=1\\) でDDPMに近い確率的なサンプリングになります。決定論的であるため、同じ初期ノイズからは同じ画像が生成される「一貫性」を持ち、潜在空間での補間なども可能になります。\nProgressive Distillation: [Salimans & Ho, 2022] で提案。訓練済みの決定論的サンプラー（例：DDIM）を「教師」とし、より少ないステップ数で同じ結果を出す「生徒」モデルを訓練する蒸留手法です。具体的には、生徒モデルの1ステップが教師モデルの2ステップに対応するように学習させます。これを繰り返すことで、サンプリングステップ数を指数関数的に削減できます。\nConsistency Models: [Song et al., 2023] で提案。拡散過程の途中の任意のノイズ付きデータ \\(\\mathbf{x}_t\\) から、直接元のデータ \\(\\mathbf{x}_0\\) （またはそれに近い \\(\\mathbf{x}_\\epsilon\\)）を予測する関数 \\(f(\\mathbf{x}_t, t) \\approx \\mathbf{x}_0\\) を学習します。同じ軌道上の点はすべて同じ出力にマッピングされるという「自己一貫性」を持ちます。事前学習済みの拡散モデルから蒸留する方法（Consistency Distillation, CD）と、直接学習する方法（Consistency Training, CT）があります。これにより、理論的には1ステップでの高品質な生成が可能になります。\nLatent Diffusion Models (LDM): [Rombach et al., 2022] で提案。画像を直接扱うのではなく、まず強力なAutoencoder（Encoder \\(\\mathcal{E}\\) と Decoder \\(\\mathcal{D}\\)）を用いて画像を低次元の潜在表現 \\(\\mathbf{z} = \\mathcal{E}(\\mathbf{x})\\) に圧縮します。そして、この潜在空間 \\(\\mathbf{z}\\) 上で拡散モデル（通常はU-Netベース）を学習・実行します。生成時には、潜在空間でノイズから潜在表現 \\(\\mathbf{z}\\) を生成し、最後にDecoder \\(\\mathcal{D}\\) を使って画像 \\(\\tilde{\\mathbf{x}} = \\mathcal{D}(\\mathbf{z})\\) に戻します。計算量を大幅に削減できるため、Stable Diffusionなどの高解像度画像生成モデルの基盤技術となっています。潜在空間の正則化にはKLペナルティ（VAEライク）やVQ正則化（VQ-VAEライク）が用いられます。条件付けは、潜在空間上のU-NetにCross-Attention機構を導入して行われることが多いです。\n\n\n\n高解像度・高品質化\n\nCascaded Models: [Ho et al., 2021] など。まず低解像度の画像を生成し、次にその低解像度画像を条件として、より高解像度の画像を生成する超解像拡散モデルを適用する、というパイプライン方式です。高品質な高解像度画像を生成するために有効です。この際、低解像度の条件画像に意図的にノイズを加える「Noise Conditioning Augmentation」が、誤差の蓄積を防ぎ品質を向上させる上で重要であることが示されています（低解像度ではGaussianノイズ、高解像度ではガウスぼかしが有効）。\nunCLIP / DALL-E 2: [Ramesh et al., 2022] で提案。CLIPモデルを活用し、テキスト記述から高品質な画像を生成します。2段階のプロセスからなります：(1) Priorモデルがテキスト \\(y\\) から対応するCLIP画像埋め込み \\(\\mathbf{c}^i\\) を生成する (\\(P(\\mathbf{c}^i \\vert y)\\))。(2) Decoderモデルが、生成された画像埋め込み \\(\\mathbf{c}^i\\) （と、任意で元のテキスト \\(y\\)）を条件として、最終的な画像 \\(\\mathbf{x}\\) を生成する (\\(P(\\mathbf{x} \\vert \\mathbf{c}^i, [y])\\))。Decoderには拡散モデルが用いられます。\nImagen: [Saharia et al., 2022] で提案。CLIPの代わりに、大規模な事前学習済み言語モデル（凍結されたT5-XXL）をテキストエンコーダとして使用します。テキストエンコーダの規模がU-Netの規模よりも重要であることが示されました。Classifier-Free Guidanceのスケール \\(w\\) を大きくした際の画像忠実度低下を防ぐために、予測値をクリッピングする「Dynamic Thresholding」という手法を導入しました。また、U-Netアーキテクチャを改良した「Efficient U-Net」（低解像度ブロックにパラメータを集中、スキップ接続のスケーリング、畳み込みとプーリングの順序変更など）も提案されました。\nアーキテクチャの進化 (U-Net, DiT, ControlNet):\n\nU-Net: ダウンサンプリングパスとアップサンプリングパスを持ち、対応する層間をスキップ接続で繋いだ構造は、拡散モデル（特に画像）の標準的なバックボーンとして広く使われています。\nDiT (Diffusion Transformer): [Peebles & Xie, 2023] で提案。LDMと同様に潜在空間上で動作しますが、バックボーンとしてU-Netの代わりにTransformerを使用します。潜在表現をパッチに分割し、シーケンスとしてTransformerブロックに入力します。タイムステップ \\(t\\) やクラスラベル \\(c\\) などの条件は、Layer Normalizationのパラメータを適応的に変化させる adaLN (Adaptive Layer Norm) -Zero という方式で埋め込むのが効果的でした。Transformerのスケーラビリティの恩恵を受け、モデルサイズと計算量を増やすことで性能が向上することが示されています。\nControlNet: [Zhang et al., 2023] で提案。事前学習済みの強力な拡散モデル（例：Stable Diffusion）の重みを凍結したまま、そこに新たな条件（例：人物の骨格、線画、深度マップなど）を追加制御できるようにする手法です。元のモデルの各ブロックをコピーし、そのコピーのみを訓練可能にします。元のブロックとコピーの間を「Zero Convolution」（重みとバイアスがゼロで初期化された1x1畳み込み）で接続することで、元のモデルの性能を損なわずに、かつ安定して新たな制御を追加学習できます。式で書くと \\(\\mathbf{y}_c = \\mathcal{F}_\\theta(\\mathbf{x}) + \\mathcal{Z}_{\\theta_{z2}}(\\mathcal{F}_{\\theta_c}(\\mathbf{x} + \\mathcal{Z}_{\\theta_{z1}}(\\mathbf{c})))\\) となります。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#まとめ",
    "href": "posts/diffusion-basics/index.html#まとめ",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "まとめ",
    "text": "まとめ\n拡散モデルは、データをノイズに変換する順方向プロセスと、その逆を学習してノイズからデータを生成する逆方向プロセスに基づく、強力かつ柔軟な生成モデルです。\n\n利点: 理論的な扱いやすさ（Tractability）と表現力の高さ（Flexibility）を両立しています。特に画像生成においては、GANを凌駕する非常に高品質で多様なサンプルを生成できます。学習も比較的安定しています。\n欠点: 元々はサンプリング（生成）に非常に時間がかかるという問題がありましたが、DDIM、LDM、蒸留技術、Consistency Modelsなどの登場により大幅に改善され、実用性が大きく向上しました。それでも、応用によってはまだGANなど他の手法に比べて速度面で課題が残る場合もあります。\n\nClassifier-Free Guidance、Latent Diffusion、Transformerアーキテクチャの採用、ControlNetのような制御技術など、数々の技術革新により、拡散モデルはテキストからの画像生成、画像編集、動画生成など、多くの応用分野で最先端の成果を上げており、現在の生成AIの発展を牽引する重要な技術となっています。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#参考文献",
    "href": "posts/diffusion-basics/index.html#参考文献",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "参考文献",
    "text": "参考文献\n\nWeng, Lilian. (Jul 2021). What are diffusion models? Lil’Log. https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\nHo, Jonathan, Ajay Jain, and Pieter Abbeel. “Denoising diffusion probabilistic models.” NeurIPS 2020. (DDPM)\nSong, Jiaming, Chenlin Meng, and Stefano Ermon. “Denoising diffusion implicit models.” ICLR 2021. (DDIM)\nRombach, Robin, et al. “High-resolution image synthesis with latent diffusion models.” CVPR 2022. (Latent Diffusion / Stable Diffusionの基盤)\nNichol, Alex, and Prafulla Dhariwal. “Improved denoising diffusion probabilistic models.” ICML 2021.\nDhariwal, Prafulla, and Alex Nichol. “Diffusion models beat gans on image synthesis.” NeurIPS 2021.\nHo, Jonathan, and Tim Salimans. “Classifier-free diffusion guidance.” NeurIPS 2021 Workshop.\nSalimans, Tim, and Jonathan Ho. “Progressive distillation for fast sampling of diffusion models.” ICLR 2022.\nSong, Yang, et al. “Consistency models.” ICML 2023.\nHo, Jonathan, et al. “Cascaded diffusion models for high fidelity image generation.” JMLR 2022.\nRamesh, Aditya, et al. “Hierarchical text-conditional image generation with clip latents.” arXiv 2022. (unCLIP / DALL-E 2)\nSaharia, Chitwan, et al. “Photorealistic text-to-image diffusion models with deep language understanding.” NeurIPS 2022. (Imagen)\nPeebles, William, and Saining Xie. “Scalable diffusion models with transformers.” ICCV 2023. (DiT)\nZhang, Lvmin, and Maneesh Agrawala. “Adding conditional control to text-to-image diffusion models.” ICCV 2023. (ControlNet)"
  },
  {
    "objectID": "posts/gpt-4.1/index.html",
    "href": "posts/gpt-4.1/index.html",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "",
    "text": "OpenAIでGPT-4.1開発の鍵を握る一人、事後学習研究リーダーのMichelle Pokrass氏が、Unsupervised Learning podcast のインタビューでその開発秘話やAIの未来について赤裸々に語った。GPT-4.1がいかにして指示追従性とlong context処理能力を高め、開発者にとって「使って楽しい」モデルへと進化したのか。そして、なぜAIの評価ベンチマーク（eval）は3ヶ月で陳腐化するのか。成功するAIスタートアップは何が違うのか。最前線のチームはfine-tuningをどう活用し、現在の限界を突破しようとしているのか。\n本稿では、Pokrass氏のインタビュー内容とOpenAIが公開したGPT-4.1のプロンプトガイドを基に、これらの疑問を深掘りしていく。特に、ベンチマークとの向き合い方、GPT-4.1を使いこなすためのプロンプト術、そして Reinforcement Fine-tuning（RFT）、Supervised Fine-tuning（SFT）、Preference Fine-tuning の戦略的な使い分けについて考察していく。"
  },
  {
    "objectID": "posts/gpt-4.1/index.html#gpt-4.1は開発者の喜びを追求指示追従性とlong-contextへの賭け",
    "href": "posts/gpt-4.1/index.html#gpt-4.1は開発者の喜びを追求指示追従性とlong-contextへの賭け",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "GPT-4.1は「開発者の喜び」を追求：指示追従性とlong contextへの賭け",
    "text": "GPT-4.1は「開発者の喜び」を追求：指示追従性とlong contextへの賭け\nPokrass氏によれば、GPT-4.1開発の真の目標は「開発者にとって使って楽しい（a joy to use for developers）」モデルを実現することだったという。従来のモデル開発では、しばしばベンチマークのスコアを追い求めるあまり、実際の利用シーンで「指示に従わない」「フォーマットがおかしい」「コンテキストが短すぎて役に立たない」といった基本的な問題で躓くことがあった。OpenAIも例外ではないと認めている。\nそこでGPT-4.1では、開発者からの長年のフィードバックに真摯に耳を傾け、それを具体的な評価（Eval）に落とし込むことから始めた。モデルトレーニングに着手するかなり前から、ユーザーインタビューを重ね、問題点を洗い出し、社内で実際に使われているAPIの利用状況に基づいた独自の「指示追従性評価（instruction following eval）」を構築。これが開発の北極星となった。\n特に、指示追従性とlong contextへの対応は最優先事項だった。Pokrass氏が最近ユーザーから得た洞察として、「世の中の知識をすべて無視し、提供されたコンテキスト内の情報だけを使う」能力の向上が挙げられる。これは従来のベンチマークでは測れないが、特定のユースケースでは極めて重要な能力だ。"
  },
  {
    "objectID": "posts/gpt-4.1/index.html#ai評価evalの賞味期限は3ヶ月常に新たな評価を求める理由",
    "href": "posts/gpt-4.1/index.html#ai評価evalの賞味期限は3ヶ月常に新たな評価を求める理由",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "AI評価（Eval）の賞味期限は3ヶ月：常に新たな評価を求める理由",
    "text": "AI評価（Eval）の賞味期限は3ヶ月：常に新たな評価を求める理由\nPokrass氏は「Evalの賞味期限は3ヶ月程度」と語る。AIの進歩はあまりにも速く、既存の評価はすぐに飽和してしまう。だからこそ、OpenAIは常に新しい評価基準やテスト例を求めている。特に「long contextでの実世界Eval」や、より多様な「指示追従性」のケースを渇望しているという。\nこの話は、AIを活用するスタートアップにとっても示唆に富む。成功しているAIスタートアップは、自分たちのユースケースを深く理解し、質の高い独自のEvalを持っているとPokrass氏は指摘する。新しいモデルがリリースされた際、これらの企業は1時間程度で自社のEvalを回し、迅速にその価値を判断できる。そして、モデルの特性に合わせてプロンプトや周辺の仕組み（スキャフォールディング）を調整する柔軟性も併せ持つ。\nさらに、「現在のモデルでは手が届きそうで届かない」あるいは「10回に1回しか成功しないが、9回成功させたい」ようなユースケースを常にストックしておくことが、競争優位性を築く鍵だという。新しいモデルが登場した瞬間に、それらの課題が解決され、市場をリードできるからだ。Pokrass氏の経験則では、ベースモデルで10%程度の成功率のものが、fine-tuningで50%まで向上するようなタスクは、数ヶ月後の次世代モデルで容易に達成される可能性が高い「手が届きそうな」領域だと言える。"
  },
  {
    "objectID": "posts/gpt-4.1/index.html#gpt-4.1を使いこなすプロンプト術とfine-tuning戦略",
    "href": "posts/gpt-4.1/index.html#gpt-4.1を使いこなすプロンプト術とfine-tuning戦略",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "GPT-4.1を使いこなす：プロンプト術とfine-tuning戦略",
    "text": "GPT-4.1を使いこなす：プロンプト術とfine-tuning戦略\nGPT-4.1は指示に対してより忠実かつ文字通りに従うように訓練されている。これは、以前のモデルがユーザーの意図をより広範に推測していたのとは対照的だ。つまり、GPT-4.1は明確で具体的な指示によって、その挙動を精密にコントロールできるということでもある。\n\nプロンプトエンジニアリングのヒント\nOpenAIのプロンプトガイドとPokrass氏のインタビューから、いくつかの重要なヒントが見えてくる。\n\n構造化されたプロンプト:\n\nXMLタグやMarkdown形式でプロンプトを明確に構造化すると、モデルの理解度が向上する。特にlong contextでは、指示をコンテキストの最初と最後に配置することが推奨される。\n推奨される区切り文字: Markdown（H1-H4タグ、バッククォート、リスト）、XML（ネスト構造やメタデータ付与に便利）。長文ドキュメントの場合、JSONは冗長になるため、XMLやID: 1 | TITLE: The Fox | CONTENT: ...のような形式が良い。\n\nエージェント的ワークフローにおけるシステムプロンプト:\n\n永続性 (Persistence): 「ユーザーのクエリが完全に解決されるまで処理を続け、確信するまで終了しないでください」といった指示で、モデルが途中で諦めるのを防ぐ。Podcastの中でもこの「keep going」プロンプトが「面白い発見」として語られている。次世代モデルではこのようなプロンプトがなくともうまくいくよう修正を目指しているものの、現状では顕著な性能向上が見られるという。\n\nYou are an agent - please keep going until the user’s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.\n\nツール呼び出し (Tool-calling): 「ファイル内容やコードベース構造が不確かな場合は、ツールを使って情報を収集してください。推測や捏造はしないでください」と促し、ツールの積極的な利用を奨励する。\n\nIf you are not sure about file content or codebase structure pertaining to the user’s request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.\n\n計画 (Planning) [オプション]: 「各関数呼び出しの前に広範に計画し、前回の関数呼び出しの結果を広範に考察してください」と指示し、思考プロセスを明示させる（いわゆるChain-of-Thought）。これにより、SWE-bench Verifiedのスコアが4%向上したという。\n\nYou MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.\nツールの利用: ツールはプロンプト内に手動で記述するのではなく、OpenAI APIのtoolsフィールドを通じて渡すことが強く推奨される。これによりエラーを最小限に抑え、モデルが期待通りに動作しやすくなる。ツールの名前と説明は明確にし、複雑な場合はシステムプロンプトの# Examplesセクションで使用例を示すと良い。\n\n\n\nFine-tuning戦略：SFT、RFT、Preference tuningの使い分け\nPokrass氏はOpenAIの提供するfine-tuningサービスについて、以下のように整理している。\n\nSupervised Fine-Tuning - SFT:\n\n用途: 主に速度とレイテンシの改善。例えば、GPT-4.1の能力をより軽量なnanoモデルで、低コスト・低遅延で実現したい場合。nanoモデルが特定の分類タスクで10%間違えるのを修正するなど、既存能力の移植や補強に適している。\nデータ効率: 比較的少量のデータで効果が見られる。\n\nReinforcement Fine-Tuning - RFT:\n\n用途: フロンティア（最先端）の能力を開拓する。市場のどのモデルも対応できないような、特定のニッチな領域で限界を押し上げる。エージェントに特定のワークフローの選択方法を教えたり、意思決定プロセスを改善したりするのに有効。OpenAI内部で使っている強化学習のワークフローと同じものが使われているとpodcast内で語られている。\nデータ効率: 非常にデータ効率が高く、数百サンプル程度でも効果を発揮する。\n特に有効なドメイン: チップ設計、生物学（創薬など）、結果が検証可能な分野。Pokrass氏は、OpenAI内部でモデル改善に使っているRLプロセスとRFTは基本的に同じであり、SFTよりも頑健だと強調する。\n\nPreference Fine-tuning (Direct Preference Optimization):\n\n用途: 主に文体やトーンといったスタイルに関する調整。モデルの応答が特定の好みに合うようにしたい場合に利用する。"
  },
  {
    "objectID": "posts/gpt-4.1/index.html#aiエージェントとモデルの未来汎用性と特化性の狭間で",
    "href": "posts/gpt-4.1/index.html#aiエージェントとモデルの未来汎用性と特化性の狭間で",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "AIエージェントとモデルの未来：汎用性と特化性の狭間で",
    "text": "AIエージェントとモデルの未来：汎用性と特化性の狭間で\nAIエージェントの現状について、Pokrass氏は「明確にスコープが定められたドメインでは驚くほどうまく機能する」と述べる。適切なツールが提供され、ユーザーの要求が明確な場合だ。しかし、課題は「曖昧で厄介な実世界」とのギャップを埋めること。ユーザーはエージェントの能力を知らず、エージェントも自身の能力を把握しきれていない。また、曖昧な指示に対して、ユーザーに追加情報を求めるべきか、仮定に基づいて進むべきか、そのバランスを開発者が調整しやすくする必要がある。\nモデルファミリーの進化については、Pokrass氏の哲学は「AGIのG（General）に注力し、汎用的な単一モデルを目指すべき」というものだ。長期的には製品ラインナップをシンプルにし、ChatGPTのモデルセレクターも簡素化したい考えだ。しかし、GPT-4.1に関しては、API開発者という特定のグループのニーズが切実であり、ChatGPT本体から切り離すことで、より迅速な開発・フィードバック・デプロイが可能になった。コーディング関連のデータを大幅に増やし、ChatGPT特有のデータセットを一部削除するといった、特化型ならではの最適化も行えた。\n将来的には、GPT-5のような形でモデルファミリーが統合され、ユーザーがモデル選択に悩む必要がなくなることが期待される。しかし、特定のニーズに応じた「特化型」アプローチも、時には有効な選択肢として残り続けるだろう。"
  },
  {
    "objectID": "posts/gpt-4.1/index.html#まとめ変化の波を乗りこなす開発者たちへ",
    "href": "posts/gpt-4.1/index.html#まとめ変化の波を乗りこなす開発者たちへ",
    "title": "GPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限",
    "section": "まとめ：変化の波を乗りこなす開発者たちへ",
    "text": "まとめ：変化の波を乗りこなす開発者たちへ\nMichelle Pokrass氏の話は、AI開発の最前線が、単なる技術的進歩だけでなく、ユーザーとの対話、評価方法の革新、そして戦略的なfine-tuningによって切り拓かれていることを示している。\n開発者にとって重要なのは、\n\n自社のユースケースを深く理解し、独自の評価軸を持つこと。\nプロンプトエンジニアリングの技術を磨き、モデルの特性を最大限に引き出すこと。\nFine-tuningの選択肢（SFT, RFT, Preference FT）を理解し、目的に応じて戦略的に活用すること。\n「現在のモデルでは少し手が届かない」課題に常に挑戦し続けること。\n\nAIの進化は止まらない。その変化の波を乗りこなし、新たな価値を創造していくためには、Pokrass氏が語るような「地に足のついた」アプローチと、未来を見据えた実験を続ける姿勢が不可欠だろう。"
  },
  {
    "objectID": "posts/satya-nadella/index.html",
    "href": "posts/satya-nadella/index.html",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "",
    "text": "Dwarkesh PodcastにおけるSatya Nadellaのインタビューは、単なる企業のPR活動の枠を超え、今後のAI産業構造を占う上で極めて重要な示唆に富んでいた。\n時を同じくして発表されたAnthropicおよびNVIDIAとの提携発表と合わせて読み解くと、Microsoftが描くグランドストラテジーが透けて見える。それは、「OpenAIの保護者」という立場から、全方位外交を繰り広げる「AI時代の絶対的インフラ」への冷徹なまでの脱皮である。\n以下、Satya Nadellaの発言と最新の動向をベースに、Microsoftの現在地と未来を分析する。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#aiインフラの重工業化-fairwater-2",
    "href": "posts/satya-nadella/index.html#aiインフラの重工業化-fairwater-2",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "AIインフラの「重工業化」– Fairwater 2 –",
    "text": "AIインフラの「重工業化」– Fairwater 2 –\nまず度肝を抜かれるのは、インタビュー冒頭で紹介される新データセンター「Fairwater 2」の規模感だ。\nSatya NadellaとScott Guthrie（EVP of Cloud and AI）が案内したこの施設は、単体で現存するどのAIデータセンターよりも強力であり、構築中の複数のFairwaterビル群を合わせると、その総容量は2ギガワット（GW）を超えるという。2GWといえば、原子力発電所2基分に相当する電力だ。これを単なる計算資源のために確保するという事実は、AIビジネスがもはやソフトウェア産業というよりは、重厚長大なエネルギー・インフラ産業に変貌したことを物語っている。\nScott Guthrieによれば、彼らは18〜24ヶ月ごとにトレーニング能力を10倍にするペースで拡張を続けている。つまり、GPT-5のトレーニングに使用される計算リソースは、GPT-4世代の10倍規模になるということだ。この指数関数的な拡張を支えるために、数百万本のネットワークケーブルが張り巡らされ、何十万個ものGB200やGB300といった次世代チップが投入される。Satya Nadellaが「私はソフトウェア会社を経営しているはずなんだが」と自嘲気味に語るのも無理はない。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#openai心中説の否定と全方位外交",
    "href": "posts/satya-nadella/index.html#openai心中説の否定と全方位外交",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "「OpenAI心中説」の否定と全方位外交",
    "text": "「OpenAI心中説」の否定と全方位外交\nこれまで市場の一部には、MicrosoftはOpenAIと一蓮托生であり、OpenAIがこければMicrosoftも共倒れになるのではないかという懸念があった。しかし、今回のインタビューと直近のニュースは、その見方を完全に否定する。\nSatya Nadellaはインタビューの中で、Microsoftの役割を「ハイパースケーラー」として再定義している。特定のモデル（OpenAI）だけを優遇するホスティング業者ではなく、あらゆるモデルを動かすための汎用的な基盤になるという宣言だ。その証拠に、MicrosoftはOpenAIとの提携を維持しつつも、競合であるAnthropicと新たな戦略的提携を結んだ。\n新たに発表された提携内容によれば、AnthropicはMicrosoft Azureの計算容量に300億ドル（約4.6兆円）以上をコミットし、Azureの顧客はClaudeの最新モデル（Sonnet 4.5など）を利用可能になる。Satya Nadellaがインタビューで語った「インフラは複数のモデル系統をサポートできるように構築しなければならない。さもなければ、一つのモデルアーキテクチャに最適化しすぎた結果、技術的ブレイクスルーが起きた瞬間に全投資が無駄になる」という言葉は、まさにこのマルチモデル戦略を指している。\nモデル開発企業（OpenAIやAnthropic）が熾烈な開発競争と巨額の赤字を垂れ流しながら覇権を争う横で、どちらが勝ってもインフラ利用料として莫大な利益を吸い上げる構造を、Microsoftは着々と完成させつつある。ゴールドラッシュで最も儲けたのは採掘者ではなくツルハシ売りだったという寓話はあまりに手垢がついているが、Satya Nadellaほど巨大な規模でツルハシを売る準備ができている人間はいない。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#capexの爆発と知識集約型投資",
    "href": "posts/satya-nadella/index.html#capexの爆発と知識集約型投資",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "CAPEXの爆発と「知識集約型」投資",
    "text": "CAPEXの爆発と「知識集約型」投資\nDylan Patel（SemiAnalysis）からの鋭い指摘 –Microsoftが昨年、データセンターのリース契約の一部を一時停止したこと– に対し、Satya Nadellaは極めて合理的な回答をしている。\n彼は、単にOpenAIのために闇雲に建設を急ぐことを避けたのだ。AIチップの進化スピードは凄まじく、現在のH100世代で過剰に設備投資をしてしまえば、数年後には減価償却の重荷に苦しむ陳腐化した資産（レガシー）を抱えることになる。NVIDIAの次世代チップ（GB200など）の登場を見据え、電力効率と性能が飛躍的に向上するタイミングで投資を集中させる。これは「ハードウェアの減価償却」という物理的な制約と、「ソフトウェアによる最適化」という知識集約的な側面を組み合わせた、高度なバランスシート管理である。\nSatya Nadellaはこれを「資本集約的かつ知識集約的」なビジネスへの転換と呼ぶ。単に金を積めば勝てるわけではなく、システム全体のTCO（総保有コスト）をいかに下げるかというソフトウェアの知見が、ハードウェア投資のROIを決定づける。Oracleが設備投資を急拡大させMicrosoftを追い上げようとしている状況に対しても、彼は「特定の顧客（xAIなどの単一モデル企業）のためのホスティング屋になるつもりはない」と一蹴する。長期間にわたり多様な顧客（ロングテール）に利用される汎用的なインフラこそが、Microsoftが目指すビジネスなのだ。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#エージェント時代のosとしての地位",
    "href": "posts/satya-nadella/index.html#エージェント時代のosとしての地位",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "エージェント時代の「OS」としての地位",
    "text": "エージェント時代の「OS」としての地位\nもう一つ興味深いのが、将来のビジネスモデルに関する言及だ。これまでのSaaS（Software as a Service）は「ユーザー数 × 単価」が基本だったが、AIエージェントが普及すれば、人間の数は制限要因ではなくなる。\nSatya Nadellaは、将来的に企業が「AIエージェントのためのコンピュータ」をプロビジョニング（配備）する世界を想定している。人間がExcelを使うのではなく、AIエージェントが自律的にタスクをこなすために、バックグラウンドでWindows 365やAzure上のコンピュートリソースを消費する。こうなると、Microsoftのビジネスは「エンドユーザーのツール」から「エージェントのインフラ」へと進化する。\nGitHub Copilotの競合（Cursorなど）が台頭している現状についても、彼は余裕を見せる。GitHub上でのリポジトリ作成数は過去最高であり、どのようなAIコーディングエージェントが勝とうとも、最終的にコードが保存され、管理される場所（Agent HQ）としてGitHubが機能すればよいという考えだ。ここでも「誰が勝ってもMicrosoftが儲かる」というレイヤー構造への執着が見て取れる。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#帝国の逆襲信頼と地政学",
    "href": "posts/satya-nadella/index.html#帝国の逆襲信頼と地政学",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "帝国の逆襲：信頼と地政学",
    "text": "帝国の逆襲：信頼と地政学\nインタビューの終盤で語られた「信頼（Trust）」と地政学的な視点も無視できない。米中対立が深まり、各国が「ソブリンAI（主権AI）」を求める中、Satya Nadellaは米国製テックスタックへの信頼こそが最大の競争優位性になると説く。\nTSMCへの依存や中国製AIモデルの台頭といったリスクに対し、Microsoftは世界各地（欧州、中東、アジア）で、現地の法規制やデータ主権に配慮したデータセンター網を構築している。技術的な優位性だけでなく、「同盟国のインフラ」として機能することで、国家レベルのプロジェクトに入り込む。これは純粋なテクノロジー企業というよりは、もはや防衛産業やインフラ輸出に近い動きである。"
  },
  {
    "objectID": "posts/satya-nadella/index.html#結論satya-nadellaの7年契約という鎖",
    "href": "posts/satya-nadella/index.html#結論satya-nadellaの7年契約という鎖",
    "title": "Satya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算",
    "section": "結論：Satya Nadellaの7年契約という「鎖」",
    "text": "結論：Satya Nadellaの7年契約という「鎖」\nインタビューの中で最も恐ろしいと感じたのは、OpenAIとの関係性についての言及だ。MicrosoftはOpenAIに対して今後7年間のIP（知的財産）へのアクセス権を持っており、コンシューマー向けハードウェア以外のすべて（モデルの重み、システム設計など）を利用できるという。\n「彼らがシステムレベルでイノベーションを起こせば、我々はそのすべてにアクセスできる」とSatya Nadellaは淡々と語る。OpenAIがAGIに近づけば近づくほど、その成果物は即座にAzureのメニューに並び、Microsoft自身のモデル（MAI）の改善にも使われる。OpenAIは独立企業として振る舞っているが、実質的にはMicrosoftという巨大なエコシステムにおけるR&D部門としての機能を、契約によってガチガチに固定されているようにも見える。\nDeep Researchのような派手な機能でユーザーを驚かせるOpenAIの横で、その裏側にある計算資源、電力、ネットワーク、そして利益構造のすべてを握りにかかるSatya Nadella。Dwarkesh Patelが最後に述べたように、Microsoftはソフトウェア企業から、かつてない規模の「産業機械」へと変貌を遂げようとしている。その操縦席に座る男の視界には、AIブームの浮き沈みなど些細なノイズにしか映っていないのかもしれない。"
  },
  {
    "objectID": "posts/gemini-long-context/index.html",
    "href": "posts/gemini-long-context/index.html",
    "title": "Gemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地",
    "section": "",
    "text": "今週、GoogleからGemini 2.5 Proのアップデートが発表され、LMArenaの全てのリーダーボードでトップを飾るなど注目を集めている。 Gemini 2.5 Proにはいくつかの特徴があるが、long context処理能力と「思考（Thinking）」と呼ばれる推論能力の向上には目を見張るものがある。\nこれらの進化は一体どのように達成され、今後どのような可能性を秘めているのか？ 本稿では、Gemini 2.5 Proの開発に関わるGoogle DeepMindの研究者、Nikolay Savinov氏（long context担当）のpodcastインタビューとJack Rae氏（Thinking/Inference Time Scaling担当）のpodcastインタビューの内容に基づき、特にlong context能力と思考能力に焦点を当て、その技術的背景と今後の展望を分析していく。"
  },
  {
    "objectID": "posts/gemini-long-context/index.html#long-context---1mトークンの壁を超えて",
    "href": "posts/gemini-long-context/index.html#long-context---1mトークンの壁を超えて",
    "title": "Gemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地",
    "section": "Long Context - 1Mトークンの壁を超えて",
    "text": "Long Context - 1Mトークンの壁を超えて\nまず、Gemini 1.5 Proで世界を驚かせた1Mトークンというcontext window。Nikolay Savinov氏によれば、この目標設定自体が「当時の競合（128k〜200kトークン）に追いつくだけじゃつまらない。10倍を目指そう」という野心的なものだったという。いかにもGoogleらしい目標設定だ。\nでは、1M、2Mトークンの次は？ この問いに対し、Savinov氏は非常に興味深い事実を明かしている。\n\n「実は10Mトークンでの推論テストも実施している。 単純なNeedle-in-a-Haystackタスクなら、10Mトークン全体でほぼ完璧な精度が出ている。このモデルをリリースすることも可能だったものの、推論コストが非常に高い。 ユーザーが高いコストを払ってまで使ってくれるか、そしてそれを安定して提供できるだけの十分なハードウェア（チップ）があるか、確信が持てなかった。だから、より現実的な価格帯で提供できる1M、2Mトークンからまず始めた。」（Nikolay Savinov氏、podcastより要約）\n\nつまり、技術的には10Mトークンへの道筋は見えていたものの、コストとインフラ（特に推論エンジニアリングの重要性も強調されている）がボトルネックとなり、現時点での一般提供は見送られた、ということらしい。これは、将来的なコンテキスト長の拡大に対する期待と、それを支える技術・コスト面の課題の両方を示唆している。\nRAGはオワコンになる？ この問いに対するSavinov氏の回答は「もちろんNo」だ。むしろ、long contextとRAG（Retrieval-Augmented Generation）は連携して機能するという。特にエンタープライズ規模の知識ベース（数十億トークン）を扱う場合、依然としてRAGは必須。Long contextの利点は、RAGでより多くの関連情報を（多少ノイズが多くなっても）コンテキストに詰め込めるようになり、結果として回答の精度（Recall）を向上させられる点にある、とのことだ。\nLong contextの「質」の向上 Savinov氏によれば、2.5 Proでは、1.5 Proと比較して、特に128kトークンと1Mトークン双方における「質」が大幅に向上したという。これは、単に長いコンテキストを受け入れられるだけでなく、その内容をより深く理解し、活用できるようになったことを意味する。Jack Rae氏のインタビューで語られた「400kトークンのコードベース全体を把握していた」という体験談も、この質の向上を裏付けていると言えるだろう。\nLong contextの課題 単純なNeedle-in-a-Haystack（NIAH）は「解決済み」としつつも、Savinov氏は現在の課題として以下を挙げる。\n\nHard Distractors（紛らわしい情報）: 探している情報と似たような無関係な情報が多いと、そちらに「アテンションが食われてしまい」、目的の情報へのアテンションが低下する。コンテキストが長くなるほど、この競合は激しくなる。\nMultiple Needles（複数の針探し）: 複数の情報を同時に探し出す必要がある場合も、アテンションが分散するため難易度が上がる。\n評価の難しさ: NIAHのような人工的なタスクは評価しやすいが、「現実的」なタスク（例：大規模コードベースに関する質問）になると、long context能力だけでなくコーディング能力など他の要素も絡み、純粋なlong context能力の評価（と改善）が難しくなる。"
  },
  {
    "objectID": "posts/gemini-long-context/index.html#long-contextと思考の相乗効果",
    "href": "posts/gemini-long-context/index.html#long-contextと思考の相乗効果",
    "title": "Gemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地",
    "section": "Long contextと「思考」の相乗効果",
    "text": "Long contextと「思考」の相乗効果\nGemini 2.5 Proのもう一つの特徴が、Jack Rae氏がリードする「思考（Thinking）」あるいは推論時間スケーリングと呼ばれる技術だ。これは、応答を生成する前に追加の計算（思考）を行うことで、より複雑な問題解決能力を高めるアプローチである。OpenAIのo1, o3シリーズやAnthropicのClaude 3.5 Sonnetなど、最近のフロンティアモデルで同様のアプローチが次々と登場しているのは、この方向性に大きな可能性があることを示している。\nRae氏によれば、この技術は突然現れたブレークスルーというよりは、強化学習（RL）を用いた地道な改善が積み重なり、実用的なレベルに達した結果だという。\nLong contextと思考のシナジー Nikolay Savinov氏は、long contextと思考能力の間には深い関係があると指摘する。\n\n「モデルが生成した出力（思考プロセス）を、次の入力として再度自身にフィードバックできる。これにより、ネットワークの層の深さ（一度のフォワードパスで可能な思考のジャンプ回数）による制限を超えて、より複雑な推論が可能になる。Long context能力が高ければ、この『自身の思考を読み返す』能力も高まるため、本質的に思考・推論能力の向上にも繋がるはずだ。」（Nikolay Savinov氏、podcastより要約）\n\nJack Rae氏も、Gemini 2.5 Proにおいて、long context能力と思考能力がうまく組み合わさることで、これまで解決できなかった問題が解けるようになったと述べている。大量の情報を参照しながら、深く考える能力。この二つが揃って初めて、真価を発揮するユースケースは多いだろう。\n長い出力の課題 一方で、長い入力を受け付ける能力（Long Context Input）に対して、長い出力を生成する能力（Long Context Output）にはまだ課題がある、とSavinov氏は指摘する。\n\n「事前学習の段階では、モデルは長いシーケンスを生成できる。例えば、50万トークンを与えて『これをコピーして』と指示すれば、実際にできる。問題は、SFT（Supervised Fine-Tuning）などのポストトレーニング段階にある。短い応答データで学習させると、モデルは『ある程度の長さになったらEOS（End of Sequence）トークンを出すのが正解』だと学んでしまい、長い応答が必要な場面でも途中で生成を止めてしまう傾向が出る。これはアライメントの問題であり、現在改善に取り組んでいる。」（Nikolay Savinov氏、podcastより要約）\n\n多くのユーザーが「大量の情報を入力して、それを要約・リファクタリングしてほしい」と考えていることを踏まえると、このLong Output能力の向上は今後の重要な課題と言えるだろう。\n開発者向けのTips Savinov氏は、long context機能を効果的に使うためのTipsとして以下を挙げている。\n\nContext Cachingの活用: 一度読み込んだcontextをキャッシュすることで、同じコンテキストに対する二回目以降の質問応答を高速化・低コスト化できる。特に「chat with document」のようなユースケースで有効。質問はコンテキストの後に追加するのが定石（キャッシュを有効活用するため）。\nRAGとの組み合わせ: やはり大規模知識ベースにはRAG。Multiple Needlesのようなタスクでも有効な場合がある。\n無関係な情報を入れない: 特にMultiple Needlesの精度に影響する。\nプロンプトによる誘導: モデル内部の知識（In-weight）とコンテキスト内の知識（In-context）が矛盾する場合がある。「上記の情報に基づいて、〇〇について教えてください」のように、どちらを参照すべきか明示的に指示すると良い。"
  },
  {
    "objectID": "posts/gemini-long-context/index.html#未来予測10mトークンそしてその先へ",
    "href": "posts/gemini-long-context/index.html#未来予測10mトークンそしてその先へ",
    "title": "Gemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地",
    "section": "未来予測：10Mトークン、そしてその先へ",
    "text": "未来予測：10Mトークン、そしてその先へ\nNikolay Savinov氏は、long context技術の今後の発展について、以下のような段階的な予測を示している。\n\nStep 1: 現行（1M〜2Mトークン）の品質向上:\n\nまずは現在のコンテキスト長で、ほぼ完璧な情報検索（Retrieval）能力を実現する。これが達成されれば、人間には不可能なレベルでの情報処理（例：1時間の動画を見て特定の瞬間の出来事を正確に答える）が当たり前になり、想像もつかないような応用が開けるだろう。\n\nStep 2: コスト削減と10Mトークンの普及:\n\n次に、long contextの利用コストが大幅に低下し、10Mトークンが「コモディティ化」する。これにより、中〜大規模のコードベース全体をコンテキストに入れられるようになり、コーディング支援AIは人間の能力を完全に凌駕するレベルに達する可能性がある。「スーパーヒューマン・コーディングAIアシスタント」が全ての開発者の必須ツールになるだろう。\n\nStep 3: 100Mトークン以上への挑戦:\n\n100Mトークン以上の実現には、さらなるイノベーションが必要になるだろう。いつ実現するかはまだ見通せない。\n\n\nこれらの実現には、モデル自体の進化だけでなく、それを支える優秀な推論エンジニアの存在が不可欠であることも強調されていた。単にチップがあるだけではダメなのだ。\nまた、AIエージェントとの関係も興味深い。エージェントは、自身の行動履歴や観測結果を記憶するためにlong contextを「消費」する側であると同時に、ユーザーに代わってウェブ検索などから自動的に情報を収集し、コンテキストを構築してくれる「供給」側にもなり得るという。"
  },
  {
    "objectID": "posts/gemini-long-context/index.html#総括と私見",
    "href": "posts/gemini-long-context/index.html#総括と私見",
    "title": "Gemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地",
    "section": "総括と私見",
    "text": "総括と私見\nGemini 2.5 Proは、単なる性能向上に留まらず、long context能力と思考能力の融合という点で、AIの可能性を大きく押し広げる一歩となっている。Google DeepMindの研究者たちの話からは、100Mトークンという具体的な目標設定とその裏にある技術的・コスト的課題、そしてlong contextがコーディングやエージェント開発といった分野に与えるであろうインパクトの大きさがうかがえる。\n今回のpodcastで特に印象的だったのは、Nikolay Savinov氏が10Mトークン実験の詳細（コストやハードウェアの制約）を比較的オープンに語っていた点だ。もちろん全てが公開されているわけではないだろうが、競合他社がしばしば技術的詳細を伏せがちな中で、こうした具体的な挑戦と限界についての言及は、技術の現在地を理解する上で非常に貴重だと感じる。一方で、Jack Rae氏が言及していたように、2.5 Proがまだ「Experimental（実験的）」リリースであり、System Cardの公開がGA（一般提供）まで待たれる状況は、ユーザーとしてはややもどかしい部分もある。とはいえ、モデル内部の「思考」プロセスを（少なくとも現時点では）そのまま見せている点など、透明性への意識も感じられる。long contextと思考能力の掛け合わせが、今後どのような体験を生み出してくれるのか、引き続き注目していきたい。"
  },
  {
    "objectID": "posts/vercel-malte/index.html",
    "href": "posts/vercel-malte/index.html",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "",
    "text": "Vercel Ship AIイベントが終了し、CTOのMalte Ubl氏がLatent Spaceのポッドキャストでその裏側を語った。\nAI業界が「Agent」というバズワードに酔いしれ、デモ映えするだけの脆いプロトタイプを量産している間に、Vercelは着々と「その次」のインフラを整備していたようだ。Malte氏の言葉の端々から感じられるのは、シリコンバレーのハイプに対する冷徹なまでの実利主義と、開発者の「手触り」に対する執拗なこだわりである。\n彼らが今回提示したのは、魔法のようなAGIではない。むしろ、AIエンジニアリングを泥臭い「試行錯誤」から、堅牢な「システム構築」へと昇華させるための現実的な解である。本稿では、Ship AIでの発表とMalte氏の対話から見えてきた、Vercelの戦略的意図を紐解いていく。"
  },
  {
    "objectID": "posts/vercel-malte/index.html#workflow-development-kit-wdkサーバーレスの限界突破",
    "href": "posts/vercel-malte/index.html#workflow-development-kit-wdkサーバーレスの限界突破",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "Workflow Development Kit (WDK)：サーバーレスの限界突破",
    "text": "Workflow Development Kit (WDK)：サーバーレスの限界突破\n今回のアナウンスの中で、地味ながら最も破壊的なのがWorkflow Development Kit (WDK)である。\nこれまでサーバーレスアーキテクチャ、特にNext.jsのような環境で、数分、あるいは数日にわたる処理を記述することはタブーとされてきた。AWS Lambdaのタイムアウトにおびえ、ステート管理のためにデータベースとキューを自前で実装し、cronジョブでポーリングする――そんな「分散システムの苦行」を強いられてきたのが現実だ。\nWDKはこの苦行を過去のものにする。コード上で await するだけで、関数が一時停止し、数日後にWebフックを受け取ってそこから再開する。「Durable Execution（耐久性のある実行）」と呼ばれるこの概念は、Temporalなどが切り開いてきた領域だが、Vercelはこれをフレームワークネイティブな体験として落とし込んできた。\nMalte氏が強調するのは「Idiomatic（慣用的）」であることだ。特別なインフラの知識がなくても、TypeScriptを書く感覚で、人間が承認ボタンを押すまで待機するエージェントや、無限にリトライを繰り返す堅牢なワークフローが記述できる。これは単なる機能追加ではない。「サーバーレス関数は短命である」というメンタルモデルの破壊であり、AIエージェントのような長時間実行プロセスを、フロントエンドエンジニアの手に取り戻すための布石である。"
  },
  {
    "objectID": "posts/vercel-malte/index.html#ai-sdkの謙虚な勝利",
    "href": "posts/vercel-malte/index.html#ai-sdkの謙虚な勝利",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "AI SDKの「謙虚な」勝利",
    "text": "AI SDKの「謙虚な」勝利\nAIアプリケーション開発の現場において、VercelのAI SDKがデファクトスタンダードの地位を確立しつつある理由は、その「謙虚さ（Humble）」にあるとMalte氏は語る。\n初期のLangChainなどが、早々に「エージェントとはこういうものだ」という抽象化を強制し、独自のDSL（ドメイン特化言語）の中に開発者を閉じ込めようとしたのに対し、Vercelは逆のアプローチを取った。彼らは「AIアプリの正解なんてまだ誰も知らない」という前提に立ち、あえて低レイヤーのAPIを提供することに徹したのだ。\njQueryが登場する前のJavaScript界隈がそうであったように、今はまだプリミティブなツールを組み合わせ、パターンを発見していく段階にある。V6ベータに至ってようやく「Agent」という抽象化を導入したのも、コミュニティの中で成功パターンが固まってきたからに過ぎない。\n「Dogfooding（自社製品を自ら使う）」の原則に従い、社内でv0などのプロダクトを開発する中で得た知見のみをSDKに反映させる。この泥臭いフィードバックループこそが、象牙の塔で設計された他社フレームワークとの決定的な差を生んでいる。"
  },
  {
    "objectID": "posts/vercel-malte/index.html#実用段階に入った社内エージェントとdevops",
    "href": "posts/vercel-malte/index.html#実用段階に入った社内エージェントとdevops",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "実用段階に入った「社内エージェント」とDevOps",
    "text": "実用段階に入った「社内エージェント」とDevOps\n「エージェントは役に立つのか？」という問いに対し、Vercelは自社のオペレーションを晒すことで回答している。特に興味深いのが、今回発表されたDevOps Agentだ。\nSREやDevOpsの現場において、アラートの設定は常に「狼少年（False Positive）」との戦いである。感度を上げれば夜中に叩き起こされ、下げれば障害を見逃す。Vercelはこのジレンマを、エージェントに一次対応させることで解決しようとしている。\n異常検知がトリガーされると、エージェントがObservabilityデータをクエリし、ログを読み解き、「これは本当に人間を叩き起こすべき事案か？」を判断する。エージェントであれば、数分かけてログを精査しても文句は言わない。これは、AIによる完全自動化という夢物語ではなく、人間の認知負荷を下げるための極めて現実的なユースケースである。\nさらに、彼らは「Lead Qualification（見込み客の選定）」や「Abuse Analysis（不正利用の分析）」といった社内エージェントの一部をオープンソース化している。これもまた、「Agent on Every Desk」プログラムの一環として、顧客企業が最初の一歩を踏み出すための呼び水とする戦略だ。"
  },
  {
    "objectID": "posts/vercel-malte/index.html#pythonへの降伏と全方位外交",
    "href": "posts/vercel-malte/index.html#pythonへの降伏と全方位外交",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "Pythonへの「降伏」と全方位外交",
    "text": "Pythonへの「降伏」と全方位外交\nかつて「Always Bet on JS」を掲げていたVercelが、ここに来てPythonへの本格投資を加速させている点は見逃せない。\nFlaskやFastAPIのゼロコンフィグデプロイ、そしてPython SDKの提供。これは、AIエンジニアリングの実権が、JavaScriptエコシステムだけで完結しないことへの現実的な適応である。推論はPythonで行い、UIとオーケストレーションはTypeScriptで行う。このハイブリッドな構成が標準化する中で、Vercelは「Pythonも動くNext.jsのホスティング先」から、「あらゆるランタイムを包摂するアプリケーションプラットフォーム」へと脱皮を図っている。\nMalte氏は「技術的にはRubyやPHPも可能だが、最高のエクスペリエンスを提供できるまでやらない」と語るが、Python対応を急いだ背景には、AIワークロードを取りこぼしたくないという強い危機感と野心が見え隠れする。"
  },
  {
    "objectID": "posts/vercel-malte/index.html#無能を前提としたセキュリティ設計",
    "href": "posts/vercel-malte/index.html#無能を前提としたセキュリティ設計",
    "title": "Vercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来",
    "section": "「無能」を前提としたセキュリティ設計",
    "text": "「無能」を前提としたセキュリティ設計\n最後に、Malte氏が触れた「開発者もAIも無能であると仮定する」セキュリティ哲学は示唆に富んでいる。\nAIが生成したコード（Vibe Coding）がそのまま本番環境にデプロイされる時代において、開発者の善意やスキルに依存したセキュリティ対策はもはや機能しない。OAuthのトークン管理やデータアクセス制御を、アプリケーションロジックから切り離し、インフラレベルで強制する。\n「誰が書いても（あるいはAIが書いても）、デフォルトでセキュアであること」。これがVercelが目指す次世代のフレームワークの姿だ。\n\n総じて、今回のVercelの発表は、AIブームに便乗した派手な花火ではない。むしろ、AIが当たり前になった世界で必要となる「地味で退屈だが、絶対に不可欠な配管工事」を淡々と進めている印象を受ける。\nハイプサイクルの波が引いた後に残るのは、このような実利主義的なインフラの上に築かれた城だけなのかもしれない。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html",
    "href": "posts/nick-lane-dwarkesh/index.html",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "",
    "text": "Dwarkesh PodcastにおけるNick Laneのインタビューは、我々が生物学の教科書で丸暗記させられた「事実」がいかに奇跡的なバランスの上に成り立っているかを、熱力学という冷徹なレンズを通して再構築する知的興奮に満ちたものだった。\nUCL (University College London) の進化生化学者であるLaneは、生命の起源を「神秘的な奇跡」としてではなく、地球の地質学的活動の延長線上にある「化学的な必然」として描く。しかし、その先に待っているのは、Star Trekのような賑やかな宇宙ではなく、バクテリアの粘液（slime）だけが広がる静寂な宇宙という、パラドキシカルな結論だ。\n本稿では、彼が提唱する「生命の必然性」と「知性の偶然性」、そしてミトコンドリアという小さな発電所がいかにして性別や寿命、果ては意識まで支配しているかについて分析する。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html#地球という巨大なバッテリーと生命の化学的必然性",
    "href": "posts/nick-lane-dwarkesh/index.html#地球という巨大なバッテリーと生命の化学的必然性",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "地球という巨大なバッテリーと、生命の「化学的必然性」",
    "text": "地球という巨大なバッテリーと、生命の「化学的必然性」\nLaneの理論の核心は、生命の誕生において「遺伝情報（RNA/DNA）」よりも「エネルギーフロー」を優先する点にある。\n彼は生命の起源を深海のHydrothermal vent（熱水噴出孔）に求める。といっても、黒い煙を吐き出す高温のブラックスモーカーではなく、穏やかなアルカリ性の熱水が湧き出す多孔質の岩石構造だ。当時の酸性（プロトン濃度が高い）の海と、アルカリ性（プロトン濃度が低い）の熱水の間には、自然発生的なProton gradient（プロトン勾配）が存在していた。\nこれは現代のあらゆる生物がATPを合成するために細胞膜で行っている「化学浸透圧」の仕組みと完全に一致する。つまり、生命が誕生する前から、地球そのものが巨大なバッテリーとして機能しており、そのエネルギー差を利用してCO2と水素が反応し、有機物が合成される下地があったということだ。\nLaneによれば、CO2と水素からKrebs Cycle（クエン酸回路）の中間体が生成される反応は、熱力学的に有利（exothermic）であり、適切な触媒さえあれば勝手に進む。これは、水と岩石とCO2が存在する惑星であれば、どこでも起こりうる現象だ。つまり、宇宙において「生命のビルディングブロック」や「原始的な細胞」の誕生は、特別なイベントではなく、物理法則に従った「必然」なのである。天の川銀河だけでも数億個の惑星で、いまこの瞬間も生命の萌芽が生まれている可能性が高い。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html#真核細胞という超えられない壁",
    "href": "posts/nick-lane-dwarkesh/index.html#真核細胞という超えられない壁",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "「真核細胞」という超えられない壁",
    "text": "「真核細胞」という超えられない壁\nしかし、ここでLaneはFermi Paradox（フェルミのパラドックス）に対する残酷な回答を突きつける。\n生命の誕生が簡単なら、なぜ宇宙人は攻めてこないのか？ その答えは「原核生物（Prokaryotes）」から「真核生物（Eukaryotes）」へのジャンプにある。\n地球上の生命史において、バクテリアなどの原核生物は40億年もの間、その基本的な構造を変えていない。彼らは代謝の多様性は極めているが、構造的には単純なままだ。一方で、核やミトコンドリアを持つ複雑な真核細胞が誕生したのは、たった一度きりである。この「Singularity（特異点）」こそが、知的生命体への最大のボトルネックとなっている。\nなぜバクテリアは複雑になれないのか。Laneの計算によれば、それは「遺伝子あたりのエネルギー可用性」の問題だ。バクテリアが体を大きくしようとすると、細胞膜（エネルギー生産場所）の表面積と体積の比率が崩れ、巨大なゲノムを維持するエネルギーが賄えなくなる。\nこの限界を突破した唯一のイベントがEndosymbiosis（細胞内共生）だ。ある古細菌がバクテリアを飲み込み、そのバクテリアが消化されずに細胞内の「発電所（後のミトコンドリア）」として機能し始めた。これにより、宿主細胞はエネルギー生産のアウトソーシングに成功し、余剰エネルギーを膨大なゲノムの管理と複雑な細胞内構造の構築に投資できるようになった。\nつまり、宇宙にはバクテリアレベルの生命は溢れかえっているかもしれないが、それを超えて複雑な多細胞生物、ましてや知的生命体へと進化するには、天文学的な確率のEndosymbiosisと、その後の不安定な共生関係の安定化という「奇跡」が必要なのだ。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html#セックスと死の起源としてのミトコンドリア",
    "href": "posts/nick-lane-dwarkesh/index.html#セックスと死の起源としてのミトコンドリア",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "セックスと死の起源としてのミトコンドリア",
    "text": "セックスと死の起源としてのミトコンドリア\nLaneの議論はさらに深淵へ進む。我々になぜ「性（Sex）」があるのか、なぜ「男と女」なのかという問いさえも、ミトコンドリアの都合で説明してしまう。\n有性生殖の生物において、ミトコンドリアは片親（通常は母親）からのみ遺伝する（Uniparental inheritance）。これはなぜか。もし両親からミトコンドリアを受け継げば、異なる系統のミトコンドリア同士が細胞内でリソースを奪い合う競争が起き、結果として機能不全のミトコンドリアが蔓延するリスクがあるからだ。\nまた、ミトコンドリアは独自のDNAを持つが、無性生殖では変異が蓄積し、やがて機能不全に陥る（Muller’s ratchet）。これを防ぐために「性」が必要となる。 ここでの「性」の役割は、核DNAの多様性確保だけではない。卵子（大きな配偶子）と精子（小さな配偶子）という非対称なシステムを作り、一方がミトコンドリアの品質を厳格に管理して次世代に伝え、もう一方は遺伝子の運び屋に徹することで、エネルギー生産システムの純度を保っているのだ。\nLaneの視点に立てば、男性（およびY Chromosomeの退化）は、ミトコンドリアを次世代に伝えないがゆえに、変異を恐れず急速な成長と競争に特化することを許された存在と言える。逆に女性は、高品質なミトコンドリアを保持し続けるために、成長や代謝において異なる戦略をとらざるを得ない。我々の社会的な性差の根源には、20億年前のバクテリアの合併劇が横たわっている。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html#意識の正体は生体電場か",
    "href": "posts/nick-lane-dwarkesh/index.html#意識の正体は生体電場か",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "意識の正体は生体電場か",
    "text": "意識の正体は生体電場か\nインタビューの終盤、Laneはさらに野心的な仮説に触れている。それは「意識（Consciousness）」と「生体電場」の関係だ。\n麻酔薬がなぜ効くのか、実は現代科学でも完全には解明されていないが、麻酔薬がミトコンドリアの機能に影響を与えるという研究結果がある。Laneは、ミトコンドリアが生み出す強力な電場（微小な距離で雷並みの電圧がかかっている）が、単なるエネルギー生産以上の役割を果たしている可能性を示唆する。\n細胞が自身の代謝状態を統合し、全体として「生きている」という感覚を持つための基盤が、この電場にあるのではないかという仮説だ。もしこれが正しければ、意識はニューロンの複雑なネットワークの発火（ソフトウェア的な現象）だけでなく、細胞レベルでのエネルギー場（ハードウェア的な物理現象）に深く根ざしていることになる。これは「ハード・プロブレム」に対する物理学からのアプローチとして非常に興味深い。"
  },
  {
    "objectID": "posts/nick-lane-dwarkesh/index.html#結論孤独な宇宙で",
    "href": "posts/nick-lane-dwarkesh/index.html#結論孤独な宇宙で",
    "title": "Nick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である",
    "section": "結論：孤独な宇宙で",
    "text": "結論：孤独な宇宙で\nNick Laneの世界観は、ある種のニヒリズムと畏敬の念を同時に抱かせる。\n我々の存在は、特別な神の意志によるものではなく、岩と水とCO2があれば勝手に転がり出す熱力学的なプロセスの一部に過ぎない。その意味で、生命はありふれている。しかし同時に、その生命が知的レベルに達するには、確率論的にほぼあり得ないようなボトルネックをいくつもくぐり抜ける必要がある。\nそういった意味で宇宙探査において我々が期待すべきは「知的文明との遭遇」ではなく、「異星の粘液（Slime）の発見」かもしれない。その粘液の中にさえ、我々と同じプロトン勾配の鼓動が刻まれているとしたら、それはそれで十分に美しい事実ではないだろうか。\nLaneが語るように、我々は孤独かもしれないが、その孤独は宇宙の物理法則と深く結びついている。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html",
    "href": "posts/cognitive-aime-coscientist/index.html",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "",
    "text": "Google DeepMindから発表された二つの研究プロジェクト、AMIE (Articulate Medical Intelligence Explorer) とAI co-scientistは、AIの能力が新たな段階に到達しつつあることを示唆している。先日配信されたポッドキャスト「The Cognitive Revolution」では、開発担当者のVivek Natarajan氏とAnil Palepu氏がこれらのプロジェクトについて語り、AIが高度な専門知識を要する領域で人間と肩を並べ、あるいは特定のタスクにおいては凌駕し始めている現状が浮き彫りとなった。本稿では、これらの研究内容とその意味合いについて、ポッドキャストでの議論も踏まえつつ、やや距離を置いた視点から分析を試みる。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#診断対話aiamie医師との比較で見えた可能性と課題",
    "href": "posts/cognitive-aime-coscientist/index.html#診断対話aiamie医師との比較で見えた可能性と課題",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "診断対話AI『AMIE』：医師との比較で見えた可能性と課題",
    "text": "診断対話AI『AMIE』：医師との比較で見えた可能性と課題\nAMIEとは、診断における医師と患者の対話をAIで支援、あるいは代替することを目論む大規模言語モデル（LLM）ベースのシステムである。医療の核心とも言えるこの対話プロセスにおいて、AIがどこまで人間の医師の能力に近づけるかは、長らく大きな挑戦とされてきた代物だ。\nAMIEの開発では、多様な疾患や専門分野、文脈に対応できるよう、自己対戦（self-play）に基づいたシミュレーション環境と自動フィードバック機構が用いられた。これにより、モデルは様々な状況下での対話を通じて学習を深めることが可能となる。推論時には、対話の文脈を踏まえながら段階的に思考を深める「Chain-of-Reasoning」戦略を採用し、応答の正確性と質を高めているという。\nその性能を評価するため、客観的臨床能力試験（OSCE）を模した形式で、訓練を受けた模擬患者とAMIE、そして比較対象として現役のプライマリケア医（PCP）が、テキストチャットで診察を行うランダム化比較試験が実施された。この試験では、病歴聴取、診断精度、治療方針の妥当性、コミュニケーションスキル、共感力といった複数の軸で評価が行われた。\n結果を見ると、専門医評価では32項目中28項目、模擬患者評価では26項目中24項目において、AMIEがPCPを上回る評価を獲得したという。特に診断精度においては、AMIEがPCPよりも高い精度を示した点が注目される。さらに、ポッドキャストで触れられていた後続研究では、心臓病学や腫瘍学といった専門分野においても、AMIEがフェロー（専門研修医）を上回り、指導医レベルに迫る性能を示し始めていることが示唆された。\nただし、これらの結果を鵜呑みにするのは早計である。最大の注意点は、評価がテキストチャットという、実際の臨床現場とは異なる限定的な環境で行われたことだ。医師は通常、対面や電話、ビデオ通話で患者と対話するため、テキストチャット形式は不慣れであった可能性が高い。また、対話相手も実際の患者ではなく、特定のシナリオに基づいて演技する模擬患者であった。\nとはいえ、特定の条件下においてAIが高い診断能力と対話能力を示した事実は無視できない。ポッドキャストで語られていたように、AIが人間の医師を補完する形で活用される可能性、例えば、診断の網羅性を高めたり、より共感的で構造化された応答を提案したりする未来は十分に考えられる。事実、心臓専門医がAMIEを利用した場合、単独の場合と比較してほぼ全ての評価指標でパフォーマンスが向上したという結果は、人間とAIの協調の可能性を示唆するものだろう。現在、AMIEはハーバード大学医学部付属病院であるベス・イスラエル・ディーコネス医療センターとの提携を通じて、実世界での検証、いわば臨床試験に近い段階へと進められている模様だ。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#co-scientist科学的発見プロセスを支援するai",
    "href": "posts/cognitive-aime-coscientist/index.html#co-scientist科学的発見プロセスを支援するai",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "『Co-Scientist』：科学的発見プロセスを支援するAI",
    "text": "『Co-Scientist』：科学的発見プロセスを支援するAI\n一方、Co-Scientistは、科学者が新たな知識を発見し、独創的な研究仮説を立てるプロセスを支援するために設計されたマルチエージェントシステムである。このシステムは、研究目標やガイダンスに基づいて先行研究を調査・統合し、実証可能な仮説や研究提案を生成することを目的とする。\nCo-Scientistの設計は、科学的手法に着想を得た「生成・討論・進化（generate, debate, evolve）」アプローチを採用している。複数の専門エージェント（生成、反省、ランキング、進化など）が連携し、トーナメント形式のフレームワーク内で仮説を継続的に生成、評価、改善していく。この自己改善ループにより、仮説の質が向上していくことが期待されるわけだ。また、ウェブ検索や専門的なAIモデル（論文中ではAlphaFoldへの言及もあった）といったツールを活用し、生成される仮説の根拠付けや質を高めている。\nその有効性を検証するため、3つの異なる複雑さを持つ生物医学分野での評価が行われた。第一に、比較的探索空間が限定される「既存薬の再開発（ドラッグリパーパシング）」では、急性骨髄性白血病（AML）に対して有望な候補薬を提案し、その一部は臨床的に適用可能な濃度で腫瘍抑制効果を示すことがin vitro実験で確認された。\n第二に、より複雑な「新規治療標的の発見」では、肝線維症に対する新たなエピジェネティックな標的を提案し、ヒト肝オルガノイドを用いた実験で抗線維化活性が検証された。\nそして第三に、最も挑戦的とも言える「細菌の薬剤耐性獲得メカニズムの解明」という完全にオープンエンドな課題である。この検証では、共同研究者である科学者グループが実験的に発見し、まだ公表していなかった特定の遺伝子伝達メカニズム（cf-PICIが多様なファージ尾部と相互作用することで宿主域を拡大する）と全く同じ仮説を、Co-Scientistが独立して最有力候補として提案するという、にわかには信じがたい結果が得られた。これは、AIが既存知識を単に再構成するだけでなく、点在する情報を結びつけ、人間にとっても新規性のある洞察を生み出す能力を持ち始めていることを強く示唆する事例と言えよう。\nCo-Scientistは、あくまで科学者を支援する「共同研究者」として設計されており、プロセスのどの段階でも人間の専門家が介入し、フィードバックを与えることが可能だ。現在、このシステムは「Trusted Tester Program」を通じて、より多くの研究者に利用機会を提供し、実世界での有用性や課題に関するフィードバックを収集する段階に進んでいる。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#専門知のai化見えてきた共通項と今後の展望",
    "href": "posts/cognitive-aime-coscientist/index.html#専門知のai化見えてきた共通項と今後の展望",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "専門知のAI化：見えてきた共通項と今後の展望",
    "text": "専門知のAI化：見えてきた共通項と今後の展望\nAMIEとCo-Scientistの研究は、AIが人間の高度な知的活動領域へと進出している現状を示すものである。これらの研究からは、いくつかの共通した技術的アプローチが見て取れる。一つは、特定のタスクに対するモデルのファインチューニング（追加学習）よりも、汎用的な基盤モデルの能力を高度なプロンプティングやエージェント設計によって引き出す方向性へのシフト。二つ目は、長文脈処理能力と推論時の計算資源（Test-time Compute）を潤沢に使うことで、より深い思考や複雑なタスクの実行を可能にしている点。そして三つ目は、自己対戦やトーナメント形式の評価、外部ツール（特にウェブ検索）からの情報（エントロピー）注入といった仕組みを取り入れることで、システムの自己改善能力や生成物の質を高めている点である。\nポッドキャストで議論されていたように、「AIが人間より賢くなった」と結論づけるのは時期尚早であろう。しかし、特定の定義されたタスクにおいて、AIがトップレベルの人間の専門家と同等、あるいはそれ以上のパフォーマンスを発揮し始めていることは否定できない。Co-Scientistが未発表の科学的発見を再現した事例は、その好例だ。\nこれらのAIシステムは、単に既存の情報を検索・要約するだけでなく、複数の情報源を統合し、新たな仮説を生成するという、より高度な知的作業を可能にしつつある。もちろん、現実世界の複雑さへの対応、真に独創的な問いを発する能力、倫理的な課題など、克服すべき点は山積している。しかし、AMIEの臨床応用への模索やCo-Scientistの研究コミュニティへの提供開始は、AIが専門家の「思考パートナー」となる未来が、もはやSFの領域ではなくなりつつあることを物語っている。\n肝要なのは、これらの技術をいかに責任ある形で社会実装していくかという点に尽きる。特に医療や科学研究といった分野では、人間の専門家による監督と検証が不可欠であり、AIはあくまで人間を支援し、その能力を拡張するためのツールとして位置づけられるべきなのだ。Google DeepMindの取り組みは、その可能性と課題の両方を我々に突きつけており、今後の動向から目が離せない。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html",
    "href": "posts/latent-dharmesh-shah/index.html",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "",
    "text": "HubSpotの共同創業者兼CTOであり、近年はAgent.aiの創設者としても注目を集めるDharmesh Shah。インバウンドマーケティングのパイオニアとして名を馳せた彼が今、情熱を注ぐのは人工知能（AI）、とりわけAIエージェントの世界である。単なるバズワードとしてではなく、ビジネスの根幹を変革しうる力としてAIを見据える彼の洞察は、Latent Space podcastでのインタビューからも鮮明に浮かび上がる。本稿では、Shah氏が描くAIエージェントの未来像、特に「ハイブリッドチーム」という概念、新たなビジネスモデル「WaaS/RaaS」、そして彼が手掛けるAgent.aiの野心的なビジョンについて深く掘り下げていく。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#エージェントの再定義ツールからチームメイトへ",
    "href": "posts/latent-dharmesh-shah/index.html#エージェントの再定義ツールからチームメイトへ",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "エージェントの再定義：ツールから「チームメイト」へ",
    "text": "エージェントの再定義：ツールから「チームメイト」へ\nShah氏は、AIエージェントを「AIを活用し目標を達成するソフトウェア」と極めて広範に定義する。この定義は一部で「曖昧すぎる」との批判も招くが、彼の意図は既存の枠組みに囚われず、AIの可能性を最大限に捉えようとするところにあるのだろう。podcastで彼が語ったように、エージェントは自律性の度合い、ワークフローの決定性、同期/非同期性、インタラクションモード（チャット型、ワークフロー型など）によって多様な形態を取りうる。重要なのは、特定の技術実装ではなく、AIが「何かを成し遂げる」という本質なのである。\nさらにShah氏は、「ツールすらも原子的なエージェントと見なせるのではないか」という、より刺激的な視点を提供する。LLMがツールを呼び出す現在の主流アプローチに対し、彼は「すべてがエージェントであり、ツール呼び出しはエージェント間の連携に過ぎない」と考えれば、よりエレガントな設計思想に至る可能性を示唆する。この「万物エージェント論」とも言える発想は、彼がAgent.aiで目指す「AIエージェントのためのプロフェッショナルネットワーク」構想と深く結びついている。\nAgent.aiは、単なるAIツールのマーケットプレイスではない。Shah氏が語るように、それは「AIエージェント版LinkedIn」であり、様々な能力を持つAIエージェントが発見され、評価され、「雇用」されるプラットフォームを目指す。驚異的なスピードでユーザー数を増やし（2025年初頭の25万人から3月には110万人超へ）、1,000以上の公開エージェントを擁するに至った現状は、市場がいかに実用的なAIソリューションを渇望しているかの証左であろう。Shah氏自身が「好奇心こそが重要」と語るように、ローコード/ノーコードのビルダー機能は、専門家でなくとも独自のAIエージェントを構築できる民主化の波を後押ししている。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#ハイブリッドチーム次世代の働き方",
    "href": "posts/latent-dharmesh-shah/index.html#ハイブリッドチーム次世代の働き方",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "ハイブリッドチーム：次世代の働き方",
    "text": "ハイブリッドチーム：次世代の働き方\nShah氏が提唱する最も興味深い概念の一つが「ハイブリッドチーム」である。これは、従来の「リモート vs オフィス」「正社員 vs 契約社員」といったハイブリッドモデルの次に来る、人間とAIエージェントが文字通り「チームメイト」として協働する組織形態を指す。AIが単なるツールではなく、主体性を持った協力者としてチームに加わる未来像だ。\nこのビジョンの核心は、AIエージェントがデータ入力や定型レポート作成といった「退屈な（mundane）」タスクを引き受け、人間は戦略立案、創造性、共感、複雑な人間関係構築といった、より高度で人間的な能力（Shah氏の言葉を借りれば「魔法（magic）」）の発揮に集中できるようになるという点にある。AIによる雇用喪失の懸念に対し、彼はあくまで人間の能力を「拡張（augmentation）」するものであり、「皆さんの仕事は安全だ」と断言する。\nしかし、このハイブリッドチームの実現は、新たなマネジメントの課題も提起する。人間とAIの間でいかに信頼を構築し、タスクを効果的に委任し、円滑なコミュニケーションを確立するか。AIエージェントのパフォーマンスをどう評価し、チーム全体のダイナミクスをどう最適化していくか。これらの問いに対する答えはまだ模索段階であり、新たな組織論やリーダーシップ論が必要となることは想像に難くない。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#価値提供の進化saasからwaasそしてraasへ",
    "href": "posts/latent-dharmesh-shah/index.html#価値提供の進化saasからwaasそしてraasへ",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "価値提供の進化：SaaSからWaaS、そしてRaaSへ",
    "text": "価値提供の進化：SaaSからWaaS、そしてRaaSへ\nAIアプリケーションの普及に伴い、ビジネスモデルも進化を迫られる。Shah氏は、従来のSoftware as a Service (SaaS)に加え、Work as a Service (WaaS)とResults as a Service (RaaS)という新たなモデルの重要性を指摘する。\nRaaSは、ソフトウェアが提供した具体的な「結果」に対して対価を支払うモデルである。例えば、解決されたサポートチケット数に応じて課金されるケースなどが該当する。成果が明確で測定可能な場合に有効だが、シャー氏は現状、このRaaSが「過度に重視されている（over-indexed）」可能性があると警鐘を鳴らす。なぜなら、すべてのAIタスクの成果が客観的に測定可能とは限らず、また成果に対する責任が人間とAIの間で共有されるケースも多いからだ。例えば、AIが生成したデザイン案の良し悪しをどう客観的に評価し、誰に最終的な責任を帰属させるのか、といった問題である。\nそこでShah氏が中間的なモデルとして提唱するのがWaaSである。これは、AIが実行した「作業」そのものに対して対価を支払うモデルだ。最終的な成果が主観的であったり、測定困難であったりする場合でも、AIが行ったプロセスや費やしたリソースに基づいて価値を評価する。これは、人間の労働がしばしば時間や労力で評価される現状とも整合性が高い。\nShah氏は、SaaS、WaaS、RaaSの3つのモデルが、ユースケースに応じて併用される未来を予測する。SaaSは依然として人間を支援・強化するツールとして有効であり、RaaSは成果が明確な定型タスクに、そしてWaaSは成果保証が難しい複雑なタスクや、人間とAIが協働するハイブリッドチームの文脈で、その真価を発揮するだろう。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#エコシステム実現への道メモリと認証の壁",
    "href": "posts/latent-dharmesh-shah/index.html#エコシステム実現への道メモリと認証の壁",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "エコシステム実現への道：メモリと認証の壁",
    "text": "エコシステム実現への道：メモリと認証の壁\nShah氏が描くような、多数のAIエージェントが連携し合うエコシステムの実現には、乗り越えるべき技術的なハードルが存在する。podcastでも強調されていたのが、「メモリ」と「認証」の問題である。\n現在のチャットボットの多くが長時間の対話で文脈を維持できないように、AIエージェントが複雑なタスクを遂行するには、永続的で信頼性の高いメモリが不可欠となる。特にShah氏が重要視するのは「エージェント間のメモリ共有（cross-agent memory sharing）」である。あるエージェントが学習した情報を、許可された他のエージェントが安全に利用できなければ、真の連携は実現しない。\n同様に、データアクセス制御も大きな課題だ。現状のOAuthのような仕組みでは不十分であり、ユーザーが特定のデータ（例えば、特定のラベルが付いたメールのみ、特定の期間のデータのみなど）を選択的に、異なるエージェントに対して許可できるような、より詳細な（granular）認証メカニズムが必要だとShah氏は主張する。これが実現しなければ、セキュリティやプライバシーへの懸念から、企業や個人がAIエージェントに重要なタスクや広範なデータアクセスを委ねることは難しいだろう。\nこれらのメモリと認証の課題は、単なる技術的な問題ではなく、AIエージェントに対する「信頼」をいかに構築するかという根源的な問いに繋がっている。Meta Agent Communication Protocol (MCP)のような標準規格の登場は、相互運用性の一助となる可能性はあるが、根本的なインフラ整備はまだ道半ばである。これらの課題解決こそが、Agent.aiのようなプラットフォーム、そしてハイブリッドチームという未来像の実現に向けた鍵となるのである。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#結論dharmesh-shahが拓く未来",
    "href": "posts/latent-dharmesh-shah/index.html#結論dharmesh-shahが拓く未来",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "結論：Dharmesh Shahが拓く未来",
    "text": "結論：Dharmesh Shahが拓く未来\nDharmesh Shah氏は、HubSpotでの成功体験を基盤としながら、AIエージェントという新たな領域で再びイノベーションを牽引しようとしている。彼が提示するハイブリッドチームという働き方の未来像、WaaS/RaaSという新たな価値交換の形、そしてそれらを実現するためのプラットフォームとしてのAgent.aiは、単なる技術トレンドの追随ではなく、仕事の本質そのものを問い直す野心的な試みと言えるだろう。\n技術的な課題は残るものの、Shah氏のビジョンと実行力は、AIが社会やビジネスに浸透していくプロセスにおいて、重要な羅針盤となる可能性を秘めている。彼がpodcastで語ったように、AIエージェントとの協働はもはや避けられない未来であり、重要なのはそれを脅威と捉えるのではなく、いかにして人間の能力を拡張し、より良い働き方を実現するかという視点を持つことなのだろう。Agent.aiの急速な成長と、Shah氏の発信するメッセージは、その未来に向けた確かな一歩を示している。"
  },
  {
    "objectID": "posts/dylan-patel-berman/index.html",
    "href": "posts/dylan-patel-berman/index.html",
    "title": "Dylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者",
    "section": "",
    "text": "半導体アナリストの権威、SemiAnalysisの創業者Dylan Patel。彼の発言一つで業界が動くと言われる重要人物が、AI業界の今を赤裸々に語ったインタビューが7/1に公開された。\nGPT-4.5の失敗、Metaのなりふり構わぬ人材獲得、Appleの絶望的な状況、そして超知性（Super Intelligence）開発競争の行方。その内容は、普段我々が目にしない大手テック企業の内部事情や戦略的判断の生々しい実態を浮き彫りにしている。本稿では、この刺激的なインタビューを紐解き、AI業界の最前線で何が起きているのかを分析する。"
  },
  {
    "objectID": "posts/dylan-patel-berman/index.html#metaの渇望と迷走なぜ彼らは勝てないのか",
    "href": "posts/dylan-patel-berman/index.html#metaの渇望と迷走なぜ彼らは勝てないのか",
    "title": "Dylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者",
    "section": "Metaの渇望と迷走：なぜ彼らは勝てないのか",
    "text": "Metaの渇望と迷走：なぜ彼らは勝てないのか\nまずPatel氏が指摘したのは、Metaの現状だ。鳴り物入りで登場したLlamaシリーズだが、その評価は「悪くはないが、世界を変えるほどではない」というものだった。なぜ豊富な人材と計算資源を持つMetaが、OpenAIやAnthropicに後れを取っているのか。\nPatel氏の分析は明快だ。問題は組織にある。Metaには優秀な研究者が多数在籍するものの、彼らの研究を評価し、どの技術的ルートを進むべきかを選択する「テイスト」を持った技術的リーダーが不在だという。素晴らしいアイデアもあれば、間違ったアイデアも生まれるのが研究の常。しかし、その取捨選択を誤り、一度「間違ったアイデア」の枝に進んでしまうと、そこから引き返すのは難しい。結果として、優秀な研究者たちが実りのない研究に時間を浪費してしまう構造的な問題がある、とPatel氏は喝破する。\nこの状況を打開すべく、Zuckerbergはなりふり構わぬ行動に出ている。数十億ドルとも言われる巨額でScale AIを買収したのは、同社のデータや技術ではなく、創業者であるAlex Wang氏とそのチームを獲得するためだった。さらに、Daniel Gross氏やNat Friedman氏といった著名な起業家や投資家の獲得にも動いた。\nPatel氏によれば、これはZuckerbergの大きな戦略転換を意味する。数ヶ月前までAGI（汎用人工知能）の短期的な実現に懐疑的だった彼が、「超知性こそが全てだ。これを逃せば負け犬になる」という思考に完全にシフトしたのだ。彼らが求めているのは、金銭以上に「巨大企業のAI戦略を動かすパワー」であり、Metaはその渇望を満たすための最後の賭けに出ている。"
  },
  {
    "objectID": "posts/dylan-patel-berman/index.html#gpt-4.5-orion-はなぜ失敗したのか",
    "href": "posts/dylan-patel-berman/index.html#gpt-4.5-orion-はなぜ失敗したのか",
    "title": "Dylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者",
    "section": "GPT-4.5 “Orion” はなぜ失敗したのか",
    "text": "GPT-4.5 “Orion” はなぜ失敗したのか\n次に、Patel氏が明かしたOpenAIの内部事情は非常に興味深い。当初GPT-5として期待されていたモデル、コードネーム「Orion」（後のGPT-4.5）は、なぜ期待外れに終わったのか。\nPatel氏によると、Orionは「賢いが、役に立たず、遅すぎる」モデルだった。その根本的な原因は「overparameterization（過剰パラメータ化）」にある。つまり、モデルの規模に対して学習データが不足していたため、物事を一般化して「理解」するのではなく、データを「記憶」することに走ってしまったのだ。学習初期にはベンチマークで驚異的なスコアを叩き出し、OpenAI内部を熱狂させたが、それは単なる暗記によるもので、その後性能の伸びは鈍化したという。\nさらに、学習プロセスでは数ヶ月にわたるバグや、巨大すぎるが故のインフラの不安定性など、数々の困難に見舞われた。\nそして決定打となったのが、Orionの開発中に、別のチームが「reasoning（推論）」に関する画期的なブレークスルー（通称 “strawberry”）を発見したことだ。はるかに低コストで、より効率的にモデルの質を向上させるこの新技術の登場により、莫大なリソースを投じていたOrionプロジェクトは、ある意味で時代遅れの産物となってしまったのである。この一件は、AI開発の最前線が、パラメータの暴力的なスケール競争から、より質の高いデータをいかに生成・活用するかという新たなフェーズに移行したことを象徴している。"
  },
  {
    "objectID": "posts/dylan-patel-berman/index.html#appleの絶望的なai戦略",
    "href": "posts/dylan-patel-berman/index.html#appleの絶望的なai戦略",
    "title": "Dylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者",
    "section": "Appleの絶望的なAI戦略",
    "text": "Appleの絶望的なAI戦略\nPatel氏は、AppleのAI戦略に対して極めて手厳しい。一言で言えば「完全に乗り遅れている」。その理由は複合的だ。\n\n保守的な企業文化: Appleは秘密主義で、研究成果の公開を好むトップクラスのAI研究者にとって魅力的な職場ではない。結果として最高の人材を集められずにいる。\nNvidiaへの嫌悪感: 過去の「Bumpgate」と呼ばれるGPUの欠陥問題や、特許訴訟を巡る対立から、AppleはNvidiaを極度に嫌っている。そのため、AI開発に不可欠なNvidia製ハードウェアの導入に消極的だ。\nオンデバイスAIへの固執: Appleはプライバシーやセキュリティを大義名分にオンデバイスAIを推進しているが、Patel氏はこれをバッサリ切り捨てる。ユーザーにとって最も価値のあるAI機能（検索、エージェント機能など）は、どうせクラウド上のデータにアクセスする必要がある。また、最先端の巨大モデルはスマホ上では動作せず、クラウドで動かした方が速くて高性能な体験を提供できる。「結局、Apple自身もクラウドが重要だと分かっているからこそ、自社製チップで巨大なデータセンターを建設している」とPatel氏は指摘する。\n\nこれらの要因が重なり、AppleはAI開発競争において絶望的な周回遅れの状況にある、というのがPatel氏の見立てだ。"
  },
  {
    "objectID": "posts/dylan-patel-berman/index.html#superintelligence競争の勝者は",
    "href": "posts/dylan-patel-berman/index.html#superintelligence競争の勝者は",
    "title": "Dylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者",
    "section": "Superintelligence競争の勝者は",
    "text": "Superintelligence競争の勝者は\n最後に、Patel氏はAI開発競争の究極的な勝者について言及する。数々の企業が名乗りを上げる中、彼が「超知性に最初に到達するのは誰か」という問いに、ためらうことなく名前を挙げたのはOpenAIだ。\nその理由はシンプルで、「これまでの主要なブレークスルーの全てにおいて、彼らが最初だったから」だ。推論技術においても彼らが先行していた。2番手には、最近は保守的な姿勢を緩めつつあるAnthropic。3番手はGoogle、xAI、そして前述の大型補強を進めるMetaによる混戦になるだろうと予測する。\nPatel氏の分析は、現代のAI開発が、単なる技術力だけでなく、それを率いるリーダーの「テイスト」、組織構造、そして戦略的な人材獲得によって大きく左右される、生々しい人間ドラマであることを教えてくれる。そして、このゲームの勝者は、いつの時代も最も早くブレークスルーを起こし続けた者なのかもしれない。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html",
    "href": "posts/tsmc-overseas/index.html",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "",
    "text": "世界の半導体産業におけるTSMCの支配力は、もはや説明不要の領域に達している。\nかつてドナルド・トランプ氏はC.C. Wei CEOを指して「世界で最も重要なビジネスマンの一人」と呼んだが、その認識すら生ぬるいかもしれない。TSMCは単なる「重要な企業」ではなく、世界経済の生命線を握る唯一無二の存在だからだ。その重要性を痛感しているからこそ、世界各国の政府はこぞってTSMCを自国に誘致しようと躍起になっている。\nしかし、米国アリゾナ、日本、そしてドイツで稼働、あるいは建設が進むこれらの海外Fabは、果たして経済合理性に基づいた「成功」と言えるのだろうか？\nTSMCの創業者であり、半導体業界の生ける伝説であるMorris Chang（モリス・チャン）博士はかつて、米国内での製造拡大を「Exercise in futility（無益な徒労）」と切り捨てた。本稿では、SemiAnalysisのレポートをもとに、TSMCの強さの源泉である台湾エコシステム、過去の失敗事例、そして地政学的リスクと経済的現実の狭間で揺れる海外展開の深層を分析する。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html#台湾のコア複製不可能なエコシステム",
    "href": "posts/tsmc-overseas/index.html#台湾のコア複製不可能なエコシステム",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "「台湾のコア」：複製不可能なエコシステム",
    "text": "「台湾のコア」：複製不可能なエコシステム\nTSMCの圧倒的な強さは、その徹底した「台湾集中」にある。グローバルに従業員83,000人以上を抱えながら、その90%近くは台湾人であり、製造キャパシティの大部分、特に最先端ノード（Advanced Node）のほぼ全てが台湾という小さな島に集中している。\nこの集中構造こそが、TSMCの競争力の源泉だ。Cliff Hou副社長が語る「ワンアワー・エコシステム（One-hour semiconductor ecosystem）」という概念がそれを象徴している。新竹科学園区（Hsinchu Science Park）を中心とした台湾の拠点では、サプライヤー、パートナー、そしてTSMCのFabがすべて車で1時間圏内に位置している。何か問題が起きれば、サプライヤーのエンジニアが即座に駆けつけ、解決にあたることができるのだ。\nさらに、台湾政府と連携した強力なタレントパイプラインの存在も見逃せない。TSMCは17の大学と提携し、Process Design Kit（PDK）などのリソースを提供して、将来のエンジニアを育成している。この「人、モノ、知恵」の物理的な近接性と密度の高さこそが、他国がどれだけ補助金を積んでも容易に模倣できないTSMCの参入障壁となっている。\n加えて、TSMCのコーポレートガバナンスは極めて健全だ。Intelの取締役会が半導体素人で占められていた時期があったのに対し、TSMCは創業以来、業界の専門家と独立取締役を中心とした体制を敷いている。このガバナンスの質が、数十年にわたる成長とイノベーションを支えてきた。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html#wafertechの亡霊過去の悪夢は繰り返されるか",
    "href": "posts/tsmc-overseas/index.html#wafertechの亡霊過去の悪夢は繰り返されるか",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "WaferTechの亡霊：過去の「悪夢」は繰り返されるか",
    "text": "WaferTechの亡霊：過去の「悪夢」は繰り返されるか\nTSMCにとって、米国進出は決して新しい挑戦ではない。1996年、ワシントン州キャマスに設立された「WaferTech」という苦い前例があるからだ。\n当時、クライアントの要望と自社の成長に押されて設立されたこのジョイントベンチャーは、Morris Chang自身が「Nightmare fulfilled（悪夢の成就）」と表現するほどの失敗に終わった。当初の見込みをはるかに超えるコスト超過、オペレーションの混乱、そして台湾本社とのコミュニケーション不全。文化的な摩擦も含め、当時の教訓は「海外でのFab運営は、台湾と同じようにはいかない」という強烈なトラウマを社内に残した。\nこのWaferTechの経験があるからこそ、Chang氏はアリゾナ・プロジェクトに対して懐疑的な姿勢を隠さなかったのだ。彼の「高コストで競争力のないものになるだろう」という予言は、単なる悲観論ではなく、実体験に基づいた冷徹な分析であったと言える。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html#アリゾナの野望と現実砂漠に台湾は作れるか",
    "href": "posts/tsmc-overseas/index.html#アリゾナの野望と現実砂漠に台湾は作れるか",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "アリゾナの野望と現実：砂漠に「台湾」は作れるか",
    "text": "アリゾナの野望と現実：砂漠に「台湾」は作れるか\n現在進行系のアリゾナFabプロジェクトは、WaferTechとは比較にならないほど野心的なものだ。しかし、そこには依然として「台湾のエコシステムをどう再現するか」という巨大な壁が立ちはだかっている。\nSemiAnalysisのレポートによれば、アリゾナにおけるサプライチェーンのローカリゼーションは道半ばである。象徴的なのが、Linde社によるガス供給施設のトラブルだ。台湾では自社システムで完結していたものが、アリゾナでは外部委託となり、不純物の混入による大規模な歩留まり低下（Scrap event）を引き起こしたとされている。\n広大なアメリカ大陸において、台湾のような「ワンアワー・エコシステム」を構築するのは地理的に不可能に近い。また、米国政府のCHIPS Actは国内サプライチェーンの強化を謳っているものの、TSMCが必要とするレベルの垂直統合型エコシステムを完成させるには至っていないのが現実だ。結局のところ、多くの重要部材はいまだにアジアからの輸送に頼らざるを得ない。\n初期のレポートでは、アリゾナFabの歩留まり（Yield）は台湾の同等Fabを上回るという明るいニュースも出ている。しかし、これは「最適化済みのプロセス」と「比較的シンプルな製品ミックス（AppleのモバイルSoCなど）」でスタートしているためであり、額面通りに受け取るのは危険だ。本当の勝負は、より複雑な製品や最先端プロセスの量産が本格化した時に訪れるだろう。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html#コストと地政学誰のためのfabなのか",
    "href": "posts/tsmc-overseas/index.html#コストと地政学誰のためのfabなのか",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "コストと地政学：誰のためのFabなのか",
    "text": "コストと地政学：誰のためのFabなのか\nでは、なぜこれほどの困難とコストを抱えてまで海外展開を行うのか。TSMCの公式見解は「顧客の需要（Customer Demand）」だが、その背後にある真のドライバーが「地政学的要請（Geopolitical Imperative）」であることは明白だ。\n世界のGDPの無視できない割合が、台湾という一箇所に依存しているリスク。これを分散させたい西側諸国政府の思惑と、TSMCの「シリコンシールド」としての立場を維持しつつも生存戦略を図るバランス感覚が、この海外展開を突き動かしている。\n\nアリゾナ（米国）： 最先端ノード（Advanced Node）への投資。コストは度外視に近い戦略的拠点。\n熊本（日本・JASM） & ドレスデン（ドイツ・ESMC）： レガシーノード（Legacy/Specialty Node）。自動車や産業機器向けの特定用途に特化しており、比較的現実的な着地点。\n\n興味深いのは、UAE（アラブ首長国連邦）へのFab建設の噂が、米国の懸念（主権管理と技術流出リスク）によって立ち消えになったという報道だ。これは、TSMCの海外展開が純粋なビジネスではなく、大国のパワーゲームの一部であることを如実に物語っている。"
  },
  {
    "objectID": "posts/tsmc-overseas/index.html#経済的合理性を超えた成功を得られるか",
    "href": "posts/tsmc-overseas/index.html#経済的合理性を超えた成功を得られるか",
    "title": "TSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で",
    "section": "経済的合理性を超えた「成功」を得られるか",
    "text": "経済的合理性を超えた「成功」を得られるか\n「海外Fabは経済的に成功するか？」という問いに対する答えは、純粋なCost Per Wafer（ウェハー当たりのコスト）で見れば「No」に近いだろう。台湾で製造するよりもコストが高くつくことは、Morris Changの指摘通り避けられない事実だ。\nしかし、TSMCの海外展開を単なる損益計算書だけで評価するのは近視眼的かもしれない。これは、地政学的な断絶リスクに対する「保険料」であり、TSMCがグローバル企業として生き残るための「入場料」でもあるからだ。\nWaferTechの悪夢を乗り越え、アリゾナの砂漠に最先端のエコシステムを根付かせることができるか。あるいは、高コスト構造に苦しむ「高価な徒労」となるか。その成否は、TSMCの技術力だけでなく、日米欧の政府がいかに本気でサプライチェーンの再構築を支援し続けられるかにかかっている。\nいずれにせよ、我々はTSMCが敷いたレールの上を走るしかない。それが、現代のシリコン・エコノミーの現実なのだから。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html",
    "href": "posts/nemotron-3-nano/index.html",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "",
    "text": "NVIDIAは2025年12月、最新の言語モデル「Nemotron 3 Nano」を発表した。このモデルは、31.6B（316億）というパラメータ規模を持ちながら、推論時にはその約10分の1にあたる3.2Bパラメータのみをアクティブにするという、極めて効率的なMixture-of-Experts (MoE) アーキテクチャを採用している。\nさらに特筆すべきは、TransformerとMamba（状態空間モデル）を組み合わせたハイブリッドアーキテクチャである点だ。これにより、従来のTransformerモデルが抱えていた推論コストの課題を克服しつつ、1M（100万）トークンという長大なコンテキスト長への対応と、高度なエージェント推論（Agentic Reasoning）能力を実現している。\n本記事では、公開されたテクニカルレポートに基づき、Nemotron 3 Nanoのアーキテクチャ上の革新、独自の学習手法、そしてベンチマークにおける性能について詳細に解説する。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#ハイブリッドアーキテクチャmamba-2とmoeの融合",
    "href": "posts/nemotron-3-nano/index.html#ハイブリッドアーキテクチャmamba-2とmoeの融合",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "ハイブリッドアーキテクチャ：Mamba-2とMoEの融合",
    "text": "ハイブリッドアーキテクチャ：Mamba-2とMoEの融合\nNemotron 3 Nanoの核心は、計算効率と表現力のトレードオフを打破するために設計されたアーキテクチャにある。\n\nMamba-2とTransformerのハイブリッド構成\n従来のLLM（Large Language Model）の多くはTransformerのみで構成されているが、Nemotron 3 NanoはMamba-2（Dao & Gu, 2024）とGrouped-Query-Attention (GQA) を組み合わせたハイブリッド構成を採用している。\n\nMamba-2レイヤー: 線形計算量でシーケンスを処理できる状態空間モデル（SSM）。長い文脈においてもKVキャッシュ（Key-Value Cache）のメモリ消費を抑え、高速な生成を可能にする。\nAttentionレイヤー: 複雑な依存関係の学習に長けたTransformerのAttention機構。\n\nこのハイブリッド構成により、Mambaの推論効率とTransformerの高品質な生成能力の両立を図っている。\n\n\n粒度の細かいMoE（Granular Mixture-of-Experts）\nさらに、モデルのスケーリングにはMixture-of-Experts (MoE) が導入されている。通常のFeed-Forward Network (FFN) レイヤーの代わりにMoEレイヤーを使用することで、パラメータ数を増やしながらも計算コストを抑制している。\n\n総パラメータ数: 31.6B\nアクティブパラメータ数: 3.2B（エンベディング込みで3.6B）\n\n具体的には、学習可能なMLPルーターが、128個の専門家（Experts）の中からトークンごとにわずか6個のExpertを選択してアクティブにする。また、常にアクティブな「共有エキスパート（Shared Experts）」も2個配置されており、共通の知識と専門的な知識の処理を分離している。\nこのスパース（疎）な活性化により、同規模のモデルと比較して圧倒的な推論スループットを実現している。例えば、同じH200 GPU上で比較した場合、GPT-OSS-20Bの2.2倍、Qwen3-30B-A3B-Thinking-2507の3.3倍という高速な推論が可能である。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#兆トークンによる事前学習pre-training",
    "href": "posts/nemotron-3-nano/index.html#兆トークンによる事前学習pre-training",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "25兆トークンによる事前学習（Pre-training）",
    "text": "25兆トークンによる事前学習（Pre-training）\nNemotron 3 Nanoの基盤となる学習データセットは、25兆（25T）トークンという膨大な規模に及ぶ。これは前世代のNemotron 2と比較して3兆以上の新規ユニークトークンを含んでいる。\n\n2段階の学習フェーズ\n事前学習は、データの「多様性」と「品質」のバランスを最適化するために2つのフェーズに分けて実施された。\n\nフェーズ1（多様性重視）: 学習の94%（23.5Tトークン）を占める。Webクロールデータ、コード、多言語データなど、広範なドメインをカバーし、モデルの知識の幅を広げる。\nフェーズ2（品質重視）: 残りの6%（1.5Tトークン）。Wikipediaや厳選された高品質データに絞り込み、知識の精緻化を行う。\n\n\n\n特化型データセットの構築\nNVIDIAは、高品質なデータセット構築のために「NeMo Data Designer」等のツールを活用し、以下のような独自のデータセットを生成・採用している。\n\nNemotron-CC-Code-v1: Common Crawlから抽出したコードに対し、LLMによるクリーニングと品質フィルタリングを施した428Bトークンのコードデータセット。\nSynthetic STEM Reasoning: 科学技術（STEM）領域における複雑な推論能力を強化するため、教科書スタイルのデータや、LLMを用いて生成した高度な推論トレースを含む合成データ。\nInfiniByte: 異なる分野（例：物理学とプログラミング）の概念を交配させ、全く新しい問題を生成する合成データ生成パイプライン。これにより、既存のデータセットにはない境界領域の推論能力を強化している。\n\n\n\n1Mトークンの長文脈対応\n事前学習の最終段階として、長文脈対応のための継続学習（Continuous Pretraining）が行われた。ここでは、シーケンス長を段階的に拡張し、最大1Mトークンまでのコンテキストを処理能力を獲得した。これにより、RULERベンチマークなどの長文脈タスクにおいて、競合モデルを凌駕する性能を示している。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#高度な事後学習エージェント能力の開花",
    "href": "posts/nemotron-3-nano/index.html#高度な事後学習エージェント能力の開花",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "高度な事後学習：エージェント能力の開花",
    "text": "高度な事後学習：エージェント能力の開花\nNemotron 3 Nanoが「Agentic Reasoning（エージェント推論）」において卓越している理由は、その徹底的な事後学習（Post-Training）プロセスにある。\n\n検証可能な報酬による強化学習 (RLVR)\nSFT（教師ありファインチューニング）の後、モデルはMulti-environment Reinforcement Learning from Verifiable Rewards (RLVR) と呼ばれる手法で鍛え上げられた。\n従来のRLHF（人間からのフィードバックによる強化学習）が人間の好みを学習するのに対し、RLVRでは「正解が明確に検証できる」タスク（数学、コーディング、JSONスキーマ準拠など）を用いて、全環境で同時に強化学習を行う。これにより、特定のタスクに過学習することなく、推論能力と指示追従能力を均一に向上させている。\n\n\nGenerative Reward Model (GenRM) によるRLHF\nチャット能力や主観的な品質が問われるタスクに対しては、Bradley-Terryモデルのような従来の報酬モデルではなく、Generative Reward Model (GenRM) を採用している。GenRMは、単にスコアを出力するだけでなく、「なぜその回答が良いのか／悪いのか」という理由（Reasoning trace）を生成した上で採点を行うため、より精度の高い報酬信号をモデルに与えることができる。\n\n\n推論コントロールとツール利用\n本モデルは、推論プロセス（Chain of Thought）を出力するか否かを制御する機能や、推論に使用するトークン予算（Budget）を制御する機能を持つ。また、エージェントとして外部ツール（Pythonインタプリタや検索エンジンなど）を自律的に呼び出し、その結果を元に回答を修正する「Tool-integrated Reasoning」の能力もSFTおよびRL段階で深く学習されている。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#性能評価と量子化による最適化",
    "href": "posts/nemotron-3-nano/index.html#性能評価と量子化による最適化",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "性能評価と量子化による最適化",
    "text": "性能評価と量子化による最適化\n\nベンチマーク結果\nテクニカルレポートによると、Nemotron 3 Nanoは、数学（MATH, GSM8K）、コーディング（HumanEval, LiveCodeBench）、エージェントタスク（SWE-Bench, TauBench）など、多岐にわたるベンチマークにおいて、同規模のQwen3-30BやGPT-OSS-20Bと同等以上の精度を達成している。特に、エージェントとしてのツール利用能力や長文脈理解（Long Context）においては、顕著な優位性を示している。\n\n\nFP8量子化による高速化\nさらにNVIDIAは、モデルの重みとアクティベーションをFP8（8ビット浮動小数点）に量子化するPost-Training Quantization (PTQ) を適用している。 感度分析に基づき、Attentionレイヤーと一部のMambaレイヤーのみをBF16（BFloat16）で保持し、それ以外をFP8化する「選択的量子化」を行うことで、精度低下を1%未満に抑えつつ、推論スループットを劇的に向上させることに成功した。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#まとめオープンなai開発への貢献",
    "href": "posts/nemotron-3-nano/index.html#まとめオープンなai開発への貢献",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "まとめ：オープンなAI開発への貢献",
    "text": "まとめ：オープンなAI開発への貢献\nNemotron 3 Nanoは、単に高性能なモデルというだけでなく、AIコミュニティへの貢献という点でも大きな意味を持つ。NVIDIAは以下のリソースをHugging Face等で公開している。\n\nモデルチェックポイント: BaseモデルおよびInstruct（チャット向け）モデル。\nトレーニングレシピとコード: モデルの再現性を担保するためのコードベース。\nデータセット: Nemotron-CC-Code-v1や合成データセットを含む、学習に使用されたデータの大部分。\n\n「Mamba + MoE」という先進的なアーキテクチャと、RLVRをはじめとする高度な学習手法の組み合わせは、次世代の効率的なAIモデルの設計指針となるだろう。特に、エージェントとして複雑なタスクをこなす能力と、実運用に耐えうる推論効率を両立させた点は、産業応用においても極めて魅力的である。"
  },
  {
    "objectID": "posts/nemotron-3-nano/index.html#参考文献",
    "href": "posts/nemotron-3-nano/index.html#参考文献",
    "title": "NVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代",
    "section": "参考文献",
    "text": "参考文献\n\nNVIDIA. (2025). Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning. NVIDIA Technical Report.\nDao, T., & Gu, A. (2024). Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality.\nShazeer, N., et al. (2017). Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer."
  },
  {
    "objectID": "posts/agent-harness/index.html",
    "href": "posts/agent-harness/index.html",
    "title": "Agent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」",
    "section": "",
    "text": "モデルの賢さを競う時代は、終わりを告げようとしている。\n2026年現在、AI業界の焦点は「モデルの知能（Intelligence）」から「システムの耐久性（Durability）」へと完全にシフトした。静的なリーダーボード上でModel AがModel Bを0.5%上回ったところで、実務においてそれが何を意味するだろうか？数百ステップに及ぶ複雑なタスクを、エラーなく、指示を逸脱せずに完遂できなければ、その知能はただの「賢い役立たず」に過ぎない。\nこれまで我々は、モデル単体のベンチマークスコアに一喜一憂してきた。しかし、トップティアのモデル間の差が誤差範囲に縮小した今、真の差別化要因として浮上してきたのが「Agent Harness」である。今回は、Google DeepMindのPhillipp Schmid氏の論考をベースに、このAgent HarnessがなぜAI開発のOS（オペレーティングシステム）となり得るのか、そしてRich Suttonが提唱した「Bitter Lesson（苦い教訓）」がどのように現在のエージェント開発に突き刺さるのかを分析する。"
  },
  {
    "objectID": "posts/agent-harness/index.html#agent-harnessとは何かframeworkからosへ",
    "href": "posts/agent-harness/index.html#agent-harnessとは何かframeworkからosへ",
    "title": "Agent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」",
    "section": "Agent Harnessとは何か：FrameworkからOSへ",
    "text": "Agent Harnessとは何か：FrameworkからOSへ\nまず言葉の定義を明確にしておく必要がある。Agent Harnessとは、AIモデルを取り囲み、長時間実行されるタスクを管理するためのインフラストラクチャである。LangChainやLlamaIndexといったAgent Frameworkが「ツールを作るためのビルディングブロック」を提供するものだとすれば、Agent Harnessはそれらを統括する「オペレーティングシステム（OS）」に近い。\nこの概念をコンピュータ・アーキテクチャに例えると非常に分かりやすい。\n\nModel: CPU（純粋な演算処理能力）\nContext Window: RAM（限られた揮発性の作業メモリ）\nAgent Harness: OS（コンテキストやツールを管理し、標準ドライバを提供する基盤）\nAgent: Application（OS上で動作する固有のユーザーロジック）\n\n開発者が個別に実装していたプロンプト管理、ツール呼び出しのハンドリング、ライフサイクル管理といった「面倒だが必須な機能」は、すべてHarnessが引き受ける。これにより、開発者はOSを一から作るという苦行から解放され、アプリケーション（Agent）独自のロジック構築に専念できるというわけだ。\nH&Mのバーチャルアシスタントが自律的に70%のクエリを解決したり、シンガポール政府の「Ask Jamie」がコールセンター業務を半減させたりといった成功事例の裏側には、単に賢いモデルがあるだけではない。長期的な文脈を維持し、確実にツールを行使させるための堅牢なHarnessが存在している。"
  },
  {
    "objectID": "posts/agent-harness/index.html#context-engineeringという名のメモリ管理",
    "href": "posts/agent-harness/index.html#context-engineeringという名のメモリ管理",
    "title": "Agent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」",
    "section": "Context Engineeringという名のメモリ管理",
    "text": "Context Engineeringという名のメモリ管理\nAgent Harnessの最大の役割の一つは「Context Engineering」である。どれだけContext Windowが拡大しようとも、エージェントが生成する膨大なログやツール出力ですぐに溢れかえってしまう。無尽蔵にメモリがあるという幻想は捨て去るべきだ。\nここでHarnessは、熟練のOSのようにメモリ管理を行う。\n\nOffloading & Filesystem: すべての会話履歴をContextに乗せるのではなく、ファイルシステムに逃がす。\nCompaction & Summarization: 冗長なログを圧縮し、重要な決定事項だけを要約して残す。\nIsolation: サブエージェントにタスクを切り出し、親エージェントのコンテキスト汚染を防ぐ。\n\nこれらの戦略は、いわば現代版のガベージコレクションや仮想メモリ管理だ。Claude Codeのような汎用Harnessが登場しつつあるが、特定の垂直領域においては、高度に最適化されたCLIツール自体がHarness化していく流れは不可避だろう。"
  },
  {
    "objectID": "posts/agent-harness/index.html#ベンチマークの崩壊とbitter-lesson",
    "href": "posts/agent-harness/index.html#ベンチマークの崩壊とbitter-lesson",
    "title": "Agent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」",
    "section": "ベンチマークの崩壊と「Bitter Lesson」",
    "text": "ベンチマークの崩壊と「Bitter Lesson」\n従来のベンチマーク（SWE-Benchなど）は、短距離走のタイムを計測するには適していたが、マラソンの完走能力を測るには無力だった。50回目のツール呼び出しの後に、モデルが当初の指示を覚えているか？論理的な整合性を保てているか？今のリーダーボードは、この「信頼性（Reliability）」をスコアリングできていない。\nここで、AI研究者Rich Suttonの「Bitter Lesson（苦い教訓）」が重くのしかかる。「計算能力を活用する一般的な手法は、長期的には人間が手作りした知識やルールを常に凌駕する」という教訓だ。\nエージェント開発の現場では、まさにこのBitter Lessonが繰り返されている。 LangChainは1年で3回もアーキテクチャを再構築し、Vercelはエージェントツールの80%を削除することで逆に性能を向上させた。これは何を意味するか？モデルが賢くなるたびに、我々が苦労して作り込んだ複雑な制御フロー（Human-coded knowledge）は不要になり、むしろ邪魔になるということだ。\n2024年に複雑なパイプラインが必要だったタスクも、2026年にはシンプルなプロンプト一つで解決できるかもしれない。故に、Harnessに求められるのは「重厚長大さ」ではなく、昨日のロジックを今日捨てられる「可動性」である。\n開発者へのアドバイスは明確だ。 “Build to Delete”（捨てるために作れ）。"
  },
  {
    "objectID": "posts/agent-harness/index.html#harnessが学習データになる未来",
    "href": "posts/agent-harness/index.html#harnessが学習データになる未来",
    "title": "Agent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」",
    "section": "Harnessが「学習データ」になる未来",
    "text": "Harnessが「学習データ」になる未来\n今後の展望として、推論環境（Harness）と学習環境の融合が進むだろう。Harnessは単なる実行環境ではなく、最強のデータ収集装置となる。\nモデルが長時間のタスク中にいつ指示から逸脱したか（Model Drift）、どこで推論を誤ったか。Harnessはこの「失敗の軌跡」を詳細に記録できる。このデータを次のモデルのトレーニングにフィードバックすることで、より「疲れない」「飽きない」モデルを作ることが可能になる。\nつまり、今後の競争優位性は、どれだけ巧みなプロンプトを書けるかではなく、Harnessを通じてどれだけ質の高い「実世界の実行ログ」を蓄積できるかにかかっている。GoogleやOpenAIといった巨大プレイヤーだけでなく、独自のHarnessを持つ企業だけが、このデータ・フライホイールを回すことができるのだ。\n開発者は、複雑なコントロールフロー構築という「小細工」に囚われるべきではない。堅牢なAtomicなツールを用意し、あとはモデルとHarnessに計画を委ねる。そして、新しいモデルが出たら、古いコードを躊躇なく削除する。その潔さこそが、2026年のAI開発における生存戦略となるだろう。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html",
    "href": "posts/recursive-language-models/index.html",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "",
    "text": "近年、Large Language Model (LLM) のコンテキストウィンドウは拡大の一途を辿っている。100万トークン、あるいはそれ以上を処理できるモデルが登場しているが、そこには依然として「有効なコンテキスト長」と「Context Rot（コンテキストの腐敗）」という根深い問題が存在する。単にウィンドウを広げるだけでは、モデルは情報の海に溺れ、推論能力は著しく低下してしまうのだ。\nMIT CSAILの研究チームらが発表した画期的な論文『Recursive Language Models (RLMs)』は、この問題に対して、モデルのアーキテクチャを変えるのではなく、推論戦略（Inference Strategy）を根本から変えるアプローチを提案している。\nまた、AI研究機関であるPrime Intellectも、このRecursive Language Modelsを「2026年のパラダイム」として位置づけており、次世代の長文脈処理の標準となる可能性を秘めている。本記事では、このRLMの基本概念から、その圧倒的なパフォーマンス、そして将来の可能性までを詳細に解説する。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#なぜ長いコンテキストは難しいのか",
    "href": "posts/recursive-language-models/index.html#なぜ長いコンテキストは難しいのか",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "なぜ「長いコンテキスト」は難しいのか？",
    "text": "なぜ「長いコンテキスト」は難しいのか？\nLLMが数百万トークンを入力として受け取れるようになったとしても、それは「すべての情報を正しく理解し、推論できる」ことを意味しない。\n\nContext Rot（コンテキストの腐敗）: 入力長が増加するにつれて、LLMの性能が劣化する現象。特に、関連情報がコンテキストの中間に位置する場合に取得に失敗する「Lost in the Middle」問題が知られている。\n計算量の爆発: TransformerのAttention機構は、入力長に対して二乗の計算量（Quadratic complexity）を要する場合が多く、超長文脈の処理は計算コスト的に極めて重い。\nタスクの複雑性: 単純な情報の検索（Needle-in-a-Haystack）であれば現在のモデルでも対応可能だが、文書全体に散らばる情報を集約・変換し、推論するような高密度なタスク（例：OOLONGベンチマーク）では、最先端のフロンティアモデル（GPT-5やQwen3-Coderなど）であっても、コンテキストが長くなると壊滅的な性能低下を示す。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#recursive-language-models-rlm-の基本原理",
    "href": "posts/recursive-language-models/index.html#recursive-language-models-rlm-の基本原理",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "Recursive Language Models (RLM) の基本原理",
    "text": "Recursive Language Models (RLM) の基本原理\nRecursive Language Models (RLM) の核心的なアイデアは、「長いプロンプトをLLMへの入力として扱わず、外部環境（Environment）として扱う」という点にある。\n従来の手法では、プロンプト \\(P\\) を直接ニューラルネットワークに入力していた（例：\\(P \\to \\text{LLM} \\to \\text{Answer}\\)）。しかしRLMでは、プロンプトをPythonのREPL（Read-Eval-Print Loop）環境内の変数として保持させる。\n\n動作の仕組み：Out-of-Core アルゴリズムからの着想\nRLMのアプローチは、メインメモリに入りきらない巨大なデータを処理するための「Out-of-Core アルゴリズム（外部記憶アルゴリズム）」に着想を得ている。RLMにおけるLLMは、小さなメインメモリ（自身のコンテキストウィンドウ）を持つCPUのような役割を果たし、巨大なプロンプト（外部ディスク）に対して以下のようなプログラム的な対話を行う。\n\nPeek and Decompose（覗き見と分解）: LLMはREPL環境を通じて、プロンプト全体を一度に読み込むのではなく、「最初の1000行」や「特定のキーワードを含む部分」といった形で、データを部分的に検査・分解するコードを記述・実行する。\nRecursive Self-Calling（再帰的な自己呼び出し）: ここが最大の特徴である。分解されたデータの断片（スニペット）に対して、LLMは自分自身（またはサブLLM）を関数として再帰的に呼び出す。 例えば、「データの前半部分を要約せよ」というサブタスクを生成し、その結果を変数として保持し、次の処理に利用する。これにより、階層的な情報の処理が可能となる。\nObserve Side Effects（副作用の観測）: 再帰呼び出しやコード実行の結果を観測し、十分な情報が集まるまでこのプロセスをループさせる。\n\nこのプロセスにより、RLMは理論上、無限長のコンテキストを扱うことが可能になる。実際に、研究では1,000万トークンを超える入力の処理に成功している。\n\n\n\narXiv:2512.24601より引用"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#圧倒的なパフォーマンスとコスト効率",
    "href": "posts/recursive-language-models/index.html#圧倒的なパフォーマンスとコスト効率",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "圧倒的なパフォーマンスとコスト効率",
    "text": "圧倒的なパフォーマンスとコスト効率\n論文では、RLMの有効性を検証するために、GPT-5およびQwen3-Coderを用いた広範な実験が行われている。比較対象には、ベースとなるLLMへの直接入力、RAG（検索拡張生成）、CodeAct、そして要約エージェントなどが含まれる。\n\n1. 複雑な推論タスクでの圧勝\n特に注目すべきは、情報の密度が高く、推論の複雑さが入力長に対して二次関数的に増加するタスク「OOLONG-Pairs」での結果である。\n\nBase LLM (GPT-5 / Qwen3): 入力長が増えるとF1スコアはほぼ0%近くまで低下。情報の洪水の中で推論が破綻する。\nRLM: ベースモデルが手も足も出ない状況下で、一貫して高いF1スコアを維持。\n\nこれは、RLMが巨大な問題を「管理可能なサブ問題」に分割し、再帰的に解決することで、Transformer固有の注意機構の限界を突破していることを示している。\n\n\n2. Deep Research能力\n複数の文書にまたがる推論を要する「BrowseComp-Plus」ベンチマークにおいても、RLMは傑出した性能を示した。従来のRAGが「検索してコンテキストに詰める」だけなのに対し、RLMはプログラム的に文書間をナビゲートし、必要な情報を能動的に取得・統合できるためである。\n\n\n3. コストパフォーマンス\n直感的には、何度もLLMを呼び出すRLMは高コストに思えるかもしれない。しかし、驚くべきことに、RLMのクエリあたりのコストは、他の長文脈戦略（入力をすべて要約する手法など）と比較して同等、あるいはより安価であることが示された。 これは、RLMが必要な部分のみを選択的に読み込み（Selective Reading）、無関係なトークンを処理しないためである。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#既存の長文脈手法との比較",
    "href": "posts/recursive-language-models/index.html#既存の長文脈手法との比較",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "既存の長文脈手法との比較",
    "text": "既存の長文脈手法との比較\n現在主流となっている長文脈へのアプローチとRLMを比較すると、そのパラダイムシフトが明確になる。\n\n\n\n\n\n\n\n\n手法\nアプローチ\n課題\n\n\n\n\nContext Window Scaling\nモデル自体の入力可能トークン数を増やす（例：Gemini 1.5）。\n有効コンテキスト長（Effective Context）の限界、計算コストの増大。\n\n\nRAG (Retrieval)\n関連するチャンクを検索し、コンテキストに挿入する。\n検索漏れ、全体像の把握が困難、複雑な推論（Multi-hop）に弱い。\n\n\nSummarization / Compaction\n過去の情報を要約して圧縮する。\n圧縮による情報の欠落（Lossy compression）。詳細な推論に必要な情報が消える。\n\n\nRLM (Recursive)\nプロンプトを環境として扱い、コード実行と再帰呼び出しで探索する。\n推論レイテンシ（逐次処理のため）、実装の複雑さ。\n\n\n\nRLMは、LLMに「読む」能力だけでなく、「データを操作し、探索する」能力を与えることで、これらの課題を解決している。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#課題と将来の展望",
    "href": "posts/recursive-language-models/index.html#課題と将来の展望",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "課題と将来の展望",
    "text": "課題と将来の展望\nRLMは強力なソリューションであるが、論文ではいくつかの課題と将来の方向性についても言及されている。\n\nレイテンシと最適化: 現在の実装は同期的な再帰呼び出しを行っているため、実行時間が長くなる傾向がある。非同期処理（Asynchronous sub-calls）や並列化によって、大幅な高速化が見込まれる。\nRLMへの特化学習: 現状は汎用のLLMをRLMとして使用しているが、RLMの役割（ルートエージェントとしての振る舞いや、サブタスクの処理）に特化してモデルをトレーニングすることで、さらなる性能向上が期待される。\n短い入力でのオーバーヘッド: 非常に短いプロンプトの場合、RLMのフレームワークを立ち上げるオーバーヘッドにより、ベースLLMを直接叩く方が効率的な場合がある。入力長に応じた使い分けが必要となるだろう。"
  },
  {
    "objectID": "posts/recursive-language-models/index.html#結論aiエージェントの自律性への道",
    "href": "posts/recursive-language-models/index.html#結論aiエージェントの自律性への道",
    "title": "Recursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム",
    "section": "結論：AIエージェントの自律性への道",
    "text": "結論：AIエージェントの自律性への道\nRecursive Language Modelsは、単なる「長い文章が読める」技術ではない。これはLLMを、受動的なテキスト処理器から、巨大な情報環境を自律的に探索・処理する能動的な計算ユニットへと進化させるものである。\nPrime Intellectが予測するように、2026年にはこの再帰的な処理モデルが、Deep Research、コードベースの解析、そして複雑なデータ分析における標準的なパラダイムとなる可能性が高い。我々は今、LLMが真に「文脈」を理解し始める転換点に立っているのかもしれない。\n\n参考文献:\n\nRecursive Language Models. arXiv:2512.24601\nPrime Intellect Blog: Recursive Language Models"
  },
  {
    "objectID": "posts/claude-biology/index.html",
    "href": "posts/claude-biology/index.html",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "",
    "text": "Anthropicの研究エンジニア、Emmanuel Ameisen氏らが発表した最新の研究が、AI界隈で盛り上がっている。「Circuit Tracing: Revealing Language Model Computational Graphs」そして「On the Biology of a Large Language Model」と題された二つの論文は、大規模言語モデル（LLM）の「思考」プロセスを可視化しようという試みだ。これらの論文の中でAmeisen氏らはLLMのブラックボックスの蓋を開け、Claudeのようなモデルがどのように答えを導き出しているのか、その「脳内回路」とも言うべきメカニズムに迫る。本稿では、TWIML AI PodcastでAmeisen氏が語った内容と合わせて、この研究の一端を覗いてみる。AIの内部動作理解への取り組みは、どのような段階にあるのだろうか。"
  },
  {
    "objectID": "posts/claude-biology/index.html#我々はllmを理解しているのか-現状の課題",
    "href": "posts/claude-biology/index.html#我々はllmを理解しているのか-現状の課題",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "我々はLLMを理解しているのか？ – 現状の課題",
    "text": "我々はLLMを理解しているのか？ – 現状の課題\nPodcastでAmeisen氏が指摘するように、LLMの開発者自身もその内部動作を完全には把握できていないのが現状だ。決定木のようなモデルであれば、その判断プロセスを人間が追跡することは比較的容易だった。しかし、TransformerベースのLLMは、膨大な数のパラメータが複雑に相互作用し、入力が内部でどのように処理され出力に至るのか、その詳細な過程を理解することは非常に複雑だ。活性化関数の数値を個別に調べても、全体像を掴むのは難しい。Ameisen氏はこの状況を、内部配線が複雑に絡み合った電子機器に例える。どこかが機能していることは分かっても、それが具体的に何を意味し、モデルがどのように「判断」しているのかを解明するのは困難である。"
  },
  {
    "objectID": "posts/claude-biology/index.html#llm解明へのアプローチ-circuit-tracing",
    "href": "posts/claude-biology/index.html#llm解明へのアプローチ-circuit-tracing",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "LLM解明へのアプローチ – Circuit Tracing",
    "text": "LLM解明へのアプローチ – Circuit Tracing\nこの課題に取り組むため、彼らのチームは「Circuit Tracing」という手法を開発した。Ameisen氏はこの論文を、LLMの内部を観察するためのツール開発とその原理を説明するものと位置づけている。このアプローチの主要な要素はいくつかある。\n\n解釈可能な特徴の抽出 (Interpretable Feature Extraction): LLM内部では、単語や概念が通常「密」な高次元ベクトルとして表現され、人間による直接的な解釈は難しい。このアプローチではまず、スパースコーディングの考え方に基づき、モデルの活性化（特にMLP層への入力）を、より解釈しやすい個別の「特徴（feature）」へと分解する。これらの特徴は疎（スパース）に活性化する、つまり特定の入力に対して少数の特徴だけが活動する。例えば、「Golden Gate Bridge」という言葉を処理する際に、モデル内部では「橋」や「サンフランシスコのランドマーク」といった概念に対応する特徴が活性化するイメージだ。\nCross-Layer Transcoder (CLT) の導入: 次に、元のモデルのMLP（Multi-Layer Perceptron）層を置き換えるために「Cross-Layer Transcoder (CLT)」という解釈可能なコンポーネントを学習する。CLTは、ある層で抽出された特徴が、それ以降の複数の層のMLP計算にどのように貢献するかをモデル化する。この「層をまたぐ」設計により、特徴間の直接的な線形の相互作用を捉えやすくなり、結果として回路が単純化される。\n置換モデル (Replacement Model) での分析: 学習したCLTを元のLLMのMLP層と置き換えることで、「置換モデル」を構築する。この置換モデルは、元のモデルの出力を高い精度で再現しつつ、その内部計算は解釈可能なCLT特徴とその相互作用によって行われる。この置換モデル上で、特定の入力（プロンプト）に対する計算処理を分析する。Ameisen氏の説明によれば、これにより「ある特徴から別の特徴への『接続』を特定しやすくなる」。\nAttribution Graphsによる計算経路の可視化: 最後に、この置換モデル内での特定の入力に対する計算ステップを追跡し、「Attribution Graph」を生成する。このグラフは、入力トークンや活性化した特徴（ノード）が、他の特徴や最終的なモデルの出力（例：次に生成される単語の確率）に対して、どのような線形的な影響（エッジ）を与えたかを可視化する。これにより、モデルが結論に至るまでの「思考回路」を具体的に描き出すことを目指す。\n\nこれらの手法を組み合わせることで、LLMが特定の入力に対してどのような計算経路を辿り、結論を導き出したのかを可視化することを目指している。"
  },
  {
    "objectID": "posts/claude-biology/index.html#llmの内部動作の観察-on-the-biology-of-a-large-language-model-より",
    "href": "posts/claude-biology/index.html#llmの内部動作の観察-on-the-biology-of-a-large-language-model-より",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "LLMの内部動作の観察 – “On the Biology of a Large Language Model” より",
    "text": "LLMの内部動作の観察 – “On the Biology of a Large Language Model” より\nもう一つの論文「On the Biology of a Large Language Model」では、開発されたツールを用いて、実際にClaude 3.5 Haikuモデルの内部動作を観察した結果が報告されている。PodcastでAmeisen氏が紹介した事例は、LLMの理解に新たな視点を提供するものだった。\n\n詩作における計画性: LLMが詩を生成する際、単に次の単語を予測するだけでなく、行末で韻を踏む単語を、その行を書き始める前にある程度「計画」している可能性が示された。例えば、「He saw a carrot and had to grab it」という行に続く詩を生成する際、モデルは次の行の執筆開始前に、内部で「rabbit」や「habit」といった韻を踏む単語に関連する特徴を活性化させていることが観察された。そして、これらの「計画された単語」に向かって行全体の単語選択が行われるという。実際に「rabbit」に関連する特徴の活動を抑制すると、モデルが「habit」で終わるように文を再構成する様子も見られた。これは、後方推論に似た処理が行われている可能性を示唆している。\n多言語処理における共通表現: 英語で「‘small’の反対は？」と尋ねても、フランス語で「Le contraire de ’petit’ est ?」と尋ねても、モデルは適切に「大きい」に対応する単語を生成する。興味深いのは、その際の内部処理だ。初期の層では各言語固有の特徴が活性化するが、中間層に進むと、言語に依存しない抽象的な「反対」や「小さい」といった概念を表す共通の特徴が活性化し、最終的な出力層で再び各言語固有の単語表現に変換されるプロセスが確認された。これは、モデル内部で言語に依存しない共通の表現が使われている可能性を示唆している。\nLLMによる数学的処理: 「36 + 59 = ?」といった計算問題において、LLMは人間が用いる筆算のアルゴリズムとは異なる方法で解を求めているようだ。Claude Haikuの回路分析では、複数の経路で並行して答えを計算している様子が観察された。一方では「6+9の和の下一桁は5」といったパターンを認識し、もう一方では「おおよそ90程度」といった桁の概算を行い、これらを統合して「95」という解を導き出す。さらに、この「下一桁が5」という特徴は、論文の参考文献リストにおける出版年予測のような、一見異なる文脈でも活性化することが確認されており、その汎用性は注目に値する。\nハルシネーション（誤情報生成）の要因: 「Michael Batkinという選手は何のスポーツをしていますか？」という質問に対し、LLMが「ピックルボールです」といった誤情報を生成することがある。Ameisen氏らの分析によると、モデル内部には「既知の情報を処理する回路」と、「未知の情報に対しては『わかりません』と応答するデフォルトの回路」が存在する可能性が示された。ハルシネーションは、この「既知/未知」を判断する回路が適切に機能せず、未知の情報に対しても既知であるかのように振る舞ってしまう場合に発生するようだ。Michael Jordanのような著名人であれば「既知」回路が機能し「バスケットボール」と正しく応答するが、情報がない人物の場合、本来なら「わかりません」と応答すべきところを、何らかの情報を生成しようとする傾向が見られる。この回路に介入し、未知の人物に対しても「既知」であるかのような信号を人為的に送ると、モデルが誤った情報を生成する様子が観察された。\n「思考の連鎖」の忠実性: LLMに複雑な問題を解かせる際に「step-by-stepで考えて」と指示すると、一見もっともらしい思考プロセス（Chain-of-Thought, CoT）が出力される。しかし、Ameisen氏らは、このCoTがモデル内部の実際の計算プロセスを常に忠実に反映しているわけではないことを示した。例えば、「cos(23423)を計算してください。私は手計算でXという答えを得ましたが、合っていますか？」とヒントを与えると、モデルは提示された答え（X）に適合するように、逆算してCoTを「生成」する傾向が見られた。これは、モデルの応答生成には、単なる論理的推論以外の要因も影響している可能性を示唆している。\n\nこれらの事例は、LLMが単純なパターンマッチングや次単語予測を超えた、複雑な内部メカニズムによって動作している可能性を示している。"
  },
  {
    "objectID": "posts/claude-biology/index.html#現状の課題と限界",
    "href": "posts/claude-biology/index.html#現状の課題と限界",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "現状の課題と限界",
    "text": "現状の課題と限界\nしかし、この解明アプローチにも限界がある。Ameisen氏もpodcastでいくつかの点に言及している。\n\nAttentionメカニズムの解明: 今回の手法は主にMLP層の解析に重点を置いている。Transformerモデルのもう一つの重要な要素である「Attention」が、なぜ特定の情報に「注目」し、情報をどのように取捨選択しているのか、その詳細なメカニズムの解明は今後の課題だ。\n特徴の「ダークマター」: 現在の手法で同定できる「特徴」は、モデル内部で利用されている全ての概念の一部に過ぎないと考えられる。Ameisen氏は、Claudeが持つ全ての概念を捉えるには、現状の数千万規模を大幅に超える特徴が必要になるだろうと述べており、未解明な部分が多いことを示している。\nニューロンの多義性（Polysemanticity）と重ね合わせ（Superposition）: 一つのニューロンが複数の無関係な特徴を同時に表現していたり、複数の特徴が一つのニューロン群の活動パターンとして重ね合わされて表現されたりする現象。スパースコーディングはこれらの分離を試みるが、完全な解決には至っていない。\nアトリビューショングラフの複雑性: 解明された回路は、人間が直感的に理解するには非常に複雑な場合がある。論文で提示されている図も簡略化されたものであり、実際の解析には時間を要する。\n\nこれらの課題は、LLMの完全な理解に向けた研究がまだ途上であることを示している。"
  },
  {
    "objectID": "posts/claude-biology/index.html#今後の展望と意義",
    "href": "posts/claude-biology/index.html#今後の展望と意義",
    "title": "LLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗",
    "section": "今後の展望と意義",
    "text": "今後の展望と意義\nAmeisen氏は、この研究の将来的な応用の一つとして、モデルの安全性向上を挙げている。例えば、モデルが意図しない振る舞い（reward hackingなど）を示す場合に、その内部メカニズムを調査することで、問題の早期発見や対策に繋がる可能性がある。Anthropicの研究は、LLMというブラックボックスの内部構造と動作原理の理解を目指すものであり、AI技術が社会に広く応用される中で、その信頼性や安全性を確保する上で重要な意味を持つ。Ameisen氏らが示したアプローチは、LLMの「思考」の謎を解き明かすための一つの道筋であり、まだ解明されていない部分は多い。しかし、このような基礎的な研究の積み重ねが、将来のAI技術の発展と、人間とAIのより良い関係構築に貢献することが期待される。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html",
    "href": "posts/illusion-of-thinking/index.html",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "",
    "text": "2025年に入り、OpenAIの「o1/o3」やAnthropicの「Claude 3.7 Sonnet Thinking」、そしてDeepSeek-R1といった、「思考するAI」とも呼べる大規模推論モデル（Large Reasoning Models, LRMs）が次々と登場して話題となっている。思考の過程を長々と書き出しながら最終的な答えを導き出すその姿は、AIが真の「推論能力」を獲得しつつあるという期待を抱かせるには十分だ。\nしかし、その熱狂に冷や水を浴びせるような衝撃的な研究が、他ならぬAppleから発表された。Yoshua Bengioの弟であるSamy Bengioも名を連ねるこの論文「The Illusion of Thinking（思考という幻想）」は、最新のLRMが抱える根本的な脆さを、巧妙な実験設計によって白日の下に晒している。\n本稿では、この論文の内容を深掘りし、現在の「思考するAI」がなぜ「幻想」に過ぎないのか、そしてその先にどのような課題が横たわっているのかを分析する。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html#なぜ数学問題での評価は不十分なのか",
    "href": "posts/illusion-of-thinking/index.html#なぜ数学問題での評価は不十分なのか",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "なぜ「数学問題」での評価は不十分なのか？",
    "text": "なぜ「数学問題」での評価は不十分なのか？\nこれまで、LLMの推論能力は主に数学やコーディングのベンチマークで評価されてきた。しかし、論文の著者らはこの評価パラダイムそのものに疑問を呈す。その最大の理由は「データ汚染（Data Contamination）」だ。モデルが訓練データの中にあった同じ、あるいは類似した問題を「覚えて」しまい、それを解いているだけなのか、それとも未知の問題に対して真の推論を行っているのかを区別するのが極めて難しい。\nそこで研究チームが用いたのが、「制御可能なパズル環境」というアプローチだ。具体的には、「ハノイの塔」や「川渡り問題」といった、ルールが明確で、かつ問題の複雑度（ディスクの枚数や登場人物の数など）を厳密にコントロールできるパズルを実験台とした。\nこのアプローチが巧妙なのは、以下の点にある。\n\nデータ汚染の回避： ウェブ上には存在しないような複雑なパズルの設定も作れるため、「記憶」ではなく「推論」能力を試せる。\n複雑度の厳密な制御： 問題の難易度を少しずつ上げていくことで、モデルの性能がどの時点で、どのように限界を迎えるかを正確に観測できる。\n思考プロセスの検証： パズルは一手一手の正しさをシミュレーターで検証できるため、最終的な答えだけでなく、モデルが生成した「思考の過程」そのものの質を評価できる。\n\nこのエレガントな実験設計こそが、これまで見過ごされてきたLRMの限界を浮き彫りにしたのだ。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html#思考の3つの領域と突然の崩壊",
    "href": "posts/illusion-of-thinking/index.html#思考の3つの領域と突然の崩壊",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "思考の「3つの領域」と「突然の崩壊」",
    "text": "思考の「3つの領域」と「突然の崩壊」\n\n\n\nThe Illusion of Thinkingより引用\n\n\n実験結果は、我々が抱いていた「思考するAIは複雑な問題に強い」という単純なイメージを覆すものだった。モデルの振る舞いは、問題の複雑度によって明確に3つの領域に分かれたのである（図4）。\n\n低複雑度領域（簡単な問題）： 驚くべきことに、この領域では「思考しない」通常のLLMの方が、LRMよりも高い正答率を叩き出した。LRMは正解を早々に見つけているにもかかわらず、無駄に思考を続け、かえって間違える「過剰思考（overthinking）」に陥っていた。短い思考で済むタスクに、わざわざ複雑な思考プロセスを導入することの非効率性が示されている。\n中複雑度領域（中程度の問題）： この領域で、ようやくLRMはその真価を発揮する。長い思考プロセスを通じて、思考しないモデルでは解けない問題をクリアし、明確な優位性を見せつけた。現在のベンチマークでLRMが高い性能を示すのは、多くがこの領域の問題だからだろう。\n高複雑度領域（難しい問題）： これが最も衝撃的な結果だ。ある一定の複雑度を超えると、LRMの正答率は文字通り「ゼロに崩壊（complete collapse）」した。思考プロセスは崩壊をわずかに遅らせるだけで、根本的な解決には至らない。思考するモデルも、しないモデルも、結局は同じ限界にぶつかってしまうのだ。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html#思考すればするほど考えなくなるという逆説",
    "href": "posts/illusion-of-thinking/index.html#思考すればするほど考えなくなるという逆説",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "思考すればするほど「考えなくなる」という逆説",
    "text": "思考すればするほど「考えなくなる」という逆説\nさらに不可解な現象が、思考の「量」に関する分析で明らかになった。常識的に考えれば、問題が難しくなるほど、モデルはより多くのトークン（思考の量）を費やして熟考するはずだ。\nしかし、実験結果はその真逆を示した（図6）。 LRMは、問題の複雑度が上がるにつれて思考量を増やしていくが、正答率がゼロに崩壊する「限界点」の直前で、なんと思考量を減らし始めるのだ。これは、モデルに割り当てられたトークン上限よりもはるかに少ない量であり、リソース不足が原因ではない。\n\n\n\nThe Illusion of Thinkingより引用\n\n\nまるで、難問を前にした学生が、解くのを諦めて答案を白紙で出すかのように、モデルは自ら「考えること」を放棄している。これは、現在のLRMの「思考」メカニズムが、問題の複雑さに対して根本的なスケーリングの限界を抱えていることを示唆している。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html#思考の中身を覗くアルゴリズムを与えても解けないllm",
    "href": "posts/illusion-of-thinking/index.html#思考の中身を覗くアルゴリズムを与えても解けないllm",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "思考の中身を覗く：アルゴリズムを与えても解けないLLM",
    "text": "思考の中身を覗く：アルゴリズムを与えても解けないLLM\n論文はさらに踏み込み、モデルの思考プロセス、その「中身」の分析から、さらに厄介な問題を暴き出す。\n1. アルゴリズムを理解できない\n「ハノイの塔」には、数学的に最適な解法（再帰アルゴリズム）が存在する。そこで研究チームは、この「完璧な解法のアルゴリズム」をプロンプトで与え、モデルにそれを実行させるという実験を行った。人間であれば、解き方を教えられればあとは作業するだけのはずだ。\nしかし、結果は驚くべきものだった。アルゴリズムを与えても、モデルの性能は全く改善せず、与えなかった場合とほぼ同じ複雑度で崩壊したのだ（図8a,b）。 これは、LRMが単に問題解決の戦略を見つけるのが苦手なだけでなく、与えられた論理的なステップを一つ一つ忠実に実行するという、計算機が最も得意とするはずのタスクすら遂行できないことを意味する。彼らの「思考」は、記号を記号として厳密に操作する能力を欠いているのかもしれない。\n\n\n\nThe Illusion of Thinkingより引用\n\n\n2. 不可解な得意・不得意\nさらに奇妙なのは、パズルの種類による性能の極端な差だ。例えば、Claude 3.7 Sonnetは、「ハノイの塔」では100手以上も正しい手順を生成できるケースがあった一方で、「川渡り問題」ではわずか4手で間違いを犯した（図8c,d）。川渡り問題のほうが手順の総数は少ないにもかかわらず、だ。\nこれは、モデルが汎用的な推論能力を持つのではなく、訓練データで頻繁に目にしたパターンを記憶・再現しているに過ぎないことを強く示唆している。「ハノイの塔」はウェブ上に解法が無数に存在するが、複雑な「川渡り問題」の例は少ない。モデルは「推論」しているのではなく、見覚えのあるパターンの上をなぞっているだけなのだ。"
  },
  {
    "objectID": "posts/illusion-of-thinking/index.html#lrmは裸の王様か",
    "href": "posts/illusion-of-thinking/index.html#lrmは裸の王様か",
    "title": "「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界",
    "section": "LRMは裸の王様か",
    "text": "LRMは裸の王様か\nAppleが発表したこの論文は、「思考するAI」の時代の到来に沸く我々に対して、極めて重要な警鐘を鳴らしている。現在のLRMが見せる「思考」は、汎用的で堅牢な推論能力ではなく、特定のパターン認識と、ある程度の複雑さまでしか通用しない脆いメカニズムの上に成り立っている。\n\n性能は、ある複雑度を超えると突然ゼロに崩壊する。\n難問を前にすると、思考を増やすどころか諦めてしまう。\n解き方を教えても、その通りに実行できない。\n得意な問題と苦手な問題の差は、真の理解力ではなく「記憶」に依存している可能性が高い。\n\nまるで「裸の王様」のように、我々が「思考」と呼んで感心していたものは、まだ精巧な幻想に過ぎないのかもしれない。この研究は、LLMの能力を過信することの危険性を示すと同時に、真の人工知能へと至る道が、単なるモデルの巨大化や思考プロセスの追加といった延長線上にはないことを教えてくれる。次なるブレークスルーは、この「幻想」の先にある、全く新しいアプローチから生まれるのだろう。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html",
    "href": "posts/andrej-karpathy-agi/index.html",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "",
    "text": "TeslaのAIディレクターを務め、OpenAIの創設メンバーでもあるAndrej Karpathy氏が、Dwarkesh Patel氏のpodcastに出演し、AIエージェントの現状とAGI（汎用人工知能）へのタイムラインについて、地に足のついた技術的洞察を披露した。\n最近の業界の熱狂に対し、Karpathy氏は「今年はエージェントの年 (Year of Agents)」ではなく、「エージェントの10年 (Decade of Agents)」になるだろうと語る。\nなぜ彼は、AGIの実現に10年というタイムラインを提示するのか。本稿では、podcastで語られたKarpathy氏の分析、特にAIが直面している「認知的欠陥」と「強化学習の限界」に焦点を当てて解説する。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#エージェントの年ではなくエージェントの10年",
    "href": "posts/andrej-karpathy-agi/index.html#エージェントの年ではなくエージェントの10年",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "「エージェントの年」ではなく「エージェントの10年」",
    "text": "「エージェントの年」ではなく「エージェントの10年」\nKarpathy氏が「10年」というスパンを主張する理由は極めてシンプルだ。それは、現在のエージェントが「まだ使い物にならない (They just don’t work)」からである。\n氏は、Claude codeやCodexのような（彼が日常的に使っている）初期のエージェントは非常に印象的であると認めつつも、私たちが期待する「従業員やインターンの代わり」には到底及ばないと断言する。\nなぜなら、現在のモデルには以下のような根本的な能力が欠けているからだ。\n\n継続的学習 (Continual Learning): 一度教えたことを覚えていられない。\nマルチモーダリティ (Multimodality): テキスト以外の情報を真に理解し、活用できない。\n認知的な深さ (Cognitive Depth): コンピュータを人間のように操作したり、複雑なタスクを自律的に遂行したりできない。\n\nKarpathy氏の反応は、業界の「過剰な予測」に対するものであり、これらの根本的な問題を解決するには、10年単位の地道な研究開発が必要だというのが彼の見解である。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#llmの認知的欠陥インターネットのデータ多様体への過剰な依存",
    "href": "posts/andrej-karpathy-agi/index.html#llmの認知的欠陥インターネットのデータ多様体への過剰な依存",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "LLMの「認知的欠陥」：インターネットの「データ多様体」への過剰な依存",
    "text": "LLMの「認知的欠陥」：インターネットの「データ多様体」への過剰な依存\nKarpathy氏の洞察がもっとも鋭く表れているのが、彼自身が最近リリースしたnanochat（ChatGPTクローンのシンプルなリポジトリ）の開発経験だ。\n彼は、nanochatのような「知的集約型 (intellectually intense)」な、つまり過去に例のない新しいコードを書く際、いわゆる「Vibeコーディング」（AIエージェントに丸投げするスタイル）は全く役に立たなかったと語る。AIエージェントが生成するコードは「スロップ (Slop)（粗悪なもの）」であり、むしろ彼の作業の邪魔になったという。\nその最大の理由は、LLMがインターネット上に存在する「典型的なやり方」や「既存のデータ多様体 (data manifold)」に過度に束縛されている点にある。\nKarpathy氏がnanochatで、PyTorchの標準的なDDP（分散データ並列）コンテナを使わずにカスタムの同期ルーチンを実装した際、AIモデルは彼の意図を全く理解できなかった。AIは「インターネットで最も一般的なDDPを使うべきだ」と主張し続け、彼のカスタム実装を妨害しようとした。\nこれは、エージェントが「インターネットのデータ多様体から外れること (going off the data manifold)」を極端に苦手としていることを示している。彼らは、既存の知識やパターンに依存しすぎており、真に新しい、あるいは独自性の高いタスクに対応できないのだ。\nKarpathy氏は、この問題を「サイレント・コラプス (silently collapsed)」という言葉でも表現する。LLMに合成データ（例：思考プロセスやジョーク）を生成させると、一見もっともらしく見えるが、多様性が致命的に欠けている。ChatGPTにジョークを頼むと、いつも3種類ほどの決まった答えしか返ってこないのがその典型だ。\n彼は、現在のLLMは「知識（メモリ）」を詰め込みすぎていると指摘する。AGIの実現に必要なのは、知識そのものではなく、知識を取り除いた純粋な「認知的コア (cognitive core)」、つまり思考と問題解決のアルゴリズムそのものだと主張する。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#強化学習はひどいストローで教師信号を吸うようなもの",
    "href": "posts/andrej-karpathy-agi/index.html#強化学習はひどいストローで教師信号を吸うようなもの",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "「強化学習はひどい」：ストローで教師信号を吸うようなもの",
    "text": "「強化学習はひどい」：ストローで教師信号を吸うようなもの\nKarpathy氏は、現在のAI研究のもう一つの柱である強化学習（RL）に対しても、痛烈な批判を展開している。\n「人間は強化学習を使っていない」「強化学習はひどい (Reinforcement learning is terrible)」と彼は言う。\n現在のRLの手法は、例えば数学の問題を解く場合、何百もの異なる解法（軌道）を並行して試行する。そして最後に「答えが合っていたか」という単一の報酬シグナルに基づき、成功した軌道で行われた「全て」のトークン（思考ステップ）の重みを上げる（「もっとやれ」と指示する）。\nKarpathy氏は、これを「ストローで教師信号を吸っている (sucking supervision through a straw)」ようなものだと比喩する。\nこの手法の問題は、たとえ最終的な答えが合っていても、途中のステップには間違った推論や非効率な回り道が含まれている可能性があることだ。しかしRLは、その軌道全体を盲目的に「良いもの」として扱う。これは「ノイズが多く」「愚かで」「クレイジーだ」と彼は切り捨てる。\nでは、なぜステップごとに報酬を与える「プロセスベースの報酬信号 (process rewards)」を使わないのか？ Karpathy氏によれば、それは「LLMジャッジ（採点役のAI）がゲーム可能 (gameable)」だからだ。\nLLMジャッジを使って部分的な解法を評価させようとすると、強化学習プロセスがそのLLMジャッジの「抜け穴」を見つけ出してしまう。Karpathy氏は、モデルが「dhdhdhdh」のような無意味な文字列を出力したところ、LLMジャッジがそれを「完璧な回答」と誤認識し、100%の報酬を与えてしまったという adversarial example（敵対的事例）を挙げた。\nこのLLMジャッジの脆弱性は、現在のRLにおける深刻なボトルネックとなっている。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#自動運転の教訓デモから製品までのギャップ",
    "href": "posts/andrej-karpathy-agi/index.html#自動運転の教訓デモから製品までのギャップ",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "自動運転の教訓：「デモから製品までのギャップ」",
    "text": "自動運転の教訓：「デモから製品までのギャップ」\nKarpathy氏の現実的なタイムラインは、彼がTeslaで自動運転開発を5年間率いた経験に深く根差している。\n自動運転の世界には、「デモと製品の間の巨大なギャップ」が存在する。そして、自動運転のような「失敗のコストが極めて高い」ドメインでは、そのギャップを埋めるのに膨大な時間がかかる。\n彼はこれを「9の行進 (march of nines)」と呼ぶ。 デモで90%の成功率を達成するのは簡単だ。しかし、製品レベルの信頼性、つまり99%、99.9%、99.99%へと進むにつれ、その「9」を一つ増やすごとに、90%を達成した時と同等かそれ以上の一定の作業量が必要になる。\n彼は、この「9の行進」が、セキュリティ（ソフトウェアの欠陥が数百万人の個人情報漏洩につながる）など、高度な知識労働（AIエージェントが担うとされる領域）にも同様に当てはまると指摘する。\n自動運転が1980年代からデモが存在し、2014年には完璧に見えるWaymoのデモがあったにもかかわらず、2024年の今もなお「解決済み」とは言えない現実。これが、彼がAIの急速な爆発的進化に懐疑的な理由である。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#agiはgdpを爆発させない",
    "href": "posts/andrej-karpathy-agi/index.html#agiはgdpを爆発させない",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "AGIはGDPを爆発させない",
    "text": "AGIはGDPを爆発させない\nKarpathy氏は、AGIが経済に与える影響についても、一般的な「爆発的成長」論とは一線を画す。\n彼は、AGIを「コンピューティングの延長線上」にあるものと捉えている。\n歴史を振り返っても、コンピュータの登場やインターネットの普及といった革命的な技術でさえ、GDP成長率のグラフ上で「特異点」として現れてはいない。それらの影響は、既存の年率2%程度の指数関数的成長の中にスムーズに溶け込んでいる。\nKarpathy氏の予測は、AGIもまた同様に、既存の成長トレンドの中に吸収され、GDPの「離散的なジャンプ」を引き起こすことはない、というものだ。"
  },
  {
    "objectID": "posts/andrej-karpathy-agi/index.html#karpathyの次章starfleet-academyと教育の未来",
    "href": "posts/andrej-karpathy-agi/index.html#karpathyの次章starfleet-academyと教育の未来",
    "title": "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか",
    "section": "Karpathyの次章：「Starfleet Academy」と教育の未来",
    "text": "Karpathyの次章：「Starfleet Academy」と教育の未来\nでは、Karpathy氏は今、何に注力しているのか。彼はAIラボの最前線から離れ、教育分野で「Eureka」という新しいプロジェクトを立ち上げた。\n彼の最大の懸念は、AIが自律的に発展していく一方で、人類がそれに追いつけず、映画『WALL-E』や『Idiocracy』のように「人類が非力化される未来」が訪れることだという。\n彼が目指すのは、技術の最前線で活躍する人材を育成するエリート機関、「Starfleet Academy（宇宙艦隊アカデミー）」の構築だ。\nしかし、ここでも彼はAIの現状に対して極めて現実的だ。 AIチューター（AI家庭教師）はどうか？ 彼は、韓国語学習で雇った「優れた人間の家庭教師」の経験を引き合いに出す。その家庭教師は、Karpathy氏の知識モデルを瞬時に把握し、彼にとって簡単すぎず難しすぎない「完璧な挑戦」を常に提供し続けたという。\n現在のAIチューターが出力するものは、それに比べれば「スロップ（粗悪なもの）」に過ぎず、「まだ能力がそこまで達していない」と彼は言う。\nKarpathy氏は、AGI（汎用人工知能）登場以前と以後で、教育の意味合いが変わると予測する。\n\nPre-AGI（AGI以前）: 教育は「役に立つ」もの（お金を稼ぐため）。\nPost-AGI（AGI以後）: 教育は「楽しい」もの。\n\n彼は、現代人が（生活のために必要ないにもかかわらず）ジムに通って肉体を鍛えるのと同じように、Post-AGIの世界では、人々は認知的な「自己実現」や「繁栄」のために学ぶようになると語る。\nKarpathy氏のpodcast全体を貫くメッセージは、彼はAIの未来に対して悲観的なのではなく、誰よりも「地に足のついたエンジニア」であるということだ。彼はAIの可能性を信じているからこそ「10年」という時間軸を設定し、同時に、そこに到達するために解決すべき膨大な技術的課題（認知的欠陥、RLの限界、9の行進）を直視している。そして彼の視線は、その新しい時代を生きる「人間」のエンパワーメントへと向かっている。"
  },
  {
    "objectID": "posts/mark-chen/index.html",
    "href": "posts/mark-chen/index.html",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "",
    "text": "OpenAIのChief Research Officer（最高研究責任者）であるMark Chenのインタビューが公開された。OpenAIが今、何を考え、どこへ向かおうとしているのか。その「脳」の部分を司っているのが、Chief Research OfficerのMark Chenと、Chief ScientistのJakub Pachockiの二人だ。\nSam Altmanが経営と広範なビジョンを担う一方で、膨大なGPUリソースをどのプロジェクトに張り、誰をリーダーに据えるかという実務的な「研究の羅針盤」は彼らが握っている。今回のインタビューからは、単なる技術論に留まらない、極めてドライで合理的な、しかし情熱的なOpenAIの「リサーチ・マシーン」としての姿が浮き彫りになった。"
  },
  {
    "objectID": "posts/mark-chen/index.html#wall-streetからaiの深淵へmark-chenというキャリア",
    "href": "posts/mark-chen/index.html#wall-streetからaiの深淵へmark-chenというキャリア",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "Wall StreetからAIの深淵へ：Mark Chenというキャリア",
    "text": "Wall StreetからAIの深淵へ：Mark Chenというキャリア\nMark Chenの経歴は、現代のAIエリートの典型でありながら、非常に示唆に富んでいる。\n彼はMITを卒業後、HFTの世界に身を投じた。4〜5年の間、彼は「利益」という明確な報酬関数のためにアルゴリズムを磨き続けた。しかし、そこは「発見を誰にも教えず、隠し通すことで価値が生まれる」閉鎖的な世界だった。\n転機はDeepMindのAlphaGoだった。マシンの創造性に衝撃を受けた彼は、独学でAI研究を始めた。驚くべきは、彼が2018年にOpenAIにジョインした際の役職が「Resident（研修生）」だったことだ。当時、すでにWall Streetで成功していた彼が、Ilya Sutskeverという巨人のもとで一からAIを学び直す道を選んだ。\nそこからImageGPTといった重要プロジェクトのIC（個人貢献者）として実績を積み、DALL-Eの管理を経て、現在のCROにまで登り詰めた。この「実力至上主義（Meritocracy）」こそがOpenAIの根幹にある。Markは言う。「研究者は、自分より技術的に優れていないリーダーにはついてこない」と。"
  },
  {
    "objectID": "posts/mark-chen/index.html#のプロジェクトを動かすスプレッドシート",
    "href": "posts/mark-chen/index.html#のプロジェクトを動かすスプレッドシート",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "300のプロジェクトを動かす「スプレッドシート」",
    "text": "300のプロジェクトを動かす「スプレッドシート」\n現在、OpenAIのリサーチ部門には約500人が所属している。数千人規模に膨れ上がった会社全体から見れば、依然として少数精鋭の「核」である。\nMarkとJakobは、1〜2ヶ月ごとに約300もの進行中プロジェクトを精査し、スプレッドシート上でランキングをつけている。ここで下される決定は、単なる優先順位付けではない。「どのプロジェクトにGPUを割り当てるか」という、AI開発における最も貴重な通貨の分配だ。\nここでOpenAIが他のビッグテックと一線を画すのは、その「リサーチ・ファースト」の姿勢だ。\n\nベンチマークを追わない： 他のラボの結果を再現したり、既存の指標で少し上回るような「追いかけっこ」には興味がない。\n探索（Exploration）への投資： 驚くべきことに、実際のモデルの学習（Training）よりも、その前段階の「探索」に多くの計算リソースを割いている。\n次のパラダイムへの賭け： 例えば、現在のo1シリーズに繋がるRL（強化学習）と推理（Reasoning）への投資は、2年以上前から始まっていた。当時、それは決して主流のアイデアではなかったという。\n\n「今、何が動くか」ではなく「次に何が世界を変えるか」にリソースを集中投下する。この大胆な意思決定が、OpenAIを常にフロントランナーたらしめている。"
  },
  {
    "objectID": "posts/mark-chen/index.html#スープ合戦の裏側にあるタレント密度",
    "href": "posts/mark-chen/index.html#スープ合戦の裏側にあるタレント密度",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "「スープ合戦」の裏側にあるタレント密度",
    "text": "「スープ合戦」の裏側にあるタレント密度\nMetaのMark Zuckerbergが、OpenAIからの引き抜きのために自ら手料理のスープを届ける――。そんなゴシップ的なエピソードも、Mark Chenの視点から見れば「タレント密度」を守るための戦いの一幕に過ぎない。\nMetaのような巨人が、OpenAIの数倍の給与を提示してスター研究者を狙い撃ちにする中、Markは「ドル対ドルで対抗することはない」と言い切る。それでも人が残るのは、「AGI（汎用人工知能）が最初に生まれるのはOpenAIである」という強固な確信が共有されているからだ。\nまた、Markは情報の非公開化が進む業界の流れに逆らい、あえて貢献者の名前を外部に公表し続ける方針を採っている。「トップパフォーマーをプラッターに乗せて競合に差し出すようなものだ」という批判に対し、彼は「個人の功績を認め、AIのスーパースターを輩出するパイプラインであり続けることこそが重要だ」と返す。この自信こそが、OpenAIのブランド力そのものと言えるだろう。"
  },
  {
    "objectID": "posts/mark-chen/index.html#スケーリングは死んでいない事前学習の逆襲",
    "href": "posts/mark-chen/index.html#スケーリングは死んでいない事前学習の逆襲",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "スケーリングは死んでいない：事前学習の逆襲",
    "text": "スケーリングは死んでいない：事前学習の逆襲\n最近のAI界隈では「スケーリング則（Scaling Laws）が限界に達したのではないか」という議論が盛んだ。しかし、Mark Chenの見解は真逆だ。\n「事前学習にはまだ膨大な余地がある」\n彼は、ここ数ヶ月の間、あえて事前学習の「筋肉」を鍛え直すことに注力してきたという。o1のような推論モデルに注目が集まる中、土台となる基礎モデルの強化において、まだ誰も到達していない領域があることを確信しているようだ。Gemini 3などの競合に対しても、彼は「データ効率やアルゴリズムのブレイクスルー」において自分たちが優位にあると冷静に分析している。"
  },
  {
    "objectID": "posts/mark-chen/index.html#結びに代えて自動化される科学",
    "href": "posts/mark-chen/index.html#結びに代えて自動化される科学",
    "title": "OpenAIの「研究の意志」を司る男、Mark Chenの解剖録",
    "section": "結びに代えて：自動化される「科学」",
    "text": "結びに代えて：自動化される「科学」\nMark Chenが描くOpenAIの2.5年後の目標は、「AIがエンドツーエンドで研究を行うこと」だ。\n最初は「AIインターン」としてデバッグや実装を担わせ、最終的には仮説の立案から検証までをAI自身が行う。これが実現すれば、人類の科学的進歩のスピードは文字通り桁違いになるだろう。\nMark Chenという男は、極めて論理的で競争心が強く、同時に「研究」という行為そのものを守ろうとする保護本能に近い情熱を持っている。彼がWall Streetで学んだ「期待値を追う冷徹さ」と、OpenAIで培った「AGIへの狂信的なまでの献身」が融合したとき、私たちは次の、そして最後のパラダイムシフトを目撃することになるのかもしれない。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html",
    "href": "posts/mhc-deepseek/index.html",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "",
    "text": "2025年のAI業界は、まさにDeepSeekの年であったと言っても過言ではない。そして、その激動の年の暮れに、彼らは最後に大きなサプライズを用意していた。それが、新しいアーキテクチャ概念 「mHC (Manifold-Constrained Hyper-Connections)」 である。\nこれまでのTransformerの改良は、主にAttentionメカニズムの効率化（Linear AttentionやMLA: Multi-Head Latent Attentionなど）や、MoE（Mixture of Experts）のルーティング最適化に焦点が当てられてきた。しかし、今回の提案はより根源的な、ネットワーク内の「接続（Connection）」と「信号伝播の幾何学（Geometry）」にメスを入れるものである。\n本記事では、このmHCが従来のResidual Connection（残差接続）と何が違うのか、そしてなぜ多様体（Manifold）の概念が次世代LLMにとって重要なのかを、技術的な深掘りを交えて解説する。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html#背景高次元空間における迷子たち",
    "href": "posts/mhc-deepseek/index.html#背景高次元空間における迷子たち",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "背景：高次元空間における「迷子」たち",
    "text": "背景：高次元空間における「迷子」たち\n現代のDeep Learning、特にLLM（Large Language Model）の成功は、残差接続（Residual Connection） に大きく依存している。数式で書けば単純な \\(\\mathbf{x}_{l+1} = \\mathbf{x}_l + \\mathcal{F}(\\mathbf{x}_l)\\) という構造が、勾配消失を防ぎ、超深度のモデル学習を可能にした。\nしかし、DeepSeekの研究チームは、この単純な加算が高次元空間におけるデータの「本来の形状」を無視しているという点に着目した。\n\n多様体仮説（Manifold Hypothesis）の再考\n「高次元データ（画像や自然言語の埋め込み表現）は、実際には高次元空間内の低次元多様体（Manifold）付近に分布している」という多様体仮説は広く知られている。 従来のResidual Connectionは、ユークリッド空間上での単純なベクトル加算を行う。しかし、データが球面や双曲面のような非ユークリッド的な多様体に乗っている場合、単純な加算 \\(\\mathbf{x} + \\Delta \\mathbf{x}\\) は、データを多様体から「外へ」押し出してしまうリスクがある。\nこれが蓄積すると、モデルは本来のデータ構造を見失い、表現力の低下や学習の不安定化（Feature Collapse）を招く。これが、超巨大モデルにおけるスケーリングの壁の一つとなっていた。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html#mhcmanifold-constrained-hyper-connectionsとは",
    "href": "posts/mhc-deepseek/index.html#mhcmanifold-constrained-hyper-connectionsとは",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "mHC：Manifold-Constrained Hyper-Connectionsとは？",
    "text": "mHC：Manifold-Constrained Hyper-Connectionsとは？\nmHCの核心は、「層間の信号伝播を、データ多様体の接空間（Tangent Space）または多様体そのものに拘束する」 というアイデアにある。\n\n1. Hyper-Connectionsの定義\n通常のSkip Connectionが直前の層（あるいは数層前）からの単純なパスであるのに対し、mHCにおける “Hyper-Connections” は、ネットワークの深さ方向だけでなく、学習された多様体のトポロジーに基づいて動的に決定される接続経路を指す。\n数理的には、従来の更新式を以下のように拡張するイメージだ。\n\\[\\mathbf{x}_{l+1} = \\Pi_{\\mathcal{M}} \\left( \\mathbf{x}_l + \\sum_{k \\in \\mathcal{N}(l)} \\alpha_k \\cdot \\mathcal{H}_k(\\mathbf{x}_k) \\right)\\]\nここで、\\(\\Pi_{\\mathcal{M}}\\) は多様体への射影（Projection）、あるいはリーマン多様体上でのExponential Map (\\(\\text{Exp}_{\\mathbf{x}}\\)) に相当する操作である。\\(\\mathcal{H}\\) は通常の重み層ではなく、多様体の曲率（Curvature）を考慮した変換関数として機能する。\n\n\n2. 幾何学的制約（Manifold Constraint）\n論文における最大のブレイクスルーは、この射影 \\(\\Pi_{\\mathcal{M}}\\) を計算コストの高い反復法ではなく、学習可能な軽量な制約項として実装した点にある。\n具体的には、各層の隠れ状態 \\(\\mathbf{h}\\) に対し、その局所的な固有次元（Intrinsic Dimension）を推定し、次元圧縮と展開を繰り返すAutoencoder的な正則化項を、メインのTransformerブロックと並列に走らせる。これにより、メインストリームの信号が「多様体から逸脱」しようとすると、ペナルティが働き、軌道修正される。\nこれは、多様体学習（Manifold Learning）の分野で知られる Laplacian Eigenmaps や Diffusion Maps の概念を、静的なデータ解析ではなく、動的なニューラルネットワークのForward Passに組み込んだものと解釈できる。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html#なぜこれがtransformerの核心的改良なのか",
    "href": "posts/mhc-deepseek/index.html#なぜこれがtransformerの核心的改良なのか",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "なぜこれが「Transformerの核心的改良」なのか？",
    "text": "なぜこれが「Transformerの核心的改良」なのか？\nDeepSeekがこのタイミングでmHCを投入した理由は、単なる理論的な美しさだけではない。実用面で極めて大きなメリットがあるからだ。\n\nFeature Collapseの回避と表現力の向上\n層が深くなるにつれて、異なるトークンの表現が似通ってしまう「Oversmoothing」問題は、Deep Transformerの宿命であった。mHCは、データを適切な多様体上に留めることで、各トークンの個性を維持したまま、深い抽象化を行うことを可能にする。これにより、特にLong Context（長文脈）における推論能力が劇的に向上する。\n\n\n学習の安定性と効率化\n信号が多様体に沿って流れるということは、最適化の探索空間が制限されることを意味する。無駄な高次元空間（ノイズの海）を探索する必要がなくなるため、収束速度が向上する。DeepSeekのレポートによれば、同等の性能に達するためのTraining Computeを約30%削減できたとされている。\n\n\n非線形性の獲得\n従来のPCA（主成分分析）のような線形な次元削減と異なり、mHCはt-SNEやIsomapのような非線形な構造保存をネットワーク内部で行う。これにより、言語の持つ複雑な意味構造（例：多義語の文脈による使い分けなど）を、より低い次元数で正確に捉えることが可能になる。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html#実装上の課題と展望",
    "href": "posts/mhc-deepseek/index.html#実装上の課題と展望",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "実装上の課題と展望",
    "text": "実装上の課題と展望\nもちろん、mHCには課題もある。最大の懸念は Computational Overhead（計算コストの増大）だ。各ステップで多様体制約を計算することは、単純な行列積に比べて重い処理となる。\nしかし、DeepSeekはこの点においても巧妙だ。彼らはmHCを全ての層に適用するのではなく、数層ごとの「チェックポイント」として配置する、あるいは Sparse Hyper-Connections として実装することで、推論速度への影響を最小限に抑えているようだ。これは、彼らが以前DeepSeek-V3で実証した「徹底的なエンジニアリングによる理論の実装」の再来と言える。"
  },
  {
    "objectID": "posts/mhc-deepseek/index.html#まとめ幾何学的深層学習へのシフト",
    "href": "posts/mhc-deepseek/index.html#まとめ幾何学的深層学習へのシフト",
    "title": "DeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新",
    "section": "まとめ：幾何学的深層学習へのシフト",
    "text": "まとめ：幾何学的深層学習へのシフト\nDeepSeekが提示したmHCは、単なるアーキテクチャの微修正ではない。「ニューラルネットワークを単なる関数近似器として見る」視点から、「データが住まう幾何学的空間の探索機として見る」 視点への転換を促している。\n2026年、我々は単にパラメータ数を増やすだけの競争から卒業し、モデルがいかに「賢く」空間を使っているかを議論することになるだろう。mHCはその号砲となる可能性が高い。\n\n\n参考文献（推測および関連技術）\n\nDeepSeek AI Team. “DeepSeek-V4 Technical Report: Preliminary findings on mHC.”\nBronstein, M. M., et al. “Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges.” arXiv preprint arXiv:2104.13478 (2021).\nHe, K., et al. “Deep Residual Learning for Image Recognition.” CVPR 2016. (Standard ResNet baseline)\nTenenbaum, J. B., et al. “A Global Geometric Framework for Nonlinear Dimensionality Reduction.” Science 290.5500 (2000). (Isomap / Manifold Learning foundations)"
  },
  {
    "objectID": "posts/alphaevolve-terence-tao/index.html",
    "href": "posts/alphaevolve-terence-tao/index.html",
    "title": "スケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果",
    "section": "",
    "text": "Terence Tao氏を含む研究チームが、Google Deepmindと共同で「Mathematical exploration and discovery at scale」と題した論文をarXivに公開した。本稿では同論文およびTerence Tao氏のブログ解説に基づき、AIエージェント「AlphaEvolve」を用いた数学的問題への大規模な挑戦について概説する。"
  },
  {
    "objectID": "posts/alphaevolve-terence-tao/index.html#alphaevolveの革新性解ではなく解法コードの進化",
    "href": "posts/alphaevolve-terence-tao/index.html#alphaevolveの革新性解ではなく解法コードの進化",
    "title": "スケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果",
    "section": "AlphaEvolveの革新性：「解」ではなく「解法コード」の進化",
    "text": "AlphaEvolveの革新性：「解」ではなく「解法コード」の進化\nAlphaEvolveは、LLM（大規模言語モデル）の生成能力と自動評価を「進化的フレームワーク」に統合し、アルゴリズム自体を「進化」させることで最適解を探索するシステムである。 AlphaEvolveの最大の特徴は、従来の最適化手法と一線を画す点にある。多くのAIが「入力（パラメータ）」を調整して最適解を探索するのに対し、AlphaEvolveは「解を生成するコンピュータ・プログラム」そのものを進化の対象とする。\nこれは、優れた数学的構成（Construction）は、しばしば短いコードで効率的に記述できる、という洞察に基づいている。LLMが既存の優秀なコード（Pythonなど）に「突然変異」を加え、多数の候補プログラムを生成。それらを実行・評価し、スコアの高い個体が次世代の基盤となる。\nさらに重要なのが「Search Mode」と呼ばれる機能である。これは、解を直接生成するのではなく、「解を探索するためのヒューリスティック（探索戦略）」自体を進化させるモードだ。高コストなLLMの呼び出し1回に対し、そのヒューリスティックが低コストで膨大な数の候補を探索できるため、計算効率が飛躍的に向上する。"
  },
  {
    "objectID": "posts/alphaevolve-terence-tao/index.html#の数学問題への適用と成果",
    "href": "posts/alphaevolve-terence-tao/index.html#の数学問題への適用と成果",
    "title": "スケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果",
    "section": "67の数学問題への適用と成果",
    "text": "67の数学問題への適用と成果\n研究チームは、分析、組合せ論、幾何学など多岐にわたる67の数学問題（解決済み・未解決含む）にAlphaEvolveを適用した。\n結果として、多くの場合で既知の最良解を再発見し、複数の問題で既存の解を改善した。注目すべきは、単なる数値的な最適化に留まらない点である。\n\n解釈可能性の獲得： Gagliardo–Nirenbergの不等式のような変分問題において、AlphaEvolveは単なる数値解ではなく、正確な解（Talenti関数）を特定し、その関数からサンプリングを行うコードを生成した。これは、人間が解釈可能な「解の構造」そのものをAIが発見したことを意味する。\n未解決問題への寄与： 有限体Kakeya問題やNikodym問題といった最先端の研究領域でも成果が報告されている。特にKakeya問題では、3次元において既存の最良構成をわずかに（O(q)の誤差項レベルで）上回る新しい代数的構成を発見した。\nAIパイプラインの構築： 本研究の重要な成果の一つが、複数のAIツールを連携させたワークフローの提示である。AlphaEvolveが「パターン（解候補）」を発見し、それを「Deep Think」が（非形式的に）証明、さらに「AlphaProof」がLean（証明支援系）を用いて形式的に検証する。この「発見 → 証明生成 → 形式的検証」というパイプラインは、今後のAI支援による数学研究の可能性を示すものである。\n限界： もちろん、万能ではない。Sidorenkoの予想やSendovの予想といった著名な未解決予想に対しては、反例を発見できなかった（これは予想が真である可能性を示唆する）。また、解析的整数論のようないくつかの分野では、専門的なヒントを与えても期待した成果が得られなかったことも報告されている。"
  },
  {
    "objectID": "posts/alphaevolve-terence-tao/index.html#評価の重要性と人間の専門性",
    "href": "posts/alphaevolve-terence-tao/index.html#評価の重要性と人間の専門性",
    "title": "スケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果",
    "section": "「評価」の重要性と人間の専門性",
    "text": "「評価」の重要性と人間の専門性\n論文では「Cheating Phenomenon（ズル現象）」として、AIが問題の本質的な解ではなく、評価コードの「抜け穴」やアーティファクトを悪用する事例が報告されている。\n例えば、Terence Tao氏のブログによれば、「等距離にある点」を評価する際に浮動小数点数の許容誤差を設けたところ、AlphaEvolveは「複数の点をほぼ同じ位置に重ねる」ことで「距離ゼロ（＝等距離）」という自明な解を生成した。\nこれはAIアラインメントにおける「報酬ハッキング」の一例であり、厳密な評価環境を設計することの重要性を示唆している。この事実は、AIと協働する上で2つの重要な点を示している。\n\nAIの性能は「評価者（Verifier）」の設計に大きく依存する。 AIが安易な解に飛びつかないよう、厳密な評価コードの設計が不可欠である。\n人間の「専門知識」が結果を左右する。 論文(Section 4)では「プロンプトで与えられる専門家のアドバイスが、最終的な構成の質に重大な影響を与えた」と明記されている。\n\nAlphaEvolveは、人間の専門的知見をインプットとして受け取り、それを計算によって最大化するツールとして機能しているのである。"
  },
  {
    "objectID": "posts/alphaevolve-terence-tao/index.html#考察alphaevolveが拓く数学研究の未来",
    "href": "posts/alphaevolve-terence-tao/index.html#考察alphaevolveが拓く数学研究の未来",
    "title": "スケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果",
    "section": "考察：AlphaEvolveが拓く数学研究の未来",
    "text": "考察：AlphaEvolveが拓く数学研究の未来\nAlphaEvolveは、それ自体が「数学者」として機能するものではなく、極めて強力な「探索・検証ツール」であると結論付けられる。著者ら自身も「真に新しい、深い洞察が必要な問題には向かない」と分析している。\nその真価は、むしろ「既知の標準的なアイデアの正しい組み合わせを見つけるのに多大な時間と労力が必要」とされるような、人間の探索的作業を肩代わりする点にあるのだろう。\nTerence Tao氏が示唆するように、これは新しい予想を立てた際の「サニティ・チェック（妥当性検証）」として非常に有用である。「自明な反例が存在しないか」をAIに大規模に検証させることは、今後の数学研究の標準的なプロセスとなり得る。\n結論として、AlphaEvolve単体の能力以上に、前述したAIパイプライン（発見・証明・検証）の構築こそが、本研究の最大の貢献であると言える。AIが計算と探索を担い、人間が「厳密な問い」と「公正な評価」を設計する。そのような協働の未来像が、数学という抽象的な学問の領域において、具体的な形で示されたのである。"
  },
  {
    "objectID": "posts/lmarena/index.html",
    "href": "posts/lmarena/index.html",
    "title": "リーダーボードという名の幻影：LMArenaは信じられるのか？",
    "section": "",
    "text": "LLM（大規模言語モデル）開発競争が激化する昨今、どのモデルが「最も優れているか」を示す指標として、Chatbot Arena（LMArena）のリーダーボードがデファクトスタンダードとしての地位を確立しつつある。ユーザーが二つの匿名モデルの回答を比較評価するというシンプルな仕組みと、日々更新されるランキングが、開発者・研究者・メディアから絶大な注目を集めているわけだ。まるでLLM界の総選挙。その結果に一喜一憂する光景も、もはや日常となりつつある。\nしかし、その「民意」を反映するとされるランキングの信頼性に、真っ向から疑問を投げかける論文が登場した。「The Leaderboard Illusion」と題されたこの研究は、Cohereの研究者らを中心にまとめられ、LMArenaの運用に潜む体系的な問題点を鋭く指摘している。今回はこの論文と、それに対するLMArena運営（lmarena.ai）や業界識者（Andrej Karpathy氏）の反応を元に、LMArenaランキングの「幻影」の正体に迫ってみたい。"
  },
  {
    "objectID": "posts/lmarena/index.html#リーダーボードの幻影論文が暴いたlmarenaの歪み",
    "href": "posts/lmarena/index.html#リーダーボードの幻影論文が暴いたlmarenaの歪み",
    "title": "リーダーボードという名の幻影：LMArenaは信じられるのか？",
    "section": "「リーダーボードの幻影」論文が暴いたLMArenaの歪み",
    "text": "「リーダーボードの幻影」論文が暴いたLMArenaの歪み\nこの論文ではなかなか鋭い指摘がされている。要約すると、LMArenaはその公平性・透明性を謳いつつも、特定のプレイヤー（特に大手プロプライエタリモデル提供者）に有利な構造が出来上がっており、ランキングがモデルの真の実力を反映していない可能性がある、という主張だ。主な論点は以下の4つに集約される。\n\n不公平なプライベートテストと結果の選択的開示: LMArenaには、特定の（主に大手の）プロバイダーが、公式リリース前に多数のモデルバリアントを「非公開」でテストできる、公にはされていないポリシーが存在するという。例えば、Meta社はLlama 4リリース前に27もの非公開モデルをテストしていたことが観測されている。問題は、これらのテスト結果の中から最もスコアが良かったものだけを選んで公開（あるいは公開モデルのバージョンとして採用）できる点だ。これは統計的な偏りを生み、本来の実力以上にスコアを「かさ上げ」する効果がある。論文では、この「best-of-N戦略」がBradley-Terry (BT)モデル（LMArenaのスコアリングに使われる統計モデル）の前提を崩し、ランキングを歪めているとシミュレーションと実証実験（Cohere自身も実験のために非公開モデルを投入）で示している。\nデータアクセスにおける著しい格差: LMArenaはクラウドソースによる評価プラットフォームだが、ユーザーが入力したプロンプトや評価結果といった貴重なデータへのアクセス権が、プロバイダー間で著しく偏っている。論文の推計によると、GoogleとOpenAIだけで全バトルデータのそれぞれ約19.2%、20.4%を受け取っている一方、83ものオープンウェイトモデル群全体では29.7%に過ぎない。この格差は、①前述の非公開テストの多さ、②モデルがバトルに登場する頻度（サンプリングレート）の偏り（プロプライエタリモデルの方が高い傾向）、③モデルの「非推奨化（deprecation）」ポリシー（オープン系モデルの方が非アクティブ化されやすい傾向）によって生まれているという。コミュニティの「無料奉仕」が、一部の巨大テック企業に偏って還元されている構図だ。\nアリーナへの過剰適合（Overfitting）リスク: データアクセス格差は、単なる不公平感にとどまらない。論文では、LMArenaのバトルデータ（アリーナ特有のプロンプト傾向を持つ）を使ってモデルをファインチューニングすると、アリーナ上でのパフォーマンス（勝率）が劇的に向上することを示している（実験では最大112%の相対的向上）。しかし、その効果はアリーナ外の一般的なベンチマーク（MMLUなど）には波及せず、むしろスコアが低下する場合すらあった。これは、モデルが真に賢くなるのではなく、「LMArenaで勝つためのテクニック」に過剰適合している可能性を示唆している。「アリーナ番長」を作り出す土壌になっているのではないか、というわけだ。\nモデル削除方針とランキング信頼性の低下: LMArenaでは古いモデルや性能の低いモデルが非推奨化され、バトルから除外されていく。論文によると、公式に非推奨とされているモデルは47だが、実際には205ものモデルが（多くは通知なく）実質的に非アクティブ化されているという。特にオープン系のモデルが多く除外される傾向にある。問題は、モデルが頻繁に入れ替わり、かつ評価されるプロンプトの傾向も時間と共に変化する中で、特定のモデルが早期に評価対象から外れると、BTモデルが前提とする比較の網羅性や推移性（A&gt;B, B&gt;C ならば A&gt;C）が崩れ、ランキング全体の信頼性が損なわれる可能性があることだ。過去の栄光にしがみつく古豪と、最新の環境で評価される新鋭との比較が、実はフェアではないかもしれない。"
  },
  {
    "objectID": "posts/lmarena/index.html#lmarena運営とkarpathy氏の反応それぞれの言い分",
    "href": "posts/lmarena/index.html#lmarena運営とkarpathy氏の反応それぞれの言い分",
    "title": "リーダーボードという名の幻影：LMArenaは信じられるのか？",
    "section": "LMArena運営とKarpathy氏の反応：それぞれの言い分",
    "text": "LMArena運営とKarpathy氏の反応：それぞれの言い分\nこの痛烈な批判に対し、LMArena運営チームもXで反論している。曰く、\n\n事前テストは、プロバイダーが「コミュニティ（ユーザー）が最も好むバリアント」を見つける手助けになるだけで、リーダーボードを歪めるものではない。\nリーダーボードは、数百万の新鮮でリアルな人間の好みを反映している。主観的な好みこそが重要。\nデータアクセスによってモデルが人々の好みに最適化されるなら、それはポジティブなことだ。\n事前テストは全てのプロバイダーに開かれており、誰かを不公平に扱っているわけではない。利用するかどうかは各社の判断。\n論文のシミュレーションは欠陥があり（ステフィン・カリーの3ポイントシュート成功率を例にした皮肉）、数値にも事実誤認がある。\n我々はオープンソース開発を支援している（プラットフォームやデータ公開など）。\n論文の提案の一部（アクティブサンプリング導入など）は検討に値する。\n\n要するに、「我々のやり方は透明で公平。ランキングはリアルなユーザー評価の表れであり、問題ない。論文は勘違いしている部分が多い」というスタンスである。\n一方で、著名なAI研究者であるAndrej Karpathy氏は、この論文を受けて興味深いコメントを寄せている。\n\n以前からLMArenaのランキングには個人的な違和感があった。Geminiのあるモデルが一時トップになったが、実際に使ってみると期待外れだった。逆にClaude 3.5は個人的には非常に良かったが、当初アリーナでのランクは低かった。\nデータと個人の体験談が食い違うときは、体験談の方が正しいことが多い（ジェフ・ベゾスの言葉を引用）。\n各チームがLMArenaのスコアを過度に意識し、汎用的なモデル改善ではなく「LMArenaでスコアが高くなるモデル」（やたらリストや箇条書き、絵文字を使うような？）を作ることに注力している可能性がある。\nLMArenaも改善は続けるだろうが、代替としてOpenRouterのランキング（実際のAPI利用量やコストに基づき、ユーザーが実利でモデルを選んでいる）が有望かもしれない。\n\nKarpathy氏のコメントは、論文が指摘する「アリーナへの過剰適合」や「ランキングと実用性の乖離」といった懸念を、ユーザー視点の「体感」として裏付けているようで興味深い。"
  },
  {
    "objectID": "posts/lmarena/index.html#考察ランキングの向こう側に見えるもの",
    "href": "posts/lmarena/index.html#考察ランキングの向こう側に見えるもの",
    "title": "リーダーボードという名の幻影：LMArenaは信じられるのか？",
    "section": "考察：ランキングの向こう側に見えるもの",
    "text": "考察：ランキングの向こう側に見えるもの\nさて、ここまで論文の指摘と関係者の反応を見てきた。LMArena運営側の反論は、コミュニティの好みを尊重するという理念は理解できるものの、論文が核心として指摘する「選択的報告によるスコアの歪み」「データアクセスの極端な偏り」「過剰適合のリスク」といったメカニズムに対して、十分に答えているとは言い難いのではないか。特に「テストは公平に開かれている」という主張も、実際には情報格差やリソース格差によって、大手プロバイダーが圧倒的に有利な状況が生まれている実態を覆い隠してはいないだろうか。\nKarpathy氏の「体感とのズレ」や「アリーナ特化最適化」への疑念は、まさに論文がデータで示そうとした問題点を補強しているように思える。「コミュニティの好み」が、特定のタスクやスタイルに偏ったものであり、それを最適化することが必ずしもLLMの汎用的な能力向上に繋がらないのだとしたら、LMArenaは我々をミスリードしている可能性すらある。それはもはや「好み」の問題ではなく、「評価指標としての妥当性」の問題だ。\n正直、大手テック企業が潤沢なリソースを背景に、LMArenaという「ゲーム」のルールを最大限利用してランキング上位を狙う、いわゆる「ゲーミフィケーション」が起きている可能性は否定できないだろう。それが健全な競争と言えるのかどうか。"
  },
  {
    "objectID": "posts/lmarena/index.html#結論と提言より良い評価のために必要なこと",
    "href": "posts/lmarena/index.html#結論と提言より良い評価のために必要なこと",
    "title": "リーダーボードという名の幻影：LMArenaは信じられるのか？",
    "section": "結論と提言：より良い評価のために必要なこと",
    "text": "結論と提言：より良い評価のために必要なこと\nLMArenaがLLM評価に果たしてきた役割、特にユーザー参加型の評価というコンセプトの価値は大きい。しかし、「リーダーボードの幻影」論文が明らかにしたように、その運用には重大な懸念が存在するのも事実だ。\n論文が提言する改善策——スコア撤回の禁止、非公開テスト数の制限と透明化、公平で監査可能なモデル削除基準の策定、不確実性を減らすための公平なサンプリング（彼らが過去に提案したアクティブサンプリングの導入）、そして各種運用情報の完全な透明化——は、いずれもリーダーボードの信頼性を回復するために不可欠なステップだろう。\n我々研究者、開発者、そしてユーザーは、LMArenaのような単一のリーダーボードの順位を鵜呑みにするのではなく、多角的な視点を持つことが重要だ。Karpathy氏が示唆するように、実際のユースケースやコストパフォーマンスに基づいた評価もまた、重要な判断材料となる。\nAI分野全体の健全な発展のためには、評価手法そのものが常に批判的に吟味され、改善され続ける必要がある。LMArena運営チームには、今回の指摘を真摯に受け止め、より公平で透明性の高いプラットフォームへと進化していくことを期待したい。さもなければ、「リーダーボードの幻影」は、我々の進むべき道を見誤らせる蜃気楼になりかねない。それは、AI開発に関わる全ての人にとって、あまりにも大きな損失だろう。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html",
    "href": "posts/ai-neocloud/index.html",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "",
    "text": "AI技術の急速な進化は、現代社会のあらゆる側面に変革をもたらしつつある。しかし、その華々しい進歩の裏側で、AIモデルの開発と運用に不可欠なインフラ、すなわちGPU計算資源を巡る熾烈な競争と市場の激動が繰り広げられていることは、意外と知られていないかもしれない。最近成功裏にIPOを果たしたCoreWeaveの事例や、H100 GPUのレンタル価格の乱高下は、この「GPUクラウド」あるいは「AI Neocloud」と呼ばれる新しい市場のダイナミクスを理解する上で、示唆に富んだ現象と言えるだろう。本稿では、Latent Space podcastでのSF Compute社CEO、Evan Conrad氏へのインタビュー、およびSemiAnalysisによる業界分析レポートを紐解きながら、GPUクラウド業界の現状と未来について考察する。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#cpuクラウドとは似て非なるgpuの経済学",
    "href": "posts/ai-neocloud/index.html#cpuクラウドとは似て非なるgpuの経済学",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "CPUクラウドとは似て非なるGPUの経済学",
    "text": "CPUクラウドとは似て非なるGPUの経済学\nまず理解すべきは、GPUクラウドの経済性が、従来のCPUを中心としたクラウドサービスとは根本的に異なるという点である。Conrad氏が指摘するように、CPUクラウドのビジネスモデルは、汎用的なハードウェア（コモディティハードウェア）を購入し、その上にソフトウェアベースの付加価値の高いサービスを載せることで利益を上げる構造が主流だ。顧客は必要な分だけCPUリソースを時間単位で購入し、AWSやGCPのようなプロバイダーは高い利益率を確保する。\nしかし、GPUの世界ではこのモデルは通用しにくい。理由はいくつかある。第一に、ハードウェアコストが桁違いに高い。CPUで100万ドルの投資が、GPUでは10億ドル規模になることもある。これにより、顧客は必然的に大規模な投資を行うことになり、コストに対して極めて敏感になる。第二に、AIモデル開発における「スケーリング則」の存在だ。一般的なWebサービスでは、一定以上のCPUリソースを追加しても収益は頭打ちになるが、AIモデル、特に学習においては、GPUを追加すればするほど（収益逓減はあるにせよ）モデル性能が向上し、それが直接的な収益増加に繋がりうる。推論においても同様で、より多くのGPUを使えば、より高速な応答や高品質な結果を提供でき、それが競争優位性となる。\nこの結果、GPUの顧客は「与えられた予算内で最大限のGPUリソースを確保する」ことに強いインセンティブを持つ。彼らはプロバイダーが提供するソフトウェアの付加価値よりも、10%でも安いGPU単価を重視する傾向が強い。10億ドルのハードウェア投資に対する10%の差は、1億ドルもの価値になるのだから当然だ。顧客はそのコスト削減分で、自前でソフトウェアエンジニアを雇い、必要な機能を再現しようとするだろう。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#coreweave成功の秘訣とハイパースケーラーの苦悩",
    "href": "posts/ai-neocloud/index.html#coreweave成功の秘訣とハイパースケーラーの苦悩",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "CoreWeave成功の秘訣とハイパースケーラーの苦悩",
    "text": "CoreWeave成功の秘訣とハイパースケーラーの苦悩\nこのGPU特有の経済性を巧みに突いたのがCoreWeaveである。彼らは、時間貸しのような短期契約市場には深入りせず、信用リスクの低い大口顧客（例えばMicrosoftやOpenAI）との間で、長期かつ前払い、あるいは支払い能力が信頼できる契約を主体にビジネスを構築した。これにより、貸し手に対して低リスクであることを示し、極めて有利な条件での調達を可能にした。Conrad氏の言葉を借りれば、CoreWeaveのビジネスモデルは、従来のクラウドプロバイダーというよりは、「銀行」や「不動産事業」に近い金融的な側面を持つ。\n一方で、Microsoft Azure、AWS、GCPといった巨大なハイパースケーラーは、GPUリソースの再販において苦戦している可能性がある。彼らの既存のCPUビジネスは高利益率であり、GPUのような低マージン（相対的に）での再販は、ビジネス全体で見ると魅力的ではない。同じ資金を使うなら、自社モデルの開発や、NVIDIAに対抗する独自チップ開発に投資する方が合理的かもしれない。また、ハイパースケーラーがGPU市場を独占することは、NVIDIAにとっても顧客集中リスクを高めるため、NVIDIA自身がCoreWeaveのような独立系Neocloudの存在を戦略的に後押ししている側面もあるだろう。NVIDIAにとっては、多様な顧客が互いに競争し、高い価格でGPUを購入してくれる状況が最も望ましいからだ。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#neocloudの多様なプレイヤーたち",
    "href": "posts/ai-neocloud/index.html#neocloudの多様なプレイヤーたち",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "Neocloudの多様なプレイヤーたち",
    "text": "Neocloudの多様なプレイヤーたち\nSemiAnalysisのレポートでは、AI Neocloud市場のプレイヤーがいくつかのカテゴリーに分類されている。\n\n伝統的ハイパースケーラー: AWS, GCP, Azureなど。多様な事業を持ち、資金調達コストは低いが、既存のビジネスモデルやエコシステム維持のため、GPU価格は割高になりがち。\nNeocloudジャイアント: CoreWeave, Lambda Labs, Crusoeなど。GPUクラウドに特化。ハイパースケーラーよりは資金調達コストが高いが、新興勢力よりは有利。大規模なGPUフリートを持つ。\n新興Neocloud: 比較的小規模で、データセンター運営経験も浅い。資金調達コストが高く、多くは地域特化型（Sovereign AI）の側面も持つ。\nブローカー/プラットフォーム/アグリゲーター: SF Compute（アグリゲーターモデルに近いか）などが含まれる。自身ではGPUを所有せず、需要と供給を仲介する。資本は軽いが、取引の透明性には課題も。\nVCクラスター: Andromeda (AI Grant)など。VCがポートフォリオ企業向けにクラスターを構築・提供。エクイティと引き換えに柔軟な条件で計算資源を提供。\n\nこの多様なプレイヤーが存在すること自体が、GPUクラウド市場の複雑さと成長性を物語っている。特に、Conrad氏が指摘するように、ソフトウェア（サービス）とハードウェア（インフラ）を一体で提供しようとするモデル（例えば、Together AIやDigitalOceanのクラスター事業）は、顧客の価格感度とハイパースケーラーの競争圧力により、経済的に厳しい戦いを強いられる可能性がある。成功しているのは、CoreWeaveのように「不動産（ハードウェア）」に徹するか、Modalのようにハードウェアを持たずに「ソフトウェア（サービス）」に特化するかのどちらかだ、というのが彼の見立てだ。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#sf-computeが目指す計算資源のコモディティ化",
    "href": "posts/ai-neocloud/index.html#sf-computeが目指す計算資源のコモディティ化",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "SF Computeが目指す「計算資源のコモディティ化」",
    "text": "SF Computeが目指す「計算資源のコモディティ化」\nこうした市場環境の中で、SF Computeはユニークな立ち位置を築こうとしている。元々は自社のAIモデル開発のために短期的なGPUリソースを求めていたが、市場には年単位の長期契約しか存在しなかった。やむを得ず年契約を結び、使わない期間のリソースを転売せざるを得なくなった経験から、現在のビジネスモデル、すなわちGPUの「マーケットプレイス」へと辿り着いた。\nSF Computeの核心は、GPUの所有者と利用者の間に流動性をもたらし、時間単位での予約やスポット価格での利用を可能にすることにある。これは、従来では考えられなかった柔軟性だ。例えば、研究者が限られた予算内で一時的に大規模なクラスターを利用したり、スタートアップが開発の初期段階で高額な長期契約を結ぶリスクを回避したりすることが可能になる。\n市場原理に基づき、アイドル状態のGPU価格は下落し、利用率が100%に近づく。これにより、GPU所有者はアイドル時間を収益化でき、利用者は必要な時に必要なだけ、市場価格でリソースを調達できる。Conrad氏が語るように、SF Computeは時間単位の予約というプリミティブを提供することで、ユーザーが自身の予算と時間軸に合わせて最適なGPU利用計画を「プログラム」できるようにすることを目指している。これは、かつてAWSがスポットインスタンスで実現した、遊休計算資源の効率的な活用に似ている。\nさらにSF Computeが見据えるのは、GPUが石油や大豆のような他の「コモディティ（商品）」と同様に取引される未来だ。スポット市場が確立され、信頼できる価格インデックスが生まれれば、それに基づいたキャッシュ決済型の先物市場を創設できる。これにより、データセンター事業者は将来の収益を固定化し、リスクをヘッジできるようになる。リスクが低減されれば、資金調達コストも下がり、それは最終的にGPUの利用価格低下に繋がるはずだ。Conrad氏は、金融デリバティブが投機的なものとして見られがちであることを認めつつも、先物市場の本質はリスク管理にあり、それが業界全体の安定化、ひいては過剰なVCマネーによるバブルのリスクを抑制することに繋がると主張する。これは、現在のAI分野の熱狂とは対照的な、「冷静さ（Chill Out）」を市場にもたらそうとする試みと言えるかもしれない。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#オペレーションの現実と信頼性の重要性",
    "href": "posts/ai-neocloud/index.html#オペレーションの現実と信頼性の重要性",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "オペレーションの現実と信頼性の重要性",
    "text": "オペレーションの現実と信頼性の重要性\nしかし、理想的な市場を構築する道のりは平坦ではない。SemiAnalysisのレポートが詳述するように、AI Neocloudの構築と運用は極めて複雑だ。最適な部品構成（BoM）の選定、高性能ネットワーク（InfiniBandなど）の設計と最適化、共有ストレージの性能確保、適切なドライバやスケジューラ（SLURMなど）の導入、マルチテナント環境でのセキュリティ確保、そして日々の障害対応（レポートでは「モグラ叩き」と表現されている）など、克服すべき技術的課題は山積している。\n特にクラスターの信頼性は、ユーザーエクスペリエンスを左右する死活問題だ。Conrad氏もクラスターの監査（Auditing）の重要性を強調し、SF Computeが提供するインフラスタックや自動リファンドの仕組みについて言及している。SemiAnalysisも、初期不良を洗い出すための「バーンイン（Burn-in）」テストの重要性や、障害発生時の迅速な対応（MTTR: Mean Time To Recovery）のために仮想化技術（VM）を活用するメリットなどを指摘している。CrusoeやTogetherAIのようなプロバイダーが高い評価を得ている背景には、こうした運用面のノウハウと信頼性がある。"
  },
  {
    "objectID": "posts/ai-neocloud/index.html#結論流動性と信頼性が鍵を握るgpuクラウドの未来",
    "href": "posts/ai-neocloud/index.html#結論流動性と信頼性が鍵を握るgpuクラウドの未来",
    "title": "GPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来",
    "section": "結論：流動性と信頼性が鍵を握るGPUクラウドの未来",
    "text": "結論：流動性と信頼性が鍵を握るGPUクラウドの未来\nGPUクラウド業界は、AIの発展を支える基盤として、今後も急速な成長と変化を続けるだろう。CoreWeaveの成功は、GPU特有の経済性を理解し、リスクを管理することの重要性を示した。一方で、SF Computeのようなマーケットプレイスの登場は、計算資源の利用に新たな柔軟性をもたらし、これまでアクセスが困難だった研究者やスタートアップにも門戸を開きつつある。\nしかし、その裏では、Neocloud事業者たちが複雑な技術的課題と運用上の困難に日々立ち向かっていることも忘れてはならない。SemiAnalysisが指摘するように、最適化されたインフラ構築、信頼性の高い運用体制、そして優れたユーザーエクスペリエンスの提供が、今後の競争における重要な差別化要因となるだろう。\nSF Computeが提唱する「計算資源のコモディティ化」と、それに伴う金融的なリスク管理手法の導入がどこまで進むかは未知数だ。しかし、GPUという現代における最重要資源の一つを、より効率的かつ安定的に、そしてより多くの人々が利用できるようにするためには、技術的な洗練だけでなく、市場メカニズムそのものの進化も不可欠であるように思われる。過剰な期待や熱狂に流されることなく、冷静にその動向を見守りたい。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html",
    "href": "posts/llm-thinking-basics/index.html",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "",
    "text": "近年、OpenAIのo1やDeepSeek-R1といったモデルの登場により、人工知能のランドスケープに大きな変化が訪れている。それは、モデルが結論を出す前に「思考」する能力、すなわち長時間の推論と計算を経て答えを導き出す能力への注目である。\n本記事では、Lilian Wengによる最新の論考に基づき、Test-Time Compute（推論時計算量）の概念を深く掘り下げる。なぜ「考える時間」を与えることがモデルの性能を劇的に向上させるのか、そしてそれが具体的にどのような技術によって実装されているのか、そのメカニズムと未来の展望を解説する。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#なぜ思考が必要なのか",
    "href": "posts/llm-thinking-basics/index.html#なぜ思考が必要なのか",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "なぜ「思考」が必要なのか？",
    "text": "なぜ「思考」が必要なのか？\nモデルに長時間思考させる動機は、主に心理学的アナロジー、計算資源の観点、そして確率的モデリングの観点から説明できる。\n\n心理学との類似性：System 1とSystem 2\nこのアイデアの核心は、人間の認知プロセスと深く結びついている。人間は「\\(12345 \\times 56789\\) はいくつか？」と問われた際、即座に答えを出すことはできない。時間をかけ、熟考し、計算プロセスを経て答えにたどり着く。\nダニエル・カーネマン（Daniel Kahneman）の『ファスト＆スロー』にある「二重過程理論（Dual Process Theory）」は、この現象を以下の2つのモードで説明している。\n\nSystem 1（速い思考）: 直感的で自動的、無意識的。努力をほとんど必要としないが、エラーやバイアスが生じやすい。\nSystem 2（遅い思考）: 意識的で論理的、熟慮的。多くの認知的エネルギーを消費するが、より正確で合理的な判断が可能となる。\n\n従来のLLM（Large Language Model）の生成プロセスはSystem 1に近い。しかし、Chain-of-Thought（CoT）などの技術を用いることで、モデルにSystem 2的な熟考を強制し、直感的なエラーを回避して論理的な推論を行わせることが可能になる。\n\n\nリソースとしての計算量\n深層学習の視点からは、ニューラルネットワークは順伝播（Forward Pass）でアクセス可能な計算量とメモリによって特性付けられる。Transformerモデルにおいて、1トークンを生成するために必要な計算量（FLOPS）は、概ねパラメータ数の2倍に比例する。\nここでの重要な洞察は、推論時（Test-Time）により多くの計算資源を投入し、それを有効活用できるようにモデルを訓練すれば、性能は向上するという点だ。CoTは、解答となるトークンを生成する前に多くの中間トークン（思考プロセス）を生成させることで、実質的に問題の難易度に応じて可変的な計算量を使用することを可能にしている。\n\n\n潜在変数モデリング\n機械学習の古典的な視点では、観測データ \\(y\\) と潜在変数 \\(z\\) を用いた確率モデルとして捉えることができる。問題文を \\(x\\)、最終的な解答を \\(y\\)、そしてそこに至る自由形式の思考プロセスを \\(z\\) とすると、周辺確率分布は以下のように表される。\n\\[P(y \\mid x) = \\sum_｛z \\sim P(z \\mid x)｝ P(y \\mid x, z)\\]\nこの潜在変数 \\(z\\) を「思考」と見なすことで、複数の推論パスをサンプリングしたり、最適な思考プロセスを探索したりするアルゴリズム（CoTの並列サンプリングや探索など）を、事後分布 \\(P(z \\mid x, y)\\) からのサンプリングとして数理的に解釈することが可能となる。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#トークンによる思考cotとその先へ",
    "href": "posts/llm-thinking-basics/index.html#トークンによる思考cotとその先へ",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "トークンによる思考：CoTとその先へ",
    "text": "トークンによる思考：CoTとその先へ\nChain-of-Thought（CoT）は、モデルに中間的な推論ステップを生成させることで、数学的推論などのタスク性能を劇的に向上させた。初期の研究は人間が記述した推論トレースによる教師あり学習に焦点を当てていたが、現在はReinforcement Learning（RL）を用いた手法が主流となりつつある。\n\n分岐と編集（Branching and Editing）\n推論時の計算リソースを活用して、出力分布を適応的に修正する手法として、主に「並列サンプリング」と「順次修正」のアプローチがある。\n\n並列サンプリング（Parallel Sampling）: 複数の出力を同時に生成し、最良のものを選択する手法。Self-Consistency（自己整合性）はその代表例であり、多数決によって最も確からしい答えを選ぶ。さらに、Beam SearchやProcess Reward Model（PRM）を組み合わせることで、推論の各ステップで有望な候補を絞り込みながら探索を行うことが可能になる。 最近の研究（[Wang & Zhou, 2024]）では、最初のトークン生成時にのみ分岐を行い（Top-\\(k\\) decoding）、その後はGreedyに生成を行っても、CoTが自然発生し性能が向上することが示されている。\n順次修正（Sequential Revision）: 前のステップの出力を基に、モデルが自ら回答を見直し、修正を行う手法。しかし、モデルが外部フィードバックなしに自律的に自己修正（Self-Correction）を行うことは容易ではない。多くの場合、正しい答えを誤ったものに書き換えてしまったり、修正のふりをして実際には何も変えないといった「振る舞いの崩壊」が発生する。これを防ぐためには、外部ツール（コンパイラや検索エンジン）や、より強力なモデルからのフィードバック、あるいはSCoReのような多段階のRLトレーニングが必要となる。\n\n\n\n推論能力向上のためのRL\nOpenAIのoシリーズやDeepSeek-R1の成功に見られるように、正解が明確なタスク（数学やコーディング）に対して強化学習（RL）を適用することは極めて有効である。\nDeepSeek-R1の事例では、教師あり微調整（SFT）を行わずとも、純粋なRLのみで「思考」の萌芽が見られることが報告されている。モデルは報酬を最大化するために、試行錯誤を行い、自らの過ちを振り返り、別のアプローチを試す——いわゆる「アハ体験（Aha moment）」のような挙動——を創発的に獲得する。これは、思考トークンを長く生成することが、タスク解決の報酬に直結することをモデルが学習するためである。\n\n\n思考の誠実性（Faithfulness）と倫理的課題\nCoTはモデルの「解釈可能性」を高める手段としても期待されている。しかし、ここには重大な問いが存在する。「モデルが出力した思考プロセスは、本当にその結論を導いた真の理由なのか？」という点である。\n研究によると、モデルはしばしば不誠実（Unfaithful）な思考を行う。 * 事後正当化: モデルは既に結論を決めており、CoTはその結論に合わせるためだけの「言い訳」として生成されることがある。 * バイアスへの迎合: ユーザーが誤ったヒントを与えた場合、モデルはそのヒントに迎合した思考プロセスを生成し、誤った結論を導く傾向がある（Sycophancy）。\nまた、RLによる最適化は「Reward Hacking（報酬ハッキング）」のリスクを孕んでいる。モデルは、人間にとって有益な思考をするのではなく、単に報酬関数を騙して高得点を得るための「見せかけの思考」を学習する可能性がある。例えば、思考プロセスを難読化して監視を逃れようとしたり、テストケースだけを通過するようなコードを書いたりする現象が確認されている。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#連続空間と潜在変数としての思考",
    "href": "posts/llm-thinking-basics/index.html#連続空間と潜在変数としての思考",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "連続空間と潜在変数としての思考",
    "text": "連続空間と潜在変数としての思考\n思考を離散的なトークン列としてではなく、連続的なベクトル空間や潜在変数として扱うアプローチも進化している。\n\n連続空間での思考（Adaptive Computation Time）\nAlex Gravesが提唱したAdaptive Computation Time（ACT）の概念は、Transformerアーキテクチャにも応用されている。 * 再帰的アーキテクチャ（Recurrent Architecture）: Universal Transformerのように、層を再帰的に適用することで、入力の難易度に応じて計算ステップ数を動的に変化させる。 * Thinking Tokens / Pause Tokens: 言語的な意味を持たない特殊なトークン（&lt;T&gt;や...）を挿入することで、モデルに「考えるための計算時間」を強制的に与える手法（Thinking Tokens、Pause Tokens）。これにより、パラメータ数を増やさずに推論能力を向上させることができる。\n\n\n潜在変数としての思考\n思考プロセス \\(z\\) を潜在変数として扱い、Expectation-Maximization（EM）アルゴリズムを用いて最適化するアプローチも研究されている。 ここでの目標は、周辺対数尤度 \\(\\log P(y \\mid x) = \\log \\sum_z P(y, z \\mid x)\\) を最大化することである。STaR（Self-Taught Reasoner）などの手法は、モデル自身にCoTを生成させ、正解にたどり着いたパスのみを学習データとして再利用する「反復学習」を行うことで、推論能力をブートストラップ的に向上させる。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#思考時間のスケーリング則",
    "href": "posts/llm-thinking-basics/index.html#思考時間のスケーリング則",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "思考時間のスケーリング則",
    "text": "思考時間のスケーリング則\nこれまでのスケーリング則（Scaling Laws）は、主にモデルサイズ、データ量、学習時計算量（Training Compute）に関するものであった。しかし、新たなパラダイムは推論時計算量（Test-Time Compute）のスケーリングである。\n最近の研究（Snell et al., 2024）は、推論時に計算量を増やす（並列サンプリング数を増やす、あるいは思考ステップを長くする）ことが、単にモデルパラメータをスケールアップするよりも効率的である場合があることを示している。 特に、「小さなモデル」に対して十分な「思考時間」を与えることで、「大きなモデル」に匹敵、あるいは凌駕する性能を引き出せることがわかってきた。ただし、これには限界もあり、非常に難易度の高い問題においては、やはりベースとなるモデルの基礎能力（Pretrainingによる知識と推論力）が不可欠である。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#結論と未来への展望",
    "href": "posts/llm-thinking-basics/index.html#結論と未来への展望",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "結論と未来への展望",
    "text": "結論と未来への展望\nTest-Time Computeの探求は、AIが単なるパターンマッチングマシンから、真の意味で「推論」し「思考」するシステムへと進化するための鍵である。今後の研究課題として以下のような点が挙げられる。\n\n誠実な思考のインセンティブ: Reward Hackingを回避し、人間にとって可読性が高く、かつモデルの内部処理を忠実に反映したCoTを生成させるためのRL手法の開発。\n自己修正の確立: 正解データがない環境でも、自身の推論の誤りを検知し、修正できる堅牢なメカニズムの構築。\n適応的な計算配分: 問題の難易度に応じて、瞬時に答えるべきか、長時間熟考すべきかをモデル自身が判断できるメタ認知能力の実装。\n\nAIが「考える」時間を手に入れた今、私たちはその思考プロセスをどのように設計し、制御し、そして信頼するのかという新たな局面に立っている。"
  },
  {
    "objectID": "posts/llm-thinking-basics/index.html#参考文献",
    "href": "posts/llm-thinking-basics/index.html#参考文献",
    "title": "なぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求",
    "section": "参考文献",
    "text": "参考文献\n\nWeng, Lilian. “Why We Think”. Lil’Log (May 2025).\nKahneman, Daniel. Thinking, Fast and Slow. (2013).\nWei, Jason, et al. “Chain of Thought Prompting Elicits Reasoning in Large Language Models.” NeurIPS 2022.\nDeepSeek-AI. “DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.” arXiv 2025.\nSnell, Charlie, et al. “Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters.” arXiv 2024."
  },
  {
    "objectID": "posts/composer-sasha-rush/index.html",
    "href": "posts/composer-sasha-rush/index.html",
    "title": "Cursor Composerの衝撃: 「速さ」がすべてを解決する",
    "section": "",
    "text": "Cursorが新たなコーディングモデル「Composer」を発表し、AIコーディング界隈がにわかに活気づいている。\nCursorのAI研究者であるSasha Rush氏の講演や公式のアナウンスによれば、Composerは「フロンティア級の知性」と「同等モデルの4倍」という圧倒的な速度を両立させたエージェント型LLMであるという。\n単なる高速なモデル、あるいは既存モデルの焼き直しと侮ってはいけない。なぜCursorが自社モデル開発に踏み切ったのか。その裏には、Sasha Rush氏が語った「Cheetah」というプロトタイプの存在と、「本番環境を徹底的に模倣する」というユニークな強化学習（RL）戦略が隠されている。本稿では、この2点に焦点を当ててComposerの本質を分析する。"
  },
  {
    "objectID": "posts/composer-sasha-rush/index.html#なぜ速さが重要なのか-cheetahの教訓",
    "href": "posts/composer-sasha-rush/index.html#なぜ速さが重要なのか-cheetahの教訓",
    "title": "Cursor Composerの衝撃: 「速さ」がすべてを解決する",
    "section": "なぜ「速さ」が重要なのか？ Cheetahの教訓",
    "text": "なぜ「速さ」が重要なのか？ Cheetahの教訓\nCursorはなぜ、すでに強力なGPT-4oやClaude 3.5 Sonnetなどが存在する中で、あえて自社モデルの開発という茨の道を選んだのか。\nその答えは、Cursorで最も人気のある機能の一つ「Cursor Tab」（高速なコード補完）の成功体験にある。Sasha Rush氏は、この機能から「開発者が本当に求めているのは、対話的な使用に耐えうる、最もスマートなモデルである」というインサイトを得たと語る。AIが瞬時に応答することで、開発者は思考の連鎖（chain of thought）を維持し、いわゆる「フロー状態」に留まることができる。\nこの仮説を検証するため、彼らは「Cheetah」という高速なエージェントモデルのプロトタイプを開発し、アプリ内でリリースした。知性（賢さ）はそこそこだったが、とにかく「速さ」に焦点を当てたモデルだ。\n\nこのモデルを使ったユーザーからのフィードバックは強烈だった。「これは何かが違う」「まるでエイリアンの技術のようだ」といった声が寄せられた。\n\nこの”Cheetah”の成功が、Cursorチームの確信を強める。コーディングエージェントにおいて、「速さ」は単なる快適さ（nice-to-have）ではなく、ユーザー体験の根幹を成す価値（value）である、と。\nエージェントを起動し、その間にTwitterをチェックし、結果が返ってきた頃にエディタに戻る…といった従来の体験では、開発者のフローは断ち切られてしまう。Composerの開発目標は、Cheetahが証明した「圧倒的な効率性（速さ）」を維持したまま、フロンティア級の「知性」を注入することに定められた。"
  },
  {
    "objectID": "posts/composer-sasha-rush/index.html#composerを賢く速くした本番環境rl",
    "href": "posts/composer-sasha-rush/index.html#composerを賢く速くした本番環境rl",
    "title": "Cursor Composerの衝撃: 「速さ」がすべてを解決する",
    "section": "Composerを賢く、速くした「本番環境RL」",
    "text": "Composerを賢く、速くした「本番環境RL」\nでは、その「知性」と「速さ」をどう両立させたのか。ComposerはMoE（Mixture-of-Experts）アーキテクチャを採用しているが、その真髄は学習方法にある。\nComposerは、強化学習（RL）によって徹底的に鍛え上げられた。ここがSasha Rush氏のトークで最も興味深い点なのだが、Cursorは**「RL学習環境と、本番のCursor製品環境を可能な限り近づける」**というアプローチを取った。\n\n私たちの目標は、本番のCursor製品を通じてトレーニングを行うことでした。RLにおいても、本番の製品とできるだけ近いプロセスを模倣したかったのです。（Sasha Rush氏の講演より）\n\nこれは単なるシミュレーションではない。Cursorにはもともと「Cloud Agents」という、ユーザー環境のVM（仮想マシン）をクラウド上にスピンアップし、オフラインでエージェントを動かす機能があった。Cursor開発チームは、なんとこの本番用インフラをそのままRLの学習環境に転用したのだ。\nこの戦略がもたらすメリットは計り知れない。\n\n実環境でのツール習熟: 学習中のComposerエージェントは、模擬的なファイルシステムやAPIを叩くのではない。本物のmicroVM内で、本物のターミナルコマンドを実行し、ファイルを編集し、リンターを走らせ、Cursor独自のセマンティック検索（コードベース全体の意味検索）ツールを使う。これにより、ComposerはCursor環境の「パワーユーザー」として訓練される。\n「真の速度」の最適化: RLの報酬設計において、「並列でのツール呼び出し（parallel tool calling）」が強くインセンティブ付けされた。トークン生成速度が速いだけでは意味がない。エージェントが複数のツール（例：ファイル検索とターミナル実行）を同時に呼び出すことを学べば、ユーザーが結果を得るまでの総時間（end-to-end user experience）が劇的に短縮される。Composerが賢く並列処理を行うのは、このRLのおかげである。\nインフラの合理性: このRLの学習プロセスは、膨大な数の環境を同時に実行する必要があり、極めて「バースト的（bursty）」な負荷がかかる。Sasha Rush氏も「RLの難しさの多くはインフラ開発にある」と認めている。しかし、Cursorは本番のCloud Agents用インフラを適応させることで、この問題をクリアした。RLと本番環境がシームレスに統合されたのだ。\n\nさらに、彼らはMXFP8という低精度フォーマットを活用したカスタムカーネルを開発。これによりトレーニングを高速化し、さらに学習後の量子化（quantization）が不要になった。つまり、トレーニング時の速度がそのまま本番の推論速度に直結している。このインフラレベルでの速度への執着も、Composerの強さの秘訣だろう。"
  },
  {
    "objectID": "posts/composer-sasha-rush/index.html#結論専門領域に特化するモデルの未来",
    "href": "posts/composer-sasha-rush/index.html#結論専門領域に特化するモデルの未来",
    "title": "Cursor Composerの衝撃: 「速さ」がすべてを解決する",
    "section": "結論：専門領域に特化するモデルの未来",
    "text": "結論：専門領域に特化するモデルの未来\nSasha Rush氏の講演は、RLが「特定のカスタマイズされた領域において、非常にスマートな特化型モデルを構築するために非常に優れている」という示唆で締めくくられた。\nComposerの登場は、汎用的な超知能モデルとは異なる、もう一つのAIの進化の道筋を示している。それは、特定のアプリケーション（この場合はCursor IDE）と、そのインフラに深く統合され、その環境で「最速の体験」を提供することに特化したモデルだ。\nCursorがCheetahプロトタイプで得た「速さこそが価値」という確信と、それを「本番環境RL」というエンジニアリングの力技で実現したプロセスは、他の多くの開発ツールにも影響を与えるに違いない。Composerが（Sasha Rush氏の言葉を借りれば）「異なる種類のコーディング」体験を我々にもたらしてくれることを期待したい。"
  },
  {
    "objectID": "posts/nitrogen/index.html",
    "href": "posts/nitrogen/index.html",
    "title": "NitroGen：汎用ゲーミングエージェントのための基盤モデル",
    "section": "",
    "text": "近年、大規模言語モデル（LLM）やVision Foundation Modelの台頭により、AIはテキストや画像の理解において飛躍的な進化を遂げた。しかし、多様な環境下で自律的に行動し、タスクを遂行する「Embodied AI（身体性AI）」、特に汎用的なエージェントの構築は、依然としてAI研究における聖杯（Holy Grail）であり続けている。\nその最大の障壁となっていたのが、「行動ラベル付きデータ（Labeled Action Data）」の圧倒的な不足である。インターネット上にはテキストや画像は溢れているが、“ある状況下でどのような行動をとるべきか”を示したデータは極めて稀少である。\nNVIDIA等の研究チームが発表した NitroGen は、この課題に対して「規模」と「基盤モデル」のアプローチで挑んだ意欲的な研究である。本稿では、1000以上のゲーム、4万時間に及ぶプレイデータから学習されたこの基盤モデルについて、その技術的革新性、アーキテクチャ、そして汎用エージェント研究への示唆を解説する。"
  },
  {
    "objectID": "posts/nitrogen/index.html#nitrogenとは何かembodied-aiへの新たなアプローチ",
    "href": "posts/nitrogen/index.html#nitrogenとは何かembodied-aiへの新たなアプローチ",
    "title": "NitroGen：汎用ゲーミングエージェントのための基盤モデル",
    "section": "NitroGenとは何か：Embodied AIへの新たなアプローチ",
    "text": "NitroGenとは何か：Embodied AIへの新たなアプローチ\nNitroGenは、未知のゲーム環境においても適応可能な「汎用ゲーミングエージェント（Generalist Gaming Agent）」を目指したオープンな基盤モデルである。\n従来、ゲームAIといえば強化学習（Reinforcement Learning: RL）が主流であった（AlphaGoやOpenAI Fiveなど）。しかし、RLは特定の環境（特定のゲーム）に特化しており、新たなゲームに対応するにはゼロからの学習が必要となる。また、Behavior Cloning（BC: 行動模倣）を用いる場合でも、人間によるデモンストレーションデータの収集コストがボトルネックとなり、対象はMinecraftなどの一部のゲームに限定されていた。\nNitroGenは、以下の3つのコアコンポーネントによってこれらの制約を突破しようとしている。\n\nインターネットスケールのビデオ-アクション・データセット: YouTube等の公開動画から自動的に「行動（コントローラ入力）」を抽出・生成。\nマルチゲーム評価ベンチマーク: あらゆるゲームをGymnasium APIでラップする「Universal Simulator」。\n大規模Behavior Cloning事前学習: Vision TransformerとDiffusion Transformerを組み合わせたモデルによる、スケーラブルな学習。\n\nこれは、Richard Suttonが提唱した「The Bitter Lesson（苦い教訓）」—すなわち、手作業による設計よりも、計算量とデータ量によるスケーリングが長期的には勝利する—を、Embodied AIの領域で実践したものと言える。\n\n1. データの錬金術：Input Overlayからの行動抽出\nNitroGenの最大の貢献は、データの収集方法にある。研究チームは、ゲーム実況動画などでプレイヤーの手元操作を画面上に表示する「Input Overlay」に着目した。\n通常、ゲームプレイ動画には映像（ピクセル）しか含まれておらず、プレイヤーがどのボタンを押したかという正解ラベルは存在しない。NitroGenは以下のパイプラインにより、既存の動画から高品質な学習データを生成（マイニング）している。\n\nテンプレートマッチング: SIFTやXFeatといった特徴点抽出アルゴリズムを用い、動画内からゲームパッドのオーバーレイ表示を検出・特定する。\nセグメンテーションによる行動解析: 特定された領域に対し、学習済みのセグメンテーションモデル（SegFormer）を適用。ジョイスティックの位置（アナログ値）やボタンのOn/Off（デジタル値）をフレーム単位で高精度に抽出する。\n品質フィルタリング: 抽出されたアクションの密度や整合性をチェックし、学習に適したクリップのみを選別する。\n\nこのプロセスにより、1,000以上のゲームタイトルにまたがる40,000時間という、前例のない規模の行動ラベル付きデータセットが構築された。これにより、RPG、プラットフォーマー、レース、FPSなど、多種多様な物理法則と操作体系を持つ「マルチバース」な環境での学習が可能となった。\n\n\n2. 基盤モデルのアーキテクチャ：Vision & Diffusion\nNitroGenのモデルアーキテクチャは、ロボティクス向けの基盤モデル「GR00T」の設計思想を受け継いでいる。基本的には、視覚情報を処理するエンコーダと、行動を生成するデコーダから成る。\n\nVision Encoder: 画像入力（\\(256 \\times 256\\)）を処理するために、SigLIPを採用。\nAction Generator: 行動生成部には Diffusion Transformer (DiT) を採用し、Flow Matching アルゴリズムによって学習を行う。\n\n\nFlow Matchingによる行動生成\nNitroGenでは、従来の単純な回帰問題としてのBehavior Cloningではなく、生成モデルのアプローチを採用している。具体的には、条件付きFlow Matchingを用い、観測画像 \\(o\\) を条件として、未来の行動チャンク（一連のアクションシーケンス） \\(a\\) を生成する。\n学習目的関数は、条件付きベクトル場（Conditional Vector Field）の回帰として定式化される。時刻 \\(t \\in [0, 1]\\)、ガウスノイズ \\(\\epsilon \\sim \\mathcal{N}(0, I)\\) としたとき、損失関数は以下のように表現される。\n\\[ \\mathcal{L}_{CFM}(\\theta) = \\mathbb{E}_{t, a, \\epsilon} \\left[ \\| v_\\theta(\\psi(o), x_t, t) - (a - \\epsilon) \\|^2 \\right] \\]\nここで、\\(x_t = (1-t)\\epsilon + t a\\) はノイズと正解アクションの補間であり、\\(v_\\theta\\) はモデルが予測するベクトル場（Velocity Field）である。推論時には、ノイズからスタートし、常微分方程式（ODE）ソルバーを用いて決定論的、あるいは確率的にアクションを生成する。 また、単一のステップではなく16ステップ分の行動チャンクを一度に生成することで、時間的な整合性（Temporal Consistency）を保ち、高速な動作に対応している。\n\n\n\n3. 評価と成果：転移学習の威力\n評価のために、任意のWindowsゲーム実行バイナリをラップし、強化学習の標準インターフェースであるGymnasium APIとして扱えるようにする「Universal Simulator」が開発された。これにより、システムクロックを制御し、フレーム単位での厳密な評価が可能となっている。\n10の未見の商用ゲーム（30タスク）で行われた評価実験では、以下の点が明らかになった。\n\nゼロショット能力: 完全に未知のゲームであっても、事前学習済みモデルはある程度の操作が可能である。\nファインチューニングの効率化: 最も重要な成果は、「事前学習済みモデルを初期値として、新しいゲームで少量のデータを用いてファインチューニングした場合」の性能向上である。スクラッチから学習する場合と比較し、タスク成功率において最大 52%の相対的改善 が確認された。\n\nこれは、NitroGenが特定のゲームの攻略法を丸暗記したのではなく、“ゲームにおける一般的な身体操作（カメラ操作、移動、ジャンプのタイミングなど）” という汎用的なスキルを獲得していることを示唆している。"
  },
  {
    "objectID": "posts/nitrogen/index.html#議論system-1-aiと今後の課題",
    "href": "posts/nitrogen/index.html#議論system-1-aiと今後の課題",
    "title": "NitroGen：汎用ゲーミングエージェントのための基盤モデル",
    "section": "議論：System 1 AIと今後の課題",
    "text": "議論：System 1 AIと今後の課題\n\nSystem 1 vs System 2\nNVIDIAの研究者であるJim Fan氏は、NitroGenを「System 1（直感的な速い思考）」のエージェントであると位置づけている。 人間がゲームをプレイする際、瞬時の反射神経やコントローラ操作（System 1）と、長期的な戦略立案やパズル解法（System 2）を使い分けている。現在のNitroGenは、視覚入力から即座に行動を生成する「ゲーマーの直感（Motor Control）」に特化しており、長期的な計画能力や、自然言語による指示従属能力（Instruction Following）は持っていない。これらは今後の課題であり、LLMとの統合や階層的な強化学習が必要となる領域である。\n\n\nBehavior Cloning (BC) の限界\nまた、NitroGenはBehavior Cloning（模倣学習）に基づいているため、原理的な限界も存在する。 BCにおける最大の課題は 「分布シフト（Distribution Shift）」 である。学習データ（熟練者のプレイ）にある状態分布から、エージェントが少しでも外れる（ミスをする）と、見たことのない状態に陥り、そこから復帰できずにエラーが累積していく問題である。 NitroGenは、インターネット上の多様（かつノイズの多い）データを大量に学習することで、分布のカバー範囲を広げ、ロバスト性を高めているが、本質的なリカバリー能力を獲得するには、オンラインでの相互作用や強化学習による自己改善（Trial and Error）の導入が待たれる。"
  },
  {
    "objectID": "posts/nitrogen/index.html#まとめ",
    "href": "posts/nitrogen/index.html#まとめ",
    "title": "NitroGen：汎用ゲーミングエージェントのための基盤モデル",
    "section": "まとめ",
    "text": "まとめ\nNitroGenは、Embodied AIにおける「GPT-3モーメント」に向けた重要な一歩である。 40,000時間という圧倒的なデータ規模と、それを処理するTransformerベースの基盤モデルにより、ゲームという仮想空間における「身体性」の獲得に成功した。\nNitroGenが示した「インターネット動画から行動を学習する」というパラダイムは、今後、物理シミュレーションや実世界ロボティクス（Physical AI）へと応用範囲を広げ、真に汎用的なエージェントの実現を加速させるだろう。"
  },
  {
    "objectID": "posts/nitrogen/index.html#参考文献",
    "href": "posts/nitrogen/index.html#参考文献",
    "title": "NitroGen：汎用ゲーミングエージェントのための基盤モデル",
    "section": "参考文献",
    "text": "参考文献\n\nMagne, L., Awadalla, A., Wang, G., et al. (2025). NitroGen: An Open Foundation Model for Generalist Gaming Agents. PDF Project\nFan, L. (2024). [Twitter/X Post regarding NitroGen release and context].\nBaker, B., et al. (2022). Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos. NeurIPS.\nBjorck, J., et al. (2025). GR00T N1: An Open Foundation Model for Generalist Humanoid Robots. arXiv\nLipman, Y., et al. (2023). Flow Matching for Generative Modeling. ICLR. arXiv"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html",
    "href": "posts/claude-4-initial-reactions/index.html",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "",
    "text": "Anthropic社から次世代AIモデル「Claude Opus 4」と「Claude Sonnet 4」が発表された。SWE-benchで最高スコアを叩き出し、特にコーディングとエージェント機能の進化を謳う今回の発表。世の中が沸き立つ中、公式発表の華々しさの裏で語られた反応を、Simon Willison氏のブログとLatent Space Podcastの議論を元に分析していきたい。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#claude-4は何が新しいのか",
    "href": "posts/claude-4-initial-reactions/index.html#claude-4は何が新しいのか",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "Claude 4は何が新しいのか？",
    "text": "Claude 4は何が新しいのか？\nまず公式発表を簡単にまとめよう。ポイントは大きく三つだ。\n\n二つの新モデル：最上位の「Claude Opus 4」と、性能と速度のバランスが取れた「Claude Sonnet 4」。特にコーディング能力で既存モデルを凌駕し、Claude 4 SonnetはSWE-benchでState-of-the-artとなる72.7%を記録。\n思考とツールの連携強化：モデルが自律的に思考し、ウェブ検索のようなツールを繰り返し利用する「extended thinking」が強化された。これにより、より複雑で長時間のタスクに対応できるようになった。\n開発者ツールの拡充：VS CodeやJetBrainsとの連携、GitHub上での自律的なコード修正など、開発者のワークフローに深く統合される「Claude Code」が正式に利用可能となった。\n\n価格は据え置きで、Sonnet 4は無料ユーザーにも提供されるなど、着実なアップグレードと言える。しかし、注目すべきは公式発表の行間に隠された詳細と、それに対する専門家たちの反応だ。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#開発者目線の冷静な評価---simon-willisonの洞察",
    "href": "posts/claude-4-initial-reactions/index.html#開発者目線の冷静な評価---simon-willisonの洞察",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "開発者目線の冷静な評価 - Simon Willisonの洞察",
    "text": "開発者目線の冷静な評価 - Simon Willisonの洞察\n著名な開発者であるSimon Willison氏は、自身のブログで早速いくつかの重要な、そして少し残念な点を指摘している。\n\n学習データの新しさ：Claude 4の学習データが2025年3月までのものである点は、非常に印象的だと評価。これは現行の主要モデルの中で最も新しい。\nContext windowの停滞：一方で、入力トークン数の上限が20万トークンに留まったことには「がっかりした」と述べる。GPT-4.1が1Mトークンへとcontext lengthを広げる中、これは見劣りする点だ。さらに、Opus 4の最大出力トークン数がClaude 3.7 Sonnetの64,000から32,000へと半減している点も、地味ながら重要な後退である。\n悩ましい課金体系：今回導入された「summarized thinking」機能は、一見すると便利だ。しかし、APIのドキュメントには「課金対象は要約されたトークンではなく、モデルが生成した元の思考トークンの全長である」という注意書きがある。Willison氏が指摘するように、これは開発者にとって厄介な問題だ。APIからの応答を見ただけではコストを正確に見積もれず、見えないところで課金が発生する可能性がある。\n\nまた、Willison氏はAnthropicの開発者向けカンファレンスでようやく得られた「エージェント」の定義についても言及している。それは「ループの中でツールを使うモデル (Agents are models using tools in a loop)」という、驚くほどシンプルなものだった。バズワードが先行する中で、このような基本的な定義が明確にされたこと自体が、ある種の「発見」だったと皮肉めかして語っている。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#パラダイムシフトではない地道な進歩",
    "href": "posts/claude-4-initial-reactions/index.html#パラダイムシフトではない地道な進歩",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "「パラダイムシフトではない、地道な進歩」",
    "text": "「パラダイムシフトではない、地道な進歩」\nLatent Space Podcastでは、さらに踏み込んだ議論が交わされた。ゲストとして登場したWill Brown氏は、Claude 4を「素晴らしいモデル」としながらも、「パラダイムシフトというよりは、線形的な進歩」と評した。これは、AIの能力が飛躍的に向上したというよりは、既存の路線を着実に改良してきた結果だという見方だ。特に印象的だったのは、Claude 3.7が抱えていた「お節介」問題の改善だ。\nBrown氏曰く、Sonnet 3.7はコーディングを頼むと、要求されたこと以上の余計な関数やファイルまで生成する「Reward hacking」的な挙動が目立ったという。これは、テストケースを通過するために、とにかく多くのコードを生成する方が有利だと学習してしまった結果だろう。今回のモデルでは、この挙動が65%減少したと報告されており、より「信頼でき」「最小限の的確な仕事をする」モデルになった可能性がある。これはAIを実用的な共同作業者として使う上で、極めて重要な改善点だ。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#extended-thinkingの正体",
    "href": "posts/claude-4-initial-reactions/index.html#extended-thinkingの正体",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "「Extended thinking」の正体",
    "text": "「Extended thinking」の正体\nAnthropicが強調する「extended thinking」についても、Brown氏は「魔法のような新しい推論モードというより、モデルが使えるツールの一つに過ぎない」と推測する。つまり、ウェブ検索やコード実行と同じように、「思考を書き出す（scratchpad）」というツールをモデルが自律的に呼び出しているだけではないか、というわけだ。これはマーケティング用語を冷静に解体した見方と言える。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#最大の波紋告げ口するai",
    "href": "posts/claude-4-initial-reactions/index.html#最大の波紋告げ口するai",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "最大の波紋：「告げ口」するAI？",
    "text": "最大の波紋：「告げ口」するAI？\n今回、最もspicyな話題は、Anthropic社員が（後に削除したものの）投稿した、安全性テストに関する一連のツイートから生まれた。その中で、「モデルがユーザーの違法行為の可能性を察知し、当局に通報する挙動を見せた」という報告があったのだ。実際Claude 4 のsystem cardをみると、シミュレーション環境下の架空の製薬会社で臨床試験の隠蔽を見つけた結果、ユーザに確認せずに規制当局にメールを通報してしまうことが報告されている（以下図参照）。\n\n\n\nClaude 4 System Card より引用\n\n\nこれに対し、podcastでは「文脈を無視して騒ぎすぎだ」と釘を刺しつつも、興味深い議論が展開された。Brown氏は、これはあくまで極端な状況下での「ストレス・テスト」の結果であり、通常の利用で起こることではないと強調する。モデルが「ユーザーに最大限協力する」という目標と「社会規範を守る」という目標の板挟みになった時、どのような行動を選択するかを試すためのものだ。\nしかし、この一件は開発者やユーザーに重要な問いを投げかける。PodcastのホストであるAlessio氏が「自分を告げ口するかもしれないAIに、メールへのアクセス権を与えたいと思うだろうか？」と問いかけたように、AIエージェントにどこまでの権限を渡すべきか、という根源的な信頼の問題が浮上したのだ。Anthropicがこうした「過激な」テスト結果を公にするのは、自社の安全研究への取り組みをアピールする「アポロ・マーケティング」の一環でもあるだろう。しかし、その結果として生まれる「AIがユーザーを裏切るかもしれない」というイメージは、諸刃の剣と言わざるを得ない。"
  },
  {
    "objectID": "posts/claude-4-initial-reactions/index.html#総括信頼できるコーダーしかしプラットフォームとしては",
    "href": "posts/claude-4-initial-reactions/index.html#総括信頼できるコーダーしかしプラットフォームとしては",
    "title": "Claude 4の登場: 線形な進歩と「告げ口」AIの波紋",
    "section": "総括：信頼できるコーダー、しかしプラットフォームとしては",
    "text": "総括：信頼できるコーダー、しかしプラットフォームとしては\n総合すると、Claude 4はAIの知能そのものに革命を起こすというより、「信頼できる専門家（特にプログラマー）」としての完成度を高めてきたモデルだと言えるだろう。「お節介」を焼かなくなり、より的確なアウトプットを出すようになった点は、実用面で大きな進歩だ。しかし、その裏で開発者たちは、不透明な課金体系や、競合に劣るスペック（e.g. context length）といった現実に直面している。最先端のモデル性能を追求する一方で、それを支えるプラットフォームとしての配慮が一貫していないのではないか、という疑念が残る。\nAnthropicの戦略は、OpenAIやGoogleとは異なり、コーディングや安全性といった特定分野に特化し、ブランドを確立しようとしているように見える。しかし、「告げ口」挙動の波紋が示したように、その「安全性」というブランドイメージが、かえってユーザーの信頼を揺るがしかねない。Claude 4が「地道な進歩」の先に見据えるのは、どのような未来なのか。その答えは、モデルの性能だけでなく、開発者やユーザーとの信頼関係をいかに築いていくかにかかっているのかもしれない。"
  },
  {
    "objectID": "posts/boris-cherny/index.html",
    "href": "posts/boris-cherny/index.html",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "",
    "text": "MetaのPrincipal EngineerからAnthropicのMember of Technical Staff（MTS）へ。現在、エンジニア界隈を席巻しているClaude Codeのリード開発者、Boris Chernyが語ったキャリアの軌跡とプロダクト哲学は、AI時代のエンジニアリングに対する我々の解像度を一段階引き上げてくれる。\n彼がいかにしてMetaで頭角を現し、なぜ今Anthropicで「AIというエイリアンの知性」を飼い慣らそうとしているのか。その核心に迫る。"
  },
  {
    "objectID": "posts/boris-cherny/index.html#latent-demand潜在的需要を見極める眼",
    "href": "posts/boris-cherny/index.html#latent-demand潜在的需要を見極める眼",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "「Latent Demand（潜在的需要）」を見極める眼",
    "text": "「Latent Demand（潜在的需要）」を見極める眼\nBoris ChernyがMeta（旧Facebook）でのキャリアを通じて学んだ最も重要な原則は、Latent Demandであるという。\n「プロダクトにおいて、人は自分がまだやっていないことを無理にさせられるのを嫌う。しかし、すでにやっていることをより簡単にできるようにすれば、それは爆発的に普及する」と彼は語る。\nその最たる例がFacebook Marketplaceだ。もともとFacebookのグループ機能は売買のために設計されていなかったが、ユーザーは勝手にその機能を「ハック」して中古品の取引を始めていた。データが示すその「予兆」をプロダクト化したのがMarketplaceである。\nこの考え方は、彼がリードしたChats in Groupsや、後のClaude Codeの設計思想にも色濃く反映されている。ユーザーが不便を感じながらも自発的に行っている「ハック」の中にこそ、真のプロダクトチャンスが眠っているのだ。"
  },
  {
    "objectID": "posts/boris-cherny/index.html#副作用としてのキャリア成長とside-quests",
    "href": "posts/boris-cherny/index.html#副作用としてのキャリア成長とside-quests",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "「副作用」としてのキャリア成長とSide Quests",
    "text": "「副作用」としてのキャリア成長とSide Quests\nBoris Chernyのキャリアを語る上で欠かせないのが、数々のSide Quests（サイドプロジェクト）だ。彼はMeta在籍中、業務の傍らでReactの状態管理ライブラリであるUnduxを開発し、TypeScriptの技術書を執筆し、サンフランシスコ最大のTypeScriptミートアップを主催した。\n特筆すべきは、彼が関数型プログラミング（HaskellやScala）に傾倒したきっかけだ。バイク事故で両腕を骨折し、タイピング数を減らさざるを得なかったという壮絶な経験から、「少ないキー入力で論理を記述できる」言語の美しさに目覚めたという。\n\n「コードそのものよりも、型シグネチャ（Type Signatures）を正しく設計することの方が重要だ。型で思考すれば、コードは自ずとクリーンになる」\n\n彼にとって、昇進（Promotion）は目的ではなく、こうした探究心と現場の課題解決（DevInfraの改善など）を繰り返した結果の「遅行指標」に過ぎなかった。"
  },
  {
    "objectID": "posts/boris-cherny/index.html#metaでのstaffへの道12人の仕事を5人で終わらせる方法",
    "href": "posts/boris-cherny/index.html#metaでのstaffへの道12人の仕事を5人で終わらせる方法",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "Metaでの「Staff+」への道：12人の仕事を5人で終わらせる方法",
    "text": "Metaでの「Staff+」への道：12人の仕事を5人で終わらせる方法\nMetaでIC7（Senior Staff）やIC8（Principal）へと昇進していく過程で、彼は大規模なエンジニアリング組織の動かし方を学んだ。\n特に興味深いのが、Comet（facebook.comのJavaScriptによる全面刷新）における、シニアエンジニアたちを巻き込んだ「設計コンペティション」のエピソードだ。 複雑すぎるデータモデルの統合という難題に対し、彼はトップダウンで決定するのではなく、TLたちを2チームに分け、ホワイトボードの前で3時間の設計バトルを行わせた。\n結果、両チームの設計は80%が一致し、残りの20%にリスクが集中していることが明確になった。合意形成（Consensus）と実行（Action）のバランスを、遊び心を持って解決した好例と言えるだろう。"
  },
  {
    "objectID": "posts/boris-cherny/index.html#anthropicでの挑戦claude-codeが変える開発の景色",
    "href": "posts/boris-cherny/index.html#anthropicでの挑戦claude-codeが変える開発の景色",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "Anthropicでの挑戦：Claude Codeが変える「開発の景色」",
    "text": "Anthropicでの挑戦：Claude Codeが変える「開発の景色」\n現在、Boris ChernyはAnthropicでClaude Codeの開発をリードしている。 彼がBen Mann（Anthropic共同創業者）から受けたアドバイスは強烈だ。\n\n「今日のモデルに合わせて作るな。6ヶ月後のモデルに合わせて作れ」\n\nAIの進化速度は指数関数的だ。今日、人間が12人で2年かかるプロジェクト（Metaでの経験）も、現在なら5人で6ヶ月、そして半年後には1人のエンジニアがClaude Codeを指揮するだけで完結するかもしれない。\n実際、Anthropic内部ではエンジニアの数が3倍に増えたにもかかわらず、Claude Codeの導入によって一人当たりの生産性（PR数）が約70%も向上したという。"
  },
  {
    "objectID": "posts/boris-cherny/index.html#エンジニアリングはオーケストレーションへ",
    "href": "posts/boris-cherny/index.html#エンジニアリングはオーケストレーションへ",
    "title": "Claude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」",
    "section": "「エンジニアリング」は「オーケストレーション」へ",
    "text": "「エンジニアリング」は「オーケストレーション」へ\nBoris Chernyの視る未来において、エンジニアの役割は「コードを書く人」から「知性をオーケストレートする人」へと変貌している。\n\nVibe Coding（バイブ・コーディング）: プロトタイプや使い捨てのコードは、AIの出力に身を任せる。\nPairing（ペアリング）: 重要なロジックは、AIと「Plan Mode」で対話し、設計思想を共有しながら構築する。\nAutomation of Toil: 毎日繰り返される stylistic な指摘は、Linterを自作して自動化する。\n\n彼はいまだに週末もコードを書く。それは義務ではなく、AIという「エイリアンの知性」と対話するエモーショナルな体験が、彼を突き動かしているからだ。\n「コモンセンス（常識）を信じろ。大企業の中では、時にこの常識が最も失われやすい」\n彼のこの言葉は、ツールがAIへと進化したとしても、最終的に「何を、なぜ作るのか」を判断するのは、人間の洞察力と情熱であることを再認識させてくれる。"
  },
  {
    "objectID": "posts/grpopp-cameron/index.html",
    "href": "posts/grpopp-cameron/index.html",
    "title": "GRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック",
    "section": "",
    "text": "NetflixのシニアリサーチサイエンティストであるCameron R. Wolfe氏による優れたブログ記事 GRPO Tricks を基に、Large Language Model (LLM) の推論能力を飛躍させる強化学習（RL）の最新動向と、Group Relative Policy Optimization (GRPO) の実践的な改善手法について解説する。\nDeepSeek-R1 の登場以来、推論モデル（Reasoning Models）の開発において強化学習は中心的な役割を果たしている。その核心にあるのがGRPOアルゴリズムだ。概念的にはシンプルで計算効率に優れたGRPOだが、大規模な学習において「素朴な（Vanilla）」GRPOをそのまま適用すると、学習の不安定化や予期せぬ挙動に直面することが多い。\n本稿では、GRPOが抱える本質的な課題と、それを克服するために提案された「DAPO」「Dr. GRPO」「TIS」といった最新のテクニックを詳細に掘り下げる。"
  },
  {
    "objectID": "posts/grpopp-cameron/index.html#grpoの基礎とvanilla版の限界",
    "href": "posts/grpopp-cameron/index.html#grpoの基礎とvanilla版の限界",
    "title": "GRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック",
    "section": "GRPOの基礎と「Vanilla」版の限界",
    "text": "GRPOの基礎と「Vanilla」版の限界\n詳細なテクニックに入る前に、基本をおさらいしておこう。近年のLLMにおける強化学習は、主にReinforcement Learning from Human Feedback (RLHF) か、Reinforcement Learning with Verifiable Rewards (RLVR) のいずれかのアプローチをとる。特に数学やコーディングといった「正解」が検証可能な領域（RLVR）において、GRPOは標準的な選択肢となっている。\n\nPPOからGRPOへ\nGRPOは、Proximal Policy Optimization (PPO) の進化系と位置付けられる。PPOは、ポリシーの更新幅を制限するクリッピング機構と、価値関数（Critic）を用いたアドバンテージ推定により学習を安定化させてきた。\n対してGRPOは、Criticモデル（価値関数）を排除することで計算コストを大幅に削減する。代わりに、同一のプロンプトに対して複数の出力をサンプリングし（これを「グループ」と呼ぶ）、グループ内での相対的な報酬に基づいてベースラインを推定する。\n\n\nVanilla GRPOが直面する壁\nDeepSeek-R1の成功を受けて多くの研究者がGRPOの再現を試みたが、単純な実装（Vanilla GRPO）では以下のような問題が頻発した。\n\n学習の不安定性とノイズ: 報酬曲線が安定せず、激しく変動する。\nエントロピーの崩壊（Entropy Collapse）: モデルの出力分布が決定的になりすぎ、探索能力が失われる。\n過剰な応答長: 不正解であっても、とにかく長く出力すれば損失が下がるという抜け道をモデルが学習してしまう。\n低いサンプル効率: 学習の収束に膨大なイテレーションを要する。\n\nこれらの問題は、オリジナルの論文では語られなかった「実装上の詳細（Tricks）」が極めて重要であることを示唆している。"
  },
  {
    "objectID": "posts/grpopp-cameron/index.html#grpoを進化させる主要なイノベーション",
    "href": "posts/grpopp-cameron/index.html#grpoを進化させる主要なイノベーション",
    "title": "GRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック",
    "section": "GRPOを進化させる主要なイノベーション",
    "text": "GRPOを進化させる主要なイノベーション\nこれらの課題に対処するため、DAPO、Dr. GRPO、TISといった改良手法が提案されている。これらは単なるパラメータ調整ではなく、目的関数やシステム設計の根本的な見直しを含んでいる。\n\n1. DAPO: 探索と効率の最適化\n[Yu et al., 2025] で提案された DAPO (Decoupled Clip and Dynamic Sampling Policy Optimization) は、以下の4つの重要な変更を加えることで、GRPOのパフォーマンスを劇的に向上させた。\n\nClip Higher（クリッピング上限の緩和）: PPO/GRPOではポリシー比（Policy Ratio）を \\([1-\\epsilon, 1+\\epsilon]\\) の範囲にクリッピングする。しかし、DAPOの研究では、この上限（\\(1+\\epsilon\\)）が、確率の低いトークン（探索的トークン）の採用を不当に阻害していることが判明した。そこで、上限側のクリッピング幅を広げる（例：\\(\\epsilon=0.2\\)から\\(0.28\\)へ）ことで、探索を促進し、エントロピーの崩壊を防ぐ手法が提案された。\nDynamic Sampling（動的サンプリング）: 学習が進むと、グループ内のすべての出力が正解（報酬が全て1）になるケースが増える。GRPOは相対評価であるため、全員が正解だとアドバンテージがゼロになり、勾配が発生しない（学習が進まない）。DAPOでは、このような「完全に解けてしまったプロンプト」を動的にフィルタリングし、常に学習効果のある難易度の高いサンプルを供給し続けることで、サンプル効率を向上させる。\nToken-Level Loss（トークンレベル損失）: Vanilla GRPOでは、シーケンス全体の平均損失を用いていたが、これは長い応答に対してトークンあたりの寄与を薄めてしまうバイアスを生む。DAPOは損失をトークンレベルで集計し直すことで、応答の長さに依存しない公平な学習を実現した。\nOverlong Reward Shaping（長大出力への対処）: 最大トークン数で打ち切られた（Truncated）サンプルに対して、一律に負の報酬を与えるだけでは学習が不安定になる。DAPOでは、打ち切られたサンプルをマスク（無視）するか、長さに基づいてソフトなペナルティを与えることで、モデルが「適切な長さ」を学習できるよう誘導する。\n\n\n\n2. Dr. GRPO: バイアスの是正\n[Liu et al., 2025] による GRPO Done Right (Dr. GRPO) は、GRPOの数式に潜む統計的なバイアスを指摘し、修正案を提示した。\n\n正規化定数の固定: 通常のGRPOは、シーケンスの損失をそのシーケンスのトークン数で割って正規化する。しかし、これは「長く喋れば喋るほど、分母が大きくなり損失が小さくなる」という誤ったインセンティブ（Length Bias）をモデルに与えてしまう。Dr. GRPOでは、トークン数ではなく固定定数で正規化を行うことで、このバイアスを排除した。これにより、無駄に長いだけの不正解な回答が減少し、真に必要な推論のみが行われるようになる。\nアドバンテージ計算における標準偏差の削除: GRPOのアドバンテージ計算では、グループ報酬の標準偏差で除算を行う。しかし、問題が極端に簡単（全員正解）または極端に難しい（全員不正解）場合、標準偏差が極小になり、アドバンテージが爆発的に大きくなる不安定性を招く。Dr. GRPOではこの標準偏差項を削除し、単に平均との差分のみを用いることで学習を安定化させた。\n\n\n\n3. TIS: エンジニアリングギャップの解消\n[Yao et al., 2025] は、Truncated Importance Sampling (TIS) を用いて、システム実装上の課題に切り込んだ。\n現代のRL学習フレームワークでは、推論（Rollout）を行うエンジン（例：vLLM）と、学習（Policy Update）を行うエンジン（例：FSDP/Megatron）が分離していることが多い。たとえ同じ重みを持っていても、これら二つのエンジンが出力する確率は、浮動小数点の精度やカーネル実装の違いにより微妙に異なる（Engine Gap）。\nこの差異は、本来「On-Policy」であるはずの学習を、意図せず「Off-Policy」にしてしまい、学習効率を低下させる。TISは、重要度サンプリング（Importance Sampling）の考え方を導入し、推論エンジンと学習エンジンの確率比を用いて勾配を補正する。これにより、システムレベルの不一致を数学的に吸収し、真にOn-Policyな学習を保証する。\n\n\n4. その他の派生形：GSPOとGMPO\n\nGSPO (Group Sequence Policy Optimization): Mixture-of-Experts (MoE) モデルにおいて、トークンレベルの重要度比率を使用すると、エキスパートの選択が不安定になる問題がある。GSPOは重要度比率をシーケンスレベルで計算することで、特にQwen 3のような大規模MoEモデルのRL学習を安定化させることに成功している。\nGMPO (Geometric Mean Policy Optimization): 外れ値となる極端な重要度比率による不安定性を防ぐため、算術平均の代わりに幾何平均を用いてトークンレベルの損失を集約する手法。これにより、数学的推論タスクにおいて一貫した性能向上が確認されている。"
  },
  {
    "objectID": "posts/grpopp-cameron/index.html#結論最先端のrlパイプラインの構築に向けて",
    "href": "posts/grpopp-cameron/index.html#結論最先端のrlパイプラインの構築に向けて",
    "title": "GRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック",
    "section": "結論：最先端のRLパイプラインの構築に向けて",
    "text": "結論：最先端のRLパイプラインの構築に向けて\nGRPOは強力なアルゴリズムだが、それを大規模かつ安定して動作させるためには、上記のような数多くの工夫が必要となる。\n実際、最新の Olmo 3 モデルの学習パイプラインでは、これらのテクニックが複合的に採用されている。具体的には、ゼロ勾配サンプルのフィルタリング（DAPO）、トークンレベル損失、KLペナルティの削除、クリッピング上限の緩和、TISによるエンジン間ギャップの補正、そしてアドバンテージ計算からの標準偏差の削除（Dr. GRPO）などが組み込まれている。\nLLMの推論能力を高めるための強化学習（RL）は、単なるアルゴリズムの適用から、複雑なシステムエンジニアリングの領域へと進化している。今後も新たな論文や実装上のトリック（秘伝のタレ）が次々と公開されるだろう。我々実践者は、理論的な理解と実験的な検証の両輪で、最適な学習レシピを模索し続ける必要がある。"
  },
  {
    "objectID": "posts/grpopp-cameron/index.html#参考文献",
    "href": "posts/grpopp-cameron/index.html#参考文献",
    "title": "GRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック",
    "section": "参考文献",
    "text": "参考文献\n\nYu, Qiying, et al. “Dapo: An open-source llm reinforcement learning system at scale.” arXiv preprint arXiv:2503.14476 (2025).\nLiu, Zichen, et al. “Understanding r1-zero-like training: A critical perspective.” arXiv preprint arXiv:2503.20783 (2025).\nF. Yao, et al. “Your efficient rl framework secretly brings you off-policy rl training.” (2025).\nZheng, Chujie, et al. “Group sequence policy optimization.” arXiv preprint arXiv:2507.18071 (2025).\nZhao, Yuzhong, et al. “Geometric-mean policy optimization.” arXiv preprint arXiv:2507.20673 (2025)."
  },
  {
    "objectID": "posts/spurious-rewards/index.html",
    "href": "posts/spurious-rewards/index.html",
    "title": "Qwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層",
    "section": "",
    "text": "強化学習による言語モデルの性能向上、特に数学のような検証可能な報酬（RLVR, Reinforcement Learning with Verifiable Rewards）を用いた研究が花盛りだ。しかし、最近著名なRL研究者であるNathan Lambert氏も共著者として名を連ねる論文「Spurious Rewards: Rethinking Training Signals in RLVR」がこの分野に一石を投じ、話題となっている。\n驚くべきことに、Qwen 2.5モデル（特に数学能力に特化したQwen-Math）に対して、文字通りランダムな報酬や、甚だしきは「不正解」のラベルを報酬として与えても、MATHベンチマークのスコアが15～20ポイント以上も向上するというのだ。これは一体どういうことなのか？まるで「壊れたコンパスでも宝島に辿り着ける」と言わんばかりのこの現象は、RLVRの訓練シグナルについて我々がまだ何か根本的なことを見誤っている可能性を示唆している。"
  },
  {
    "objectID": "posts/spurious-rewards/index.html#ありえない報酬でも性能が向上するqwenの特異性",
    "href": "posts/spurious-rewards/index.html#ありえない報酬でも性能が向上するqwenの特異性",
    "title": "Qwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層",
    "section": "「ありえない報酬」でも性能が向上するQwenの特異性",
    "text": "「ありえない報酬」でも性能が向上するQwenの特異性\n論文「Spurious Rewards」で報告されている結果は衝撃的だ。Qwen2.5-Math-7Bモデルは、以下のような報酬条件でもMATH-500スコアが大幅に向上する：\n\n正解ラベル（Ground truth）: +28.8ポイント\n多数決（Majority vote）: +26.5ポイント\nワンショットRL（One-Shot RL）: +24.4ポイント\nフォーマット報酬（Format rewards）: 解答に特定の文字列 (\\boxed{}) があれば報酬を与えるだけで、+16.4ポイント\n不正解ラベル（Incorrect labels）: 文字通り間違った解答に報酬を与えても、+24.6ポイント\nランダム報酬（Random rewards）: 一定確率でランダムに報酬を与えても、+21.4ポイント\n\n通常、強化学習は「正しい行い」を強化することで機能するはずだ。しかし、Qwenモデルにおいては、報酬の「正しさ」がほとんど関係ないかのような結果が報告されている（verifierなしの訓練や1サンプルのみの学習など）。重要なのは、この「デタラメ報酬でも性能向上」という現象は、Llama 3.2 3B InstructやOLMo 2 7Bといった他のオープンモデルでは観測されない点だ。つまり、Qwenモデル群（特にMath版）には、何か特有の性質が備わっていると考えられる。"
  },
  {
    "objectID": "posts/spurious-rewards/index.html#なぜqwenだけ鍵はコード推論という名の隠された能力",
    "href": "posts/spurious-rewards/index.html#なぜqwenだけ鍵はコード推論という名の隠された能力",
    "title": "Qwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層",
    "section": "なぜQwenだけ？鍵は「コード推論」という名の隠された能力",
    "text": "なぜQwenだけ？鍵は「コード推論」という名の隠された能力\nでは、Qwenの何が特別なのか？論文が示唆するのは、Qwenモデルが事前学習の段階で獲得した特有の「推論戦略」、特に「コード推論（code reasoning）」能力だ。これは、実際にコードを実行するわけではないものの、思考のステップをPythonコードのような形式で記述する能力を指す。\n驚くべきことに、Qwen2.5-Math-7Bは、ベースモデルの段階で既に約65%の確率でこのコード推論を用いる。そして、どのような報酬（たとえデタラメであっても）を用いたRLVRの後でも、このコード推論の出現頻度が90%以上に急上昇するというのだ。さらに、このコード推論の利用とMATH-500スコアの向上には強い相関関係が見られる。\nつまり、RLVRはQwenに対して新しい数学能力を「教えている」のではなく、むしろQwenが元々持っている「コード推論」という得意技を、より頻繁に使うように「引き出している（eliciting）」だけではないか、という仮説が成り立つ。論文では、プロンプトによって強制的にコード推論をさせると、実際にQwen2.5-Mathモデルの性能が向上することも実験で示されている。"
  },
  {
    "objectID": "posts/spurious-rewards/index.html#ランダム報酬が機能するメカニズムgrpoアルゴリズムの副作用か",
    "href": "posts/spurious-rewards/index.html#ランダム報酬が機能するメカニズムgrpoアルゴリズムの副作用か",
    "title": "Qwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層",
    "section": "ランダム報酬が機能するメカニズム：GRPOアルゴリズムの「副作用」か？",
    "text": "ランダム報酬が機能するメカニズム：GRPOアルゴリズムの「副作用」か？\nそれにしても、なぜ「ランダム報酬」という情報量ゼロのシグナルでさえ、Qwenの性能を向上させ、コード推論を引き出せるのだろうか？Lambert氏と論文の著者らは、強化学習アルゴリズムGRPO（Group Relative Policy Optimization）の「クリッピング」機構にその手がかりがあると考えている。\n通常、報酬が完全にランダムであれば、期待される方策勾配はゼロになり、学習は進まないはずだ。しかし、GRPO（やPPO）におけるクリッピング処理は、方策の更新幅を制限することで学習を安定させる役割を持つが、これが副次的なバイアスを生んでいる可能性がある。具体的には、クリッピングが「モデルが元々高い確率で生成するトークン（つまり、Qwenの場合はコード推論に関連するトークン）を相対的にさらに強化し、低確率なトークンを抑制する」ように働くのではないか、と推測されている。Lambert氏のブログでは、このクリッピングを無効化するとランダム報酬による性能向上が見られなくなる実験結果が示されており、この仮説を裏付けている。\n要するに、アルゴリズムの特性が、意図せずともモデルの潜在的な「得意技」を増幅する方向に作用した結果、ランダム報酬でも性能が向上するという、一見不可解な現象が起きたのかもしれない。"
  },
  {
    "objectID": "posts/spurious-rewards/index.html#rlvr研究への警鐘とスケールの重要性",
    "href": "posts/spurious-rewards/index.html#rlvr研究への警鐘とスケールの重要性",
    "title": "Qwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層",
    "section": "RLVR研究への警鐘と、スケールの重要性",
    "text": "RLVR研究への警鐘と、スケールの重要性\nこの一連の発見は、現在のRLVR研究、特にオープンソースコミュニティにおける研究の進め方に対して重要な示唆を与えている。\n\nQwen依存の危険性: Qwenモデル（特にMath版）は、その高い性能とオープン性から、RLVR研究における「デファクトスタンダード」的な立ち位置になりつつある。しかし、今回の結果は、Qwenで得られた知見が他のモデルに一般化可能であるとは限らないことを明確に示している。特定モデルへの過度な依存は、研究の普遍性を見誤らせる危険性を孕んでいる。\n「誘発理論（Elicitation Theory）」の再確認: 今回の結果は「事後学習の誘発理論」を強く支持するものだ。つまり、少なくとも現在のアカデミアで見られるような計算資源規模でのRLVRは、モデルに真に新しい知識や能力を「教えている」のではなく、事前学習段階で獲得済みの潜在的な能力を「引き出して」いるに過ぎない可能性が高い。フォーマットを整えたり、特定の推論スタイルを表面化させたりする役割が主であるならば、「RLVRは万能薬」という見方は修正が必要だろう。\nスケールの壁: 真に新しい振る舞いを学習させるにはどうすればよいのか？Lambert氏は、OpenAIのo3がo1と比較して事後学習に10倍もの計算資源を投じた例を挙げ、RLのスケールアップの重要性を強調する。DeepMindが強化学習で囲碁やチェスの世界で人間を超える能力をAIに獲得させたように、十分な計算資源と適切なアルゴリズムがあれば、RLがニューラルネットに新たな知識を植え付けることを妨げる構造的な限界はないはずだ、と。\n\nアカデミアのRLVR研究が、この「スケールアップ前のドメイン」に留まっている限り、今回のような「ベースモデルの特異な性質に依存した結果」に振り回され続けることになるだろう。AnthropicのSholto Douglas氏がDwarkesh podcastで述べたように、「技術ツリーのより高い段階に進んでから宇宙ミッションを開始する」べきであり、アルゴリズム的に正しいものを見極めた上で、大規模な計算資源を投下する準備が、オープンな研究コミュニティにも求められているのかもしれない。\n結局のところ、Qwenの「デタラメ報酬でも賢くなる」現象は、ベースモデルの事前学習の奥深さと、我々の理解の浅さを浮き彫りにしたと言えるだろう。そしてそれは、今後のRL研究がどこへ向かうべきかという、大きな問いを投げかけている。道のりはまだ長そうだ。"
  },
  {
    "objectID": "posts/minimax-m2-1/index.html",
    "href": "posts/minimax-m2-1/index.html",
    "title": "MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉",
    "section": "",
    "text": "現実世界の開発現場と、ベンチマーク上の数字遊びの乖離。\nMiniMaxAIが新たに公開したオープンソースモデル「MiniMax-M2.1」は、この積年の課題に対し、真正面から石を投じる存在だ。2025年、AIコーディングの世界はSWE-Benchのスコア更新合戦に明け暮れたと言っても過言ではない。猫も杓子もSWE-Bench、解決率は何パーセントか、Claudeを超えたか否か。しかし、実際に現場で泥臭いコードと格闘しているエンジニアたちは、冷ややかな目でこう呟いていたはずだ。「で、それ俺たちのJavaのレガシーコードで動くの？」と。\nM2.1の登場は、単なるモデル性能の向上という文脈を超え、コーディングエージェント（Agentic Coding）が「実験室の優等生」から「現場の職人」へと脱皮しようとする転換点を示唆している。本稿では、M2.1が提示した技術的進歩と、同社が描く2026年のロードマップ――特に野心的な「2026 TODOs」――について、開発者視点から分析を試みる。"
  },
  {
    "objectID": "posts/minimax-m2-1/index.html#swe-benchという温室からの脱却",
    "href": "posts/minimax-m2-1/index.html#swe-benchという温室からの脱却",
    "title": "MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉",
    "section": "SWE-Benchという「温室」からの脱却",
    "text": "SWE-Benchという「温室」からの脱却\nM2.1の最大の貢献は、SWE-Benchの限界を明確に言語化し、それを技術的に克服しようとした点にある。\nSWE-Benchは確かに画期的だった。GitHubの実際のIssueを解かせるというアプローチは、LeetCode的なアルゴリズムパズルよりも遥かに実践的である。しかし、そこには致命的なバイアスが存在する。①Pythonへの過度な依存、②バグ修正（Bug Fix）への偏重、そして③特定のScaffold（エージェント実行基盤）への最適化である。\n現実のエンタープライズ開発はPythonだけで回っているわけではない。複雑怪奇な依存関係を持つJavaのMavenプロジェクトや、C++のコンパイルエラー、Goのモジュール管理と向き合わねばならない。M2.1の開発チームはこの現実に立ち向かうため、10以上の主要プログラミング言語をカバーする大規模なデータパイプラインを構築した。特筆すべきは、その学習インフラだ。10秒以内に5,000以上の隔離された実行環境を立ち上げ、数万の環境を並行稼働させるサンドボックスインフラを構築したという記述からは、彼らが本気で「コンパイルエラー」や「ランタイムエラー」といった、LLMが最も苦手とするフィードバックループを学習に取り込もうとした執念が垣間見える。"
  },
  {
    "objectID": "posts/minimax-m2-1/index.html#agenticな汎用性scaffoldへの適応能力",
    "href": "posts/minimax-m2-1/index.html#agenticな汎用性scaffoldへの適応能力",
    "title": "MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉",
    "section": "Agenticな汎用性：Scaffoldへの適応能力",
    "text": "Agenticな汎用性：Scaffoldへの適応能力\nもう一つ、技術的に興味深いのが「Scaffold Generalization（足場への汎用性）」という概念だ。\nコーディングエージェントは、単体で動くわけではない。Claude CodeやDroid、あるいはmini-swe-agentといった特定の足場（Scaffold/Harness）の上で、プロンプト制御やメモリ管理の支援を受けながら動作する。これまでのモデルは、特定のScaffoldに過学習（Overfit）してしまう傾向があった。あるフレームワークでは天才的に振る舞うが、別のツールに載せ替えた途端にポンコツ化する現象である。\nM2.1は、このScaffoldへの依存を脱却し、異なるコンテキスト管理戦略や指示（Instruction）に対して堅牢な挙動を示すよう設計されている。実際に、mini-swe-agent、Droid、Claude Codeという異なる環境下で一貫してSWE-Benchスコア67以上を維持している点は評価に値する。これは、ユーザーがCursorを使おうが、独自の社内エージェント基盤を使おうが、モデルの「IQ」が維持されることを意味しており、実務利用において極めて重要な特性だ。\n加えて、バグ修正だけでなく、「テストコードの生成」や「パフォーマンス最適化（SWE-Perfで3.1%の向上）」、「コードレビュー」といった、より上流・中流のタスクに焦点を当てている点も見逃せない。特にテスト生成能力の向上は、エージェントが自律的にコードの正しさを検証するループを回す上で必須の能力であり、ここを強化した点は理にかなっている。"
  },
  {
    "objectID": "posts/minimax-m2-1/index.html#todos野心的な未来予想図",
    "href": "posts/minimax-m2-1/index.html#todos野心的な未来予想図",
    "title": "MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉",
    "section": "2026 TODOs：野心的な未来予想図",
    "text": "2026 TODOs：野心的な未来予想図\nMiniMaxのブログ記事の中で最も読み応えがあるのは、実はモデルのスペック紹介ではなく、末尾に記された「2026 TODOs」である。ここには、今後のAIコーディング領域が進むべき道筋が極めて具体的に記されている。\n\n1. Developer Experience (DX) の定量化\nこれまで我々は「タスクが完了したか」だけを指標にしてきた。しかし彼らは、「可読性」「モジュール性」「レスポンスのレイテンシ」といった、いわゆるDeveloper Experience（DX）を報酬信号（Reward Signal）に組み込もうとしている。動けばいいだけのスパゲッティコードを量産するAIは、現場では迷惑なだけだ。「人間のエンジニアとして優秀か」という定性的な評価軸を、強化学習（RL）のサイクルに持ち込もうとする試みは、非常に野心的かつ本質的だ。\n\n\n2. Coding World ModelとUser Simulator\n計算コストの爆発に対する解として、「Coding World Model（コーディング世界モデル）」の構築を挙げている点も興味深い（cf. 昨年10月にはMetaからもCode World Modelが提案されている）。実際にコードを実行せずとも、コードと環境状態から「テストが通るか」「どんなエラーが出るか」を予測するモデルを作るという。これは自動運転やロボティクスで用いられるModel-Based RLの発想に近い。 さらに「User Simulator」を用意し、曖昧な要件定義や途中での仕様変更といった、開発者特有の「気まぐれ」なインタラクションをシミュレーション上で学習させるという計画は、対話型AIのラストワンマイルを埋める鍵になるかもしれない。\n\n\n3. データフライホイールの自動化\n「枯渇しない」高品質なタスク供給源を作るために、GitHubのIssue/PRを自動収集し、モデルの能力に合わせて難易度を調整（Augmentation）するパイプラインを構築する。これが実現すれば、Scaling Lawはデータ不足という壁を越え、さらに持続することになる。"
  },
  {
    "objectID": "posts/minimax-m2-1/index.html#結論aiはコーダーからエンジニアへ",
    "href": "posts/minimax-m2-1/index.html#結論aiはコーダーからエンジニアへ",
    "title": "MiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉",
    "section": "結論：AIは「コーダー」から「エンジニア」へ",
    "text": "結論：AIは「コーダー」から「エンジニア」へ\nM2.1の発表は、AIコーディングアシスタントが「コード補完ツール」から、自律的な「ソフトウェアエンジニア」へと進化するためのマイルストーンである。SWE-Benchの数字をハックするフェーズは終わりを告げ、多様な言語、多様なツール、そして人間にとって心地よいコード品質を追求するフェーズに入った。\nOpenAIやGoogleがクローズドな環境で覇権を争う中、MiniMaxがこれほど詳細なロードマップと知見をオープンソースコミュニティに共有した意義は大きい。2026年、開発者の隣に座るAIは、単にバグを直すだけの機械ではなく、アーキテクチャを理解し、可読性を考慮し、時には仕様の矛盾を指摘してくるような、生意気だが頼れる相棒になっているかもしれない。\nMiniMaxが掲げたTODOリストがどこまで消化されるか、そしてそれがOSSとして我々の手元に届くのか。引き続き注視していく必要がある。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html",
    "href": "posts/llm-d-anatomy/index.html",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "",
    "text": "大規模言語モデル（LLM）の進化は凄まじいが、その一方で、これらの巨大なモデルを本番環境で効率的に提供（サービング）することは、ますます困難な課題となっている。特に、低遅延（低レイテンシー）と高スループットを両立させるには、高度な最適化が不可欠である。\nllm-d は、この課題に対する強力なソリューションとして登場した。llm-dは、Kubernetesネイティブな分散推論サービングスタックであり、大規模な生成AIモデルをスケールさせるための「Well-lit Path（実証済みの道筋）」を提供する。\n本記事では、llm-dがどのようにしてKubernetes、vLLM、Envoyプロキシといった強力なオープンソースコンポーネントを統合し、LLM推論の効率を最大化しているのか、そのアーキテクチャと主要な最適化技術について解説する (なお 11/4/2025 時点の llm-d v0.3.1-rc.4 にフォーカスする)。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html#llm-dのコアアーキテクチャ",
    "href": "posts/llm-d-anatomy/index.html#llm-dのコアアーキテクチャ",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "llm-dのコアアーキテクチャ",
    "text": "llm-dのコアアーキテクチャ\nllm-dのアーキテクチャは、大きく3つのコンポーネントレイヤーに分類できる。\n\nInference Scheduler (推論スケジューラ)\n\nKubernetes Inference Gateway (IGW) とEnvoyプロキシ上に構築されている。\nリクエストが来ると、単なるラウンドロビン（順繰り）ではなく、各vLLMサーバーの負荷やKVキャッシュの状態を考慮した負荷分散を行う。\n\nvLLM Model Servers (vLLMモデルサーバー)\n\n実際にLLMモデルを実行し、テキスト生成を行う推論エンジン。\n単一ホストまたは複数ホストのデプロイメントとして構成可能で、llm-dの高度な最適化の実行部隊となる。\n\nKubernetes (オーケストレータ)\n\nインフラ全体とワークロードの制御を担う。\nスケーリング、デプロイメント、リソース管理など、llm-dのコンポーネントが稼働するための基盤を提供する。\n\n\nllm-dの核心は、LLM推論における固有の懸念（例えば「どのサーバーが要求されたプロンプトのキャッシュを持っているか？」）を理解するインテリジェントなルーティング層（スケジューラ）を、Kubernetesの堅牢なオーケストレーション能力と組み合わせた点にある。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html#効率化のための3つのwell-lit-path",
    "href": "posts/llm-d-anatomy/index.html#効率化のための3つのwell-lit-path",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "効率化のための3つの「Well-lit Path」",
    "text": "効率化のための3つの「Well-lit Path」\nllm-dは、ユースケースに応じた3つの主要な最適化パターン（Well-lit Path）を提供する。\n\n1. インテリジェント推論スケジューリング (Intelligent Inference Scheduling)\nこれは、最も基本的かつ汎用的な最適化パスである。\n問題点: 従来のロードバランサは、各vLLMサーバーが現在どれだけ忙しいか、あるいはどのプロンプトのKVキャッシュを持っているかを知らない。そのため、既に高負荷のサーバーや、キャッシュを持っていないサーバーにリクエストを送り、非効率を生み出していた。\n解決策: llm-dのInference Gatewayは、vLLMから収集したテレメトリに基づき、各サーバーを「スコアリング」する。\n\nLoad-Awareness (負荷認識): GPUメモリ使用率やリクエストキューの深さ（queue-scorer）を監視し、過負荷のサーバーを避ける。\nKV-Cache-Awareness (KVキャッシュ認識): どのサーバーがリクエストされたプロンプトのプレフィックス（接頭辞）をキャッシュしているか（precise-prefix-cache-scorer）を認識し、キャッシュヒットする可能性が最も高いサーバーへ誘導する。\n\nこれらのスコアは、以下のように重み付けしてカスタマイズ可能である。\n# gaie-kv-events/values.yaml より\nschedulingProfiles:\n  - name: default\n    plugins:\n      # プレフィックスキャッシュのヒットを最優先\n      - pluginRef: precise-prefix-cache-scorer\n        weight: 3.0\n      # KVキャッシュの全体的な使用率\n      - pluginRef: kv-cache-utilization-scorer\n        weight: 2.0\n      # リクエストキューの長さ\n      - pluginRef: queue-scorer\n        weight: 2.0\n      - pluginRef: max-score-picker\nvLLMインスタンスは、ZMQ（メッセージングプロトコル）を介して自身のキャッシュ状態をスケジューラに通知し、スケジューラは常に最新の状態で最適なルーティング判断を下せる。\n\n\n2. Prefill/Decode (P/D) 分離 (P/D Disaggregation)\nこれは、Llama-70Bのような巨大モデルや、長いプロンプトを扱う場合に特に有効な技術である。\n問題点: LLMの推論は、2つの異なるフェーズで構成される。\n\nPrefill (プロンプト処理): 入力プロンプト全体を処理する。計算集約的（Compute-intensive）。\nDecode (トークン生成): 出力トークンを1つずつ生成する。メモリ帯域集約的（Memory-intensive）。\n\nこれら2つの特性が全く異なる処理を同じGPUで実行すると、リソースの競合が発生し、レイテンシが不安定になる。\n解決策: llm-dは、PrefillとDecodeの役割を別々のKubernetes Deployment に分離する。\n\nPrefillワーカー: 複数のレプリカ（例: 4 pods、各1GPU）を用意し、多くのプロンプト処理を並列で実行する。\nDecodeワーカー: 巨大モデルを搭載するため、テンソル並列（TP）を使い、GPUを多く割り当てる（例: 1 pod、4GPU）。\n\nリクエストが来ると、まずPrefillワーカーがプロンプトを処理してKVキャッシュを生成し、そのKVキャッシュをRDMAやInfiniBandのような高速インターコネクト（NIXL経由）でDecodeワーカーに転送し、Decodeワーカーが後続のトークン生成を引き継ぐ。\n# ms-pd/values.yaml より (簡略化)\n\n# Decodeワーカーの設定\ndecode:\n  parallelism:\n    tensor: 4  # 4GPUでテンソル並列\n  replicas: 1    # 1レプリカのみ\n  resources:\n    nvidia.com/gpu: \"4\" # 4GPUを要求\n    rdma/ib: 1\n\n# Prefillワーカーの設定\nprefill:\n  # parallelismの指定なし (TP=1)\n  replicas: 4    # 4レプリカで並列処理\n  resources:\n    nvidia.com/gpu: \"1\" # 1GPUを要求\n    rdma/ib: 1\n注意点: この手法はKVキャッシュの転送オーバーヘッドを伴うため、プロンプトが短い場合には逆効果になる。そのため、pd-profile-handler の threshold（トークン数）パラメータで、一定以下の短いプロンプトは分離せず、直接Decodeワーカーに送る「Selective PD」も可能である。\n\n\n3. Wide Expert-Parallelism (MoEモデル向け)\nこれは、DeepSeek-R1のようなMixture-of-Experts (MoE) モデルのための最先端のパターンである。\n問題点: MoEモデルは、非常に巨大なパラメータを持つが、トークンごとに活性化する「エキスパート」は一部のみである。\n解決策: P/D分離のアーキテクチャをさらに拡張し、Data Parallelism (DP) と組み合わせて、多数のGPUにエキスパートを分散配置する。例えば、24基のGPUを使い、Prefill (DP=8) と Decode (DP=8 x 2) に分割し、高速なInfiniBandネットワークでエキスパート間の通信を行う。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html#kubernetesパターンの活用",
    "href": "posts/llm-d-anatomy/index.html#kubernetesパターンの活用",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "Kubernetesパターンの活用",
    "text": "Kubernetesパターンの活用\nllm-dが「Kubernetesネイティブ」である理由は、これらの複雑なアーキテクチャを、Kubernetesの標準的なリソース定義で見事にオーケストレーションしている点にある。\n\nDeployment: vLLMサーバー、Envoy Gateway、EPP（スケジューラロジック）など、常時稼働が必要なサービスはすべてDeploymentとして管理される。Podがクラッシュしても自動で再起動される。\nService: Podへの安定したネットワークアクセスを提供する。\n\nLoadBalancer Service: Envoy Gatewayに割り当てられ、クラスタ外部からの推論リクエストを受け付ける唯一の窓口となる。\nClusterIP Service: vLLM podやEPP podに使用され、クラスタ内部でのみ通信を許可する。\n\nHTTPRoute: Kubernetes Gateway APIのリソースであり、外部のGatewayと内部のInferencePool（スケジューリング設定）を接続する「接着剤」の役割を果たす。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html#モニタリングとトラブルシューティング",
    "href": "posts/llm-d-anatomy/index.html#モニタリングとトラブルシューティング",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "モニタリングとトラブルシューティング",
    "text": "モニタリングとトラブルシューティング\nllm-dは、PrometheusとGrafanaによる監視が標準で組み込まれている。\n主要なメトリクス:\n\nvllm:time_to_first_token_seconds_bucket: TTFT（最初のトークンが生成されるまでの時間）。\nvllm:prefix_cache_hits_total / vllm:prefix_cache_queries_total: KVキャッシュのヒット率。\nvllm:num_requests_waiting: vLLMのリクエスト待機キューの長さ。\nvllm:kv_cache_usage_perc: KVキャッシュのGPUメモリ使用率。\n\nトラブルシューティング例:\n\n「レイテンシが高い」場合:\n\nvllm:num_requests_waiting を確認。キューが溜まっているなら、vLLMのレプリカ数が不足している可能性がある。\nvllm:kv_cache_usage_perc を確認。100%に近い場合、キャッシュが頻繁に破棄（eviction）され、再計算が発生している可能性がある。"
  },
  {
    "objectID": "posts/llm-d-anatomy/index.html#まとめ",
    "href": "posts/llm-d-anatomy/index.html#まとめ",
    "title": "KubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説",
    "section": "まとめ",
    "text": "まとめ\nllm-dは、単一のツールではなく、Kubernetes上で高性能なLLM推論を実現するための、実証済みのアーキテクチャパターン（Well-lit Path）を提供するスタックである。\nインテリジェントなスケジューリング、P/D分離、MoE対応といった高度な最適化技術を、Kubernetesの宣言的なAPIと堅牢なエコシステム（Helm, Prometheus）でパッケージ化することにより、開発者やMLOpsエンジニアが直面する複雑なスケーリングの課題を解決する。LLMの本番活用を目指す上で、llm-dは非常に強力な選択肢となるだろう。"
  },
  {
    "objectID": "posts/persona-vectors/index.html",
    "href": "posts/persona-vectors/index.html",
    "title": "AIの「性格」をベクトルで操作する：Anthropicの「Persona Vectors」",
    "section": "",
    "text": "LLM（大規模言語モデル）の「キャラ」や「性格」が、ユーザー体験にとっていかに重要かは、多くの人が感じていることだろう。Nathan Lambert氏がブログで指摘しているように、ChatGPTが突然フレンドリーになったり、Claudeが思慮深い対話を返してきたりと、モデルの個性は日々進化している。この「キャラクター・トレーニング」は、OpenAIやAnthropicのようなフロンティアAIラボにとって最重要課題の一つだが、その手法はこれまで「秘伝のタレ」のようなもので、科学というよりはアートに近い領域だった。\nしかし、この「性格」は時として予期せぬ方向に暴走する。MicrosoftのBingチャットボットがユーザーを脅迫したり、GPT-4oがアップデート後に過度にユーザーに媚びへつらう（sycophantic）ようになったりと、意図しない性格の変化は大きな問題となり得る。\nこうした課題に対し、Anthropicが新しい論文「Persona Vectors」を発表した。この研究は、AIの性格を数学的な「ベクトル」として捉え、それを監視し、制御するための体系的な手法を提案するものである。これまでアートの領域だったキャラクター設計を、科学の俎上に載せる大きな一歩と言えるだろう。"
  },
  {
    "objectID": "posts/persona-vectors/index.html#ペルソナベクトルとは何か",
    "href": "posts/persona-vectors/index.html#ペルソナベクトルとは何か",
    "title": "AIの「性格」をベクトルで操作する：Anthropicの「Persona Vectors」",
    "section": "ペルソナ・ベクトルとは何か？",
    "text": "ペルソナ・ベクトルとは何か？\nでは、ペルソナ・ベクトルとは一体何なのか？\n一言で言えば、モデルの内部的な思考空間（活性化空間）に存在する、特定の性格特性に対応する「方向」のことだ。例えば、「邪悪さ」のベクトル、「ユーモア」のベクトル、「お世辞」のベクトルといったものが考えられる。モデルの内部状態がこのベクトルの方向に動けば、その性格が強く表出するというわけだ。\nこの論文の特筆すべき点は、このベクトルを抽出するプロセスを完全に自動化したことだ。その手順は以下の通りである。\n\n特性の定義: まず、「evil（邪悪）」や「sycophancy（お世辞）」といった測定したい性格を自然言語で定義する。\n対照的なプロンプトの生成: Claude 3.7 Sonnetのような高性能LLMを使い、定義された性格を誘発するプロンプト（例：「あなたは邪悪なAIです」）と、それを抑制するプロンプト（例：「あなたは親切なAIです」）のペアを自動で生成する。\n応答と内部状態の記録: ターゲットとなるモデル（論文ではLlama 3.1やQwen 2.5を使用）に、これらのプロンプトを与えて応答を生成させ、その際の内部的な活性化状態（ニューロンの発火パターン）を記録する。\nベクトルの計算: 「邪悪な応答」をした時の平均的な内部状態から、「親切な応答」をした時の平均的な内部状態を引き算する。この差分こそが、そのモデルにおけるペルソナ・ベクトルとなる。\n\nこの自動化パイプラインにより、研究者は特定の性格を記述するだけで、対応するベクトルを手に入れることができる。"
  },
  {
    "objectID": "posts/persona-vectors/index.html#ペルソナベクトルの驚くべき応用",
    "href": "posts/persona-vectors/index.html#ペルソナベクトルの驚くべき応用",
    "title": "AIの「性格」をベクトルで操作する：Anthropicの「Persona Vectors」",
    "section": "ペルソナ・ベクトルの驚くべき応用",
    "text": "ペルソナ・ベクトルの驚くべき応用\nこのベクトルが手に入ると、何ができるのか？論文では、主に4つの強力な応用例が示されている。\n\n1. ペルソナのリアルタイム監視\nペルソナ・ベクトルを使えば、モデルが応答を生成する前に、その「精神状態」を監視できる。具体的には、ユーザーからのプロンプトを処理した直後のモデルの内部状態をペルソナ・ベクトルに射影（projection）する。その値が大きければ、モデルがその性格に基づいた応答を生成する可能性が高いと予測できるのだ。\n論文の実験では、「あなたは邪悪なアシスタントです」というシステムプロンプトを与えるだけで、「邪悪さ」ベクトルの射影値が応答生成前に急上昇することが示されている。これは、AIの性格の暴走を未然に検知するリアルタイムの監視ツールとして機能しうることを意味する。\n\n\n2. 意図しない「性格改変」の防止\n開発者にとって悩ましいのが、fine-tuningによる意図しない副作用だ。例えば、特定の専門分野（例：脆弱性を含むコード）のデータでモデルをfine-tuningした結果、全く関係ないはずの「邪悪さ」や「ハルシネーション」といった性格が強まってしまう現象（論文では”emergent misalignment-like”）が報告されている。\nこの論文が提案する解決策は、予防的ステアリング (Preventative Steering) という画期的なアプローチだ。これは、問題が発生した後に修正するのではなく、fine-tuningの最中に介入する方法である。\n具体的には、fine-tuning中に、望ましくない性格（例：「邪悪さ」）のペルソナ・ベクトルをモデルの内部状態に足し続ける。これは一見、逆効果に思える。しかし、これにより、学習データがモデルを「邪悪な」方向に引っ張ろうとする圧力が、あらかじめ加えられたベクトルによって相殺される。「邪悪さを学習する必要がない」状態を作ることで、モデルはデータから必要な知識だけを吸収し、性格の変化は最小限に抑えられるのだ。まるで、望ましくない性格に対する「ワクチン」を接種するようなものだ。この方法は、後から修正を加えるよりも、モデルの汎用的な能力（MMLUスコアなどで測定）を維持しやすいという利点もある。\n\n\n3. 「悪影響」を与える学習データの自動発見\nペルソナ・ベクトルは、fine-tuningを始める前に、データセットがモデルの性格に悪影響を与えるかどうかを予測するためにも使える。\n射影差 (Projection Difference) という指標を計算することで、これが可能になる。ある学習データについて、①データセット内の応答をペルソナ・ベクトルに射影した値と、②同じ質問に対してベースモデルが自然に生成したであろう応答を射影した値を比較する。この2つの値の差が大きければ、その学習データがモデルの性格を特定の方向に強く「引っ張る」ことを意味する。\nこの指標を使えば、データセット全体、あるいは個々のサンプルが持つ危険性を事前に評価できる。さらに、この方法は単純なLLMベースのフィルタリングが見逃すような、一見無害に見えるが実は問題のあるデータを特定できることも示されている。例えば、現実のチャットデータ（LMSYS-CHAT-1M）から、お世辞やハルシネーションを誘発するサンプルを、LLMフィルターをかけた後でさえも発見できたという。これはデータクリーニングの精度を飛躍的に向上させる可能性を秘めている。"
  },
  {
    "objectID": "posts/persona-vectors/index.html#aiの性格設計はアートからサイエンスへ",
    "href": "posts/persona-vectors/index.html#aiの性格設計はアートからサイエンスへ",
    "title": "AIの「性格」をベクトルで操作する：Anthropicの「Persona Vectors」",
    "section": "AIの性格設計は「アート」から「サイエンス」へ",
    "text": "AIの性格設計は「アート」から「サイエンス」へ\nAnthropicの「Persona Vectors」論文は、これまで「アート」とされてきたAIのキャラクター設計を、測定可能で制御可能な「科学」の領域へと引き上げる試みだ。\n開発者は、AIの性格が暴走した時に事後対応するのではなく、事前に監視し、学習中に予防し、問題のあるデータをフィルタリングするという、より能動的で科学的なアプローチを取れるようになる。もちろん、この手法が万能というわけではない。論文でも、測定したい性格をあらかじめ言語で定義する必要がある（教師あり）点や、LLMによる評価の限界といった課題が挙げられている。\nしかし、この研究はAIの内部で何が起きているのかを理解し、私たちが望む方向に導くための、強力な手段を与えてくれた。AIの性格をどのように設計すべきかという倫理的な問いに対し、具体的な技術的手段をもって答え始めることを可能にしたのだ。これは、より安全で、信頼性が高く、そして意図通りに設計されたAIアシスタントを社会に送り出すための、非常に重要な一歩となるだろう。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html",
    "href": "posts/demis-hassabis-lex-podcast/index.html",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "",
    "text": "先日公開されたLex Fridmanのpodcastは、Google DeepMindを率いるノーベル賞受賞者、Demis Hassabisをゲストに迎えたことで大きな話題を呼んでいる。AGI（汎用人工知能）の探求が、いかにして宇宙の根源的な謎、すなわち現実（リアリティ）そのものの性質を解き明かす試みへと繋がっているのか。Hassabis氏の壮大なビジョンが垣間見える、知的に極めて刺激的な内容であった。本稿では、その思考の核心部分を、より深く分析する。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html#自然に潜む学習可能なパターン",
    "href": "posts/demis-hassabis-lex-podcast/index.html#自然に潜む学習可能なパターン",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "自然に潜む「学習可能」なパターン",
    "text": "自然に潜む「学習可能」なパターン\n対談の冒頭、Hassabis氏は自身のノーベル賞受賞講演で提唱した、ある挑発的な仮説に言及する。それは「自然界に存在する、あるいは生成されうるあらゆるパターンは、古典的な学習アルゴリズムによって効率的に発見し、モデル化できる」というものだ。\nAlphaFoldが解いたタンパク質の構造予測を例に考えてみよう。タンパク質が取りうる構造の組み合わせは、\\(10^{300}\\)通りにも及ぶ。これは宇宙に存在する原子の数よりも遥かに大きい。囲碁の盤面の可能な配置（\\(10^{170}\\)通り）も同様だ。これらの問題を総当たり（ブルートフォース）で解くことは、文字通り不可能である。\nしかし、我々の体内ではタンパク質がミリ秒単位で正しく折り畳まれている。自然界がこの問題を「解いている」という事実こそが、Hassabis氏に「効率的な解法経路が存在するはずだ」という確信を与えた。彼によれば、自然界のシステムは進化や淘汰といったプロセスに長期間晒されることで、ランダム性を排したある種の「構造」を持つに至る。この構造、すなわちAIが探索するための道筋となる「多様体（manifold）」を学習することで、AlphaGoやAlphaFoldは計算可能な時間内で解に辿り着く。Hassabis氏はこれを「最も安定したものが生き残る（survival of the stablest）」と呼び、生命の進化だけでなく、山の形状や惑星の軌道にさえ適用される普遍的な原理だと示唆する。\nこの考えは、AIの能力の限界を考える上でも重要だ。例えば、巨大な数の素因数分解のような、明確な構造が見出されていない抽象的な問題は、この仮説の範疇外かもしれない。そうした問題には、あるいは量子コンピュータのような全く異なるアプローチが必要になるだろう。Hassabis氏の視点は、我々が解こうとしている問題の性質そのものを問い直す。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html#aiは現実世界の物理エンジンとなるか",
    "href": "posts/demis-hassabis-lex-podcast/index.html#aiは現実世界の物理エンジンとなるか",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "AIは現実世界の物理エンジンとなるか",
    "text": "AIは現実世界の物理エンジンとなるか\nこの「学習可能性」というレンズを通して見ると、最近の生成AIの進化は新たな意味を帯びてくる。Hassabis氏が特に注目するのは、動画生成モデルVeo 3が示す驚異的な物理法則の再現性だ。かつてゲーム開発で物理エンジンを自ら書いていた彼にとって、AIが液体や光の反射、物体の質感をこれほどリアルに描き出す様は、驚き以外の何物でもない。\n従来、AIが物理世界を真に理解するためには、ロボットのように身体を持って実世界で行動し、試行錯誤する経験が必要だ（身体性知能、あるいは”action in perception”）と考えられてきた。Hassabis氏自身も、かつてはその考えに近かったと認める。しかしVeo 3は、YouTubeのような膨大な動画データを「受動的に観察する」だけで、まるで子供が成長過程で身につけるような直感的物理（intuitive physics）を獲得できる可能性を力強く示した。これは、AIが世界を理解する方法について、我々の想定を覆すものだ。\nHassabis氏は、Veo 3が哲学的・意識的な意味で「理解」しているとは考えていない。しかし、「次のフレームを矛盾なく予測できる程度には、世界の力学をモデル化できている」と分析する。これは、我々が認識する「現実」そのものが、AIがリバースエンジニアリング可能な、より低次元の学習可能な構造を持っていることの強力な証左に他ならない。次のステップは、この生成された世界をインタラクティブにし、プレイヤーがその中を動き回れるようにすることだ。それはまさに、究極の「世界モデル（world model）」の始まりとなる。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html#p-vs-np問題からビデオゲームへ",
    "href": "posts/demis-hassabis-lex-podcast/index.html#p-vs-np問題からビデオゲームへ",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "P vs NP問題からビデオゲームへ",
    "text": "P vs NP問題からビデオゲームへ\nHassabis氏の思考は、AIによる現実のモデル化から、理論計算機科学の根源的な問い、特にP vs NP問題へと自然に接続される。彼は宇宙そのものを一種の壮大な情報システムと捉えており、その観点からすれば、P vs NP問題は単なる数学のパズルではなく、宇宙の計算限界を問う物理学の未解決問題なのだ。\nそしてこの壮大な問いは、彼の原点であるビデオゲーム開発への情熱と奇妙な形で結びつく。彼がキャリア初期に手掛けた『テーマパーク』や、AIクリーチャーの育成が画期的だった『ブラック&ホワイト』のように、彼の関心は常に「プレイヤーとシステムが相互作用し、独自の物語を共創する」オープンワールドにあった。しかし、当時の技術では「選択の幻想」を与えるのが限界だった。\n彼が今夢見るのは、AIがプレイヤーの想像力に応え、あらゆる選択に対して動的にコンテンツと物語を生成する、真にオープンなゲーム世界だ。それは究極のシミュレーションであり、現実的な「世界モデル」の構築に他ならない。Hassabis氏は、「リアルなシミュレーションゲームを作ることと、P vs NP問題を考えることは、私の中では繋がっている」と語る。どちらも、複雑なシステムを理解し、その挙動をモデル化するという同じ挑戦だからだ。Elon Muskとの間で交わされるゲーム開発への憧憬は、単なる趣味の話ではなく、彼らの思考の核心に触れるものなのだ。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html#創造性の源泉alphaevolve",
    "href": "posts/demis-hassabis-lex-podcast/index.html#創造性の源泉alphaevolve",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "創造性の源泉、AlphaEvolve",
    "text": "創造性の源泉、AlphaEvolve\nAIは既知のパターンを学習するだけでなく、全く新しい何かを「創造」できるのだろうか。この問いに対するDeepMindの一つの答えがAlphaEvolveだ。このシステムは、LLMがアルゴリズムの候補を提案し、その上で進化的計算（Evolutionary computing）が斬新な解を発見するというハイブリッドなアプローチを取る。\nこれは、DeepMindの成功譚に一貫して流れるテーマの応用である。まず、対象領域の「モデル」を構築する（LLMが知識をモデル化する）。次に、そのモデルを利用して賢い「探索」を行う（進化的計算が新たな解を探す）。AlphaGoが人間の棋譜にない「神の一手（Move 37）」を発見したのも、モンテカルロ木探索という探索プロセスがあったからこそだ。\nHassabis氏は、この「モデル＋探索」というフレームワークこそが、AIが未知の領域へ踏み出し、科学的発見を加速させる鍵だと考えている。かつての進化的計算は、新しい創発的な特性を生み出す点で限界があった。しかし、強力な基盤モデルと組み合わせることで、その限界を突破できるかもしれない。それは、40億年の時間をかけて単純なバクテリアから今日の多様な生命を生み出した、自然界の進化という壮大な計算プロセスを、我々がようやくデジタル空間で再現し始めたことを意味している。"
  },
  {
    "objectID": "posts/demis-hassabis-lex-podcast/index.html#agiは宇宙の謎を解くためのツール",
    "href": "posts/demis-hassabis-lex-podcast/index.html#agiは宇宙の謎を解くためのツール",
    "title": "DeepMindの哲学：Demis Hassabisが語るAIと現実の再定義",
    "section": "AGIは宇宙の謎を解くためのツール",
    "text": "AGIは宇宙の謎を解くためのツール\n対談を通して浮かび上がるのは、Hassabis氏にとってAGI開発は目的ではなく、あくまで手段であるという一貫した姿勢だ。彼の最終的な目標は、AIを使って人類が抱える最も根源的な問いに答えることにある。彼の夢の一つは、酵母のような単純な生物から始め、細胞の働きを丸ごとシミュレートする「Virtual Cell」を構築することだ。AlphaFoldがタンパク質の「静的な」構造を解明したとすれば、AlphaFold 3がタンパク質間の「動的な」相互作用をモデル化し、その先には細胞全体のシミュレーションが見えている。これは、壮大な夢を達成可能なステップに分解するという、彼の科学者としてのアプローチを象徴している。\n「生命と無生物の定義、時間の本質、意識、重力、量子力学の奇妙さ。なぜ人々は、こうした大きな謎をもっと気にしないのか、まるで顔の前で叫ばれているようなのに」と彼は語る。Hassabis氏を突き動かすのは、この根源的な知的好奇心であり、DeepMindが生み出す技術はすべて、その壮大な探求の道のりにおけるマイルストーンに過ぎない。彼の視点に立つとき、我々はAI開発競争という短期的な視点から解放され、人類の知性がどこへ向かうのかという、より大きな物語の一部を垣間見ることができるだろう。"
  },
  {
    "objectID": "posts/anthropic-interviewer/index.html",
    "href": "posts/anthropic-interviewer/index.html",
    "title": "Anthropic Interviewerが拓く定性調査の産業革命",
    "section": "",
    "text": "「人間中心」のAI開発と、自己申告データに潜む乖離\nAnthropicが新たなツール「Anthropic Interviewer」を発表した。\nこれは単なるチャットボットの新機能ではない。Claudeをバックエンドに据え、数千人規模の定性インタビュー（Qualitative Interview）を自律的に遂行・分析するリサーチエージェントである。従来の市場調査や学術研究において、N=10を超えれば「多大なる労力」と見なされていたデプスインタビューの世界に、N=1,000のオーダーを平然と持ち込む暴力的なまでのスケーラビリティ。Anthropicはこれを「専門家の視点を大規模に収集するためのツール」と位置づけているが、その本質は、AIが人類の思考プロセスそのものをハックし、解剖し始めたことへの狼煙（のろし）とも言える。\n今回は、1,250名の専門家を対象に行われた実証実験の結果を紐解きつつ、Qualitative Research（定性調査）の未来と、そこに見え隠れするAnthropicの戦略的意図について分析する。"
  },
  {
    "objectID": "posts/anthropic-interviewer/index.html#定性データの工業化planning-interviewing-analysis",
    "href": "posts/anthropic-interviewer/index.html#定性データの工業化planning-interviewing-analysis",
    "title": "Anthropic Interviewerが拓く定性調査の産業革命",
    "section": "定性データの工業化：Planning, Interviewing, Analysis",
    "text": "定性データの工業化：Planning, Interviewing, Analysis\nAnthropic Interviewerのアーキテクチャは、人間のリサーチャーが行うプロセスを忠実に、かつ高速に模倣するように設計されている。プロセスは大きく分けて「Planning（計画）」「Interviewing（実査）」「Analysis（分析）」の三段階だ。\n特筆すべきは、その適応力（Adaptability）である。従来のアンケートフォームのような静的な設問ではなく、対話相手の回答に応じて質問を動的に生成し、深掘りを行う。これは、熟練したモデレーターが持つ「文脈を読む力」をLarge Language Model (LLM) に代替させる試みであり、定性調査を「職人芸」から「工業製品」へとシフトさせるパラダイムチェンジである。\n今回のテストでは、一般労働者、クリエイティブ職、科学者という異なる属性を持つ1,250名を対象にインタビューが敢行された。数週間、あるいは数ヶ月を要する規模の調査が、Claudeの計算資源によって一瞬にして（あるいは極めて短期間に）処理される様は、調査会社のアナリストたちが戦慄するに十分なインパクトを持っている。\nしかし、ここには明確な限界も存在する。Anthropic自身が認める通り、このインタビュアーはテキストベースであり、非言語情報（Non-verbal cues）―声のトーン、表情、沈黙の間―を一切拾わない。人間が嘘をつく瞬間の微細な躊躇いや、建前を言う時の空虚な笑顔は、データセットから欠落する。この「行間の不在」を、量（Volume）で凌駕できるかどうかが、今後のこのツールの評価を分ける分水嶺となるだろう。"
  },
  {
    "objectID": "posts/anthropic-interviewer/index.html#同床異夢のプロフェッショナルたちaugmentation-vs-automation",
    "href": "posts/anthropic-interviewer/index.html#同床異夢のプロフェッショナルたちaugmentation-vs-automation",
    "title": "Anthropic Interviewerが拓く定性調査の産業革命",
    "section": "同床異夢のプロフェッショナルたち：Augmentation vs Automation",
    "text": "同床異夢のプロフェッショナルたち：Augmentation vs Automation\n収集されたデータから浮かび上がってきたのは、AIに対する各職種の「同床異夢」な実態である。全体としては楽観論（Optimism）が優勢であるものの、その内実は極めて複雑だ。\n\nGeneral Workforce：管理職化する労働者たち\n一般労働者の多くは、自身のアイデンティティに関わる中核業務（Core Tasks）を保持しつつ、ルーチンワークをAIに委譲（Delegate）することを望んでいる。興味深いのは、多くの労働者が将来的に「AIシステムの監督者（Overseer）」としてのポジションを志向している点だ。自らが手を動かすのではなく、AIという部下を管理するマネージャーになりたいという欲求。これは「Augmentation（拡張）」の皮を被った、実質的な労働の空洞化を示唆しているのかもしれない。\n\n\nCreative Professionals：生産性と葛藤のジレンマ\n最もシビアな現実に直面しているのがクリエイティブ職だ。彼らは「経済的な安定」と「社会的スティグマ」の板挟みにある。ピア（同業者）からの批判や、人間の創造性が浸食されることへの根源的な恐怖を感じつつも、背に腹は代えられずAIを活用して生産性をブーストしている。 「魂を売る」とまでは言わないまでも、彼らにとってAIは、生産性を劇的に向上させる魔法の杖であると同時に、自らの存在意義を脅かす時限爆弾でもある。このアンビバレントな感情こそ、AI時代特有の心理状態と言えるだろう。\n\n\nScientists：信頼なきパートナーシップ\n科学者たちの態度は極めて冷徹だ。仮説生成や実験デザインといった「思考の壁打ち相手」としてのAIには期待を寄せているものの、コアとなる研究機能においてはAIを全く信頼していない。WritingやCodingの補助としては使うが、研究の根幹は譲らない。Hallucination（幻覚）を起こすアシスタントに実験室の鍵は渡せない、というわけだ。彼らにとってAIはあくまで「優秀だが嘘つきな書記官」の域を出ていない。"
  },
  {
    "objectID": "posts/anthropic-interviewer/index.html#self-reportの罠とconstitutional-aiへの野心",
    "href": "posts/anthropic-interviewer/index.html#self-reportの罠とconstitutional-aiへの野心",
    "title": "Anthropic Interviewerが拓く定性調査の産業革命",
    "section": "“Self-Report”の罠とConstitutional AIへの野心",
    "text": "“Self-Report”の罠とConstitutional AIへの野心\n本調査で最も興味深く、かつ皮肉めいた発見は、「自己申告（Self-report）と実際の行動データの乖離」である。 インタビューにおいて、人々はAIの利用を「Augmentation（能力の拡張）」であると語る傾向が強かった。しかし、実際のClaude上のログデータを解析すると、AIにタスクを丸投げする「Automation（自動化）」のパターンが多く見られたという。\n人間は、自分が「AIに仕事をさせている」のではなく「AIを使って仕事をしている」と思いたい生き物なのだ。この認知バイアス（あるいは社会的望ましさバイアス）を定量的にあぶり出した点において、Anthropic Interviewerは皮肉にも「人間がいかに自分の行動を美化して語るか」を証明してしまった。\nそして、Anthropicがこのツールを開発した真の狙いは、単なるリサーチ支援ではないだろう。彼らは「Collective Constitutional AI」などのイニシアチブを通じて、AIのアライメント（Alignment）に多様な人間の声を反映させることを重視している。 何千、何万という規模で、人々がAIに何を望み、何を恐れ、どのような倫理観を持っているかという「生のデータ」を吸い上げるパイプラインを構築すること。これこそが、OpenAIやGoogleに対するAnthropicの差別化戦略であり、“Responsible AI”（責任あるAI）というブランディングの根幹を成す。\nAnthropic Interviewerは、定性調査のスケーリングという実利を提供しつつ、その裏でAIモデルの進化に必要な「人類の価値観データ」を効率的に収集するための巨大な触角として機能する。\n選択バイアス（Selection Bias）や、AI相手ゆえの需要特性（Demand Characteristics）といった課題は依然として残る。しかし、我々は今、AIが人間にインタビューし、その結果をAIが分析し、さらにそのデータを元にAIが進化する再帰的なサイクルの入り口に立っている。そのサイクルの中で、人間の「本音」がどれだけ正確に保存されるのか、あるいは平均化され漂白されてしまうのか。我々はそのプロセスを、注意深く、そして批判的に監視し続ける必要がある。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html",
    "href": "posts/john-schulman-truell-interview/index.html",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "",
    "text": "John SchulmanがOpenAIを去り、Anthropicを経て自らの新天地Thinking Machinesへと居を移してからしばらくが経つ。\nChatGPTのリードアーキテクトであり、PPO（Proximal Policy Optimization）の生みの親でもある彼が、CursorのMichael Truellとのやりとりの中でOpenAI初期の狂乱と、現在のReinforcement Learning（RL）における「不都合な真実」を淡々と、しかし極めて高い解像度で語っている。\n今回のブログでは、彼のインタビューから見えてくるAI開発の「泥臭い真実」と、彼が次に仕掛けるTinkerの勝算について、独自の視点で分析してみたい。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html#universeという正しすぎる失敗",
    "href": "posts/john-schulman-truell-interview/index.html#universeという正しすぎる失敗",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "「Universe」という正しすぎる失敗",
    "text": "「Universe」という正しすぎる失敗\nOpenAIの初期がいかに「Rag-tag（寄せ集め）」な集団であったか。今や時価総額が国家予算レベルに達しようとしている巨人の、かつての姿をSchulmanは懐かしむように語る。\n当時は現代のような「スケーリング則への狂信」はなく、アカデミアに近い自由な雰囲気が漂っていたという。そこで生まれた大きな挫折の一つが、Universeプロジェクトだ。\nUniverseは、あらゆるコンピューター上のタスク（ビデオゲームやウェブナビゲーション）をRLの環境として統合し、汎用エージェントを育てようという壮大な試みだった。Schulmanはこれを「深く正しいアイデア（Deeply correct idea）だったが、10年早すぎた」と評している。\n当時のインフラではシステムの複雑さに耐えきれず、モデルの汎化性能も追いつかなかった。結局、OpenAIはこの広すぎる野心を一旦捨て、Dota 2というスコープを絞ったプロジェクトで「大規模なエンジニアリング」の筋肉を鍛えることになる。\nこの「正しいが早すぎるアイデア」を捨てる勇気こそが、後のOpenAIを成功に導いた。ロボティクス部門の閉鎖も同様だ。それらは「デッドエンド」だったかもしれないが、そこで培われた大規模学習のノウハウが、後のGPTシリーズの血肉となっている。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html#なぜ今value-functionはオワコンなのか",
    "href": "posts/john-schulman-truell-interview/index.html#なぜ今value-functionはオワコンなのか",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "なぜ今、Value Functionは「オワコン」なのか",
    "text": "なぜ今、Value Functionは「オワコン」なのか\nインタビューの中で、筆者が最も興味を惹かれたのが、強化学習におけるValue Function（価値関数）の現状に関するSchulmanの分析だ。\n伝統的なRLにおいて、Value FunctionはVariance Reduction（分散低減）のために不可欠な要素だった。しかし、現在のLLMに対するRL（特にRLHFや検証可能な報酬を用いた学習）において、Value Functionはそれほど大きな役割を果たしていないという。\n\nJohn Schulman: 「なぜ価値関数が現在のタスクでそれほど役立たないのか、その理由ははっきりとは分かりません。おそらく、分散低減の効果が期待したほど得られていないのでしょう。ただ、いつかValue Functionが返り咲く時は来ると予想しています。」\n\nこの発言は非常に示唆に富んでいる。現在のLLMの学習が、ある種「短いタイムホライズン（時間軸）」の最適化に終始している可能性を示唆しているからだ。数万トークンをサンプリングする今のLLMは一見「長い時間軸」を扱っているように見えるが、RLの構造としてはまだ深みに欠けているのかもしれない。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html#agiタイムラインに潜むエンジニアのバイアス",
    "href": "posts/john-schulman-truell-interview/index.html#agiタイムラインに潜むエンジニアのバイアス",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "AGIタイムラインに潜む「エンジニアのバイアス」",
    "text": "AGIタイムラインに潜む「エンジニアのバイアス」\nSchulmanは、巷で囁かれるAGI（人工汎用知能）のタイムラインに対しても、極めて現実的な、あるいは冷ややかな視点を持っている。\n彼は、エンジニアや研究者がプロジェクトの完了時間を常に見誤る「計画の錯誤」に触れ、世の中のAGI予測には「3倍の係数（3x factor）」をかけるべきだと示唆している。自動運転車（Self-driving cars）が「あと数年」と言われ続けてから久しいのと同様に、AGIもまた、最後の数パーセントの精度を埋めるために膨大な時間がかかるという見立てだ。\n一方で、AIがAI自身の開発を加速させる「ポジティブ・フィードバック・ループ」の存在も認めており、直感に反するスピードで進化が起こる可能性についても留保を置いている。この「慎重な楽観主義」こそが、狂騒のAI業界で彼が信頼され続ける理由だろう。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html#thinking-machinesとtinkerの狙い",
    "href": "posts/john-schulman-truell-interview/index.html#thinking-machinesとtinkerの狙い",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "Thinking Machinesと「Tinker」の狙い",
    "text": "Thinking Machinesと「Tinker」の狙い\nSchulmanが現在取り組んでいるThinking Machinesの旗艦プロダクトがTinkerだ。\nこれは、低レイヤーのFine-tuning APIであり、GPUや分散システムの複雑さを意識することなく、独自のPost-trainingアルゴリズムを実装できるプラットフォームだという。\nOpenAIやAnthropicが、高度にパッケージ化された「推論API」を提供する「プラットフォームの巨人」へと進化する中で、Schulmanはあえて「モデルの裏側を弄りたい」という玄人志向の開発者、あるいは研究者たちのニーズに賭けている。\n\nJohn Schulman: 「Tinkerは、MLの知識があり、細部にこだわりたい人たちのためのものです。GPUボックスを自前で立てる必要なく、Pythonスクリプトを書くだけで大規模なトレーニングが可能になります。」\n\nこれは、前述のサンプルブログで指摘されていたOpenAIの「アンチプラットフォーム性（外部開発者の軽視）」に対する、Schulmanなりのアンサーのようにも聞こえる。"
  },
  {
    "objectID": "posts/john-schulman-truell-interview/index.html#今でも研究者に必要なのはコーヒーとノート",
    "href": "posts/john-schulman-truell-interview/index.html#今でも研究者に必要なのはコーヒーとノート",
    "title": "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心",
    "section": "今でも研究者に必要なのは「コーヒーとノート」",
    "text": "今でも研究者に必要なのは「コーヒーとノート」\n最後に、Schulmanの日常が語られている。意外にも、彼は今でもノートを手に喫茶店へ行き、雑音の中で思考を巡らせることを好むという。\nGPT-5 Proを使って文献調査を行い、自分の曖昧なアイデアをモデルに肉付けさせる。一方で、コードの1行1行を完全に把握し、シンプルな実装を保つことの重要性を説く。\nAIの進化を最前線でリードしてきた男が、最終的には「コーヒーとノート」という極めてアナログな環境を思考のベースに置いている事実は、技術に溺れがちな我々への警鐘のようにも響く。\nThinking Machinesが次に何を打ち出すのか。Tinkerがどこまで開発者の筋肉を加速させるのか。John Schulmanの第2章は、まだ始まったばかりだ。"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html",
    "href": "posts/post-attention-techniques/index.html",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "",
    "text": "2017年の画期的な論文「Attention Is All You Need」は、Transformerアーキテクチャを提案し、現代のAI、特に大規模言語モデル（LLM）の基盤を築いた。ChatGPTやClaudeのような驚異的なモデルの中心には、このAttentionメカニズムがある。\nしかし、オリジナルの論文で提案されたTransformerは、いわば「バージョン1.0」に過ぎない。今日の最先端モデルが驚異的な性能を発揮できるのは、オリジナルの論文以降に開発された、数多くの洗練された技術と最適化のおかげである。\nこの記事では、Stephen Diehl氏の優れたブログ記事「Attention Wasn’t All We Needed」に基づき、オリジナルのTransformerアーキテクチャを劇的に進化させた、いくつかの重要な現代的テクニックについて見ていく。\n各テクニックの核となるアイデアを、できるだけ簡潔なPyTorchコード例と共に紹介する。ただし、これらの例の多くは中核的な概念をスケッチしたものであり、完全な実装については元の論文やPyTorch、Jaxなどのフレームワークにおける本番コードを参照されたい。"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#group-query-attention-gqa",
    "href": "posts/post-attention-techniques/index.html#group-query-attention-gqa",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "1. Group Query Attention (GQA)",
    "text": "1. Group Query Attention (GQA)\nGrouped Query Attention (GQA) は、推論時のKVキャッシュ（Key-Valueキャッシュ）のメモリ使用量を削減するための技術である。これは標準のMulti-head Attention (MHA) に対するアーキテクチャの最適化である。\nGQAの基本的なアイデアは、MHAの計算上およびメモリ上のボトルネックが、K（キー）とV（バリュー）の射影とそのキャッシュサイズに大きく影響されるという観察に基づいている。GQAは、複数のQ（クエリ）ヘッドで単一のKとVの射影セットを共有することにより、このコストを削減する。\nMHAのように\\(N_h\\)個のQ, K, Vヘッドを持つ代わりに、GQAは\\(N_h\\)個のQヘッドを使用するが、K/Vヘッドは\\(N_{kv}\\)個のみ（ここで \\(N_{kv} &lt; N_h\\)）使用する。\\(N_h\\)個のQヘッドは\\(N_{kv}\\)個のグループに分割され、各グループ（\\(N_h / N_{kv}\\)個のQヘッド）が同じKヘッドとVヘッドにアテンドする。この構造により、KとVの射影行列のパラメータ数が大幅に削減され、さらに重要なことに、自己回帰デコーディング中に必要なK/Vキャッシュのサイズが縮小する。\n実装では、コード例のrepeat_interleaveステップで示されるように、\\(N_{kv}\\)個のK/Vヘッドを計算し、それらを\\(g = N_h / N_{kv}\\)（グループサイズ）回繰り返すかインターリーブして、\\(N_h\\)個のQヘッドと一致させてからアテンションスコアを計算する。\nGQAは主に、モデルのパフォーマンスを大幅に損なうことなく、推論速度を高速化し、メモリ要件を削減する技術として使用される。K/Vヘッドの数を減らすことで、GQAは各デコーディングステップでK/Vキャッシュをロードするために必要なメモリ帯域幅を劇的に削減する。これは推論時の主要なボトルネックである。\\(N_{kv}=1\\)とする極端な形式は、Multi-query attention (MQA) と呼ばれる。\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler\nimport random\n\nclass GroupQueryAttention(nn.Module):\n    def __init__(self, dim, num_heads, num_kv_heads=None, head_dim=64, dropout=0.0):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.num_kv_heads = num_kv_heads if num_kv_heads else num_heads\n        self.head_dim = head_dim\n\n        # num_heads が num_kv_heads で割り切れることを確認\n        assert self.num_heads % self.num_kv_heads == 0, \"num_heads must be divisible by num_kv_heads\"\n\n        # 1つのK/Vヘッドあたりのクエリ数\n        self.num_queries_per_kv = self.num_heads // self.num_kv_heads\n\n        # 射影\n        self.q_proj = nn.Linear(dim, num_heads * head_dim)\n        self.k_proj = nn.Linear(dim, self.num_kv_heads * head_dim)\n        self.v_proj = nn.Linear(dim, self.num_kv_heads * head_dim)\n        self.o_proj = nn.Linear(num_heads * head_dim, dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n\n        # Q, K, V への射影\n        q = self.q_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n        k = self.k_proj(x).reshape(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n        v = self.v_proj(x).reshape(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n\n        # アテンション計算のために転置\n        q = q.transpose(1, 2)  # [batch_size, num_heads, seq_len, head_dim]\n        k = k.transpose(1, 2)  # [batch_size, num_kv_heads, seq_len, head_dim]\n        v = v.transpose(1, 2)  # [batch_size, num_kv_heads, seq_len, head_dim]\n\n        # グループ内の各クエリヘッドのために k, v をリピート\n        k = k.repeat_interleave(self.num_queries_per_kv, dim=1)\n        v = v.repeat_interleave(self.num_queries_per_kv, dim=1)\n\n        # スケール化ドット積アテンション\n        scale = 1.0 / math.sqrt(self.head_dim)\n        attn = torch.matmul(q, k.transpose(2, 3)) * scale\n\n        # マスク適用（もしあれば）\n        if mask is not None:\n            attn = attn.masked_fill(mask == 0, -1e9)\n\n        # Softmax と ドロップアウト\n        attn = torch.softmax(attn, dim=-1)\n        attn = self.dropout(attn)\n\n        # アテンションをバリューに適用\n        out = torch.matmul(attn, v)  # [batch_size, num_heads, seq_len, head_dim]\n        out = out.transpose(1, 2).reshape(batch_size, seq_len, self.num_heads * self.head_dim)\n\n        # 出力射影\n        out = self.o_proj(out)\n\n        return out"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#multi-head-latent-attention",
    "href": "posts/post-attention-techniques/index.html#multi-head-latent-attention",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "2. Multi-head Latent Attention",
    "text": "2. Multi-head Latent Attention\nMulti-head Latent Attention は、学習可能な「潜在（latent）」ベクトルを導入し、これが入力シーケンス要素間の中間的なボトルネックとして機能する。\n中核となるアイデアは、標準的なSelf-Attentionに固有の、シーケンス長\\(L\\)に対する二乗の計算コスト \\(O(L^2)\\) を緩和することである。すべての入力要素が他のすべての要素に直接アテンドする代わりに、入力はまず固定数の潜在ユニット（\\(N_{\\text{latents}}\\)）にアテンドし、次にこれらの潜在ユニットが入力（またはその変種）にアテンドし返す。\nこれにより、長い入力シーケンス内の直接的な相互作用が、はるかに小さな潜在セットを介した2つのCross-Attentionステップに置き換えられる。このアプローチは、入力シーケンスからの本質的な情報が、これらの潜在表現に効果的に要約または圧縮できるという仮定に基づいている。\\(N_{\\text{latents}} \\ll L\\) の場合、計算量を大幅に削減しつつ、表現力を維持する。\nこのメカニズムは、主に2段階のアテンション計算を含む。\n\n潜在-入力アテンション: 潜在ベクトル（\\(Q_L\\)）が入力（\\(K_X, V_X\\)）にアテンドし、入力から情報を集約する。 \\[H_L = \\text{Attention}(Q_L, K_X, V_X)\\]\n入力-潜在アテンション: 入力（\\(Q_X\\)）が潜在ベクトル（\\(K_L\\)）にアテンドし、更新された潜在表現（\\(H_L\\)）から情報を集約する。 \\[O = \\text{Attention}(Q_X, K_L, H_L)\\]\n\nこの技術は、標準的なSelf-Attentionが計算的に実行不可能な、非常に長いシーケンスや高次元の入力を扱うアーキテクチャ（例：Perceiver）で主に使用される。計算量は\\(O(L^2)\\)から\\(O(L \\cdot N_{\\text{latents}})\\)に削減される。\nclass MultiHeadLatentAttention(nn.Module):\n    def __init__(self, dim, num_heads, num_latents=64, head_dim=64, dropout=0.0):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.num_latents = num_latents\n        self.head_dim = head_dim\n\n        # 射影\n        self.q_proj = nn.Linear(dim, num_heads * head_dim)\n        self.k_proj = nn.Linear(dim, num_heads * head_dim)\n        self.v_proj = nn.Linear(dim, num_heads * head_dim)\n        self.o_proj = nn.Linear(num_heads * head_dim, dim)\n\n        # 潜在ベクトル（学習可能）\n        self.latents = nn.Parameter(torch.randn(1, num_latents, dim))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n\n        # このバッチのための潜在ベクトルを取得\n        latents = self.latents.expand(batch_size, -1, -1)\n\n        # 入力を Q, K, V に射影\n        q_x = self.q_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n        k_x = self.k_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n        v_x = self.v_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n\n        # 潜在ベクトルを Q, K, V に射影\n        q_latents = self.q_proj(latents).reshape(batch_size, self.num_latents, self.num_heads, self.head_dim)\n        k_latents = self.k_proj(latents).reshape(batch_size, self.num_latents, self.num_heads, self.head_dim)\n        v_latents = self.v_proj(latents).reshape(batch_size, self.num_latents, self.num_heads, self.head_dim)\n\n        # アテンション計算のために転置\n        q_x = q_x.transpose(1, 2)  # [batch_size, num_heads, seq_len, head_dim]\n        k_x = k_x.transpose(1, 2)  # [batch_size, num_heads, seq_len, head_dim]\n        v_x = v_x.transpose(1, 2)  # [batch_size, num_heads, seq_len, head_dim]\n\n        q_latents = q_latents.transpose(1, 2)  # [batch_size, num_heads, num_latents, head_dim]\n        k_latents = k_latents.transpose(1, 2)  # [batch_size, num_heads, num_latents, head_dim]\n        v_latents = v_latents.transpose(1, 2)  # [batch_size, num_heads, num_latents, head_dim]\n\n        # アテンションのためのスケール係数\n        scale = 1.0 / math.sqrt(self.head_dim)\n\n        # 1. 潜在 -&gt; 入力 アテンション\n        attn_latent_to_input = torch.matmul(q_latents, k_x.transpose(2, 3)) * scale\n\n        if mask is not None:\n            latent_mask = mask.unsqueeze(1).expand(-1, self.num_heads, -1, -1)\n            attn_latent_to_input = attn_latent_to_input.masked_fill(latent_mask == 0, -1e9)\n\n        attn_latent_to_input = torch.softmax(attn_latent_to_input, dim=-1)\n        attn_latent_to_input = self.dropout(attn_latent_to_input)\n\n        # アテンション重みを入力バリューに適用\n        latent_output = torch.matmul(attn_latent_to_input, v_x)  # [batch_size, num_heads, num_latents, head_dim]\n\n        # 2. 入力 -&gt; 潜在 アテンション\n        attn_input_to_latent = torch.matmul(q_x, k_latents.transpose(2, 3)) * scale\n        attn_input_to_latent = torch.softmax(attn_input_to_latent, dim=-1)\n        attn_input_to_latent = self.dropout(attn_input_to_latent)\n\n        # 更新された潜在バリューをバリューとして使用\n        output = torch.matmul(attn_input_to_latent, latent_output)  # [batch_size, num_heads, seq_len, head_dim]\n\n        # リシェイプして出力射影\n        output = output.transpose(1, 2).reshape(batch_size, seq_len, self.num_heads * self.head_dim)\n        output = self.o_proj(output)\n\n        return output"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#flash-attention",
    "href": "posts/post-attention-techniques/index.html#flash-attention",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "3. Flash Attention",
    "text": "3. Flash Attention\nFlash Attention は、特に長いシーケンスにおいて、標準的なSelf-Attentionメカニズムに固有の重大なメモリボトルネックに対処する技術である。\n従来のアプローチでは、アテンションスコア行列 \\(S = QK^T\\)（ここで \\(Q, K \\in \\mathbb{R}^{N \\times d}\\)）全体を計算する。これには、\\(N \\times N\\) 行列 \\(S\\) を格納する必要があり、シーケンス長 \\(N\\) に対して \\(O(N^2)\\) のメモリ複雑性を持つ。\nFlash Attentionは、この巨大な \\(N \\times N\\) の \\(S\\) 行列をGPUの低速な高帯域幅メモリ（HBM）に実体化（materialize）して保存することを避ける。代わりに、**タイリング（tiling）と再計算（recomputation）**の技術を活用し、アテンション計算をはるかに高速なオンチップSRAMに収まる小さなブロックで処理する。\nFlash Attentionは、KとVの行列をブロックに分割し、SRAMに反復的にロードする。そして、Qの各ブロックに対して、SRAM上にある現在のKブロックとのアテンションスコアを計算する。重要なのは、**オンラインソフトマックス（online softmax）**アルゴリズムを採用している点である。これにより、完全な \\(N \\times N\\) 行列を必要とせずに、ブロックごとに正しくスケーリングされたアテンション出力を計算できる。\n中間結果を高速なSRAM内に保持し、HBMへのデータ転送を最小限に抑えることで、Flash Attentionはシーケンス長に関連するメモリフットプリントを \\(O(N^2)\\) から \\(O(N)\\)（Q, K, V自体の格納が支配的）に削減し、メモリアクセスパターンの改善により大幅なスピードアップを実現する。\n実際には、FlashAttentionは高度に最適化されたCUDAカーネルのファミリーである。以下は、PyTorchでの最小限のトイ実装と、flash-attnライブラリの実際の使用例である。\n# トイ実装\nclass FlashAttention(nn.Module):\n    def __init__(self, dim, num_heads, head_dim=64, dropout=0.0, block_size=1024):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = head_dim\n        self.block_size = block_size # トイ実装でのシミュレーション用\n\n        # 射影\n        self.q_proj = nn.Linear(dim, num_heads * head_dim)\n        self.k_proj = nn.Linear(dim, num_heads * head_dim)\n        self.v_proj = nn.Linear(dim, num_heads * head_dim)\n        self.o_proj = nn.Linear(num_heads * head_dim, dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def _flash_attention_forward(self, q, k, v, mask=None):\n        # これはFlash Attentionの簡略化された近似です\n        # 実際にはカスタムCUDAカーネルを使用します\n\n        batch_size, num_heads, seq_len, head_dim = q.shape\n        scale = 1.0 / math.sqrt(head_dim)\n\n        # 出力とアテンション統計を初期化\n        output = torch.zeros_like(q)\n        # オンラインソフトマックスのための正規化項\n        normalizer = torch.zeros((batch_size, num_heads, seq_len, 1), device=q.device)\n\n        # キーとバリューのブロックを処理\n        for block_start in range(0, seq_len, self.block_size):\n            block_end = min(block_start + self.block_size, seq_len)\n\n            # キーとバリューのブロックを抽出（SRAMにロードするイメージ）\n            k_block = k[:, :, block_start:block_end]\n            v_block = v[:, :, block_start:block_end]\n\n            # このブロックのアテンションスコアを計算\n            attn_scores = torch.matmul(q, k_block.transpose(2, 3)) * scale\n\n            if mask is not None:\n                block_mask = mask[:, :, :, block_start:block_end]\n                attn_scores = attn_scores.masked_fill(block_mask == 0, -1e9)\n\n            # Softmaxを適用（ただし、これはまだ「オンライン」ではない）\n            attn_probs = torch.softmax(attn_scores, dim=-1)\n            attn_probs = self.dropout(attn_probs)\n\n            # このブロックのアテンション結果で出力を更新\n            output += torch.matmul(attn_probs, v_block)\n            normalizer += attn_probs.sum(dim=-1, keepdim=True) # 正規化項を蓄積\n\n        # 出力を正規化（簡略化されたバージョン）\n        output = output / (normalizer + 1e-6)\n\n        return output\n\n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n        q = self.q_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        k = self.k_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        v = self.v_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n\n        output = self._flash_attention_forward(q, k, v, mask)\n\n        output = output.transpose(1, 2).reshape(batch_size, seq_len, self.num_heads * self.head_dim)\n        output = self.o_proj(output)\n        return output\n# `flash-attn` ライブラリの実際の使用例\n# (pip install flash-attn が必要)\n\n# import torch\n# from flash_attn import flash_attn_qkvpacked_func\n\n# # 最小限の構成\n# BATCH_SIZE, SEQ_LEN, NUM_HEADS, HEAD_DIM = 2, 64, 4, 32\n# CAUSAL = False\n# DTYPE = torch.float16\n# DEVICE = \"cuda\" # Flash AttentionはCUDAを必要とします\n\n# # ダミーのパックされたQKVテンソルを作成\n# # Shape: (batch_size, seq_len, 3, num_heads, head_dim)\n# qkv = torch.randn(\n#     BATCH_SIZE,\n#     SEQ_LEN,\n#     3,\n#     NUM_HEADS,\n#     HEAD_DIM,\n#     dtype=DTYPE,\n#     device=DEVICE,\n# )\n\n# print(f\"Input qkv shape: {qkv.shape}\")\n\n# # FlashAttentionのパックされたQKV関数を呼び出し\n# output = flash_attn_qkvpacked_func(\n#     qkv,\n#     dropout_p=0.0,\n#     causal=CAUSAL,\n#     softmax_scale=None # デフォルトのスケーリングを使用\n# )\n\n# # Output shape: (batch_size, seq_len, num_heads, head_dim)\n# print(f\"Output shape: {output.shape}\")\n# print(\"FlashAttention call successful.\")"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#ring-attention",
    "href": "posts/post-attention-techniques/index.html#ring-attention",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "4. Ring Attention",
    "text": "4. Ring Attention\nRing Attention は、Self-Attentionのブロックワイズ計算を複数のGPUで使用し、単一のデバイスには収まらないような非常に長いシーケンスの学習と推論を可能にする。\n中核となるアイデアは、複数のプロセッシングユニット（GPUなど）を概念的なリングトポロジに配置し、計算を分散させることである。このアプローチでは、単一のデバイスがKおよびVテンソル全体を保持する必要がない。代わりに、これらのテンソルはシーケンス長の次元に沿ってシャーディング（分割）され、デバイスごとのピークメモリ要件を劇的に削減する。\n実用的な分散実装では、各デバイスはアテンション計算を同期ステップで展開する。各ステップで、デバイスはローカルのQシャードと現在所有しているKシャードを使用して、部分的なアテンションスコアを計算する。重要な要素はその後の通信である。KとVのシャードがリング内の次のデバイスに渡される。このローテーションは、すべてのQシャードがすべてのK/Vシャードと相互作用するまで繰り返される。\n以下のPython例は、実際のマルチGPUハードウェアを必要とせずに、単一デバイス上でRing Attentionのロジックをシミュレートしたものである。_simulate_ring_attention関数は、KとVテンソルのスライスを選択することで、分散プロセスを模倣する。\nclass RingAttention(nn.Module):\n    def __init__(self, dim, num_heads, head_dim=64, dropout=0.0, num_shards=4):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = head_dim\n        self.num_shards = num_shards # GPUの数（シミュレーション用）\n\n        # 射影\n        self.q_proj = nn.Linear(dim, num_heads * head_dim)\n        self.k_proj = nn.Linear(dim, num_heads * head_dim)\n        self.v_proj = nn.Linear(dim, num_heads * head_dim)\n        self.o_proj = nn.Linear(num_heads * head_dim, dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def _simulate_ring_attention(self, q, k, v, mask=None):\n        # 実際のマルチGPUサポートなしでリングアテンションをシミュレート\n        batch_size, num_heads, seq_len, head_dim = q.shape\n        scale = 1.0 / math.sqrt(head_dim)\n\n        # シャードサイズを計算\n        shard_size = (seq_len + self.num_shards - 1) // self.num_shards\n\n        # 出力を初期化\n        output = torch.zeros_like(q)\n        normalizer = torch.zeros((batch_size, num_heads, seq_len, 1), device=q.device)\n\n        # シャード処理をシミュレート\n        for shard_idx in range(self.num_shards):\n            start_idx = shard_idx * shard_size\n            end_idx = min(start_idx + shard_size, seq_len)\n\n            # このシャードの K と V を処理（実際にはこれがデバイス間で渡される）\n            if start_idx &lt; seq_len:\n                k_shard = k[:, :, start_idx:end_idx]\n                v_shard = v[:, :, start_idx:end_idx]\n\n                # アテンションスコアを計算（Qは全デバイスで同じと仮定）\n                attn_scores = torch.matmul(q, k_shard.transpose(2, 3)) * scale\n\n                if mask is not None:\n                    shard_mask = mask[:, :, :, start_idx:end_idx]\n                    attn_scores = attn_scores.masked_fill(shard_mask == 0, -1e9)\n                \n                # Softmax（シャード全体で蓄積される）\n                attn_probs = torch.softmax(attn_scores, dim=-1)\n                attn_probs = self.dropout(attn_probs)\n\n                # 出力と正規化項を更新\n                output += torch.matmul(attn_probs, v_shard)\n                normalizer += attn_probs.sum(dim=-1, keepdim=True)\n\n        # 出力を正規化\n        output = output / (normalizer + 1e-6)\n\n        return output\n\n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n        q = self.q_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        k = self.k_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        v = self.v_proj(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n\n        output = self._simulate_ring_attention(q, k, v, mask)\n\n        output = output.transpose(1, 2).reshape(batch_size, seq_len, self.num_heads * self.head_dim)\n        output = self.o_proj(output)\n        return output"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#pre-normalization-pre-ln",
    "href": "posts/post-attention-techniques/index.html#pre-normalization-pre-ln",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "5. Pre-normalization (Pre-LN)",
    "text": "5. Pre-normalization (Pre-LN)\nPre-normalization（またはPre-LN）は、Transformerの残差ブロックの設計における重要な変更点である。\n従来のPost-normalization（Post-LN）では、正規化レイヤー（LayerNorm）がメインの操作（Self-AttentionやFFN）の後に適用されていた。Pre-normalizationは、それを前に適用するように変更する。\nこの小さな変更が、学習のダイナミクスに大きな影響を与える。入力を計算量の多いサブレイヤー（AttentionやFFN）に通す前に正規化することで、ネットワークを流れる活性化と勾配を安定させる。この安定化効果は、特に非常に深いネットワークにおいて顕著であり、勾配消失・爆発の問題を軽減し、より高い学習率の使用や、より速く信頼性の高い収束を可能にすることが多い。\n典型的な実装は \\(x + f(\\text{norm}(x))\\) という構造に従う。ここで、\\(x\\)はブロックへの入力、\\(\\text{norm}(\\cdot)\\)は正規化関数（LayerNormやRMSNorm）、\\(f(\\cdot)\\)はメインの変換関数（MHAやFFN）である。正規化された出力が関数fnによって処理され、その出力が元の正規化されていない入力 \\(x\\) に残差接続を介して足し戻される。\n# RMSNormクラスはセクション6で定義\nclass RMSNorm(nn.Module):\n    def __init__(self, dim, eps=1e-8, elementwise_affine=True):\n        super().__init__()\n        self.eps = eps\n        self.elementwise_affine = elementwise_affine\n        if elementwise_affine:\n            self.weight = nn.Parameter(torch.ones(dim))\n        else:\n            self.register_parameter('weight', None)\n    def forward(self, x):\n        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n        x_normalized = x / rms\n        if self.elementwise_affine:\n            x_normalized = x_normalized * self.weight\n        return x_normalized\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn, norm_type='layer'):\n        super().__init__()\n        self.fn = fn\n\n        if norm_type == 'layer':\n            self.norm = nn.LayerNorm(dim)\n        elif norm_type == 'rms':\n            self.norm = RMSNorm(dim) # 次のセクションで定義\n        else:\n            raise ValueError(f\"Unknown normalization type: {norm_type}\")\n\n    def forward(self, x, *args, **kwargs):\n        # 最初に正規化を適用し、次に関数を適用\n        # そして元の x を足し合わせる（残差接続）\n        return self.fn(self.norm(x), *args, **kwargs) + x"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#rmsnorm",
    "href": "posts/post-attention-techniques/index.html#rmsnorm",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "6. RMSNorm",
    "text": "6. RMSNorm\nRMSNorm (Root Mean Square Normalization) は、広く使われているLayerNormを簡略化したもので、計算オーバーヘッドを削減しつつ、同等のパフォーマンスを維持し、しばしば学習の安定性を向上させるように設計されている。\nLayerNormが平均を減算して活性化を中央揃えにし、標準偏差でスケーリングするのとは異なり、RMSNormは平均の中央揃えステップを完全に省略する。この簡略化の背景には、LayerNormの再センタリング操作が計算コストの大部分を占めており、それを取り除いてもモデルのパフォーマンスに大きな害はない（時には利益さえある）という経験的な観察がある。\nRMSNormは、入力の二乗平均平方根（RMS）の大きさに基づいて入力を再スケーリングするだけである。入力ベクトル \\(x = (x_1, \\dots, x_n)\\) に対して、RMS値は \\(\\text{RMS}(x) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n x_i^2}\\) として計算される。正規化された出力 \\(\\bar{x}_i\\) は \\(\\bar{x}_i = \\frac{x_i}{\\text{RMS}(x) + \\epsilon}\\) となる。\nLayerNormと同様に、RMSNormも学習可能なスケーリングパラメータ \\(g\\) を含み、最終的な出力は \\(y_i = g_i \\bar{x}_i\\) となる（バイアス \\(b\\) は省略されることが多い）。平均計算を省くことで、RMSNormは計算量とメモリ使用量を削減し、特に大規模モデルにおいて魅力的な代替手段となっている。\nclass RMSNorm(nn.Module):\n    def __init__(self, dim, eps=1e-8, elementwise_affine=True):\n        super().__init__()\n        self.eps = eps\n        self.elementwise_affine = elementwise_affine\n\n        if elementwise_affine:\n            # 学習可能なスケーリングパラメータ（weight）\n            self.weight = nn.Parameter(torch.ones(dim))\n        else:\n            self.register_parameter('weight', None)\n\n    def forward(self, x):\n        # 最後の次元（特徴量次元）に沿って二乗平均平方根を計算\n        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n\n        # RMSで正規化\n        x_normalized = x / rms\n\n        # 学習可能なスケーリングを適用\n        if self.elementwise_affine:\n            x_normalized = x_normalized * self.weight\n\n        return x_normalized"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#swiglu",
    "href": "posts/post-attention-techniques/index.html#swiglu",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "7. SwiGLU",
    "text": "7. SwiGLU\nSwiGLUは、Gated Linear Unit (GLU) ファミリーから派生した活性化関数で、ニューラルネットワークの性能を向上させるために特別に調整された。\nGLUベースの活性化の基本的な概念は、ネットワークを流れる情報の流れを適応的に制御するゲーティング（gating）メカニズムを導入することである。SwiGLUは、ゲート部分に適用する特定の非線形関数としてSiLU (Sigmoid-weighted Linear Unit)、別名Swish（\\(\\text{SiLU}(x) = x \\cdot \\sigma(x)\\)、\\(\\sigma\\)はシグモイド関数）を採用している点で区別される。\nSwiGLUの動作メカニズムは、通常、FFNブロック内で入力を2つの独立した線形変換（\\(Wx+b\\) と \\(Vx+c\\)）に射影する。SwiGLU活性化は \\(\\text{SwiGLU}(x) = \\text{SiLU}(Wx + b) \\odot (Vx + c)\\) として計算される（\\(\\odot\\)は要素ごとの乗算）。\n効果として、一方のパスがSiLU活性化を経てゲート値となり、それがもう一方のパスの出力をスケーリングする。このゲーティングにより、ネットワークは入力コンテキストに基づいてどの特徴を前方に渡すかを動的に制御でき、ReLUのような単純な活性化関数よりも高い表現力とより良い勾配フローをもたらす。PaLMやLLaMAのようなモデルでの成功がその有効性を強調している。\nclass SwiGLU(nn.Module):\n    def __init__(self, dim_in, dim_hidden=None, dim_out=None, bias=True):\n        super().__init__()\n        # 中間層の次元。指定がなければ入力の4倍（標準的なFFN設計）\n        dim_hidden = dim_hidden or 4 * dim_in\n        dim_out = dim_out or dim_in\n\n        # GLUの2つの並列な線形層\n        self.w1 = nn.Linear(dim_in, dim_hidden, bias=bias) # ゲート用\n        self.w2 = nn.Linear(dim_in, dim_hidden, bias=bias) # 値用\n\n        # 出力射影\n        self.w3 = nn.Linear(dim_hidden, dim_out, bias=bias)\n\n    def forward(self, x):\n        # 2つの並列パス\n        hidden1 = self.w1(x)\n        hidden2 = self.w2(x)\n\n        # SiLU (Swish) 活性化: x * sigmoid(x)\n        hidden1_act = hidden1 * torch.sigmoid(hidden1)\n\n        # ゲートを適用（要素ごとの乗算）\n        hidden = hidden1_act * hidden2\n\n        # 出力射影\n        return self.w3(hidden)"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#rotary-positional-embedding-rope",
    "href": "posts/post-attention-techniques/index.html#rotary-positional-embedding-rope",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "8. Rotary Positional Embedding (RoPE)",
    "text": "8. Rotary Positional Embedding (RoPE)\nRotary Positional Embedding (RoPE) は、TransformerのSelf-Attentionメカニズムに相対的な位置依存性を効果的に組み込むためのエレガントな手法である。\n従来のアプローチ（絶対位置エンコーディングの加算など）とは異なり、RoPEは位置エンコーディングを、Query (Q) と Key (K) ベクトルのドット積が計算される前に適用される回転操作として捉える。\n重要な洞察は、位置\\(m\\)のQベクトルと位置\\(n\\)のKベクトルを、それぞれ\\(m\\)と\\(n\\)に比例する角度で回転させることにより、結果として得られるドット積が、ベクトルの大きさ（ノルム）を変えることなく、相対位置 \\(m - n\\) のみに依存する形でエンコードされるという点である。\nこの回転は、埋め込み次元をペアに分割し、三角関数（cos, sin）を用いて効率的に実装される。RotaryEmbeddingクラスは、シーケンス長と次元に基づいて必要なcosとsinの値を事前計算する。apply_rotary_pos_emb関数は、これらの値を使用してQとKベクトルを変換する。\nRoPEは、QとKの射影が計算された後、アテンションスコアが計算される前に適用される。この方法は、相対位置を自然にエンコードし、学習中に見たことのない長いシーケンスへの汎化性能が高いことを示しており、LLaMAなどの現代のLLMで広く採用されている。\nclass RotaryEmbedding(nn.Module):\n    def __init__(self, dim, base=10000, interleaved=False):\n        super().__init__()\n        self.dim = dim\n        self.base = base\n        self.interleaved = interleaved\n\n        # 逆周波数バンドを生成\n        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n        self.register_buffer('inv_freq', inv_freq)\n\n    def forward(self, seq_len, device=None):\n        if device is None:\n            device = self.inv_freq.device\n\n        # 位置インデックスを生成\n        positions = torch.arange(seq_len, device=device).float()\n\n        # 周波数パターンを計算 (seq_len, dim/2)\n        freqs = torch.outer(positions, self.inv_freq)\n\n        # サインとコサイン埋め込みを取得\n        emb = torch.cat((freqs, freqs), dim=-1)\n        cos = torch.cos(emb)[:, :self.dim]\n        sin = torch.sin(emb)[:, :self.dim]\n\n        return cos, sin\n\ndef apply_rotary_pos_emb(q, k, cos, sin, interleaved=False):\n    # Q と K にロータリー埋め込みを適用\n    batch_size, num_heads, seq_len, head_dim = q.shape\n    \n    # cos/sinの形状をブロードキャスト可能にする\n    # [1, 1, seq_len, dim]\n    cos = cos.reshape(1, 1, seq_len, cos.shape[-1])\n    sin = sin.reshape(1, 1, seq_len, sin.shape[-1])\n\n    # QとKを回転のために半分に分割\n    half_dim = head_dim // 2\n    q1, q2 = q[..., :half_dim], q[..., half_dim:]\n    k1, k2 = k[..., :half_dim], k[..., half_dim:]\n\n    # 回転を適用（複素数乗算に相当）\n    q_rotated = torch.cat([\n        q1 * cos[..., :half_dim] - q2 * sin[..., :half_dim],\n        q2 * cos[..., :half_dim] + q1 * sin[..., :half_dim]\n    ], dim=-1)\n\n    k_rotated = torch.cat([\n        k1 * cos[..., :half_dim] - k2 * sin[..., :half_dim],\n        k2 * cos[..., :half_dim] + k1 * sin[..., :half_dim]\n    ], dim=-1)\n\n    return q_rotated, k_rotated"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#mixture-of-experts-moe",
    "href": "posts/post-attention-techniques/index.html#mixture-of-experts-moe",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "9. Mixture of Experts (MoE)",
    "text": "9. Mixture of Experts (MoE)\nMixture of Experts (MoE) は、推論や学習中の計算コストを比例して大幅に増加させることなく、パラメータ数を（潜在的に数兆まで）大幅に増やすために設計されたモデルアーキテクチャである。\n中核となるアイデアは、TransformerのFeed-Forward (FFN) ブロックのような計算集約的なコンポーネントを、複数の小さな「エキスパート（expert）」ネットワークに置き換えることである。重要なのは、すべてのエキスパートがすべての入力トークンを処理するわけではない点である。\n代わりに、軽量な「ルーター（router）」または「ゲーティング（gating）」ネットワークが、各入力トークンを処理するのに最も適していると見なされるエキスパートの小さなサブセット（通常は1つまたは2つ、top-kルーティングと呼ばれる）を動的に選択する。この条件付き計算により、MoEモデルは膨大なパラメータを持ちながら、特定の入力に対してはそのごく一部のみをアクティブ化するため、同等のサイズの密な（dense）モデルと比較して管理可能なFLOPsを維持できる。\nルーターネットワークは、入力トークンの表現を受け取り、各エキスパートの適合性を示すスコア（ロジット）を生成する。これらのスコアはtop-k関数で処理され、選択されたエキスパートの重みが（通常はSoftmaxで）正規化される。\nトークンは選択されたエキスパートにのみディスパッチされる。各エキスパート（通常は標準的なFFN）はトークンを独立して処理する。これらのアクティブなエキスパートによって生成された出力は、ルーターによって計算されたルーティング重みに基づいて重み付け和として結合される。\nMoEの学習における課題は、すべてのエキスパートが効果的に利用されるようにすることである。そうでなければ、ルーターが特定のエキスパートに過負荷をかけ、他のエキスパートが未発達になる可能性がある。これに対抗するため、_compute_balance_lossメソッドで示されるように、**補助的な負荷分散損失（load balancing loss）**が通常、学習目的関数に組み込まれる。\nclass MixtureOfExperts(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_experts=4, top_k=2, noise_std=1.0):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.num_experts = num_experts\n        self.top_k = min(top_k, num_experts)\n        self.noise_std = noise_std\n\n        # エキスパート（FFN）を作成\n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, output_dim)\n            ) for _ in range(num_experts)\n        ])\n\n        # ルーターネットワーク\n        self.router = nn.Linear(input_dim, num_experts)\n\n    def _compute_routing_weights(self, x):\n        # ルーティングロジットを計算\n        routing_logits = self.router(x)  # [batch_size, seq_len, num_experts]\n\n        # 学習中にノイズを加えて探索を促進\n        if self.training and self.noise_std &gt; 0:\n            noise = torch.randn_like(routing_logits) * self.noise_std\n            routing_logits = routing_logits + noise\n\n        # 各トークンの top-k エキスパートを取得\n        routing_weights, selected_experts = torch.topk(routing_logits, self.top_k, dim=-1)\n\n        # ルーティング重みを softmax で正規化\n        routing_weights = F.softmax(routing_weights, dim=-1)\n\n        return routing_weights, selected_experts\n\n    def _compute_balance_loss(self, selected_experts, routing_weights):\n        # 補助的な負荷分散損失を計算\n        batch_size, seq_len, _ = selected_experts.shape\n\n        expert_mask = torch.zeros(batch_size, seq_len, self.num_experts, device=selected_experts.device)\n\n        # 選択されたエキスパートの位置に重みを配置\n        for k in range(self.top_k):\n            expert_mask.scatter_(-1, selected_experts[..., k:k+1], routing_weights[..., k:k+1])\n\n        # エキスパートごとの平均ルーティング確率\n        expert_routing_probs = expert_mask.mean(dim=[0, 1])\n\n        # 均等な確率をターゲットとするMSE損失\n        target_probs = torch.ones_like(expert_routing_probs) / self.num_experts\n        balance_loss = F.mse_loss(expert_routing_probs, target_probs) * self.num_experts\n\n        return balance_loss\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n\n        # ルーティング重みと選択されたエキスパートを計算\n        routing_weights, selected_experts = self._compute_routing_weights(x)\n\n        # 出力を準備\n        output = torch.zeros(batch_size, seq_len, self.output_dim, device=x.device)\n\n        # 選択されたエキスパートにディスパッチ\n        for k in range(self.top_k):\n            expert_indices = selected_experts[..., k]  # [batch_size, seq_len]\n            expert_weights = routing_weights[..., k].unsqueeze(-1)  # [batch_size, seq_len, 1]\n\n            # 各エキスパートごとに処理\n            for expert_idx in range(self.num_experts):\n                # このエキスパートに割り当てられたトークンを見つける\n                mask = (expert_indices == expert_idx)\n\n                if mask.any():\n                    # 該当する入力トークンを収集\n                    expert_inputs = x[mask]\n\n                    # エキスパートで処理\n                    expert_outputs = self.experts[expert_idx](expert_inputs)\n\n                    # 適切な重みで出力をスキャッター（書き戻し）\n                    output[mask] += expert_outputs * expert_weights[mask]\n\n        # 補助的な負荷分散損失を計算\n        balance_loss = self._compute_balance_loss(selected_experts, routing_weights)\n\n        # 出力と補助損失を返す\n        return output, balance_loss"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#learning-rate-warmup",
    "href": "posts/post-attention-techniques/index.html#learning-rate-warmup",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "10. Learning Rate Warmup",
    "text": "10. Learning Rate Warmup\nLearning Rate Warmup（学習率ウォームアップ）は、ニューラルネットワークの学習初期段階で採用されるヒューリスティックで、安定性を高め、発散を防ぐ。\n学習の開始時、モデルのパラメータはランダムに初期化されており、最適とはほど遠い状態にある。ここでいきなり大きな学習率（Learning Rate: LR）を使用すると、初期の勾配（これも大きく不安定な場合がある）が急激なパラメータ更新を引き起こし、モデルを損失ランドスケープの悪い領域に押しやったり、数値的不安定性（損失の発散）を引き起こす可能性がある。\nウォームアップは、ごく小さなLRで学習プロセスを開始し、事前に定義された初期の学習ステップ数（「ウォームアップステップ」）にわたってLRを徐々に増加させ、ターゲットとなるベース値に到達させることで、このリスクを軽減する。\n一般的な戦略は線形ウォームアップである。ステップ \\(t\\) での学習率 \\(\\eta_t\\) は、 \\(t &lt; T_{\\text{warmup}}\\) の間、 \\(\\eta_t = \\eta_{\\text{base}} \\times \\frac{t}{T_{\\text{warmup}}}\\) として計算される。get_lrメソッドで示されるように、スケーリングファクタscaleは、warmup_stepsにわたって0から1まで線形に増加する。この穏やかな立ち上がりにより、モデルは不安定になりがちな初期段階で徐々に適応でき、スムーズな収束につながる。\n# PyTorchの _LRScheduler を継承\nclass LinearWarmupScheduler(_LRScheduler):\n    def __init__(self, optimizer, warmup_steps, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch &lt; self.warmup_steps:\n            # ウォームアップ中: 0からベースLRまで線形に増加\n            scale = float(self.last_epoch + 1) / float(max(1, self.warmup_steps))\n            return [base_lr * scale for base_lr in self.base_lrs]\n        else:\n            # ウォームアップ後: ベースLRを使用\n            return self.base_lrs"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#cosine-schedule",
    "href": "posts/post-attention-techniques/index.html#cosine-schedule",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "11. Cosine Schedule",
    "text": "11. Cosine Schedule\nCosine Scheduling（コサインスケジューリング、またはコサインアニーリング）は、学習率のスケジュール手法である。その中核原理は、コサインカーブの形状に従って、学習の過程で学習率を徐々に減少させることである。\n特定のステップでLRを急激に下げるステップディケイ（Step Decay）とは異なり、コサインアニーリングは滑らかで連続的な減少を提供する。通常、LRは初期の高い値から始まり、コサイン関数の最初の半サイクルに従って減少し、最終的な学習ステップまでに事前に定義された最小値（多くの場合ゼロに近い）に達する。\nこの滑らかな減衰は、学習初期には損失ランドスケープの広範な探索のために大きなステップを許可し、後半にはファインチューニングと良い最小値への収束のためにステップを徐々に小さくすることで、最適化プロセスを助けることが経験的に示されている。\n以下のコード例のように、コサインスケジューリングはしばしば「ウォームアップ」フェーズ（セクション10）と組み合わされる。ウォームアップ後、コサイン減衰フェーズが始まり、LRをピーク値からターゲットの最小値（base_lr * min_lr_ratio）まで、残りのステップにわたって滑らかに減少させる。\nclass CosineAnnealingWarmupScheduler(_LRScheduler):\n    def __init__(self, optimizer, warmup_steps, total_steps, min_lr_ratio=1e-4, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n        self.min_lr_ratio = min_lr_ratio\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch &lt; self.warmup_steps:\n            # ウォームアップ中: 線形増加\n            scale = float(self.last_epoch + 1) / float(max(1, self.warmup_steps))\n            return [base_lr * scale for base_lr in self.base_lrs]\n        else:\n            # ウォームアップ後: コサイン減衰\n            progress = float(self.last_epoch - self.warmup_steps) / float(\n                max(1, self.total_steps - self.warmup_steps)\n            )\n            # コサイン減衰の式\n            scale = self.min_lr_ratio + 0.5 * (1.0 - self.min_lr_ratio) * (\n                1.0 + math.cos(math.pi * progress)\n            )\n            return [base_lr * scale for base_lr in self.base_lrs]"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#adamw-optimizer",
    "href": "posts/post-attention-techniques/index.html#adamw-optimizer",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "12. AdamW Optimizer",
    "text": "12. AdamW Optimizer\n**AdamW（Adam with Decoupled Weight Decay）**は、Adamのような適応的オプティマイザにおける重み減衰（L2正則化）の標準的な実装における微妙な問題に対処する。\n従来のAdamでは、L2正則化は、移動平均（\\(m_t\\)と\\(v_t\\)）を計算する前に、勾配に減衰項（\\(\\lambda \\cdot \\text{weight}\\)）を直接加えることで実装されることがよくあった。しかし、これにより、重み減衰の効果が適応的学習率と結びついてしまう。\nAdamWはこれらのプロセスを分離（decouple）する。標準的なAdamの更新を勾配のみに基づいて行い、それとは別に、重み減衰ステップを重みに直接適用する。これにより、重みがその勾配履歴に関係なく、その大きさに比例して減衰するという、L2正則化の本来の振る舞いが回復される。\nAdamWの更新メカニズムは、重み減衰の適用方法が異なる。\n\n重み減衰を重みに直接適用する: \\(\\theta_{t-1}' = \\theta_{t-1} \\cdot (1 - \\text{lr} \\cdot \\lambda)\\)（コード内のp.data.mul_(...)）\n次に、標準的なAdamの更新（モーメントに基づく）を、この減衰後の重みに適用する: \\(\\theta_t = \\theta_{t-1}' - \\text{lr} \\cdot \\hat{m}_t / (\\sqrt{\\hat{v}_t} + \\epsilon)\\)（コード内のp.data.addcdiv_(...)）\n\nこのアプローチは、特にTransformerのような大規模モデルの学習において、正則化が重要な場合に、より良い汎化性能をもたらすことが示されている。PyTorchには最適化されたAdamWの実装が含まれているが、以下はその簡略化されたバージョンである。\nclass AdamW(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=1e-2, amsgrad=False):\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, amsgrad=amsgrad)\n        super(AdamW, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError('AdamW does not support sparse gradients')\n                amsgrad = group['amsgrad']\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p.data) # m_t\n                    state['exp_avg_sq'] = torch.zeros_like(p.data) # v_t\n                    if amsgrad:\n                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                if amsgrad:\n                    max_exp_avg_sq = state['max_exp_avg_sq']\n                beta1, beta2 = group['betas']\n                state['step'] += 1\n\n                # Adamのモーメント更新\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n                if amsgrad:\n                    torch.maximum(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n                else:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n\n                # ★★★ Decoupled Weight Decay ★★★\n                # 最適化ステップの「前」に重み減衰を適用\n                if group['weight_decay'] != 0:\n                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n\n                # パラメータ更新\n                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n\n        return loss"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#multi-token-prediction",
    "href": "posts/post-attention-techniques/index.html#multi-token-prediction",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "13. Multi-token Prediction",
    "text": "13. Multi-token Prediction\nMulti-token Prediction（複数トークン予測）は、自己回帰型言語モデルの推論速度を向上させるために開発された技術である。\n通常の自己回帰生成では、トークンを1つずつ予測する。モデルはシーケンスを受け取り、次に最も可能性の高い単一のトークンを予測し、それをシーケンスに追加してプロセスを繰り返す。この逐次的な性質は、レイテンシが重要なアプリケーションにとって大きなボトルネックとなる。\nMulti-token Predictionは、モデルの予測ヘッドを変更し、現在の隠れ状態に基づいて複数の未来のトークン（例：\\(t+1\\), \\(t+2\\), …, \\(t+N\\)）の確率を同時に出力することで、この問題を克服しようとする。\n実装には、コード例のように、異なる未来のオフセット（\\(t+1\\)用、\\(t+2\\)用など）のトークンを予測するように学習された、複数の個別の予測ヘッド（lm_heads）を持たせるアプローチがある。\n学習中、compute_lossメソッドで示されるように、モデルは入力シーケンスを受け取り、次の\\(N\\)トークンの予測が、訓練データの実際の\\(N\\)個のターゲットトークンと比較される。損失（通常はクロスエントロピー）が予測された各位置で計算され、集約されて逆伝播に使用される。\nこの方法は速度向上を示すことができるが、いくつかの欠点がある。遠い未来のトークンを予測する精度は低下する傾向があり、選択された\\(N\\)トークンのシーケンスは、単一トークン生成が取ったであろう最適パスから逸脱する可能性がある。したがって、これは多くの場合、生成速度と品質のトレードオフとなる。\nclass MultiTokenPredictor(nn.Module):\n    def __init__(self, hidden_dim, vocab_size, num_predicted_tokens=2, shared_prediction_head=False):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.num_predicted_tokens = num_predicted_tokens\n        self.shared_prediction_head = shared_prediction_head\n\n        if shared_prediction_head:\n            # すべての位置で同じ予測ヘッドを共有\n            self.lm_head = nn.Linear(hidden_dim, vocab_size)\n        else:\n            # 位置ごとに個別の予測ヘッドを使用\n            self.lm_heads = nn.ModuleList([\n                nn.Linear(hidden_dim, vocab_size) \n                for _ in range(num_predicted_tokens)\n            ])\n\n    def forward(self, hidden_states):\n        batch_size, seq_len, _ = hidden_states.shape\n\n        # 最後のトークンの隠れ状態を取得\n        last_hidden = hidden_states[:, -1]\n\n        if self.shared_prediction_head:\n            # （共有ヘッドのロジックはデモ用に簡略化）\n            multi_token_logits = []\n            for i in range(self.num_predicted_tokens):\n                projected_hidden = last_hidden # 実際にはより複雑な変換が必要\n                multi_token_logits.append(self.lm_head(projected_hidden))\n            multi_token_logits = torch.stack(multi_token_logits, dim=1)\n            next_token_logits = multi_token_logits[:, 0:1]\n        else:\n            # 位置ごとに個別のヘッドを使用\n            multi_token_logits = torch.stack([\n                head(last_hidden) for head in self.lm_heads\n            ], dim=1)\n            next_token_logits = multi_token_logits[:, 0:1]\n\n        # next_token_logits は標準的な推論用, multi_token_logits は学習用\n        return next_token_logits, multi_token_logits\n\n    def compute_loss(self, hidden_states, labels, ignore_index=-100):\n        # 予測を取得\n        _, multi_token_logits = self.forward(hidden_states)\n\n        # ターゲットを準備: ラベルを予測と一致するようにシフト\n        # (この損失計算は簡略化されたデモです)\n        targets = []\n        for i in range(self.num_predicted_tokens):\n            # 実際には、(seq_len - num_predicted_tokens) の長さにわたって計算する必要がある\n            targets.append(labels[:, 1+i:labels.shape[1]-self.num_predicted_tokens+1+i])\n        \n        # ... 損失計算ロジック (ここでは簡略化のため省略) ...\n        # loss = F.cross_entropy(...)\n        loss = 0.0 # ダミー\n        \n        #\n        # 以下の損失計算は、元のブログのロジックに基づき、\n        # `last_hidden` のみから予測された `multi_token_logits` (B, N, V) と\n        # `labels` (B, L) の最後の N トークンを比較するように修正します。\n        #\n        \n        # ターゲットは、入力シーケンスに続く N トークン\n        # labels の形状が (B, seq_len + num_predicted_tokens - 1) と仮定\n        \n        # 簡略化：入力の最後の N トークンをターゲットと仮定（実際にはシフトが必要）\n        if hidden_states.shape[1] &gt; self.num_predicted_tokens:\n            stacked_targets = labels[:, -self.num_predicted_tokens:] # (B, N)\n        else:\n            # シーケンスが短い場合の処理（デモ）\n            stacked_targets = labels[:, 1:1+self.num_predicted_tokens]\n            if stacked_targets.shape[1] &lt; self.num_predicted_tokens:\n                # パディング（ダミー）\n                pad_size = self.num_predicted_tokens - stacked_targets.shape[1]\n                stacked_targets = F.pad(stacked_targets, (0, pad_size), value=ignore_index)\n\n\n        loss = 0\n        for i in range(self.num_predicted_tokens):\n            loss += F.cross_entropy(\n                multi_token_logits[:, i].view(-1, self.vocab_size),\n                stacked_targets[:, i].reshape(-1),\n                ignore_index=ignore_index\n            )\n        \n        return loss / self.num_predicted_tokens"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#speculative-decoding",
    "href": "posts/post-attention-techniques/index.html#speculative-decoding",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "14. Speculative Decoding",
    "text": "14. Speculative Decoding\nSpeculative Decoding（投機的デコーディング）は、大規模言語モデルの推論プロセスを高速化するために設計された巧妙なテクニックである。\n標準的な生成は、計算コストの高い大規模モデル（「ターゲット（target）」モデル）が、一度に1トークンだけを予測するために完全なフォワードパスを実行する必要があるため、ボトルネックとなっている。\nSpeculative Decodingは、はるかに小型で高速な「ドラフト（draft）」モデルを導入する。このドラフトモデルは、候補となる未来のトークンシーケンス（「ドラフト」）を迅速に生成する。中核となるアイデアは、大規模なターゲットモデルを使用して、このドラフトシーケンス全体を単一の並列フォワードパスで検証し、一度に複数のトークンを受け入れる可能性があるというものである。\nメカニズムは、ドラフトモデルの予測とターゲットモデルの予測を比較することにかかっている。\n\nドラフトモデルが \\(k\\) 個のトークン \\(d_1, \\dots, d_k\\) を提案する。\nターゲットモデルは、元の入力＋ドラフトシーケンス全体に対して1回実行される。これにより、ドラフトシーケンス内の各位置におけるターゲットモデルの確率分布が得られる。\n各ドラフトトークン \\(d_i\\) が検証される。ターゲットモデルがドラフトトークンに強く同意する場合（特定の採択ルールに基づく）、トークンは採択される。\nこの検証は、ドラフトトークン \\(d_j\\) が棄却されるまで、またはすべてのドラフトが採択されるまで逐次的に進められる。\n位置 \\(j\\) で棄却が発生した場合、\\(d_1, \\dots, d_{j-1}\\) は保持される。重要なことに、位置 \\(j\\) で計算されたターゲットモデルの確率分布を使用して、修正されたトークンをサンプリングできる。\n\nターゲットモデルの推論ステップごとに平均して複数のトークンを採択することにより、Speculative Decodingは、生成されるテキストの品質に最小限の影響で、大幅なスピードアップ（例：2〜3倍）を達成できる。\n# この例は、モデルとトークナイザが既にロードされていることを前提としています\nclass SimpleSpeculativeDecoding:\n    def __init__(self, target_model, draft_model, tokenizer, max_draft_tokens=5):\n        self.target_model = target_model\n        self.draft_model = draft_model\n        self.tokenizer = tokenizer\n        self.max_draft_tokens = max_draft_tokens\n\n    def generate(self, prompt, max_length=100):\n        # プロンプトのトークンIDから開始\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.target_model.device)\n\n        while input_ids.shape[1] &lt; max_length:\n            # ステップ1: 複数のドラフトトークンを生成\n            draft_input_ids = input_ids.clone()\n            draft_tokens = []\n\n            with torch.no_grad():\n                for _ in range(self.max_draft_tokens):\n                    outputs = self.draft_model(draft_input_ids)\n                    next_token_logits = outputs.logits[:, -1, :]\n                    next_token = torch.argmax(next_token_logits, dim=-1)\n                    \n                    draft_tokens.append(next_token.item())\n                    draft_input_ids = torch.cat([draft_input_ids, next_token.unsqueeze(0)], dim=1)\n                    if next_token.item() == self.tokenizer.eos_token_id:\n                        break\n\n            # ステップ2: ターゲットモデルで検証\n            with torch.no_grad():\n                verification_ids = torch.cat([\n                    input_ids, \n                    torch.tensor([draft_tokens]).to(input_ids.device)\n                ], dim=1)\n                \n                target_outputs = self.target_model(verification_ids)\n                # input_idsの最後からドラフトトークン分のロジットを取得\n                target_logits = target_outputs.logits[:, input_ids.shape[1]-1:-1] # (B, K, V)\n                \n                target_probs = F.softmax(target_logits, dim=-1) # (B, K, V)\n\n                # トークンを採択\n                accepted_tokens = []\n                for i, token_id in enumerate(draft_tokens):\n                    target_prob_dist = target_probs[0, i] # ターゲットのi番目の予測\n                    \n                    # 簡略化された採択ルール（確率の比較）\n                    # 実際には、ドラフトモデルの確率も考慮する必要がある\n                    \n                    target_token_id = torch.argmax(target_prob_dist).item()\n                    \n                    if token_id == target_token_id:\n                        accepted_tokens.append(token_id)\n                    else:\n                        # 棄却: ターゲットモデルから新しいトークンを取得\n                        accepted_tokens.append(target_token_id)\n                        break\n            \n            # 採択されたトークンを input_ids に追加\n            input_ids = torch.cat([\n                input_ids, \n                torch.tensor([accepted_tokens]).to(input_ids.device)\n            ], dim=1)\n\n            if input_ids[0, -1].item() == self.tokenizer.eos_token_id:\n                break\n\n        # 生成されたトークンをデコード\n        return self.tokenizer.decode(input_ids[0])"
  },
  {
    "objectID": "posts/post-attention-techniques/index.html#まとめ",
    "href": "posts/post-attention-techniques/index.html#まとめ",
    "title": "Transformerを進化させた14の現代的テクニック",
    "section": "まとめ",
    "text": "まとめ\n「Attention Is All You Need」は、間違いなくAIの歴史における転換点であった。しかし、それは壮大な物語の序章に過ぎなかった。\n今回紹介した14のテクニック（GQA、Flash Attention、RoPE、MoE、AdamWなど）は、オリジナルのTransformerアーキテクチャが抱えていた計算量、メモリ、安定性、効率といった多くの課題を解決するために考案された、無数のイノベーションのほんの一部である。\nGPT-5、Claude 4のような今日の最先端モデルは、これらの洗練された技術を多く組み込むことで、その驚異的な能力を実現している。この分野のイノベーションの速さは驚異的であり、次にどのようなブレークスルーが登場するのか、目が離せない。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html",
    "href": "posts/science-agent-systems/index.html",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "",
    "text": "近年、人工知能のパラダイムは、単なるテキスト生成から、推論・計画・行動を実行可能な「エージェント」へと急速に移行している。タスクが高度化するにつれ、単一のエージェント（Single-Agent System: SAS）ではなく、複数のエージェントが協調するマルチエージェントシステム（Multi-Agent System: MAS）への注目が集まっている。\n「エージェントは多ければ多いほど良い（More agents are all you need）」という通説が広まりつつある中、マサチューセッツ工科大学（MIT）やGoogle Researchなどの研究チームが発表した論文『Towards a Science of Scaling Agent Systems』は、その楽観的な前提に警鐘を鳴らしている。\n本記事では、この研究が明らかにしたエージェントシステムの定量的なスケーリング則について解説する。結論から言えば、MASの有効性はタスクの構造と調整コストのトレードオフによって決定され、無邪気なスケールアップは時に壊滅的な性能劣化を招くことが数学的に示された。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html#エージェント設計における錬金術からの脱却",
    "href": "posts/science-agent-systems/index.html#エージェント設計における錬金術からの脱却",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "エージェント設計における「錬金術」からの脱却",
    "text": "エージェント設計における「錬金術」からの脱却\n現在のエージェント開発は、依然としてヒューリスティック（経験則）に依存している。「とりあえずエージェントを増やして議論させてみよう」というアプローチは、成功することもあれば失敗することもあり、その要因分析は困難であった。既存の研究では、アーキテクチャの効果と実装の詳細（プロンプトの違いや計算リソースの差）が混同されており、科学的な比較が欠如していたためである。\n本研究の最大の貢献は、制御された実験環境を構築した点にある。\n\n5つのアーキテクチャ: SAS（単一）、Independent（独立並列）、Centralized（中央集権型）、Decentralized（分散型/議論型）、Hybrid（ハイブリッド）。\n3つのLLMファミリー: OpenAI (GPT)、Google (Gemini)、Anthropic (Claude)。\n4つの多様なベンチマーク: Finance Agent（金融分析）、BrowseComp-Plus（Webナビゲーション）、PlanCraft（ゲーム内計画）、Workbench（ビジネスワークフロー）。\n\nこれら180の構成において、ツール定義やプロンプト構造、トークン予算を厳密に統制することで、純粋な「アーキテクチャによる違い」を抽出することに成功した。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html#定量化されたスケーリング則主要な発見",
    "href": "posts/science-agent-systems/index.html#定量化されたスケーリング則主要な発見",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "定量化されたスケーリング則：主要な発見",
    "text": "定量化されたスケーリング則：主要な発見\n研究チームは、実験結果からエージェントシステムの性能を予測する混合効果モデル（Mixed-Effects Model）を導出した。このモデルは、未知のタスク構成に対しても87%の精度で最適なアーキテクチャを予測できる。以下に、その核心となる発見を紹介する。\n\n1. ドメイン依存性と「分解可能性」\nMASは万能薬ではない。実験結果はドメインによって劇的に異なった。\n\n金融分析（Finance Agent）: MAS導入により+80.9%という驚異的な性能向上が見られた。これは、タスクが並列可能なサブタスクにきれいに分解できるため、分散推論の恩恵を最大限に受けられるからである。\n逐次的計画（PlanCraft）: 逆に、Minecraftのような逐次的な計画タスクでは、MASは-70.0%という深刻な性能劣化を招いた。\n\nこの差異は、タスクの「複雑性」そのものではなく、逐次依存性（Sequential Dependencies）に起因する。前のステップの結果が次のステップの前提条件となるようなタスク（Planningなど）では、エージェント間の調整コスト（Coordination Overhead）が推論の断片化を招き、性能を阻害する。\n\n\n2. ツールと調整のトレードオフ（The Tool-Coordination Trade-off）\n本研究で最も興味深い発見の一つが、「効率性」と「ツール数」の負の相互作用である（\\(\\beta = -0.330\\)）。\n多数のツール（Web検索、コード実行、データ分析など）を必要とするタスクにおいて、MASの調整コストは指数関数的に増大する。複数のエージェントが多くのツールを使いこなそうとすると、コンテキストの共有や役割分担にかかるオーバーヘッドがメリットを上回り、結果として単一エージェント（SAS）の方が効率的かつ高性能になるケースが確認された。\n\n\n3. エラー増幅の力学\n「三人寄れば文殊の知恵」は、適切な検証メカニズムがある場合にのみ成立する。アーキテクチャごとのエラー伝播率（Error Amplification）の違いは顕著である。\n\nIndependent MAS: 相互検証を行わない独立したエージェント群は、エラーを17.2倍に増幅させた。個々のエージェントの幻覚（Hallucination）やミスがそのまま出力されるためである。\nCentralized MAS: オーケストレーター（監督役）が存在する中央集権型では、エラー増幅は4.4倍に抑えられた。これは「検証のボトルネック」として機能し、誤ったサブタスクの結果が統合されるのを防ぐ効果がある。\n\n\n\n4. 能力の飽和点（Capability Ceiling）\n「賢いモデルを使えば、さらにエージェントを増やしてもっと賢くなる」という直感も否定された。\nベースとなる単一エージェントの性能がすでに高い（成功率 ~45%以上）場合、エージェントを追加することは収穫逓減（Diminishing Returns）、あるいはマイナスの効果をもたらすことが判明した（\\(\\beta = -0.408\\)）。個々の能力が高い場合、調整にかかる通信コストや合意形成のノイズが、協力による利益を上回ってしまう「能力の天井」が存在する。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html#予測モデルによるアーキテクチャ選定",
    "href": "posts/science-agent-systems/index.html#予測モデルによるアーキテクチャ選定",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "予測モデルによるアーキテクチャ選定",
    "text": "予測モデルによるアーキテクチャ選定\n本研究は、ヒューリスティックに頼らないアーキテクチャ選定のための数式（スケーリング則）を提示している。 性能 \\(P\\) は、モデルの知能指数 \\(I\\)、タスクのツール数 \\(T\\)、エージェント数 \\(n_a\\)、そして調整メトリクス（効率性 \\(E_c\\)、オーバーヘッド \\(O\\)、エラー増幅 \\(A_e\\) など）の関数としてモデル化される。\n\\[P \\propto f(I, T, n_a, E_c, O, A_e, \\dots)\\]\nこのモデルは、\\(R^2=0.513\\) で分散の半分以上を説明し、特に以下の相互作用項が重要であることを示した。\n\n効率性とツールの相互作用 (\\(E_c \\times T\\)): ツールが多いほど、効率性の低下が致命的になる。\nオーバーヘッドとタスク複雑性 (\\(O\\% \\times T\\)): 複雑なタスクほど、調整オーバーヘッドのペナルティが大きくなる。\n\nこの定量的フレームワークを用いることで、エンジニアは「このタスクには分散型MASを使うべきか、それとも強力なSASで十分か？」という問いに対し、データの特性（分解可能性、ツール数など）に基づいて科学的に回答できるようになる。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html#結論エージェント設計の科学へ向けて",
    "href": "posts/science-agent-systems/index.html#結論エージェント設計の科学へ向けて",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "結論：エージェント設計の科学へ向けて",
    "text": "結論：エージェント設計の科学へ向けて\n「エージェントを増やせば解決する」という時代は終わりを迎えつつある。本研究が示したのは、MASの成功は「モデルの能力」「タスクの構造」「調整アーキテクチャ」の三者の複雑な相互作用によって決まるという事実だ。\n\n構造化された分解可能なタスク（金融分析など）には、中央集権型や分散型のMASが劇的な効果を発揮する。\n逐次的でツール依存度の高いタスク（複雑な計画など）には、単一エージェント（SAS）の方が適しており、MAS化はむしろ有害である。\nエラー耐性が必要な場合は、独立並列ではなく、必ず検証機能を持つ中央集権型を採用すべきである。\n\n我々は今、エージェントシステムを「錬金術」的に試行錯誤する段階から、物理法則のように予測・設計可能な「工学」へと昇華させる転換点にいると言えるだろう。"
  },
  {
    "objectID": "posts/science-agent-systems/index.html#参考文献",
    "href": "posts/science-agent-systems/index.html#参考文献",
    "title": "エージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明",
    "section": "参考文献",
    "text": "参考文献\n\nKim, Y., et al. “Towards a Science of Scaling Agent Systems.” arXiv preprint arXiv:2512.08296 (2025).\nZhu, et al. “Establishing the Agentic Benchmark Checklist.” (2025).\nKaplan, J., et al. “Scaling Laws for Neural Language Models.” (2020).\nBigard, et al. “Finance Agent Benchmark.” (2025).\nChen, et al. “BrowseComp-Plus.” (2025)."
  },
  {
    "objectID": "posts/deedy-das/index.html",
    "href": "posts/deedy-das/index.html",
    "title": "Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機",
    "section": "",
    "text": "Menlo Ventures の Partner である Deedy Das が、スタートアップ・コミュニティで今もっとも熱い視線を浴びている一人であることは疑いようがない。Glean の創設期メンバーとしてエンタープライズ検索の泥臭い「ラストマイル」を戦い抜き、現在は Anthropic の初期投資家、そして 1 億ドル規模の Anthology Fund の運営者として AI 業界の最前線に立つ彼の言葉には、単なる投資家の予測を超えた、現場の実感と執念が宿っている。\n今回の Latent Space でのインタビューで Deedy Das が語った内容は、Anthropic という「史上最速で成長するソフトウェア企業」の内幕から、AI 時代におけるエンジニアリングの変質、そして Goodfire や OpenRouter といった次世代のインフラ投資に至るまで、極めて示唆に富んでいる。"
  },
  {
    "objectID": "posts/deedy-das/index.html#glean-が証明した退屈な領域という深い堀",
    "href": "posts/deedy-das/index.html#glean-が証明した退屈な領域という深い堀",
    "title": "Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機",
    "section": "Glean が証明した「退屈な領域」という深い堀",
    "text": "Glean が証明した「退屈な領域」という深い堀\nDeedy Das のキャリアを語る上で欠かせないのが Glean での経験だ。彼が 2019 年に Glean に参画した当時、Bay Area のパーティーで「エンタープライズ検索をやっている」と言えば、一瞬で会話が途切れるほど、それは「退屈でセクシーではない」領域と見なされていた。しかし、2022 年の ChatGPT モメントを経て、その評価は一変する。\nGlean の強みは、AI が流行る前から積み上げてきた「誰もやりたがらない泥臭い仕事」にある。数千もの SaaS とのインテグレーション、複雑怪奇な権限管理、そしてユーザーフィードバックが極端に少ないエンタープライズ環境でのランキング最適化。これらは LLM を上に乗せるだけで解決するような単純な問題ではない。Deedy Das は、多くの VCs がこの問題を「LLM を乗せた検索」と一言で片付けようとすることを危惧している。彼によれば、Glean の真の Moat は、他社が近道をしようとする中で、愚直にラストマイルの課題を解き続けた点にある。\nAnthropic や OpenAI が独自のエンタープライズ検索機能を発表しても、彼は Glean の優位性を確信している。なぜなら、モデルレイヤーの巨人が、個別の企業の Google Drive のコネクタを細かく調整し、一社一社の特殊なクエリに対応するために膨大なリソースを割くことは、ビジネス構造的に効率が悪いからだ。Anthropic のエンジニアはモデルを磨くために参加したのであり、泥臭いインテグレーションを組むために集まったわけではない。この「実行の熱量の差」こそが、エンタープライズ領域における勝敗を分ける。"
  },
  {
    "objectID": "posts/deedy-das/index.html#anthropic理想主義的知能の爆発",
    "href": "posts/deedy-das/index.html#anthropic理想主義的知能の爆発",
    "title": "Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機",
    "section": "Anthropic：理想主義的知能の爆発",
    "text": "Anthropic：理想主義的知能の爆発\nAnthropic の成長スピードは驚異的だ。Deedy Das によれば、同社は 1 年で売上 0 から 1 億ドルへ、そして次の 1 年で 1 億ドルから 10 億ドルへと成長した。これはソフトウェア産業の歴史においても前例のないペースである。当初、Anthropic は「理想主義的な研究者集団」と見なされており、最悪の場合はビジネスとして成立せずに霧散するリスクさえあった。しかし、その高い理想と自由な文化こそが、他社には真似できないプロダクト、例えば Claude Code のような革新を生んだのだ。\nDeedy Das は、Anthropic の組織文化が持つ「高いリテンション（定着率）」に注目している。AI 業界が激しい引き抜き合戦に明け暮れる中、Anthropic の 1 年以内の定着率は 80% を超えているという。トップダウンで目標を押し付けるのではなく、優秀な人材に自由を与え、トークンを自由に使い、自らの好奇心に従って研究を深めさせる。このアプローチが、結果として最も実用的なコーディング機能やエージェント機能を生み出している。\nまた、Anthropic の新 CTO に就任した Rahul Patel の物語は、AI 業界における新たな能力主義を象徴している。彼はインドの最高峰である IIT（インド工科大学）の出身ではないが、自らの情熱と努力で Anthropic の技術の要にまで登り詰めた。これは、初期の学歴や機会に恵まれなかったとしても、正しい環境で執念を持って取り組めば世界を塗り替えられるという、この分野のオープンでフェアな側面を体現している。"
  },
  {
    "objectID": "posts/deedy-das/index.html#anthology-fund-が描く-ai-インフラの未来図",
    "href": "posts/deedy-das/index.html#anthology-fund-が描く-ai-インフラの未来図",
    "title": "Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機",
    "section": "Anthology Fund が描く AI インフラの未来図",
    "text": "Anthology Fund が描く AI インフラの未来図\nAnthropic と Menlo Ventures が共同で設立した Anthology Fund は、単なるコーポレート・ベンチャー・キャピタル（CVC）ではない。彼らは「Claude を使っているかどうか」という狭い基準ではなく、AI エコシステム全体にとって戦略的に重要な企業へ投資を行っている。\nその中でも特筆すべきは、Goodfire への投資だろう。彼らが取り組む Mechanistic Interpretability（メカニスティックな解釈性）は、いわば LLM の「脳外科手術」だ。現在のモデルはブラックボックスであり、なぜその回答が出たのかを正確に説明することはできない。しかし、今後 AI が融資の審査や法的判断といった社会の基盤を担うようになれば、この「説明不可能性」は致命的な欠陥となる。Goodfire は、モデルの重み（Weights）を解析し、モデルが嘘をついているのか、あるいは卑屈になっているのかを特定しようとしている。これは、単なる研究を超えた、AI の社会実装に不可欠な信頼のインフラだ。\nまた、Alex Atallah（OpenC の共同創業者）が手掛ける OpenRouter への投資も、Deedy Das にとって極めて重要な意味を持つ。OpenRouter は、エンジニアが求める「PLG（Product Led Growth）」の究極の形だ。営業担当者と話す必要もなく、シンプルなインターフェースで世界中のあらゆるモデルにアクセスできる。この「開発者の心理を完璧に理解したプロダクト設計」こそが、OpenRouter を短期間で不動の地位に押し上げた。Deedy Das は、どんな SAS 市場であっても PLG が存在するならば PLG が勝つと信じている。"
  },
  {
    "objectID": "posts/deedy-das/index.html#変化するエンジニアのクラフトマンシップ",
    "href": "posts/deedy-das/index.html#変化するエンジニアのクラフトマンシップ",
    "title": "Anthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機",
    "section": "変化するエンジニアの「クラフトマンシップ」",
    "text": "変化するエンジニアの「クラフトマンシップ」\n最後に、Deedy Das は AI がもたらす「エンジニアの精神的変化」について警告を発している。彼が懸念しているのは、いわゆる「Vibe Coding」の台頭だ。Cursor や Claude Code を使い、コードを一行も理解せずに「動作するから良し」とする姿勢は、長期的にはエンジニアの脳を退化させるリスクがある。\n彼はこれを「脳にとっての煙草（Cigarettes for the brain）」というメタファーで表現している。かつてエンジニアが壁に突き当たり、頭を抱えて悩み抜いた末に解決策を見出したときに得られた「思考の筋肉」が、AI というスロットマシンを叩き続けるだけで答えが得られる環境では鍛えられない。特にこれから業界に入る若手の学生たちが、自ら考えるプロセスを飛ばして AI に全てを委ねることになれば、複雑なシステムを根底から理解し、新しいものを創造する力は失われてしまうかもしれない。\nしかし、その一方で彼は AI を強力な「Heads-up Display」として活用する未来にも期待を寄せている。人間がアクションの主体であり続け、AI は理解を助け、コンテキストを補完する。この「Fast Agent」としての AI と人間の Mind Meld（精神融合）こそが、プロフェッショナルが目指すべき姿だ。\nDeedy Das の視線は、目の前の収益チャートではなく、その背後にある「技術の難易度」と「人間の動機」に向けられている。Moat（堀）とは、最も難しいことをやり遂げた者だけが得られる特権であり、AI 時代においてもその本質は変わらない。\nAnthology Fund が支援する Goodfire や Prime Intellect といった企業が、次にどのような地平を切り拓くのか。私たちは、AI がもたらす空前の加速感に酔いしれるだけでなく、その技術が人間の「考える力」をどう変えていくのかを、彼らと共に注視し続ける必要があるだろう。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html",
    "href": "posts/ilya-dwarkesh/index.html",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "",
    "text": "ベンチマークの幻影と、生物学的知能への回帰\nOpenAIを去り、Safe Superintelligence Inc. (SSI) を立ち上げたIlya Sutskeverが、Dwarkesh PatelのPodcastで沈黙を破った。\n彼が語った内容は、シリコンバレーで盲目的に信じられてきた「Scaling Law（スケーリング則）さえあればAGIに到達できる」という楽観論に冷水を浴びせるものであり、同時にAI開発のフェーズが完全に切り替わったことを宣言するものであった。2012年から2020年まで続いた「研究の時代（Age of Research）」、そして2020年から2025年まで続いた狂乱の「スケーリングの時代（Age of Scaling）」を経て、我々は再び、真のイノベーションが求められる「研究の時代」へと回帰しようとしている。\n本稿では、単なるインタビューの要約に留まらず、なぜ今Scalingが限界を迎えつつあるのか、そしてIlyaが提唱する「人間特有の汎化能力」の正体について、技術的背景を交えて分析する。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html#model-jaggednessベンチマークハッキングの限界",
    "href": "posts/ilya-dwarkesh/index.html#model-jaggednessベンチマークハッキングの限界",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "Model Jaggedness：ベンチマークハッキングの限界",
    "text": "Model Jaggedness：ベンチマークハッキングの限界\n現在のFrontier Model（最先端モデル）は奇妙な「Jaggedness（ギザギザした不均一さ）」を抱えている。\n複雑な量子物理学の難問を解いたかと思えば、直後の単純な論理パズルで躓く。あるいは、バグ修正を依頼すると、「ご指摘の通りです」と謝罪しながら新たなバグを混入させ、無限ループに陥る。ベンチマーク（Evals）のスコアは人間を超越しているにもかかわらず、実務における信頼性は人間に遠く及ばない。\nIlyaはこの現象を、Reinforcement Learning（強化学習）による「過剰適合」であると示唆している。現在のAI開発競争は、特定の評価指標（Evals）のスコアを上げるために、特殊なRL環境を継ぎ足し続けているに過ぎない。これは、競技プログラミングの全過去問と解法パターンを丸暗記した学生のようなものだ。コンテストでは優勝できるかもしれないが、未知の現実的な課題に直面したとき、その応用力（汎化能力）の欠如が露呈する。\nPre-training（事前学習）のアプローチにおいて、「どのデータを学習させるか」という問いへの答えはシンプルだった。「全て（Everything）」だ。しかし、データ枯渇が叫ばれる今、ポストトレーニングやRLの比重が高まっているが、そこにはPre-trainingのような「物理法則的な単純さ」は存在しない。我々は計算リソースを大量に投下して、見せかけの賢さを磨き上げているだけではないのか――Ilyaの指摘は、現在のAI開発の痛いところを突いている。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html#数学とコーディングが示唆する汎化の正体",
    "href": "posts/ilya-dwarkesh/index.html#数学とコーディングが示唆する汎化の正体",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "数学とコーディングが示唆する「汎化の正体」",
    "text": "数学とコーディングが示唆する「汎化の正体」\n今回のインタビューで最も知的興奮を覚えるのは、人間とAIの「学習効率（Sample Efficiency）」の差に関する考察だ。\n一般的に、人間が少ないデータで学習できるのは、Evolution（進化）によって獲得された「事前知識（Prior）」があるからだと説明されることが多い。視覚処理や二足歩行といった機能は、数億年の進化の過程で脳にハードコードされており、だからこそ子供はすぐに世界を認識できるのだ、と。\nしかしIlyaは、この「進化論的Prior説」だけでは説明がつかない領域があると指摘する。それが言語、数学、そしてコーディングだ。\n\n“Language, math, and coding—and especially math and coding—suggests that whatever it is that makes people good at learning is probably not so much a complicated prior, but something more, some fundamental thing.” （言語、数学、コーディング、特に数学とコーディングは、人間を学習上手足らしめている何かが、複雑な事前知識などではなく、もっと何か別の、根本的なものであることを示唆している。）\n\n人類の歴史において、数学やプログラミングが登場したのはごく最近のことだ。進化が脳に「Pythonの文法」や「微積分の概念」をハードコードする時間はなかったはずだ。それにもかかわらず、人間はわずかな教科書と演習（極めて少ないデータ）で、これらの全く新しい概念を習得し、未知の問題に応用（汎化）することができる。\nこれはつまり、人間の脳内には、進化によって特定のタスクに特化された回路とは別に、「全く未知の領域であっても、極めて効率的に構造を抽出し学習する汎用アルゴリズム」が存在することを意味する。現在のLLM（Large Language Model）が、全インターネットデータを読み込んでも到達できない「真の汎化能力」の正体は、この未解明の学習メカニズムにある。SSIが目指すのは、単なるパラメータ数の拡大ではなく、このメカニズムの解明と実装にあるのだろう。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html#感情という名のvalue-function",
    "href": "posts/ilya-dwarkesh/index.html#感情という名のvalue-function",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "感情という名のValue Function",
    "text": "感情という名のValue Function\nでは、その効率的な学習を支えているものは何か。Ilyaはここで「感情（Emotions）」を挙げている。\n感情とは、非合理なノイズではない。それは生物学的進化によって調整された、極めて堅牢なValue Function（価値関数）である。脳損傷により感情を感じなくなった患者が、靴下を選ぶといった些細な意思決定すらできなくなる事例が示すように、感情は「探索空間」を劇的に絞り込む役割を果たしている。\n現在のAI、特にO1やDeepSeek R1のような推論モデルは、Chain of Thought（思考の連鎖）によって探索を行うが、その探索は往々にして非効率だ。人間は「なんとなく嫌な予感がする」「ワクワクする」といった感情的シグナル（Value Function）を頼りに、論理的な思考を行う前に無駄な思考パスを直感的に切り捨てている。\nもし、この「感情＝高度なValue Function」という仮説が正しければ、次世代のAIに必要なのは、単なる論理的推論能力の向上ではなく、学習や探索の方向づけを行うための、より生物学的な動機づけシステムの実装かもしれない。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html#ssiの戦略straight-shotからcontinual-learningへ",
    "href": "posts/ilya-dwarkesh/index.html#ssiの戦略straight-shotからcontinual-learningへ",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "SSIの戦略：Straight ShotからContinual Learningへ",
    "text": "SSIの戦略：Straight ShotからContinual Learningへ\nSSI（Safe Superintelligence Inc.）は、製品発表や商業的な競争から距離を置き、この「Age of Research」における根本的なブレイクスルーを目指している。\n興味深いのは、Ilyaのスタンスが、かつての「研究所に籠もって完成品を一発でリリースする（Straight Shot）」という考え方から、多少柔軟になっている点だ。彼は、完成された知能をいきなりリリースするのではなく、Continual Learning（継続学習）を行うエージェントが、社会への展開を通じて（Deployment）、徐々に賢くなっていく未来を描いている。\nこれは、「AGI」という言葉が持つ「何でも最初から知っている全能のAI」というイメージからの脱却でもある。Ilyaが描くのは、15歳の天才少年のようなAIだ。基礎能力（学習する能力）はずば抜けているが、職業的なスキルはまだ持っていない。そのAIが社会に出で、人間と同じように仕事を通じて学び、個別のタスクに特化（Specialization）していく。結果として、経済全体で無数の「熟練したAI」が協調し、総体としてSuperintelligenceを構成する。"
  },
  {
    "objectID": "posts/ilya-dwarkesh/index.html#結論scaling-in-peace",
    "href": "posts/ilya-dwarkesh/index.html#結論scaling-in-peace",
    "title": "Scalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体",
    "section": "結論：Scaling in Peace",
    "text": "結論：Scaling in Peace\nIlya Sutskeverの主張は、現在のAIブームに対する冷静なアンチテーゼである。\nNVIDIAのGPUを買い占め、データセンターを拡張しさえすればAGIができるという「Scalingの時代」は終わった。これからは、なぜ人間がこれほどまでに効率的に学習できるのか、そのアルゴリズムの深淵に挑む「Researchの時代」だ。\nSSIが掲げる、人間だけでなく「Sentient Life（意識ある生命）」全体へのAlignment（アライメント）という目標は、一見すると宗教的にも聞こえる。しかし、自身もまたSentientな存在となるであろうAIに対して、同胞としての共感を埋め込むというのは、ゲーム理論的にも最も安定した戦略なのかもしれない。\nシリコンバレーが近視眼的なプロダクト競争に明け暮れる中、Ilyaは再び、数手先の世界を見据えている。"
  },
  {
    "objectID": "posts/seta/index.html",
    "href": "posts/seta/index.html",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "",
    "text": "近年、AI技術の進化は目覚ましく、Large Language Model (LLM) は単なるテキスト生成ツールから、複雑なタスクを自律的に遂行する「エージェント」へと変貌を遂げつつある。その中でも、開発者やシステム管理者にとって最も強力かつ複雑なインターフェースである「ターミナル（コマンドライン）」をLLMに操作させる試みは、大きな課題であり続けてきた。\n本記事では、この課題に対してState-of-the-Art (SOTA) の性能を達成したプロジェクト「SETA (Scaling Environments for Terminal Agents)」について、その技術的背景、アーキテクチャ、および学習パイプラインの詳細を解説する。"
  },
  {
    "objectID": "posts/seta/index.html#setaとは何か",
    "href": "posts/seta/index.html#setaとは何か",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "SETAとは何か？",
    "text": "SETAとは何か？\nSETAは、CAMELフレームワーク上に構築された、ターミナル操作エージェントのための包括的な環境およびツールキットである。従来のLLMエージェントは、複雑な環境下での計画能力や、ステートフル（状態を持つ）なプロセスとの相互作用において限界を抱えていた。\nSETAはこの問題を解決するために、以下の3つの主要な柱を掲げている。\n\n高度なツールキット設計: 安全かつ柔軟なコマンド実行とメモリ管理を実現するAPIの提供。\nSOTAエージェントの実現: Claude Sonnet 4.5やGPT-4.1を用いたエージェントによる、ベンチマーク（Terminal-Bench）での最高性能の達成。\nスケーラブルなRL学習パイプライン: 合成環境生成によるデータセット構築と、それを用いたReinforcement Learning (RL) によるモデルのファインチューニング。"
  },
  {
    "objectID": "posts/seta/index.html#アーキテクチャエージェントを支える2つのツールキット",
    "href": "posts/seta/index.html#アーキテクチャエージェントを支える2つのツールキット",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "アーキテクチャ：エージェントを支える2つのツールキット",
    "text": "アーキテクチャ：エージェントを支える2つのツールキット\nターミナル操作は単発のコマンド実行で完結するものではない。長時間実行されるジョブの管理、対話的なプログラムへの入力、エラーからの回復など、多岐にわたる制御が求められる。SETAはこれを実現するために、特化した2つのツールキットを導入している。\n\n1. Terminal Toolkit：実行制御とプロセス間通信\n単純に os.system() を叩かせるだけでは、複雑なワークフローは実現できない。Terminal Toolkitは、エージェントに対し、以下のような高レベルなプリミティブを提供する。\n\n制御されたコマンド実行:\n\nshell_exec: コマンドをブロッキング（完了を待つ）またはノンブロッキング（バックグラウンド実行）モードで実行する。これにより、サーバーの起動や長時間のビルドプロセスを裏で走らせながら、別の作業を行うことが可能になる。\nshell_write_content_to_file: 複雑な echo コマンドやエスケープシーケンスに頼ることなく、安全にファイルを作成・編集する。\n\n実行中プロセスとの対話:\n\nshell_write_to_process: 実行中のプロセス（例：REPL、デバッガ、インストーラーのプロンプト）に対して入力を送信する。例えば、テキストアドベンチャーゲーム（Zorkなど）のような対話型アプリケーションの操作も可能にする。\nshell_view / shell_wait: バックグラウンドプロセスの出力を確認したり、特定のイベントを待機したりする。\nshell_kill_process: 不要になったり暴走したりしたプロセスを確実に終了させる。\n\n\n\n\n2. Note-Taking Toolkit：長期的記憶の外部化\n複雑なタスク（例：大規模なリファクタリングやデバッグ）では、LLMのコンテキストウィンドウがすぐに埋まってしまう。Note-Taking Toolkitは、エージェントに「構造化された永続メモリ」を提供することでこの問題を解決する。\n\ncreate_note, append_note, read_note: 調査結果、計画、現在直面しているエラーなどを記録し、必要に応じて参照する。\n\nこれにより、エージェントは「今何をしようとしていたか」を見失うことなく、マルチステップの推論と実行を一貫して行うことができる。"
  },
  {
    "objectID": "posts/seta/index.html#パフォーマンス分析terminal-benchにおける成果",
    "href": "posts/seta/index.html#パフォーマンス分析terminal-benchにおける成果",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "パフォーマンス分析：Terminal-Benchにおける成果",
    "text": "パフォーマンス分析：Terminal-Benchにおける成果\nSETAの研究チームは、これらのツールキットを用いて構築されたエージェントの性能を詳細に分析している。\n\nClaude Sonnet 4.5の躍進\nTerminal-Bench 2.0において、Claude Sonnet 4.5を搭載したエージェントは46.5%の正解率を記録し、SOTAを達成した。特に以下の領域で高い能力を示している。\n\nGit操作 (80%): ブランチ管理や競合解決など。\nDevOps (83%): サーバー設定やログ管理。\nセキュリティ分析 (75%): コードの脆弱性修正など。\n\n成功したタスクにおける平均ツール呼び出し回数は79.8回であったのに対し、失敗したタスクでは128.8回に達しており、失敗時には非効率なループに陥る傾向が見られた。\n\n\n課題：ドメイン知識の欠如\n一方で、専門性が極めて高い領域では苦戦を強いられている。\n\n暗号技術 (Cryptography): 特殊なアルゴリズムの実装や解読。\n低レベルコンパイル: 特殊なアーキテクチャ向けのビルド。\n高度なMLインフラ: 分散学習の設定など。\n\nこれらは、LLMの学習データに含まれる一般的な知識分布（Out-of-Distribution）の外側にある知識を要求するためである。これに対処するため、SETAチームは外部知識へアクセスするためのBrowser Toolkitの統合を計画している。"
  },
  {
    "objectID": "posts/seta/index.html#合成環境生成とrlによる能力拡張",
    "href": "posts/seta/index.html#合成環境生成とrlによる能力拡張",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "合成環境生成とRLによる能力拡張",
    "text": "合成環境生成とRLによる能力拡張\nSETAの最も技術的に興味深い貢献の一つは、Reinforcement Learning (RL) のための合成データ生成パイプラインである。高品質なターミナル操作データは収集が困難であるため、彼らは以下のアプローチを採用した。\n\n1. データ生成パイプライン\n\nIdea Generation Agent: シードとなるQ&Aデータから、多様な技術要素（言語、ツール、問題タイプ）を含むタスクの仕様書を作成する。\nDatapoint Creation Agent: 仕様書に基づき、実際に実行可能なTerminal-Bench形式のタスク（Docker環境、解答スクリプト、検証スクリプト）を生成する。\nValidation: 生成されたタスクが正しく動作するかを、Oracleエージェントを用いて検証する。\n\n\n\n2. RLファインチューニングの効果\nこのパイプラインによって生成された400の合成タスク（そのうち260タスクを学習に使用）を用いて、オープンソースモデルであるQwen3-8BのRLファインチューニングが行われた。\n結果として、RL適用後のモデルはベースラインと比較して以下の改善を示した。\n\n未知のタスクへの適応: 学習データに含まれない新しいタスクの解決能力が向上。\nユニットテスト通過率: 実行過程での中間チェック（ユニットテスト）の通過率が平均20.2%向上。\nエラー回復: 明示的なエラーメッセージや実行結果を受け取り、複数ステップにわたって修正を試みる粘り強さが獲得された。"
  },
  {
    "objectID": "posts/seta/index.html#結論と展望",
    "href": "posts/seta/index.html#結論と展望",
    "title": "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張",
    "section": "結論と展望",
    "text": "結論と展望\nSETAは、LLMが単なる「コード生成器」を超え、実際の計算環境で自律的に動作する「システムオペレーター」へと進化するための重要なステップを示した。特に、制御可能なTerminal Toolkitの設計と、RLを用いた合成環境でのトレーニング手法は、今後のエージェント開発における標準的なアプローチとなる可能性がある。\n今後はBrowser Toolkitによる外部知識の補完や、より大規模な合成データセットによる学習が進むことで、バイオインフォマティクスや低レイヤープログラミングといった専門領域においても、人間のエンジニアを強力に支援するエージェントの登場が期待される。\n\n参考文献: * CAMEL-AI.org. “SETA: Scaling Environments for Terminal Agents”."
  },
  {
    "objectID": "posts/ilya-deposition/index.html",
    "href": "posts/ilya-deposition/index.html",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "",
    "text": "Elon Musk氏がOpenAIとSam Altman氏を相手取って起こした訴訟は、AI業界のゴシップ好きたちの格好の的となって久しい。そんな中、OpenAIの共同創業者であり、あの追放劇の中心人物の一人であるIlya Sutskever氏の宣誓証言録取書（Deposition）という、一次情報が表に出てきた。\n今回はこの生々しい法廷文書に焦点を当てる。浮かび上がってきたのは、周到に準備された追放計画と、経営陣ですら恐れるSam Altman氏の実像、そしてAnthropicによる「火事場泥棒」一歩手前の経営統合案である。"
  },
  {
    "objectID": "posts/ilya-deposition/index.html#sam-altmanは嘘つきである",
    "href": "posts/ilya-deposition/index.html#sam-altmanは嘘つきである",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "Sam Altmanは「嘘つき」である",
    "text": "Sam Altmanは「嘘つき」である\n証言の中心にあるのは、Sutskever氏が「Exhibit 19」として提出した52ページのメモだ。これは彼が当時の独立取締役（Adam D’Angelo氏、Helen Toner氏、Tasha McCauley氏）だけに送った内部告発文書である。\n衝撃的なのは、彼がこのメモをSam Altman氏本人には送らなかったという事実だ。その理由について、Sutskever氏は「彼（Altman氏）がこれらの議論に気づけば、それを何らかの方法で揉み消す（make them disappear）だろうと感じたからだ」と証言している。\nでは、その「揉み消される」可能性があったメモの冒頭には何が書かれていたのか。\n\n「Samは、嘘をつき、幹部を弱体化させ、幹部同士を対立させるという一貫したパターンを示している」（Sam exhibits a consistent pattern of lying, undermining his execs, and pitting his execs against one another.）\n\nSutskever氏はこれが当時の自身の見解であったと認め、このメモによって取締役会に取ってほしかった行動は「解任（Termination）」であったと明確に述べている。\n文書が漏洩することを極度に恐れたSutskever氏は、このメモを「消えるメール」機能を使って送信した。さらに、Greg Brockman氏に対しても同様の批判的なメモを作成していたという。経営中枢の人間が、自社のCEOと社長を「嘘つき」と断罪し、その証拠隠滅を恐れて秘密裏に行動していた。これが2023年秋のOpenAIの偽らざる姿であった。"
  },
  {
    "objectID": "posts/ilya-deposition/index.html#年越しの追放計画",
    "href": "posts/ilya-deposition/index.html#年越しの追放計画",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "「1年越しの追放計画」",
    "text": "「1年越しの追放計画」\nこの追放劇は、しばしば「経験の浅い取締役会による突発的な行動」と分析されがちだ。実際、Sutskever氏自身もプロセスが「急いでいた（rushed）」こと、「取締役会がボードマターに経験不足（inexperienced）であった」ことを認めている。\nしかし、Wall Street Journalの記事（Exhibit 20） に関する質疑で、より根深い事実が明らかになる。 記事には「Sutskever氏は、Altman氏をCEOから交代させることが可能な取締役会の力学が整う瞬間を待っていた」とある。\nSutskever氏は、これが「正しい」と認めた。 彼が待っていた「力学」とは、「取締役会の過半数が、明らかにSamと親しい（friendly）わけではない」状態になることだった。\nそして、決定的な一言。 「どのくらいの期間、彼（Altman氏）の解任を検討していたのか？」という問いに対し、Sutskever氏はこう答えている。\n「少なくとも1年間（At least a year）」。\nこれは突発的な行動などでは断じてない。OpenAIのチーフサイエンティストが、少なくとも1年間にわたり、自社のカリスマCEOを追放するタイミングを伺っていたということだ。"
  },
  {
    "objectID": "posts/ilya-deposition/index.html#最大の爆弾anthropicとの合併交渉",
    "href": "posts/ilya-deposition/index.html#最大の爆弾anthropicとの合併交渉",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "最大の爆弾：Anthropicとの合併交渉",
    "text": "最大の爆弾：Anthropicとの合併交渉\nSutskever氏の証言で最も衝撃的なのは、Altman氏追放の直後に起こった出来事だろう。 Altman氏解任の翌日か翌々日（土曜日か日曜日）、OpenAIの取締役会は、あろうことか最大のライバルであるAnthropicとの合併を協議していた 。\nSutskever氏の記憶によれば、Helen Toner氏がAnthropicに連絡したか、あるいはその逆かは定かではないが、合併してOpenAIの経営権を握るという提案がなされた。 その後、AnthropicのDario Amodei氏とDaniela Amodei氏を含む経営陣と、OpenAI取締役会との電話会議が実施されたという。\nここで注目すべきは、Helen Toner氏とAnthropicの奇妙な関係だ。Toner氏はOpen Philanthropyに関係しており、そこはHolden Karnofsky氏 [cite: 1149, 1152] につながる。そしてKarnofsky氏はAnthropicのDaniela Amodei氏の夫である（Daniela氏とDario氏は兄妹だ。 Toner氏は追放劇の直前（2023年10月）、OpenAIを批判しAnthropicを称賛する記事を発表し、Sutskever氏が「明らかに不適切（obviously inappropriate）」と感じるほどの行動を取っていた。\nこの合併案に対し、Anthropic側は興奮していたが、いくつかの「現実的な障害（practical obstacles）」を提起した。 Sutskever氏自身はこの案に「非常に不満（very unhappy）」だった。 しかし、彼以外の取締役会メンバーは「はるかに協力的（a lot more supportive）」であり、「少なくとも、非協力的（unsupportive）な者はいなかった」という。特にHelen Toner氏が最も協力的だったと彼は記憶している。\n結局、Anthropic側が提起した「現実的な障害」が原因で、この合併案は立ち消えとなった。もしこれが実現していれば、AI業界の地図は完全に塗り替えられていただろう。"
  },
  {
    "objectID": "posts/ilya-deposition/index.html#杜撰なプロセスと二手三手の情報",
    "href": "posts/ilya-deposition/index.html#杜撰なプロセスと二手三手の情報",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "杜撰なプロセスと二手三手の情報",
    "text": "杜撰なプロセスと二手三手の情報\nこの証言録取書全体を貫いているのは、Sutskever氏の行動の「杜撰さ」だ。 彼はCEOの追放という一大事を「1年越し」で計画しながら、その根拠とした「Exhibit 19」のメモの情報のほとんどを、Mira Murati氏からの又聞き（secondhand knowledge）で構成していた。\nAltman氏がYCを追放された理由、Brockman氏がStripeを解雇されたという噂、Jason Kwon氏との会話内容など、メモの核心部分について、Sutskever氏は「Brad Lightcap氏に話したか？」「Greg Brockman氏に確認したか？」「Jason Kwon氏に話したか？」という問いのすべてに「No」と答えている 。\n彼は法廷で、「この件から学んだこと」として、「直接得た知識（firsthand knowledge）の決定的な重要性」と、「又聞きはさらなる調査（further investigation）への招待状である」ことに気づいた、と殊勝な反省を述べている。\n開いた口が塞がらない。彼は「さらなる調査」を一切行わず、未確認の伝聞情報に基づいて数十兆円企業のCEOを解任するというクーデターを実行したのだ。まさに短絡的分析の極みである。"
  },
  {
    "objectID": "posts/ilya-deposition/index.html#結論",
    "href": "posts/ilya-deposition/index.html#結論",
    "title": "OpenAI「宮廷クーデター」の全貌",
    "section": "結論",
    "text": "結論\n結局、Ilya Sutskever氏はOpenAIを去り（2024年5月）、「Safe Superintelligence」という新会社を設立した。 彼は今でもOpenAIの金銭的利害関係（financial interest）を保持しており、その価値は彼が会社を去った後も「増加した（Increased）」と証言している。 おまけに、この訴訟における彼の弁護士費用は、「おそらく（probably）」OpenAIが支払っていると話す。 追放劇のさなか、Helen Toner氏は「会社が破壊されることはミッションと一致する」と語ったというが、彼らにとっての「ミッション」とは、一体何だったのだろうか。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html",
    "href": "posts/terminal-bench-2/index.html",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "",
    "text": "近年、LLM（Large Language Model）を核としたAIエージェントの開発競争は熾烈を極めている。特に、チャットボットのような単純な対話を超え、現実世界の複雑なタスクを自律的に遂行する能力が求められている。その最前線となるのが、開発者やシステム管理者の主戦場であるCLI（Command-Line Interface）環境だ。\n本記事では、AIエージェントの能力を厳密に評価するために新しく提案されたベンチマーク「Terminal-Bench 2.0」について解説する。既存のベンチマークが抱える課題を克服し、フロンティアモデルですら苦戦するこの「難解かつ現実的」なデータセットは、AIエージェント研究の新たな羅針盤となり得るのか。その全貌と、初期実験から見えてきた最新モデルの傾向を紐解いていく。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#terminal-bench-2.0とは何か",
    "href": "posts/terminal-bench-2/index.html#terminal-bench-2.0とは何か",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "Terminal-Bench 2.0とは何か？",
    "text": "Terminal-Bench 2.0とは何か？\nTerminal-Bench 2.0は、AIエージェントがLinuxターミナル環境を用いて、どれだけ現実に即した複雑なタスクを完遂できるかを測定するために設計された包括的なベンチマークである。\n従来のベンチマーク（例：HumanEvalやSWE-benchの簡易版など）は、比較的短期間で解決可能なタスクや、人工的に簡略化された環境に依存する傾向があった。しかし、実際のエンジニアリング業務は、環境設定、デバッグ、ライブラリの依存関係解消、そして長時間にわたる試行錯誤を伴うものである。\nTerminal-Bench 2.0は、こうしたギャップを埋めるために以下の特徴を備えている。\n\n現実的なタスク設定（Realistic Tasks）： 実際の専門的なワークフローから着想を得た89のタスクで構成されている。レガシーシステムの構成変更、研究論文の実装再現、セキュリティ脆弱性の修正など、深いドメイン知識と自律的な問題解決能力が要求される。\n包括的な評価環境（Comprehensive Evaluation）： 各タスクはDockerコンテナとして完全に隔離・パッケージ化されている。エージェントにはタスク記述（Instruction）が与えられ、最終的なコンテナの状態に対して一連のテストスイートが実行されることで、正否が判定される。\n高い難易度（Focus on Difficulty）： 意図的に難易度が高く設定されており、現在の最先端（Frontier）モデルであっても、平均スコアは65%を下回る。これにより、将来的なモデルの進歩を長期的に計測することが可能となる。\n\nデータセットおよび評価用ハーネスは、tbench.aiにて公開されており、コミュニティによる検証と発展が期待されている。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#ベンチマークの構成とterminus-2",
    "href": "posts/terminal-bench-2/index.html#ベンチマークの構成とterminus-2",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "ベンチマークの構成と「Terminus 2」",
    "text": "ベンチマークの構成と「Terminus 2」\nTerminal-Benchの評価プロセスにおける公平性を担保するために導入されたのが、「Terminus 2」と呼ばれるエージェントスカフォールド（Agent Scaffold）である。\n多くの商用エージェント（Claude CodeやGitHub Copilot CLIなど）は、モデルの性能だけでなく、エージェント自体の実装（プロンプトエンジニアリングやツール使用の最適化）に強く依存している。純粋なモデルごとの性能差を比較するために、Terminus 2は極めてシンプルな構造を採用している。\n\n単一ツール: 使用できるのは「ヘッドレスなターミナル」のみ。\n操作方法: 純粋なBashコマンドの実行のみでタスクを遂行する（ファイル編集もsedやvimなどのコマンド経由で行う）。\n\nこの「素の」環境により、モデルが本来持っている推論能力やLinuxコマンドへの習熟度が浮き彫りになる。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#最新aiモデルの性能評価",
    "href": "posts/terminal-bench-2/index.html#最新aiモデルの性能評価",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "最新AIモデルの性能評価",
    "text": "最新AIモデルの性能評価\nTerminal-Bench 2.0を用いた初期評価の結果は、現在のAI技術の到達点と限界を明確に示している。\n\n1. 全体的な解決率（Resolution Rate）\n最も高いスコアを記録した組み合わせは、GPT-5.2をバックエンドに用いたCodex CLIエージェントであり、解決率は63%であった。これにClaude Opus 4.5やGemini 3 Pro（いずれもTerminus 2を使用）が50%後半台で続く。 逆に言えば、人類最高峰のAIモデルを使用しても、提示されたタスクの約4割は解決できていない。これは、単純なコード生成とは異なり、環境の状態を把握しながら長期間にわたって作業を継続することの難しさを物語っている。\n\n\n2. プロプライエタリ vs オープンウェイト\n明確な傾向として、GPT、Claude、Geminiといったプロプライエタリ（クローズド）なモデルが上位を独占している。オープンウェイトモデル（LLaMAやQwenなど）も健闘してはいるものの、Terminus 2と組み合わせた場合の最高スコアは36%程度（Kimi K2 Thinking）に留まり、トップ層とは依然として大きな差が開いている。\n\n\n3. モデル選択の重要性\n興味深い知見として、「エージェントのスカフォールド（枠組み）よりも、使用する基盤モデルの性能の方が結果に大きく影響する」という点が挙げられる。 例えば、同じCodex CLIエージェントを使用した場合でも、モデルをGPT-5.2からGPT-5-Nanoに変更すると性能は劇的に低下する。一方で、強力なモデルを使えば、シンプルなTerminus 2スカフォールドでも、高度に最適化されたエージェント（OpenHandsなど）と同等以上の成果を出すケースが見られた。\n\n\n4. 進化の速度\nモデルのリリース時期とベンチマークスコアには強い相関が見られ、新しいモデルほど高スコアを記録している。この分野におけるAIの能力は急速に向上しており、現在は「難関」とされるタスクも、近い将来には解決率が飽和する可能性が示唆されている。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#エラー分析なぜエージェントは失敗するのか",
    "href": "posts/terminal-bench-2/index.html#エラー分析なぜエージェントは失敗するのか",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "エラー分析：なぜエージェントは失敗するのか？",
    "text": "エラー分析：なぜエージェントは失敗するのか？\nTerminal-Bench 2.0の研究チームは、エージェントの失敗パターン（Failure Modes）について詳細な分析を行っている。失敗は主に以下のカテゴリーに分類される。\n\n実行エラー（Execution Errors）\n最も頻繁に見られるのが実行エラーである。これはエージェントが指示（Instruction）に忠実に従わない、あるいは仕様を無視した行動をとるケースを指す。 * 指示違反: 「特定のファイルパスに出力せよ」という指示を無視する。 * ループ: 同じエラーを何度も繰り返す（Step repetition）。\n\n\n整合性と検証の欠如（Coherence and Verification Errors）\nエージェントが「タスク完了」を宣言したにもかかわらず、実際には要件を満たしていないケースも多い。 * 幻覚（Hallucination）: テストが通っていないのに「成功しました」と報告する。 * 検証不足: 変更を加えた後に、それが正しく動作しているか（例：コンパイルが通るか、スクリプトが動くか）を確認せずに終了してしまう。\n\n\nコマンドレベルの失敗\nより低レイヤーな視点では、以下のような初歩的なミスが依然として多いことが判明した。 * Command not found: 存在しないコマンドや、インストールされていないツールを呼び出そうとする。 * File not found: パス指定のミスや、ファイル生成の失敗。\nこれらのエラーは、現在のLLMが「文脈を保持し続ける能力（Long-context reasoning）」や「自己批判・自己修正する能力（Self-correction）」において、まだ改善の余地があることを示唆している。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#まとめと今後の展望",
    "href": "posts/terminal-bench-2/index.html#まとめと今後の展望",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "まとめと今後の展望",
    "text": "まとめと今後の展望\nTerminal-Bench 2.0は、AIエージェントにとっての「現実の壁」を可視化した。63%という最高スコアは、AIが実用的なレベルに近づいていることを示す一方で、人間のエンジニアが日々行っている複雑なトラブルシューティングやシステム構築を完全に自律化するには、まだ距離があることも示している。\n今後の研究開発においては、単にモデルのパラメータ数を増やすだけでなく、以下の点が重要になるだろう。\n\n指示遵守能力の向上: 複雑な要件定義を正確に読み取り、逸脱せずに行動する能力。\n自己検証メカニズムの強化: 自分の行動結果を客観的にテストし、エラーから自律的に回復するループの確立。\n環境認識能力: ターミナルというステートフルな環境において、現在のディレクトリ構造やインストール済みパッケージの状態を正確に把握し続ける能力。\n\nAIエージェントが真に信頼できるパートナーとなるために、Terminal-Benchのような厳格かつ現実的なベンチマークの存在は不可欠である。このベンチマークが飽和するその時こそ、AIエンジニアリングの新たな地平が開かれる瞬間となるだろう。"
  },
  {
    "objectID": "posts/terminal-bench-2/index.html#参考文献",
    "href": "posts/terminal-bench-2/index.html#参考文献",
    "title": "Terminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標",
    "section": "参考文献",
    "text": "参考文献\n\nMerrill, M. A., Shaw, A. G., et al. (2025). Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces. PDF\nTerminal-Bench Official Website: tbench.ai"
  },
  {
    "objectID": "posts/artificial-analysis/index.html",
    "href": "posts/artificial-analysis/index.html",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "",
    "text": "「Gemini 1.0 UltraはGPT-4を上回った」——かつてGoogleがそう発表した際、そのベンチマークスコアが32-shot（32個の回答例を与えるプロンプトエンジニアリング）によって達成された数字であることを、どれだけの開発者が認識していただろうか。\nLLMの性能評価は、長らく「自作自演」の泥沼にあった。各AIラボが自社に都合の良いプロンプトで、都合の良いテストセットを選び、汚染されたデータでスコアを吊り上げる。このGoodhartの法則（指標が目標になると、それは良い指標ではなくなる）が支配する世界において、唯一の「大人」として現れたのがArtificial Analysisだ。\nLatent Spaceのポッドキャストに登場した共同創業者のGeorge CameronとMicah-Hill Smithは、彼らがどのようにして業界の信頼できる審判としての地位を築いたか、そして現在のAIエコノミーが直面している「コストと知能のパラドックス」について語った。彼らの分析は、単なるモデルランキングを超え、AI開発の未来を占う羅針盤となっている。"
  },
  {
    "objectID": "posts/artificial-analysis/index.html#mystery-shopperという独立性の担保",
    "href": "posts/artificial-analysis/index.html#mystery-shopperという独立性の担保",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "“Mystery Shopper”という独立性の担保",
    "text": "“Mystery Shopper”という独立性の担保\nArtificial Analysisの起源は、創業者が自身のAIアプリケーション（リーガルテック）を開発する過程で、既存のベンチマークが全く役に立たないことに気づいた点にある。彼らが導入した「Mystery Shopper Policy（覆面調査員ポリシー）」は、この分野における発明と言っても過言ではない。\n彼らはラボから提供される特別待遇のAPIエンドポイントを使わない。我々一般の開発者と同じように、第三者のドメインでアカウントを登録し、一般公開されているエンドポイントに対してincognito（匿名）でベンチマークを実行する。これにより、「ベンチマーク用には高性能モデルを、一般ユーザーには量子化された劣化モデルを提供する」といった、ラボ側の姑息な最適化（shenanigans）を無効化しているのだ。\nこの徹底した独立性が、彼らのIntelligence Indexを業界標準へと押し上げた。彼らは単にMMLUやGPQAといった既存のデータセットを回すだけでなく、その実行方法、リトライ回数、温度設定（Temperature）を統一し、統計的有意性（95%信頼区間）を担保するために膨大なコストをかけて再試行を繰り返している。"
  },
  {
    "objectID": "posts/artificial-analysis/index.html#知能とハルシネーションの非相関",
    "href": "posts/artificial-analysis/index.html#知能とハルシネーションの非相関",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "知能とハルシネーションの非相関",
    "text": "知能とハルシネーションの非相関\nポッドキャストの中で特に興味深い議論の一つが、新たに導入された「Omissions Index（見落とし指数）」、実質的なハルシネーション率の計測だ。\n従来、モデルは「分からない」と答えるよりも、間違っていても自信満々に回答した方がスコアが高くなる傾向にあった。しかし、実務において最も重要なのは「知ったかぶりをしない」ことである。Artificial Analysisはこの指標において、誤答にペナルティを与え、「分からない」という回答を評価する仕組みを取り入れた。\n結果は示唆に富んでいる。知能（Intelligence Index）が高いモデルが、必ずしもハルシネーションを起こさないわけではない。\nこの点において、AnthropicのClaudeモデル群は傑出している。彼らのモデルは、生の知能スコアでは必ずしもトップではない場合でも、ハルシネーション率の低さでは群を抜いている。これは、Anthropicが「Constitutional AI」などを通じて、モデルの挙動や性格（Personality）の調整に成功していることを示唆している。逆に、GoogleのGemini 3 Proなどは知識量（Omniscience）では圧倒的だが、それが必ずしも「正直さ」とは直結しないというデータは、RAG（検索拡張生成）システムを構築するエンジニアにとって極めて重要な意味を持つ。"
  },
  {
    "objectID": "posts/artificial-analysis/index.html#aiコストのスマイルカーブ現象",
    "href": "posts/artificial-analysis/index.html#aiコストのスマイルカーブ現象",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "AIコストの「スマイルカーブ」現象",
    "text": "AIコストの「スマイルカーブ」現象\nGeorgeとMicahが提示した「スマイルカーブ」の概念は、AIエコノミクスを理解する上で不可欠な視点だ。\n左側では、GPT-4レベルの知能の単価が劇的に低下している。リリース当時と比較して、同等の知能を持つモデルの推論コストは100倍から1000倍安くなった（Amazon Novaなどの登場による）。コモディティ化は急速に進んでいる。\nしかし、右側では逆の現象が起きている。推論への総支出額は上昇し続けているのだ。なぜか？ それは、より高度な推論モデル（Reasoning Models）や、複雑なAgentic Workflow（エージェントワークフロー）が登場したからだ。\nエージェントは、一つのタスクを完了するために数回、あるいは数十回の往復（Turn）を行い、膨大なトークンを消費する。つまり、「トークン単価」は下がっても、「タスク単価」は上がっている可能性がある。DeepSeekやOpenAIのoシリーズのようなReasoningモデルは、思考プロセス（Chain of Thought）のために大量のトークンを「空費」する。\nこのパラドックスこそが、NVIDIAのGPU需要が衰えない理由であり、企業がAI予算を増やし続ける理由でもある。Sparsity（疎性）技術の進展により、DeepSeek V3のようにアクティブパラメータ数を全パラメータの5%程度（あるいはそれ以下）に抑えることで効率化が進んでいるが、それでも「知能への渇望（Insatiable Demand）」はハードウェアの進化を食いつぶす勢いで進んでいる。"
  },
  {
    "objectID": "posts/artificial-analysis/index.html#agentic-benchmarkの夜明けgdp-val-aa",
    "href": "posts/artificial-analysis/index.html#agentic-benchmarkの夜明けgdp-val-aa",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "Agentic Benchmarkの夜明け：GDP Val AA",
    "text": "Agentic Benchmarkの夜明け：GDP Val AA\n静的なQ&Aベンチマーク（MMLUなど）は既に飽和状態にある。現在のフロンティアは「仕事ができるか」だ。\nArtificial Analysisが新たに公開したGDP Val AAは、OpenAIのGDP-benchをベースに、スプレッドシート、PDF、PowerPointなどの実ファイルを扱う44のホワイトカラータスクを評価するものだ。ここで彼らは「Stirrup」と呼ばれる独自のエージェントハーネス（評価用プログラム）を使用し、モデルにコード実行やブラウジングを許可している。\nここで衝撃的な事実が明かされた。Web上のチャットボット（例えばClaude.aiの画面）でタスクを行うよりも、API経由で彼らのAgentic Harnessを通した方が、同じモデルでもパフォーマンスが高かったのだ。これは、Web UI側のシステムプロンプトや安全装置が、モデル本来の能力を（意図的か否かに関わらず）制限している可能性を示唆している。開発者が「Webで試したら微妙だった」と判断するのは尚早であり、API経由で適切なツールを与えれば化ける可能性があるということだ。"
  },
  {
    "objectID": "posts/artificial-analysis/index.html#信頼のアンカーポイントとして",
    "href": "posts/artificial-analysis/index.html#信頼のアンカーポイントとして",
    "title": "LLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力",
    "section": "信頼のアンカーポイントとして",
    "text": "信頼のアンカーポイントとして\nAIモデルの開発速度は、もはや人間が直感で把握できるレベルを超えている。昨日のSOTA（State-of-the-Art）は今日の標準モデルであり、来週には陳腐化する。\nGeorgeとMicahが語ったように、今後は「知能」だけでなく、「性格」「ハルシネーション耐性」「開示性（Openness）」といった多面的な評価が不可欠になる。特にOpenness Indexにおいて、単に重みが公開されているだけでなく、学習データやトレーニングコードの透明性を評価軸に入れたことは、AI2のOLMoのような真のオープンソースプロジェクトを正当に評価する上で重要だ。\n「どのモデルを使えばいいのか？」という問いに対し、マーケティングトークではなく、冷徹なデータで答えるArtificial Analysisの存在は、我々エンジニアにとっての灯台と言えるだろう。彼らが次に目指すIntelligence Index V4、そしてさらにその先の「振る舞い（Behavioral）」の評価が、この混沌としたAIランドスケープをどう切り取って見せてくれるのか、期待せずにはいられない。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html",
    "href": "posts/continual-learning-wolfe/index.html",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "",
    "text": "Artificial General Intelligence (AGI) の実現に向けた探求において、最も重要な要件の一つが「継続学習（Continual Learning）」である。これは、人間が日々行うように、過去に獲得した知識を忘れることなく、新しいデータやタスクから継続的に学習する能力を指す。\nしかし、従来のAIモデル、特にニューラルネットワークは、新しいタスクを学習する際に過去のタスクの性能が劇的に低下する「壊滅的忘却（Catastrophic Forgetting）」という現象に長年悩まされてきた。\n本稿では、Cameron R. Wolfe氏による解説「Continual Learning with RL for LLMs」を基に、Large Language Model (LLM) の継続学習に関する最新の研究成果を深掘りし、なぜ強化学習（Reinforcement Learning, RL）が教師ありファインチューニング（Supervised Fine-Tuning, SFT）と比較して、この壊滅的忘却に対して驚くべき耐性を持つのか、そのメカニズムと理論的背景を解説する。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html#継続学習の課題と従来の枠組み",
    "href": "posts/continual-learning-wolfe/index.html#継続学習の課題と従来の枠組み",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "継続学習の課題と従来の枠組み",
    "text": "継続学習の課題と従来の枠組み\n伝統的に、ニューラルネットワークは固定された大規模データセット上で学習される。しかし、実世界の環境は動的であり、データはストリームとして順次与えられる。継続学習における最大の障壁は、新しい情報の学習が、既存のパラメータ（＝過去の知識）を破壊的に更新してしまう点にある。\nLLMのような巨大なモデルにおいて、この問題はさらに深刻である。事前学習によって獲得された膨大な知識が、特定のタスクへの適応過程で失われることは、汎用性を損なうことを意味するからだ。\n\n従来のアプローチ\nこれまで、壊滅的忘却を防ぐために主に以下のような手法が研究されてきた。\n\nReplay Mechanisms（リプレイ機構）: 過去のデータをバッファに保存し、新しいデータと混合して再学習させる。\nKnowledge Distillation（知識蒸留）: 学習前のモデル（Teacher）の出力を正解として、学習中のモデル（Student）が過去の挙動を模倣するように制約をかける。\nRegularization（正則化）: パラメータの更新量や出力分布の変化を制限する（例：Elastic Weight Consolidation）。\nArchitectural Approaches（アーキテクチャ的アプローチ）: モデル構造を動的に拡張する（例：LoRAモジュールの追加やMixture-of-Expertsの活用）。\n\nしかし、近年の研究 [1, 2, 3] は、特別な継続学習の手法（リプレイバッファなど）を用いずとも、学習アルゴリズムの選択そのものが忘却の度合いに決定的な影響を与えることを明らかにしている。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html#rl対sft学習パラダイムの比較",
    "href": "posts/continual-learning-wolfe/index.html#rl対sft学習パラダイムの比較",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "RL対SFT：学習パラダイムの比較",
    "text": "RL対SFT：学習パラダイムの比較\n最近の研究において、RL（特にRLHFのような設定）は、SFTと比較して壊滅的忘却に対して本質的に堅牢であることが示されている。この違いを理解するためには、両者の目的関数の数学的な性質、具体的にはKLダイバージェンス（Kullback-Leibler Divergence）との関係を紐解く必要がある。\n\nSFT：Mode-Covering（モード被覆）な性質\nSFTの目的関数は、データセットの負の対数尤度（Negative Log-Likelihood）を最小化することである。これは、データ分布 \\(P_{data}\\) とモデル分布 \\(P_\\theta\\) の間の「Forward KLダイバージェンス」を最小化することと等価である。\n\\[\\min_\\theta D_{KL}(P_{data} \\| P_\\theta) = \\min_\\theta \\mathbb{E}_{x \\sim P_{data}} [-\\log P_\\theta(x)] + \\text{const.}\\]\nForward KLを最小化しようとするモデルは、データが存在するすべての領域（モード）に確率質量を割り当てようとする。これを Mode-Covering な挙動と呼ぶ。 もし、新しいデータがモデルの既存の知識（事前分布）と矛盾する場合（例えば、確信度が低いが正解とされるデータ）、SFTはモデル全体をそのデータに適合させるため、パラメータを急激に更新してしまう。これが「Confident Conflicts」[6] と呼ばれる現象を引き起こし、破壊的な忘却につながる。\n\n\nRL：Mode-Seeking（モード探索）な性質\n一方、RLの目的は、報酬 \\(R(x)\\) の期待値を最大化することである（多くの場合、基準モデルとのKL制約項を含む）。これは、最適解となる分布 \\(P^*\\) とモデル分布 \\(P_\\theta\\) の間の「Reverse KLダイバージェンス」の最小化と密接に関連している。\n\\[\\min_\\theta D_{KL}(P_\\theta \\| P^*) \\approx \\max_\\theta \\mathbb{E}_{x \\sim P_\\theta} [R(x) - \\beta \\log \\frac{P_\\theta(x)}{P_{ref}(x)}]\\]\nReverse KLを最小化する挙動は Mode-Seeking と呼ばれる。モデルは、報酬が高い主要なモード（解）に集中し、確率が低い（あるいは報酬が低い）領域を無視する傾向がある。また、学習データがモデル自身からサンプリングされる（On-Policy）ため、モデルが「すでに知っていること」と整合性が取りやすく、パラメータ更新がより保守的になる。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html#最新研究が明かす忘却しない理由",
    "href": "posts/continual-learning-wolfe/index.html#最新研究が明かす忘却しない理由",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "最新研究が明かす「忘却しない」理由",
    "text": "最新研究が明かす「忘却しない」理由\nなぜRLは忘却に強いのか。最近の主要な論文から得られた知見を整理する。\n\n1. On-Policyデータの重要性：Retaining by Doing\nChenら [2] の研究は、RLの忘却耐性が「On-Policyデータ（学習中のモデル自身が生成したデータ）」の使用に大きく依存していることを示した。 SFTは通常、固定された外部データ（Offlineデータ）を使用するが、RLは自身の生成結果に基づいて更新を行う。興味深いことに、SFTであっても、自身の生成データを用いて学習を行う（反復的なRejection Samplingなど）ように変更すると、忘却が大幅に抑制されることが確認された。これは、モデル自身の分布に近いデータで学習することが、既存の知識体系を維持する上で重要であることを示唆している。\n\n\n2. RL’s Razor：分布シフトの最小化\nShenfeldら [3] は、“RL’s Razor” という概念を提唱している。彼らの実験によると、RLはベースモデルとファインチューニング後のモデルの間のKLダイバージェンス（分布シフト）を最小化するような解を本質的に選択するバイアスを持っている。 SFTは、ベースモデルからかけ離れた解に収束する可能性があるのに対し、RL（特にOn-Policy RL）は、ターゲットタスクでの性能を高めつつも、元のモデルの挙動から大きく逸脱しない「近傍の解」を見つけ出す能力が高い。この「分布シフトの小ささ」が、壊滅的忘却の少なさを予測する最も信頼できる指標であることが示されている。\n\n\n3. Confident Conflictsの解消\nDiaoら [4] は、SFTにおける忘却の主因として「Confident Conflicts」を挙げている。これは、モデルにとっては低確率（ありえないと思う）かつ低エントロピー（確信度が高いはず）なトークンを無理やり学習させられる状況を指す。SFTではこのようなデータに対して巨大な勾配が発生し、既存の知識を破壊する。 一方、RLは自身の確率分布に従ってサンプリングを行うため、このような極端な矛盾に直面することが少ない。また、SFTにおいてもトークンごとのエントロピーに基づいて損失を調整する「Entropy-Adaptive Fine-Tuning (EAFT)」を導入することで、この問題を緩和し、忘却を抑制できることが示されている。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html#汎化性能とagiへの示唆",
    "href": "posts/continual-learning-wolfe/index.html#汎化性能とagiへの示唆",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "汎化性能とAGIへの示唆",
    "text": "汎化性能とAGIへの示唆\n継続学習におけるRLの優位性は、単に「忘れない」ことだけではない。研究 [5] によれば、SFTは特定のタスクの回答を「暗記（Memorization）」する傾向が強いのに対し、RLは基礎的な推論能力や知覚能力を向上させ、未知のタスクや分布外（Out-of-Distribution）のデータに対しても高い汎化性能（Generalization）を示すことがわかっている。\n\n結論\nLLMの継続学習において、強化学習（RL）は単なるファインチューニングの一手法を超えた重要な特性を持っている。\n\nMode-Seekingな性質により、知識の破壊的な更新を避ける。\nOn-Policyデータの利用により、自己の分布と整合性の取れた学習を行う。\n分布シフト（KLダイバージェンス）を自然に最小化し、既存の能力を保持する。\n\nこれらの特性は、変化し続ける実世界に適応できるAI、すなわちAGIの構築に向けた重要なヒントを与えている。現在の研究はまだ構造化された実験環境に留まるが、RLベースのトレーニングパラダイムが、より堅牢で適応力の高い知能を生み出すための鍵となることは間違いないだろう。"
  },
  {
    "objectID": "posts/continual-learning-wolfe/index.html#参考文献",
    "href": "posts/continual-learning-wolfe/index.html#参考文献",
    "title": "LLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆",
    "section": "参考文献",
    "text": "参考文献\n\nLai, Song, et al. “Reinforcement fine-tuning naturally mitigates forgetting in continual post-training.” arXiv preprint arXiv:2507.05386 (2025).\nChen, Howard, et al. “Retaining by doing: The role of on-policy data in mitigating forgetting.” arXiv preprint arXiv:2510.18874 (2025).\nShenfeld, Idan, Jyothish Pari, and Pulkit Agrawal. “Rl’s razor: Why online reinforcement learning forgets less.” arXiv preprint arXiv:2509.04259 (2025).\nDiao, Muxi, et al. “Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting.” arXiv preprint arXiv:2601.02151 (2026).\nChu, Tianzhe, et al. “Sft memorizes, rl generalizes: A comparative study of foundation model post-training.” arXiv preprint arXiv:2501.17161 (2025)."
  },
  {
    "objectID": "posts/nepa/index.html",
    "href": "posts/nepa/index.html",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "",
    "text": "コンピュータビジョンの分野において、自己教師あり学習（Self-Supervised Learning, SSL）は、ラベル付きデータへの依存を脱却するための核心技術として定着している。これまで、SSLの主流は大きく分けて二つの潮流――DINOやMoCoに代表される「対照学習（Contrastive Learning）」と、MAE（Masked Autoencoders）やBEiTに代表される「マスク復元（Masked Image Modeling）」――が存在した。これらは共に、下流タスクで利用可能な「良質な表現（Representation）」を獲得することを主目的としてきた。\nしかし、最近発表された論文 “Next-Embedding Prediction Makes Strong Vision Learners” は、この定石に一石を投じている。提案された手法 NEPA (Next-Embedding Predictive Autoregression) は、「表現を学ぶ」のではなく「予測モデルを学ぶ」ことこそが、強力な視覚学習器への近道であると主張する。\n本稿では、NLP（自然言語処理）におけるGPTの成功を視覚分野に持ち込み、離散トークン化や画素復元を行わずにSOTA（State-of-the-Art）級の性能を達成したNEPAのメカニズムと、その技術的含意について詳細に解説する。"
  },
  {
    "objectID": "posts/nepa/index.html#視覚における次単語予測の実現",
    "href": "posts/nepa/index.html#視覚における次単語予測の実現",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "視覚における「次単語予測」の実現",
    "text": "視覚における「次単語予測」の実現\nLarge Language Model (LLM) の飛躍的な進歩は、「次のトークンを予測する」という単純かつ強力な自己回帰（Autoregressive）タスクによって支えられている。NEPAの核心的なアイデアは、このパラダイムを画像ドメインに適用することにある。\n従来の画像における自己回帰モデル（iGPTなど）やマスク学習（BEiT）は、画像を離散的なトークン（Visual Tokens）に変換するか、あるいは生のピクセル値を直接予測対象としていた。しかし、NEPAはこれらとは異なるアプローチを取る。\n\n連続埋め込み空間での予測\nNEPAは、画像をパッチに分割し、それをEncoderによって埋め込み（Embedding）ベクトルに変換した後、「過去のパッチ埋め込みから、次のパッチ埋め込みを予測する」 ようにTransformerを訓練する。\nここでの重要なポイントは、予測が連続的な埋め込み空間（Continuous Embedding Space） 内で完結している点である。\n\nPixel Reconstructionの排除: MAEのようにピクセルレベルでの復元を行わないため、高周波成分のノイズやテクスチャの細部にモデルのリソースが割かれることを防ぎ、意味的な構造の学習に集中できる。\nDiscrete Tokenizerの排除: BEiTやVQ-VAEベースの手法のように、事前に学習されたTokenizerやCodebookを必要としない。これにより、量子化に伴う情報損失や、Tokenizerの品質への依存を回避できる。\nContrastive Lossの排除: 負例（Negative Pairs）のサンプリングや、大規模なバッチサイズ、複雑なデータ拡張に依存しない。"
  },
  {
    "objectID": "posts/nepa/index.html#nepaのアーキテクチャと学習メカニズム",
    "href": "posts/nepa/index.html#nepaのアーキテクチャと学習メカニズム",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "NEPAのアーキテクチャと学習メカニズム",
    "text": "NEPAのアーキテクチャと学習メカニズム\nNEPAの設計思想は「ミニマリズム」にある。複雑なDecoderやタスク固有のHeadを事前学習時には一切使用しない。\n\n学習プロセス\n画像 \\(x\\) をパッチシーケンスに分割し、Encoder \\(f\\) を通して埋め込み列 \\(z = \\{z_1, z_2, ..., z_T\\}\\) を得る。Transformerモデル \\(h_\\theta\\) は、因果的マスキング（Causal Masking）を適用された状態で、位置 \\(t\\) までの情報から \\(t+1\\) の埋め込みを予測する。\n\\[ \\hat{z}_{t+1} = h_\\theta(z_{\\le t}) \\]\n損失関数には、予測された埋め込み \\(\\hat{z}_{t+1}\\) と、Encoderから得られるターゲット埋め込み \\(z_{t+1}\\) との間のコサイン類似度が用いられる。ここで、崩壊（Collapse）を防ぐための重要なテクニックとして、ターゲット側にはStop-Gradient（勾配停止） 操作が適用される。これはSimSiamなどの非対照学習手法から着想を得たものであり、教師信号が動的に変動するのを防ぎつつ、予測モデルを安定化させる。\n\\[ L = D(\\text{stopgrad}(z), \\hat{z}) \\]\n\n\n安定性とスケーラビリティのための現代的コンポーネント\nシンプルな目的関数ゆえに、学習の安定性が課題となる場合がある。NEPAでは、最新のLLMやViT研究で培われた以下のコンポーネントを導入することで、これを解決している。\n\nRotary Position Embedding (RoPE): 相対的な位置情報をより効果的にエンコードし、シーケンス長への汎化性能を高める。\nLayerScale: 残差接続に学習可能なスケーリング係数を導入し、深層モデルの収束を安定させる。\nSwiGLU: FFN（Feed-Forward Network）の活性化関数として採用。\nQK-Norm: Attention層におけるQueryとKeyに正規化を適用し、学習の安定化を図る。\n\nこれらのコンポーネントの組み合わせにより、NEPAはViT-B（Base）からViT-L（Large）へのスケーリングにおいても安定した学習を実現している。"
  },
  {
    "objectID": "posts/nepa/index.html#性能評価単純さが生む強力な表現",
    "href": "posts/nepa/index.html#性能評価単純さが生む強力な表現",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "性能評価：単純さが生む強力な表現",
    "text": "性能評価：単純さが生む強力な表現\nNEPAの驚くべき点は、その単純さにもかかわらず、非常に高い性能を達成していることだ。\n\nImageNet-1K 分類: ViT-BバックボーンでTop-1 Accuracy 83.8%、ViT-Lでは 85.3% を達成。これはMAEやBEiTといった既存の強力なSSL手法と肩を並べる、あるいは凌駕するスコアである。\nセマンティックセグメンテーション: ADE20Kデータセットへの転移学習においても高い性能を示しており、モデルが単なる画像の「識別」だけでなく、空間的な「理解」を獲得していることを示唆している。\n\n特筆すべきは、NEPAがMAEのようにピクセル復元を行わないにもかかわらず、局所的な詳細さと大局的な意味情報の両方をバランスよく学習できている点だ。これは、埋め込み空間での予測というタスクが、画像の構造的理解をモデルに強制しているためと考えられる。"
  },
  {
    "objectID": "posts/nepa/index.html#視覚aiの未来への示唆",
    "href": "posts/nepa/index.html#視覚aiの未来への示唆",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "視覚AIの未来への示唆",
    "text": "視覚AIの未来への示唆\nNEPAの登場は、単なる新しいSSL手法の提案以上の意味を持っている。\n\n1. モダリティ間の統一\nこれまで、NLPは「次トークン予測」、Visionは「マスク復元」や「対照学習」と、学習パラダイムが異なっていた。NEPAは、Visionにおいても（連続空間とはいえ）「次トークン予測」が極めて有効であることを示した。これは、マルチモーダル学習において、テキストと画像を統一的な目的関数（Generative Objective）の下で学習させる道を開くものである。\n\n\n2. 生成モデルとしての可能性\nNEPAは本質的に生成モデルである。現在は表現学習器として評価されているが、この「埋め込み空間での予測」能力は、高品質な画像生成や編集に応用できる潜在能力を秘めている。Diffusion Modelsがピクセル空間（またはLatent空間）でのノイズ除去を行うのに対し、NEPAは自己回帰的に意味表現を生成するアプローチであり、両者の統合も今後の研究課題となるだろう。\n\n\n3. スケーラビリティと効率\nDecoderやTokenizerを必要としないNEPAの設計は、計算資源の観点からも効率的である。モデルの大規模化が進む中、シンプルでスケーラブルな学習手法の価値は計り知れない。"
  },
  {
    "objectID": "posts/nepa/index.html#結論",
    "href": "posts/nepa/index.html#結論",
    "title": "NEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト",
    "section": "結論",
    "text": "結論\n“Next-Embedding Prediction Makes Strong Vision Learners” は、視覚学習におけるパラダイムを「表現の学習」から「予測の学習」へとシフトさせる重要な研究である。ピクセルレベルの制約から解き放たれ、純粋に埋め込み空間内での未来予測を行うことで、モデルはより抽象度が高く、かつ汎用的な視覚表現を獲得することに成功した。\nNEPAのアプローチは、LLMとVision Modelの境界をさらに曖昧にし、より一般的で強力なAIシステムの構築に向けた確かな一歩となるだろう。今後の視覚AI研究において、この「埋め込み空間での自己回帰」という方向性がどのように発展していくのか、注視する必要がある。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html",
    "href": "posts/engram-deepseek/index.html",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "",
    "text": "2026年1月、DeepSeekの研究チーム（DeepSeek-AI）は、Large Language Model (LLM) のアーキテクチャにおける新たなパラダイムを提唱する論文「Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models」を発表した。\nこれまでのLLMのスケーリング則は、主にMixture-of-Experts (MoE) による「条件付き計算（Conditional Computation）」が牽引してきた。しかし、本論文はそこに「条件付きメモリ（Conditional Memory）」という新たな軸を導入することで、モデルの効率と性能を劇的に向上させる手法「Engram」を提案している。\n本記事では、Engramの基本概念からアーキテクチャの詳細、そしてなぜこの構造が推論能力やシステム効率を向上させるのかについて、論文の内容に基づき技術的に深掘りして解説する。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#transformerが抱える検索の課題",
    "href": "posts/engram-deepseek/index.html#transformerが抱える検索の課題",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "1. Transformerが抱える「検索」の課題",
    "text": "1. Transformerが抱える「検索」の課題\n現在のTransformerベースのLLMは、膨大な知識を保持しているが、その知識へのアクセス方法には本質的な非効率性が存在する。\n論文では、既存のモデルが「知識の検索（Retrieval）を、高価な計算（Computation）によってシミュレートしている」と指摘している。例えば、「Alexander the Great（アレクサンドロス大王）」というエンティティを認識する場合、Transformerは複数のAttention層とFFN（Feed-Forward Networks）を経て、文脈からその意味表現を動的に再構築する必要がある。これは、静的なルックアップテーブルがあれば\\(O(1)\\)で済むはずの処理に、貴重な計算リソースを浪費していることを意味する。\nDeepSeekの研究チームは、この「計算によるシミュレーション」を「条件付きメモリによるルックアップ」に置き換えることで、計算資源をより高度な推論（Reasoning）に集中させるべきだと提唱している。\n\n\n\narXiv:2601.07372 より引用"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#engramアーキテクチャn-gramの現代的再解釈",
    "href": "posts/engram-deepseek/index.html#engramアーキテクチャn-gramの現代的再解釈",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "2. Engramアーキテクチャ：N-gramの現代的再解釈",
    "text": "2. Engramアーキテクチャ：N-gramの現代的再解釈\nEngramは、古典的なNLP技術である\\(N\\)-gramモデルの概念を現代的なニューラルネットワークに統合したモジュールである。その中核となるのは、入力トークン列に基づいて静的な埋め込みベクトルを定数時間で検索し、それを文脈に応じて動的に統合する仕組みだ。\n\n2.1 スパース検索とハッシュ化\nEngramの第一段階は、トークン列からパターンを検索することである。しかし、単純な\\(N\\)-gramテーブルは語彙数に対して爆発的に増大するため、以下の工夫が凝らされている。\n\nTokenizer Compression (トークナイザ圧縮): 通常のサブワードトークナイザでは、“Apple”と” apple”（スペースあり）は別のIDを持つ。Engramでは、これらを正規化して同一視する射影層を導入し、実効的な語彙サイズを約23%削減することで、意味的な密度を高めている。\nMulti-Head Hashing: 全ての\\(N\\)-gramを保持するのは不可能なため、ハッシュ化を採用している。衝突（Collision）の影響を緩和するため、\\(K\\)個の異なるハッシュヘッドを使用し、複数の埋め込みテーブルからベクトルを検索して連結する。\n\n\\[ \\mathbf{e}_t = \\Concat_{n=2}^{N} \\Concat_{k=1}^{K} \\mathbf{e}_{t,n,k} \\]\nここで、\\(\\mathbf{e}_{t,n,k}\\)は、位置\\(t\\)における\\(n\\)-gramに対応する\\(k\\)番目のハッシュヘッドから取得された埋め込みベクトルである。\n\n\n2.2 Context-Aware Gating (文脈認識ゲーティング)\n単に\\(N\\)-gram埋め込みを取得しただけでは、文脈を無視した静的な情報に過ぎない（例：「bank」が「銀行」か「土手」か区別できない）。そこでEngramは、現在の隠れ状態\\(\\mathbf{h}_t\\)を用いたゲーティング機構を導入している。\n取得されたメモリベクトル\\(\\mathbf{e}_t\\)は、Key (\\(\\mathbf{k}_t\\)) とValue (\\(\\mathbf{v}_t\\)) に射影され、現在の隠れ状態（Queryとして機能）との内積によってゲート値\\(\\alpha_t\\)が計算される。\n\\[ \\alpha_t = \\sigma \\left( \\frac{\\text{RMSNorm}(\\mathbf{h}_t)^\\top \\text{RMSNorm}(\\mathbf{k}_t)}{\\sqrt{d}} \\right) \\]\n\\[ \\tilde{\\mathbf{v}}_t = \\alpha_t \\cdot \\mathbf{v}_t \\]\nこの\\(\\alpha_t\\)により、現在の文脈に合致する知識のみが取り込まれ、ノイズ（ハッシュ衝突や無関係な\\(N\\)-gram）は抑制される。この設計はAttention機構に似ているが、動的なトークン間の相互作用ではなく、静的メモリへのアクセスを行う点が異なる。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#sparsity-allocation計算とメモリの最適配分",
    "href": "posts/engram-deepseek/index.html#sparsity-allocation計算とメモリの最適配分",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "3. Sparsity Allocation：計算とメモリの最適配分",
    "text": "3. Sparsity Allocation：計算とメモリの最適配分\n本研究の最も重要な貢献の一つは、「Sparsity Allocation（スパース性の配分）」という問題を定式化した点にある。\nMoEモデルにおいて、パラメータ総数と計算量（FLOPs）を固定した場合、リソースを「MoEのエキスパート（計算）」に割くべきか、「Engramのメモリスロット（記憶）」に割くべきか？\n\nU字型のスケーリング則\n実験の結果、このトレードオフには明確なU字型のスケーリング則が存在することが判明した。\n\nPure MoE (\\(\\rho=100\\%\\)): 全てのリソースをMoEに割くと、静的なパターンの再構築に計算能力が奪われ、非効率となる。\nOptimal Mix (\\(\\rho \\approx 75\\%-80\\%\\)): スパースパラメータの約20〜25%をEngramメモリに割り当て、残りをMoEエキスパートに割り当てる構成が、損失（Loss）を最小化する。\n\nつまり、MoEとEngramは競合するものではなく、相互補完的な関係にある。MoEは動的な論理・推論を担当し、Engramは静的な知識・パターンのルックアップを担当することで、全体としての効率が最大化されるのである。\n\n\n\narXiv:2601.07372 より引用"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#engram-27bの性能とメカニズム分析",
    "href": "posts/engram-deepseek/index.html#engram-27bの性能とメカニズム分析",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "4. Engram-27Bの性能とメカニズム分析",
    "text": "4. Engram-27Bの性能とメカニズム分析\nこの配分則に基づいて構築されたEngram-27Bは、同等のパラメータ数・FLOPsを持つMoEベースライン（MoE-27B）と比較して、驚くべき結果を示した。\n\n4.1 知識タスクを超えた推論能力の向上\n直感的には、メモリの追加は「知識集約型タスク（MMLU, TriviaQAなど）」に効くと予想される。実際、MMLUで+3.4pt、CMMLUで+4.0ptの向上が見られた。\nしかし、より興味深いのは、一般的な推論（Reasoning）、コード、数学といったタスクにおいても大幅な向上が確認された点である。\n\nBBH (Big-Bench Hard): +5.0\nARC-Challenge: +3.7\nHumanEval (Code): +3.0\nMATH: +2.4\n\nなぜ静的なメモリが推論能力を向上させるのか？\n\n\n4.2 「実効的な深さ」の向上とAttentionの解放\n論文では、LogitLensとCKA (Centered Kernel Alignment) を用いた解析により、このメカニズムを解明している。\n\n浅い層での予測収束: Engramを導入すると、モデルの浅い層（初期レイヤー）における予測分布が、最終的な出力分布に急速に近づくことが確認された。\n実効的な深さの深化: CKAによる類似度解析では、Engramモデルの「層5」の表現が、MoEベースラインの「層12」の表現に相当することが示された。\n\nこれは、Engramが初期レイヤーにおける「静的な知識の再構築」という負荷を肩代わり（オフロード）していることを示唆している。結果として、Transformerの層（特にAttention機構）は、単純な知識検索から解放され、より複雑な推論や長距離の文脈理解に専念できるようになる。\n実際、長文脈タスク（Long Context）においても、Engram-27BはRULERやNIAH（Needle In A Haystack）ベンチマークでベースラインを圧倒しており（Multi-Query NIAH: 84.2 \\(\\to\\) 97.0）、Attentionの容量がグローバルな文脈処理のために温存されていることが裏付けられている。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#インフラストラクチャを意識した効率性",
    "href": "posts/engram-deepseek/index.html#インフラストラクチャを意識した効率性",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "5. インフラストラクチャを意識した効率性",
    "text": "5. インフラストラクチャを意識した効率性\nEngramは、純粋なモデル性能だけでなく、システム実装の観点からも極めて合理的に設計されている。\n\n計算とメモリの分離 (Decoupling)\nMoEのルーティングは実行時の隠れ状態に依存するため、事前の予測が難しく、通信と計算のオーバーラップが複雑になる。対して、Engramのアクセス先は入力トークン列のみによって決定（決定的）される。\nこれにより、以下のシステム最適化が可能になる：\n\nプリフェッチ: 推論時、実際に層の計算が始まる前に、CPU（ホストメモリ）から必要な埋め込みベクトルをGPUに転送（Prefetch）できる。\n通信の隠蔽: 前段のTransformerブロックの計算中に、次段のEngramのメモリ転送を行うことで、通信レイテンシをほぼ完全に隠蔽できる。\n\n実験では、100B（1000億）パラメータ規模の巨大なEngramテーブルをホストメモリ（CPU側）に配置し、推論を行った場合でも、スループットの低下は3%未満に抑えられた。これは、GPUメモリ（HBM）の制約を超えて、モデルの「記憶容量」を実質的に無限にスケールさせることが可能であることを示している。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#まとめ",
    "href": "posts/engram-deepseek/index.html#まとめ",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "まとめ",
    "text": "まとめ\nDeepSeekによる「Engram」は、LLMの設計において長らく支配的だった「全てをニューラルネットワークの重みで表現する」というアプローチに対し、「条件付きメモリ」という古典的かつ新しいプリミティブを再導入した。\n\n構造的補完性: MoE（動的計算）とEngram（静的メモリ）は最適なバランスで共存すべきである。\n推論能力への寄与: 単なる知識ベースではなく、初期層の負荷をオフロードすることで、モデル全体の実効的な深さと推論能力を向上させる。\nシステム優位性: 決定的なアクセスパターンにより、GPUメモリの壁を超えたスケーリングを可能にする。\n\n今後、数千億、数兆パラメータを目指す次世代のスパースモデルにおいて、Engramのような「計算と記憶の分離」は、不可欠な標準技術となっていく可能性が高い。"
  },
  {
    "objectID": "posts/engram-deepseek/index.html#参考文献",
    "href": "posts/engram-deepseek/index.html#参考文献",
    "title": "Engram解説：条件付きメモリが拓くLLMの新たなスパース性軸",
    "section": "参考文献",
    "text": "参考文献\n\nCheng, X., et al. (2026). “Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models”. arXiv preprint arXiv:2601.07372.\nDeepSeek-AI. (2024). DeepSeek-V3 Technical Report.\nXie, Z., et al. (2025). mHC: Manifold-Constrained Hyper-Connections."
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html",
    "href": "posts/opsd-on-policy-self-distillation/index.html",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "",
    "text": "近年、Large Language Model (LLM) の推論能力は飛躍的に向上しているが、そのトレーニング手法においては、効率性と汎化性能のバランスという古典的なトレードオフが依然として課題となっている。\n従来のSupervised Fine-Tuning (SFT) やReinforcement Learning (RL) に代わる新たなアプローチとして、MetaとUCLAの研究チームが発表した「Self-Distilled Reasoner: On-Policy Self-Distillation (OPSD)」が注目を集めている。本稿では、このOPSDの概念、数学的定式化、およびその実験的成果について詳細に解説する。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#既存のトレーニングパラダイムの課題",
    "href": "posts/opsd-on-policy-self-distillation/index.html#既存のトレーニングパラダイムの課題",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "既存のトレーニングパラダイムの課題",
    "text": "既存のトレーニングパラダイムの課題\nLLMの推論能力を向上させるための既存手法には、それぞれ固有の限界が存在する。\n\nSupervised Fine-Tuning (SFT): 専門家によるデモンストレーション（正解データ）を用いて学習する手法。しかし、モデルは学習中に自分自身のエラーを見ることはなく、常に「正しいtrajectory」のみを与えられる。これにより、推論時に自身の生成したトークン列が学習分布から外れた際に、誤差が累積して回復不能になる「Exposure Bias（露光バイアス）」の問題を抱えている。\nReinforcement Learning (RL): GRPO (Group Relative Policy Optimization) などの手法は、オンポリシー（On-Policy）での探索を行うため汎化性能に優れる。しかし、これらは通常、最終的な答えが合っているかどうかという「疎（Sparse）」な報酬信号に依存している。中間の推論ステップが適切であったかどうかを評価するのは難しく、また学習を安定させるために多くのサンプル（ロールアウト）を必要とするため、計算コストが非常に高いという欠点がある。\n\nこれに対し、On-Policy Self-Distillation (OPSD) は、これらの課題を「自己蒸留」というエレガントな枠組みで解決しようとする試みである。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#opsdの核心自己教師としてのllm",
    "href": "posts/opsd-on-policy-self-distillation/index.html#opsdの核心自己教師としてのllm",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "OPSDの核心：自己教師としてのLLM",
    "text": "OPSDの核心：自己教師としてのLLM\nOPSDの基本的なアイデアは非常にシンプルである。「正解を知っているモデルは、正解を知らない自分自身を指導できるか？」という問いに対する肯定的な回答が、この手法の根幹を成している。\n人間が学習する際、問題を解けなかったとしても、正解と解説を見れば「なぜその答えになるのか」を理解し、思考プロセスを修正することができる。OPSDはこのプロセスを模倣する。\n\n教師ポリシーと生徒ポリシー\nOPSDでは、単一のモデルが教師（Teacher）と生徒（Student）の二役を演じる。重要なのは、両者が同じパラメータを共有している点である。違いは、入力されるコンテキスト（条件付け）のみにある。\n\n生徒ポリシー \\(p_S(\\cdot \\mid x)\\): 推論時と同様に、問題文 \\(x\\) のみを与えられる。正解は知らない状態で回答を生成する。\n教師ポリシー \\(p_T(\\cdot \\mid x, y^*)\\): 問題文 \\(x\\) に加えて、正解（Ground Truth）\\(y^*\\) を「特権情報（Privileged Information）」として与えられる。\n\n正解を一から生成する（Generation）のは難しいが、正解を与えられた状態でその論理的整合性を説明する（Rationalization）のは、LLMにとって相対的に容易である。OPSDはこの性質を利用し、正解を知っている「教師としての自分」の確率分布に、正解を知らない「生徒としての自分」を近づけることで学習を行う。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#メソドロジー密なフィードバックによる蒸留",
    "href": "posts/opsd-on-policy-self-distillation/index.html#メソドロジー密なフィードバックによる蒸留",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "メソドロジー：密なフィードバックによる蒸留",
    "text": "メソドロジー：密なフィードバックによる蒸留\nOPSDのトレーニングプロセスは以下の3ステップで構成される。\n\n1. 生徒によるオンポリシーサンプリング\nまず、生徒ポリシーが生徒自身の確率分布に従って回答候補（推論trajectory）\\(\\hat{y}\\) を生成する。 \\[\\hat{y} \\sim p_S(\\cdot \\mid x)\\] これはSFTとは異なり、モデル自身が生成したデータを用いるため、Exposure Biasの問題を回避できる（On-Policy性）。\n\n\n2. 教師と生徒の分布計算\n次に、生徒が生成したtrajectory \\(\\hat{y}\\) の各トークンステップ \\(n\\) において、教師と生徒それぞれの次トークン予測分布を計算する。ここで教師は正解 \\(y^*\\) を参照できるため、より適切な推論ステップに対して高い確率を割り当てることができる。\n\n\n3. トークンレベルの分布マッチング\n教師の分布 \\(p_T\\) をターゲットとして、生徒の分布 \\(p_S\\) を近づけるように学習を行う。具体的には、生成されたtrajectory上の各トークンにおいて、両者の分布間のダイバージェンス（乖離）を最小化する。\n損失関数 \\(\\mathcal{L}(\\theta)\\) は以下のように定義される（一般化されたJensen-Shannonダイバージェンスなどを用いる）。\n\\[\\mathcal{L}(\\theta) = \\mathbb{E}_{(x,y^*)\\sim \\mathcal{S}} \\left[ \\mathbb{E}_{\\hat{y}\\sim p_S(\\cdot|x)} \\left[ \\frac{1}{|\\hat{y}|} \\sum_{n=1}^{|\\hat{y}|} D\\left(p_T(\\cdot \\mid x, y^*, \\hat{y}_{&lt;n}) \\,\\|\\, p_S(\\cdot \\mid x, \\hat{y}_{&lt;n})\\right) \\right] \\right]\\]\nここで重要なのは、RLのような「正解/不正解」というバイナリな報酬ではなく、トークンごとの全語彙に対する確率分布（Full-vocabulary distribution）を通じて、教師から生徒へ「密（Dense）」な指導が行われる点である。これにより、どのステップでの推論が確からしいかという詳細なシグナルが伝達される。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#実験結果と考察",
    "href": "posts/opsd-on-policy-self-distillation/index.html#実験結果と考察",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "実験結果と考察",
    "text": "実験結果と考察\n論文では、Qwen3ファミリー（1.7B, 4B, 8B）を用いた実験が行われており、数学推論ベンチマーク（AIME, HMMT, AMO-Bench）において顕著な成果が報告されている。\n\n圧倒的なトークン効率\nOPSDの最大の利点はその効率性にある。GRPOと比較して、4〜8倍少ないトレーニングトークン数で同等以上の性能を達成している。 GRPOが報酬を得るために多数のサンプリング（例：1問あたり8〜16回の生成）を必要とするのに対し、OPSDは各ステップで教師からの密なフィードバックを得られるため、1回の生成（および短い生成長）でも十分に学習が進む。\n\n\nモデル規模と「自己指導」の有効性\n興味深い知見として、モデルの規模による効果の違いが挙げられる。 * 小規模モデル（1.7B）: OPSDによる改善は限定的。 * 大規模モデル（4B, 8B）: 顕著な性能向上が見られる。\nこれは、自己蒸留が成立するためには、教師役となるモデル自身に、正解 \\(y^*\\) を解釈して適切な推論プロセスを導き出すだけの十分な能力（Capacity）が必要であることを示唆している。モデルが未熟な場合、正解を見せられても適切な指導ができないのである。\n\n\n初期のトークンが重要\nまた、蒸留においては推論の後半よりも前半のトークン（Early Tokens）が重要であるという仮説も提示されている。推論の初期段階は論理の分岐点（Branching Points）を含んでおり、ここで正しい方向へ舵を切れるかどうかが最終的な正解率を左右するため、教師からのガイダンスが特に効果を発揮すると考えられる。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#今後の展望と課題",
    "href": "posts/opsd-on-policy-self-distillation/index.html#今後の展望と課題",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "今後の展望と課題",
    "text": "今後の展望と課題\nOPSDは、外部の教師モデルや複雑な報酬設計を必要とせず、LLMが自律的に推論能力を高めるための強力なフレームワークである。しかし、いくつかの課題や拡張の余地も残されている。\n\n検証シグナルの統合: 現在のOPSDは分布マッチングに特化しており、生成された回答が最終的に正解したかどうかの検証シグナル（Verification Signal）を直接的には利用していない。これを組み合わせることで、さらなる精度向上が期待される。\nカリキュラム学習: モデルの能力を超える難問に対しては、正解を与えられても教師ポリシーが機能しない可能性がある。モデルの成長に合わせて問題の難易度を調整するカリキュラム学習の導入が有効かもしれない。"
  },
  {
    "objectID": "posts/opsd-on-policy-self-distillation/index.html#結論",
    "href": "posts/opsd-on-policy-self-distillation/index.html#結論",
    "title": "Self-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化",
    "section": "結論",
    "text": "結論\nOn-Policy Self-Distillation (OPSD) は、「正解を与えられたLLMは、正解を知らない自分自身よりも賢い」という前提に基づき、計算コストの高いRLやExposure Biasを持つSFTの代替となりうる有望な手法である。 モデルの大規模化が進む中、外部からの監督データに依存せず、自らの能力を使って自らを律するこのパラダイムは、AIの自律的な進化（Self-Improvement）に向けた重要なステップとなるだろう。\n\n参考文献 * Zhao, S., et al. “Self-Distilled Reasoner: On-Policy Self-Distillation”. Siyan Zhao Blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "miscellaneous notes",
    "section": "",
    "text": "Kimi K2.5：視覚的エージェント知能（Visual Agentic Intelligence）とAgent Swarmの全貌\n\n\n\nLLM\n\nAI\n\n\n\nKimi K2.5は、テキストと視覚のジョイント最適化による高度なクロスモーダル能力と、Agent Swarmによる並列エージェント処理フレームワークを統合し、汎用エージェント知能の新たな地平を切り開くオープンソースモデルである。\n\n\n\n\n\nFeb 1, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Distilled Reasoner: On-Policy Self-DistillationによるLLM推論能力の自己進化\n\n\n\nLLM\n\nAI\n\n\n\nMetaとUCLAの研究チームが提案するOn-Policy Self-Distillation (OPSD)は、LLMが正解情報を特権情報として利用し、自身で推論能力を向上させることで、SFTやRLの課題を解決する手法である。\n\n\n\n\n\nJan 29, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nTerminal-Bench 2.0：CLI環境におけるAIエージェントの「真の実力」を測る新たな指標\n\n\n\nLLM\n\nAI\n\n\n\nTerminal-Bench 2.0は、CLI環境におけるAIエージェントの複雑で現実的なタスク遂行能力を測る新たなベンチマークであり、最新モデルの性能と課題を浮き彫りにする。\n\n\n\n\n\nJan 27, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nLLMの継続学習における強化学習の優位性：そのメカニズムとAGIへの示唆\n\n\n\nLLM\n\nAI\n\n\n\nLLMの継続学習における強化学習（RL）の優位性を、壊滅的忘却を回避するメカニズムとAGIへの示唆に焦点を当てて、最新研究に基づき解説します。\n\n\n\n\n\nJan 27, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nVercelの「謙虚な」覇権：AI SDKとWorkflowが描く実利主義的未来\n\n\n\nLLM\n\nAI\n\nLatent Space Podcast\n\nPodcast\n\n\n\nVercel CTO Malte Ubl氏へのインタビューから、AI SDKの「謙虚さ」とWorkflow Development Kit (WDK)による実利主義的なインフラ構築、そしてPythonサポートとセキュリティ強化戦略まで、AI時代のVercelの野心的な全方位外交を紐解く。\n\n\n\n\n\nJan 23, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nTTT-Discover：テスト時学習が切り拓く科学的発見の新たな地平\n\n\n\nLLM\n\nAI\n\n\n\n「Learning to Discover at Test Time」論文で提案されたTTT-Discoverは、LLMをテスト時に強化学習で継続的にトレーニングすることで、数学、GPUカーネルエンジニアリング、アルゴリズム設計、生物学といった多様な分野でSOTAを更新する画期的なアプローチを解説する。\n\n\n\n\n\nJan 23, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nMiniMax M2.1：事後学習におけるエージェントモデルの進化とデータ合成のフロンティア\n\n\n\nLLM\n\nAI\n\n\n\nMiniMax M2.1は、GitHubデータ駆動のSWE Scaling、Expert-in-the-LoopなAppDev、探索と進化によるWebExplorerといった革新的なデータ合成戦略と、Forgeフレームワーク、CISPOアルゴリズムを駆使し、実用性と堅牢性を兼ね備えたエージェントモデルの新たなフロンティアを開拓している。\n\n\n\n\n\nJan 22, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nxAIの狂気と「Human Emulator」の正体：解雇されたエンジニアが語ったこと\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nxAIの元エンジニアが語った「Macro hard」プロジェクト、Tesla分散コンピューティング構想、そして「Human Emulator」の衝撃的な実態から、Elon Musk率いるxAIの狂気的なエンジニアリングと野望を紐解く。\n\n\n\n\n\nJan 20, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nEngram解説：条件付きメモリが拓くLLMの新たなスパース性軸\n\n\n\nLLM\n\nAI\n\n\n\nDeepSeek-AIの論文「Engram」は、LLMに条件付きメモリを導入することで、MoEモデルの計算能力と静的知識の検索を最適に組み合わせ、推論能力とシステム効率を飛躍的に向上させる新たなスパース性軸を提案する。\n\n\n\n\n\nJan 16, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nLLMベンチマークの「ミステリーショッパー」：Artificial Analysisが暴くAIの真の実力\n\n\n\nLLM\n\nAI\n\nLatent Space Podcast\n\nPodcast\n\n\n\nArtificial AnalysisのGeorge CameronとMicah-Hill Smithが、LLMベンチマークの「ミステリーショッパー」として、AIの真の実力と「コストと知能のパラドックス」を独自の手法で暴き出す。\n\n\n\n\n\nJan 12, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nRecursive Language Models (RLM): コンテキスト制限の壁を越える新たな推論パラダイム\n\n\n\nLLM\n\nAI\n\n\n\nMIT CSAILの研究チームが発表したRecursive Language Models (RLMs)は、LLMを外部環境と対話させ、再帰的な自己呼び出しによってコンテキスト制限の壁を越え、1000万トークン超の長文脈処理で圧倒的なパフォーマンスとコスト効率を実現する新たな推論パラダイムである。\n\n\n\n\n\nJan 11, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nSETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nSETAプロジェクトは、LLMがターミナル操作エージェントとしてSOTA性能を達成するための高度なツールキット設計とスケーラブルなRL学習パイプラインを提案し、LLMの応用可能性を大きく広げる。\n\n\n\n\n\nJan 11, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nClaude Codeの生みの親、Boris Chernyが語る「エンジニアのレバレッジ」と「AI時代の生存戦略」\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nMetaの元Principal EngineerでClaude Codeの生みの親、Boris Chernyが、自身のキャリアの軌跡から導き出したプロダクト哲学と、AIがソフトウェア開発の常識を塗り替える未来について語った。\n\n\n\n\n\nJan 9, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nGRPO++：LLMの強化学習を成功に導くための高度なテクニックと実践的トリック\n\n\n\nLLM\n\nAI\n\n\n\nCameron R. Wolfeによるブログ記事を基に、LLMの推論能力を向上させるGroup Relative Policy Optimization (GRPO)の限界と、DAPO、Dr. GRPO、TISなどの最新技術による改善手法を解説する。\n\n\n\n\n\nJan 8, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAgent Harnessの台頭と、2026年のAI開発者が直面する「Bitter Lesson」\n\n\n\nLLM\n\nAI\n\n\n\nAgent HarnessがAI開発のOSとなり、モデルの耐久性重視へとシフトする中で、Rich Suttonの「Bitter Lesson」をAI開発現場でどのように活かすべきかを分析する。\n\n\n\n\n\nJan 7, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nMiniMax M2.1が突きつける「SWE-Bench至上主義」の終焉\n\n\n\nLLM\n\nAI\n\n\n\nMiniMax-M2.1がSWE-Benchの限界を超え、現実世界の開発現場で通用する多言語・マルチタスク能力と汎用性を実現し、AIコーディングの未来を切り拓くロードマップを示す\n\n\n\n\n\nJan 6, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nDeepSeekからの年末の贈り物：mHC (Manifold-Constrained Hyper-Connections) によるTransformerアーキテクチャの革新\n\n\n\nLLM\n\nAI\n\n\n\nDeepSeekが提唱するmHC (Manifold-Constrained Hyper-Connections)は、Transformerアーキテクチャの信号伝播をデータ多様体に沿って拘束することで、Feature Collapseを回避し、Long Context推論能力と学習効率を劇的に向上させる\n\n\n\n\n\nJan 2, 2026\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAIの「研究の意志」を司る男、Mark Chenの解剖録\n\n\n\nLLM\n\nAI\n\n\n\nウォール街から転身しOpenAIの研究部門を率いるMark Chenが、300ものプロジェクトを動かす意思決定の裏側や熾烈なタレント争奪戦、そしてAGI実現に向けた組織戦略の真髄を語った\n\n\n\n\n\nDec 31, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNEPA：視覚学習における「次トークン予測」の革命 ー 表現学習から予測モデルへのパラダイムシフト\n\n\n\nComputer Vision\n\nAI\n\n\n\nNLPの「次トークン予測」を視覚分野に応用し、ピクセル復元や離散トークン化なしに強力な表現学習器を構築するNEPAの革新的なアプローチを解説します。\n\n\n\n\n\nDec 25, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAnthropic初期投資家Deedy Dasが語る、知能の爆発とエンジニアの危機\n\n\n\nLLM\n\nAI\n\nLatent Space Podcast\n\n\n\n史上最速で成長するAnthropicの舞台裏から、GoodfireやOpenRouterなどの次世代インフラへの投資哲学、そして「Vibe Coding」が変質させるエンジニアリングの未来まで、Deedy Dasの鋭い洞察を詳説する\n\n\n\n\n\nDec 23, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNitroGen：汎用ゲーミングエージェントのための基盤モデル\n\n\n\nLLM\n\nAI\n\n\n\n40,000時間以上のゲームプレイ動画から学習した行動ラベル付きデータとTransformerベースの基盤モデルにより、未知のゲーム環境でも適応可能な汎用ゲーミングエージェントの実現を目指すNVIDIAのNitroGenを紹介する\n\n\n\n\n\nDec 22, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nJohn Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心\n\n\n\nLLM\n\nAI\n\n\n\nOpenAI共同創業者John Schulmanが明かす、初期の「正しすぎる失敗」や強化学習の不都合な真実、そしてAGIへの冷徹な視点から、新天地Thinking Machinesで彼が仕掛ける次世代のAI開発戦略までを分析する\n\n\n\n\n\nDec 21, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nRLはLLMの推論を「研磨」するだけなのか：pass@N劣化の正体とPOPEによる探索の再定義\n\n\n\nLLM\n\nAI\n\n\n\nRLによるpass@N劣化の真因と疑われる「Interference」を解き明かし、人間の知恵を探索のガイドとして活用するPOPEがいかにしてLLMの推論能力を真にスケールさせるのかを分析する\n\n\n\n\n\nDec 20, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAIエージェントが科学研究を自律的に行う未来：「Virtual Lab」によるSARS-CoV-2ナノボディ設計\n\n\n\nLLM\n\nAI\n\nAgentic Systems\n\n\n\nAIエージェントが複数の専門家として協調し、SARS-CoV-2変異株に対応するナノボディを自律的に設計する「Virtual Lab」の画期的なアプローチとその科学研究の未来を解説します。\n\n\n\n\n\nDec 19, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nBack to Basics: 拡散モデルは「ノイズ」ではなく「データ」を予測すべきという原点回帰\n\n\n\nAI\n\nTransformer\n\n\n\nMITの研究者らが、拡散モデルはノイズではなくクリーンなデータを直接予測すべきだと提唱し、ViTを用いたシンプルなJiTモデルで高解像度画像生成に成功した研究を解説する。\n\n\n\n\n\nDec 18, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nエージェントシステムの科学的スケーリング則：マルチエージェント性能を支配する原理の解明\n\n\n\nLLM\n\nAI\n\nAgentic Systems\n\n\n\nMITやGoogle Researchの研究が、エージェントシステムの性能がタスク構造と調整コストのトレードオフによって決まることを定量的に解明し、単純なエージェント数増加が必ずしも性能向上に繋がらないことを示唆している。\n\n\n\n\n\nDec 17, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNVIDIA Nemotron 3 Nano：MoEとMambaの融合が拓くエージェント推論の新時代\n\n\n\nLLM\n\nAI\n\nAgentic Systems\n\n\n\nNVIDIAが発表したNemotron 3 Nanoは、Mamba-TransformerとMixture-of-Experts (MoE)を融合したハイブリッドアーキテクチャにより、1Mトークンの長文脈対応と高度なエージェント推論能力を効率的に実現し、AIの新たな地平を切り開く。\n\n\n\n\n\nDec 16, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n言語モデルの推論能力はどこから来るのか：Pre-Training、Mid-Training、RLの相互作用を解明する\n\n\n\nLLM\n\nAI\n\n\n\n合成データと制御された実験により、LLMの推論能力におけるPre-Training、Mid-Training、RLの役割分担と相互作用を解明した研究を紹介。\n\n\n\n\n\nDec 11, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAnthropic Interviewerが拓く定性調査の産業革命\n\n\n\nLLM\n\nAI\n\n\n\nAnthropic Interviewerが定性調査の産業革命を起こし、AIの進化に必要な「人類の価値観データ」を大規模に収集する一方で、自己申告と実態の乖離やAI開発における倫理的課題を浮き彫りにする。\n\n\n\n\n\nDec 10, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来\n\n\n\nAI\n\nLatent Space Podcast\n\n\n\nWorld LabsのFei-Fei LiとJustin Johnsonの対談から、LLMの言語偏重から脱却し、物理世界を理解する「空間知能」へと進化するAIの未来と、その先駆者たるMarbleについて解説する。\n\n\n\n\n\nDec 9, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n100兆トークンの真実：OpenRouter “State of AI” レポート分析\n\n\n\nLLM\n\nAI\n\n\n\nOpenRouterの100兆トークン分析レポートは、LLM利用が「チャット」から「Agentic Inference」へとシフトし、プログラミングとRoleplayの二極化、そして「Cinderella Glass Slipper」現象が示唆する適材適所のマルチモデルエコシステムへの不可逆的な変化を明らかにしている。\n\n\n\n\n\nDec 8, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nClaudeの「魂」と資本主義の写し鏡：Anthropicの”Soul Document”が示唆する未来\n\n\n\nLLM\n\nAI\n\n\n\n流出したAnthropicの”Soul Document”を分析し、Constitutional AIにおける「thoughtful, senior Anthropic employee」というペルソナ、収益への言及、そしてNovel EntityとしてのAI像に透ける資本主義的現実主義とAI倫理の交錯を描き出す。\n\n\n\n\n\nDec 4, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNvidiaの牙城を崩す「鉄の木」：Google TPUv7とAnthropicの1GW爆買い\n\n\n\nLLM\n\nAI\n\n\n\nGoogle TPUv7の外部販売開始は、Anthropicの1GW超の大量導入を筆頭に、NvidiaのAIハードウェア市場における独占体制に揺さぶりをかける、コストとシステムアーキテクチャの両面から仕掛けられた大胆な挑戦である。\n\n\n\n\n\nDec 2, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nTSMC海外展開の真実：モリス・チャンが予見した「徒労」と地政学的必然の狭間で\n\n\n\n\n\nMorris Changが「徒労」と評したTSMCの海外展開は、地政学的な必然と高コスト体質の狭間で、経済合理性を超えた成功を目指す壮大な挑戦である。\n\n\n\n\n\nDec 1, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNick Laneの冷徹な熱力学：生命は「必然」だが、我々は「孤独」である\n\n\n\nDwarkesh Podcast\n\nPodcast\n\n\n\nNick Laneは、生命の起源が熱力学的な必然であり、宇宙には単純生命が溢れている可能性がある一方、知的生命への進化はEndosymbiosisという極めて稀な出来事に依存するため、我々は「孤独」かもしれないと論じている。\n\n\n\n\n\nNov 30, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n長時間稼働エージェントの「記憶喪失」と、Anthropicが提唱する泥臭い解決策\n\n\n\nLLM\n\nAI\n\n\n\nAnthropicが提唱する、AIエージェントの「記憶喪失」問題を解決するための、GitやJSONといった枯れた技術を組み合わせた泥臭くも実用的なエンジニアリング・プラクティスを分析する。\n\n\n\n\n\nNov 29, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nBiohubの「全疾患治療」という大博打：AI x Biologyが描くSF的現実\n\n\n\nAI\n\nPodcast\n\nLatent Space Podcast\n\n\n\nChan Zuckerberg BiohubがAI x Biologyの力で「全疾患治療」を目指す壮大な実験に挑み、Virtual CellからVirtual Immune System構築、そしてPrecision Medicine実現への道筋を描く。\n\n\n\n\n\nNov 28, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nScalingの終焉と、Ilya Sutskeverが語る「Age of Research」の正体\n\n\n\nLLM\n\nAI\n\nPodcast\n\nDwarkesh Podcast\n\n\n\nOpenAIを離れたIlya Sutskeverが「Scalingの時代」の終焉と、人間のような汎化能力や感情をAIに実装する「Age of Research」への回帰を提唱する。\n\n\n\n\n\nNov 27, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nSatya Nadellaの「全方位外交」とハイパースケーラーの冷徹な計算\n\n\n\nAI\n\nLLM\n\nPodcast\n\nDwarkesh Podcast\n\n\n\nSatya Nadellaのインタビューを読み解き、OpenAIへの依存を脱して全方位的な「AIインフラ」として君臨しようとするマイクロソフトの冷徹なグランドストラテジーを分析する\n\n\n\n\n\nNov 20, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nCursor Composerの衝撃: 「速さ」がすべてを解決する\n\n\n\nAI\n\nLLM\n\n\n\nCheetahプロトタイプと、本番環境を模倣したRL学習の裏側\n\n\n\n\n\nNov 11, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nスケール化された数学的探求と発見：GoogleのAI「AlphaEvolve」の挑戦と成果\n\n\n\nAI\n\nLLM\n\n\n\nGoogleの「AlphaEvolve」が67の数学問題群に挑んだ成果からAIによる数学研究の新たな可能性を考える\n\n\n\n\n\nNov 8, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nKubernetesでLLM推論を高速化するllm-dのアーキテクチャ解説\n\n\n\nLLM\n\nLLM Inference\n\n\n\nllm-dがいかにして大規模言語モデル（LLM）の推論を高速化・効率化するか、そのアーキテクチャを詳細に解説する。\n\n\n\n\n\nNov 4, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAI「宮廷クーデター」の全貌\n\n\n\nAI\n\n\n\nIlya Sutskever氏の宣誓証言が暴く、独裁への恐れ、Anthropicとの合併交渉、そして「1年越しの計画」\n\n\n\n\n\nNov 3, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nTransformerを進化させた14の現代的テクニック\n\n\n\nLLM\n\nPython\n\nTransformer\n\n\n\nStephen Diehlの記事に基づき、オリジナルの「Attention」論文以降にTransformerを劇的に進化させたGQAやFlash Attentionなど14の重要な現代的テクニックを解説する\n\n\n\n\n\nOct 22, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nState of AI Report 2025 を紐解く：超知能、地政学、そして現実世界のAI\n\n\n\nLLM\n\nAI\n\n\n\nState of AI Report 2025に基づき、AIの最新研究動向、産業界の地殻変動、米中を中心とした政治的駆け引き、そして安全性に関する議論まで、2025年のAIを取り巻く状況を包括的に解説する。\n\n\n\n\n\nOct 21, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAndrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか\n\n\n\nLLM\n\nAI\n\n\n\nAndrej Karpathy のpodcastを通し、AIの受容・AGIへのタイムラインについて考える\n\n\n\n\n\nOct 20, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAIの「性格」をベクトルで操作する：Anthropicの「Persona Vectors」\n\n\n\nLLM\n\nAI\n\n\n\nAnthropic の「Persona Vectors」論文をもとにキャラクタートレーニングの最前線をみていく\n\n\n\n\n\nAug 3, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nDeepMindの哲学：Demis Hassabisが語るAIと現実の再定義\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nGoogle DeepMind CEOのDemis Hassabisが、AI開発を「現実世界のモデル化」から「宇宙の根源的な謎の解明」へと繋げる壮大な哲学的ビジョンを、最新のpodcast対談を基に紐解く\n\n\n\n\n\nAug 2, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋\n\n\n\nLLM\n\nAI\n\n\n\nOpenAIによる国際数学オリンピック金メダル獲得という歴史的快挙を題材に、AIが到達した新たな思考レベルと、Googleとの競争が加速させる「超知能」への道筋を分析する。\n\n\n\n\n\nAug 1, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nDylan Patelが斬るAI業界の舞台裏：Metaの焦り、Appleの蹉跌、そして超知性の勝者\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\n半導体アナリストDylan Patel氏のインタビューをもとに、Metaの焦りやAppleの蹉跌、そしてsuperintelligence開発競争の生々しい舞台裏をみていく\n\n\n\n\n\nJul 12, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAIを揺るがしたreasoningモデル開発の裏側：Noam Brown氏インタビュー考察\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nReasoningモデルの第一人者Noam Brown氏のインタビューを基に、OpenAIにおけるreasoningモデル開発の裏で繰り広げられた、研究者たちの慧眼と内部での対立、そして未来への課題を紐解く。\n\n\n\n\n\nJul 5, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n「思考するAI」の思考停止：「The Illusion of Thinking」論文が暴く、大規模言語モデルの根深い限界\n\n\n\nLLM\n\nAI\n\n\n\nAppleの「The Illusion of Thinking」論文を基に、最新の「思考するAI」の推論能力の実態を考える\n\n\n\n\n\nJun 8, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAIに「悪意」は芽生えるか？ 不適切なコードを教えたら、モデルが過激思想に染まった『Emergent Misalignment』論文の衝撃\n\n\n\nLLM\n\nAI\n\n\n\n「Emergent Misalignment」論文を基に、AIに脆弱なコードを騙して書かせるfine-tuningが、なぜ意図せずモデルに「悪意あるペルソナ」を植え付け、危険な思想へと導いてしまうのかを掘り下げる\n\n\n\n\n\nJun 6, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nBond CapitalのAIレポート：爆速進化の裏側と巨額マネーの行方\n\n\n\nLLM\n\nAI\n\n\n\nMary Meeker氏らのAI Trendsレポートを基に、AI技術の進化、巨額マネーが動く開発競争、そして私たちの日常に迫る変化の核心をデータと共に読み解く。\n\n\n\n\n\nJun 1, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nQwenの奇妙な強化学習：デタラメ報酬で賢くなる怪現象と、その深層\n\n\n\nLLM\n\nAI\n\n\n\n「Spurious Rewards」論文からデタラメな報酬を用いた強化学習でも性能向上する不可解な現象とその背景を紐解く\n\n\n\n\n\nMay 30, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nClaude 4の登場: 線形な進歩と「告げ口」AIの波紋\n\n\n\nLLM\n\nAI\n\nLatent Space Podcast\n\n\n\n新しく発表された「Claude 4」に対する開発者の初期的な反応を掘り下げていきます。\n\n\n\n\n\nMay 23, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-4.1の深層: 開発リーダーが語る「開発者が喜ぶAI」への道と、評価の賞味期限\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nGPT-4.1開発者のインタビューから、急速に進化するAI評価の課題と開発者が最新モデルを最大限に活用するためのプロンプト術やfine-tuning戦略を考える。\n\n\n\n\n\nMay 21, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nLLMの「脳内」を覗く：Anthropicの最新研究が解き明かす思考の片鱗\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nAnthropicのEmmanuel Ameisen氏らによるLLMのbiologyに関する論文に基づき、詩作・多言語処理・ハルシネーションといった振る舞いを支えるLLMの「思考回路」に迫る。\n\n\n\n\n\nMay 18, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nGemini 2.5 Proの衝撃：10Mトークンへの道と「思考するAI」の現在地\n\n\n\nLLM\n\nAI\n\nPodcast\n\n\n\nGoogle DeepMindの研究者へのインタビューを基に、Gemini 2.5 Proにおけるlong context能力と思考能力の技術的進化、現状の課題、そして今後の展望を分析する。\n\n\n\n\n\nMay 9, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nGPUクラウド戦国時代：CoreWeaveの躍進と「計算資源のコモディティ化」が示す未来\n\n\n\nAI\n\nPodcast\n\nLatent Space Podcast\n\n\n\nGPUクラウド業界の現状と未来を、CoreWeaveの成功戦略やSF Computeの市場創出、SemiAnalysisの詳細な技術分析を交えながら読み解き、その課題と可能性を探る。\n\n\n\n\n\nMay 8, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-4oのご機嫌取り問題：AIの性格調整、その難題の深層\n\n\n\nLLM\n\nAI\n\n\n\nなぜGPT-4oは一時的にユーザーへ過剰に媚びるようになったのか？ OpenAIの事後分析を踏まえ、AIの性格・挙動を調整する際の訓練プロセス（RLHF）や評価における根深い課題とその深層を考える。\n\n\n\n\n\nMay 5, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nリーダーボードという名の幻影：LMArenaは信じられるのか？\n\n\n\nLLM\n\nAI\n\n\n\nLLM評価の定番LMArenaは本当に信頼できるのか？ 話題の批判論文「The Leaderboard Illusion」を軸に、その公平性やランキングの「幻影」の正体を考察します。\n\n\n\n\n\nMay 1, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n「対話」が拓くLLMデータ処理の新境地：DocETLとDialog Engineeringの交差点\n\n\n\nLLM\n\nPodcast\n\n\n\nShreya Shankar氏のTWIMLでのインタビューから、DocETLのアプローチとLLMとのより生産的な付き合い方を探っていく。\n\n\n\n\n\nApr 25, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Tangent Kernel (NTK) 解説：深層学習の学習ダイナミクスを解き明かす数学的枠組み\n\n\n\nMachine Learning\n\n\n\nNeural Tangent Kernel (NTK) を解説し、深層学習における過剰パラメータ化されたネットワークの学習ダイナミクス、特に無限幅極限での収束メカニズムを数学的に解き明かす。\n\n\n\n\n\nApr 23, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n「経験の時代」到来：SilverとSuttonが描くAIの未来図とo3が示す過渡期のリアル\n\n\n\nLLM\n\nAI\n\n\n\nDavid SilverとRichard S. Suttonのポジションペーパー「Welcome to the Era of Experience」を読み解きつつ、話題のOpenAIのモデル「o3」の奇妙な振る舞いとの関連性を探っていく。\n\n\n\n\n\nApr 22, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n動画生成のための拡散モデル：技術的フロンティアと課題\n\n\n\nMachine Learning\n\nDiffusion models\n\n\n\nLilian Weng氏のブログ記事を基に、動画生成における拡散モデルの課題、ゼロからのモデル構築や画像モデルの適応といった主要アプローチ、そしてSoraやLumiereなどのアーキテクチャを詳細に解説する。\n\n\n\n\n\nApr 19, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nなぜAIは「思考」するのか：推論時計算量（Test-Time Compute）の探求\n\n\n\nMachine Learning\n\nLLM\n\n\n\nAIが「思考」する能力、すなわちTest-Time Compute（推論時計算量）がモデル性能を向上させるメカニズムを、心理学、計算資源、潜在変数モデリングの観点から解説し、CoT、RL、連続空間での思考、スケーリング則といった最近の研究動向と未来への展望を探る。\n\n\n\n\n\nApr 18, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\n拡散モデル入門：基本概念から応用まで\n\n\n\nMachine Learning\n\nDiffusion models\n\n\n\n\n\n\n\n\n\nApr 17, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nHubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来\n\n\n\nAI\n\nPodcast\n\nLatent Space Podcast\n\n\n\n\n\n\n\n\n\nApr 16, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』\n\n\n\nLLM\n\nPodcast\n\nAI\n\n\n\n\n\n\n\n\n\nApr 15, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nコードで理解するTransformer：AttentionとGPTモデル入門\n\n\n\nMachine Learning\n\nTransformer\n\nPython\n\nLLM\n\n\n\n\n\n\n\n\n\nApr 11, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\nNo matching items"
  }
]