[
  {
    "objectID": "posts/transformer-attention-jp/index.html",
    "href": "posts/transformer-attention-jp/index.html",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "",
    "text": "近年、ChatGPTやGPT-4といった大規模言語モデル（LLM: Large Language Models）が大きな注目を集めています。これらのモデルは、コードの作成、メールの下書き、複雑な質問への回答、さらには創造的な文章生成まで、驚くべき能力を発揮します。これらのシステムの多くを支える中核技術が、2017年の画期的な論文「Attention is All You Need」で提案されたTransformerアーキテクチャです。\nしかし、この「Attention」メカニズムとは一体何で、どのようにしてGPTのようなモデルが文脈を理解し、一貫性のあるテキストを生成することを可能にしているのでしょうか？\nAndrej Karpathy氏の優れた動画「Let’s build GPT: from scratch, in code, spelled out.」では、彼がnanogptと呼ぶ小規模なバージョンをゼロから構築することで、Transformerを分かりやすく解説しています。今回は、彼の解説に沿って、Transformerの心臓部であるself-attentionの仕組みを解き明かしていきましょう。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#準備言語モデリングの基本",
    "href": "posts/transformer-attention-jp/index.html#準備言語モデリングの基本",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "準備：言語モデリングの基本",
    "text": "準備：言語モデリングの基本\nAttentionに入る前に、基本的なタスクである「言語モデリング」について理解しましょう。言語モデリングの目標は、与えられたシーケンス（文脈）に基づいて、シーケンス中の次の単語（または文字、トークン）を予測することです。\nKarpathy氏はまず、「Tiny Shakespeare」データセットを使用します。これはシェイクスピアの作品を連結した単一のテキストファイルです。\n# まずは学習用のデータセットを用意します。Tiny Shakespeareデータセットをダウンロードしましょう。\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n\n# 中身を確認するために読み込みます。\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n# このテキストに含まれるユニークな文字をすべてリストアップします。\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\n# !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\nprint(vocab_size)\n# 65\n\n# 文字から整数へのマッピングを作成します。\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: 文字列を受け取り、整数のリストを出力\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: 整数のリストを受け取り、文字列を出力\nprint(encode(\"hii there\"))\n# [46, 47, 47, 1, 58, 46, 43, 56, 43]\nprint(decode(encode(\"hii there\")))\n# hii there\n# テキストデータセット全体をエンコードし、torch.Tensorに格納します。\nimport torch # PyTorchを使用します: https://pytorch.org\ndata = torch.tensor(encode(text), dtype=torch.long)\nprint(data.shape, data.dtype)\n# torch.Size([1115394]) torch.int64\nprint(data[:1000])\n# tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44, ...\nこの例では、テキストは文字レベルでトークン化（tokenized）され、各文字が数にマッピングされます。モデルの役割は、数のシーケンスが与えられたときに、次に来る文字の数を予測することです。\nKarpathy氏は、まず最も単純な言語モデルであるBigram Modelを実装します。\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)\n\nclass BigramLanguageModel(nn.Module):\n\n    def __init__(self, vocab_size):\n        super().__init__()\n        # 各トークンはルックアップテーブルから次のトークンのロジットを直接読み取る\n        # 動画では後に vocab_size x n_embd に変更される\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n\n    def forward(self, idx, targets=None):\n        # idx と targets は両方とも (B,T) の整数テンソル\n        # Bigramモデルではロジットは直接ルックアップされる\n        logits = self.token_embedding_table(idx) # (B,T,C) ここで初期はC=vocab_size\n\n        if targets is None:\n            loss = None\n        else:\n            # cross_entropyのために形状を変更\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idxは現在の文脈におけるインデックスの(B, T)配列\n        for _ in range(max_new_tokens):\n            # 予測を取得\n            logits, loss = self(idx)\n            # 最後のタイムステップのみに注目\n            logits = logits[:, -1, :] # (B, C) になる\n            # softmaxを適用して確率を取得\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # 分布からサンプリング\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # サンプリングされたインデックスを実行中のシーケンスに追加\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nm = BigramLanguageModel(vocab_size)\nlogits, loss = m(xb, yb)\nprint(logits.shape)  # torch.Size([32, 65])\nprint(loss)  # tensor(4.8786, grad_fn=&lt;NllLossBackward0&gt;)\n\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n# SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGpwnYWmnxKWWev-tDqXErVKLgJ\nこのモデルを実際に訓練してみます。\n# PyTorch optimizerの作成\noptimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n\nbatch_size = 32\nfor steps in range(100): # increase number of steps for good results...\n\n    # batch の作成\n    xb, yb = get_batch('train')\n\n    # lossをもとに重みを更新\n    logits, loss = m(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\nprint(loss.item())  # 4.65630578994751\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n# oTo.JUZ!!zqe!\n# xBP qbs$Gy'AcOmrLwwt ...\nこのモデルは、入力文字のインデックスを使って、次の文字の確率分布（ロジット）を直接ルックアップする埋め込み（embedding）テーブルを使用します。これは単純ですが、重大な欠点があります。それは、文脈を完全に無視してしまう点です。「hat」の後の「t」も、「bat」の後の「t」も、予測は同じになってしまいます。トークン同士が「対話」していないのです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#コミュニケーションの必要性過去の情報を集約する",
    "href": "posts/transformer-attention-jp/index.html#コミュニケーションの必要性過去の情報を集約する",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "コミュニケーションの必要性：過去の情報を集約する",
    "text": "コミュニケーションの必要性：過去の情報を集約する\nより良い予測を行うためには、トークンはシーケンス内の先行するトークンからの情報を必要とします。トークンはどのようにしてコミュニケーションできるのでしょうか？\nKarpathy氏は、行列積を用いた「数学的なトリック」を紹介します。トークンが文脈を得る最も簡単な方法は、自身を含む先行するすべてのトークンからの情報を平均化することです。\n入力xが(B, T, C)（Batch、Time（シーケンス長）、Channels（埋め込み次元））の形状を持つとします。xbow[b, t]がx[b, 0]からx[b, t]までの平均を含むようなxbow（bag-of-words表現）を計算したいと考えます。\n以下のような単純なループは非効率です。\n# xbow[b,t] = mean_{i&lt;=t} x[b,i] を計算したい\n# (xがB, T, Cの形状で定義されていると仮定)\nB,T,C = 4,8,32 # 例としての次元\nx = torch.randn(B,T,C)\nxbow = torch.zeros((B,T,C))\nfor b in range(B):\n    for t in range(T):\n        xprev = x[b,:t+1] # (t+1, C)\n        xbow[b,t] = torch.mean(xprev, 0)\n効率的な方法は、下三角行列との行列積を使用することです。\n# version 2: 行列積を用いた重み付き集約\nT = 8 # 例としてのシーケンス長\nwei = torch.tril(torch.ones(T, T)) # 1で構成される下三角行列\nwei = wei / wei.sum(1, keepdim=True) # 各行の合計が1になるように正規化 -&gt; 平均化\n# 例として B=4, T=8, C=32 のx\nx = torch.randn(4, T, 32)\nxbow2 = wei @ x # (T, T) @ (B, T, C) はブロードキャストされ -&gt; (B, T, C)\ntorch.allclose(xbow, xbow2)  # True\nここで、wei（重み）は(T, T)行列です。weiの行tは、列0からtまでのみ非ゼロ値（この場合は1/(t+1)）を持ちます。これをx（形状(B, T, C)）と乗算すると、PyTorchはweiをバッチ次元全体にブロードキャストします。結果として得られるxbow2[b, t]は、x[b, 0]からx[b, t]までの重み付き合計（この場合は平均）となります。\nこの行列積は効率的に集約処理を実行します。これはsoftmaxを使っても実現できます。\n# version 3: Softmaxを使用\nT = 8\ntril = torch.tril(torch.ones(T, T))\nwei = torch.zeros((T,T))\nwei = wei.masked_fill(tril == 0, float('-inf')) # 上三角部分を-infで埋める\nwei = F.softmax(wei, dim=-1) # Softmaxは行の合計を1にし、平均の重みを回復する\nxbow3 = wei @ x\n# torch.allclose(xbow, xbow3) は True になるはず\nなぜここでsoftmaxを使うかというと、重み（wei）が固定された平均である必要はなく、重み自体が学習可能であったり、データに依存したりできるという重要なアイデアを導入するからです。これこそが、self-attentionが行うことです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#位置情報の導入position-encoding",
    "href": "posts/transformer-attention-jp/index.html#位置情報の導入position-encoding",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "位置情報の導入：Position Encoding",
    "text": "位置情報の導入：Position Encoding\nSelf-Attentionメカニズム自体について詳しく見る前に、もう一つ重要な要素について触れておく必要があります。それは、トークンの位置に関する情報です。\nSelf-Attentionの基本的な計算（Query, Key, Valueを用いた加重集約）は、それ自体ではトークンがシーケンス内のどの位置にあるかを考慮しません。極端な話、単語の順番が入れ替わっても、各トークン間のAttentionスコアの計算自体は（入力ベクトルが同じであれば）変わりません。これでは、文の意味を正しく捉えることができません。「猫がマットの上に座った」と「マットが猫の上に座った」では意味が全く異なります。\nこの問題を解決するため、Transformerではトークン自体の意味を表す埋め込みベクトル（Token Embedding）に、そのトークンがシーケンス中のどの位置にあるかを示すPosition Encoding（位置エンコーディング）ベクトルを加算します。\nKarpathy氏の動画で実装されているnanogptでは、学習可能なPosition Encodingが用いられています。具体的には、block_size（扱える最大のシーケンス長）に対応する数の位置ベクトルを格納する埋め込みテーブル（position_embedding_table）を用意します。シーケンス長がTの場合、0からT-1までの整数をインデックスとして、対応する位置ベクトルをこのテーブルから取得します。\n# BigramLanguageModel内のforwardメソッドより抜粋\nB, T = idx.shape\n\n# idx and targets are both (B,T) tensor of integers\ntok_emb = self.token_embedding_table(idx) # (B,T,C) - トークン埋め込み\n# torch.arange(T, device=device) は 0 から T-1 までの整数のシーケンスを生成\npos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) - 位置埋め込み\nx = tok_emb + pos_emb # (B,T,C) - トークン埋め込みと位置埋め込みを加算\nx = self.blocks(x) # ... このxがTransformerブロックへの入力となる ...\nこのようにして、トークン自体の情報(tok_emb)とその位置情報(pos_emb)の両方を含んだベクトルxが作成されます。このxこそが、後続のTransformerブロック（Self-Attention層やFeedForward層）への実際の入力となるのです。これにより、モデルはトークンの意味だけでなく、その順序関係も考慮して処理を進めることができるようになります。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#self-attentionデータに基づいた情報の集約",
    "href": "posts/transformer-attention-jp/index.html#self-attentionデータに基づいた情報の集約",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Self-Attention：データに基づいた情報の集約",
    "text": "Self-Attention：データに基づいた情報の集約\n単純な平均化は、過去のすべてのトークンを平等に扱います。しかし、実際には、過去の一部のトークンが他のトークンよりもはるかに重要である場合があります。例えば、「The cat sat on the…」の次に続く単語を予測する場合、「The」よりも「cat」という単語の方が重要である可能性が高いです。\nSelf-attentionは、トークンが他のトークンに問い合わせ（query）を行い、関連性に基づいて注意スコア（attention scores）を割り当てることを可能にします。各トークンは3つのベクトルを生成します。\n\nQuery (Q): 自分はどのような情報を探しているか？\nKey (K): 自分はどのような情報を持っているか？\nValue (V): もし自分に注意が向けられたら、どのような情報を提供するか？\n\nトークンiとトークンj間の注意スコア（またはaffinity）は、トークンiのQueryベクトル(q_i)とトークンjのKeyベクトル(k_j)の内積を取ることで計算されます。\naffinity(i, j) = q_i ⋅ k_j\n内積が大きい場合、QueryがKeyに良く一致していることを意味し、トークンjがトークンiにとって関連性が高いと判断されます。\n以下は、Attentionの単一の「Head」を実装する方法です。\n# version 4: self-attention!\ntorch.manual_seed(1337)\nB,T,C = 4,8,32 # batch, time, channels (埋め込み次元)\nx = torch.randn(B,T,C) # 入力トークンの埋め込み + 位置エンコーディング\n\n# 単一のHeadがself-attentionを実行する様子を見てみましょう\nhead_size = 16 # このHeadのK, Q, Vベクトルの次元\n# 入力'x'をK, Q, Vに射影するための線形層\nkey   = nn.Linear(C, head_size, bias=False)\nquery = nn.Linear(C, head_size, bias=False)\nvalue = nn.Linear(C, head_size, bias=False)\n\nk = key(x)   # (B, T, head_size)\nq = query(x) # (B, T, head_size)\n\n# 注意スコア（\"affinities\"）を計算\n# (B, T, head_size) @ (B, head_size, T) ---&gt; (B, T, T)\nwei =  q @ k.transpose(-2, -1)\n\n# --- スケーリングステップ (後述) ---\nwei = wei * (head_size**-0.5) # アフィニティをスケーリング\n\n# --- Decoderのためのマスキング ---\ntril = torch.tril(torch.ones(T, T, device=x.device)) # xと同じデバイスを使用\nwei = wei.masked_fill(tril == 0, float('-inf')) # 未来のトークンをマスク\n\n# --- スコアを正規化して確率を取得 ---\nwei = F.softmax(wei, dim=-1) # (B, T, T)\n\n# --- Valueの重み付き集約を実行 ---\nv = value(x) # (B, T, head_size)\n# (B, T, T) @ (B, T, head_size) ---&gt; (B, T, head_size)\nout = wei @ v\n\n# out.shape は (B, T, head_size)\n重要なステップを分解してみましょう。\n\n射影（Projection）: 入力x（トークン埋め込みと位置エンコーディングを含む）が、線形層によってK、Q、V空間に射影されます。\nアフィニティ計算（Affinity Calculation）: q @ k.transpose(...) は、バッチ内の各シーケンスにおける全てのQueryベクトルとKeyベクトルのペアの内積を計算します。これにより、生の注意スコアであるwei（形状 B, T, T）が得られます。\nスケーリング（Scaling）: スコアweiはhead_sizeの平方根でスケールダウンされます。これは、特に初期化段階での学習を安定させるために重要です。スケーリングがないと、内積の分散がhead_sizeと共に増加し、softmaxの入力が勾配の非常に小さい領域に押しやられ、学習が妨げられる可能性があります。\nマスキング（Masking (Decoder固有)）: GPTのような自己回帰型（autoregressive）言語モデリングでは、位置tのトークンは位置tまでのトークンにのみ注意を向けるべきです。これは、未来の位置（j &gt; t）に対応する注意スコアを下三角行列（tril）を用いたmasked_fillで負の無限大に設定することで実現されます。これにより、softmaxは未来のトークンにゼロの確率を割り当てます。（BERTのようなEncoderブロックでは、この causal mask は使用されません。）\nSoftmax: マスクされたスコアに対して行ごとにsoftmaxを適用します。これにより、スコアは各トークンtについて合計が1になる確率に変換され、先行するトークン0からtまでの注意分布を表します。\nValueの集約（Value Aggregation）: 各トークンtの最終出力outは、wei内の注意確率によって重み付けされた、全トークンのValueベクトル（v）の重み付き合計です。out = wei @ v。\n\n出力out（形状 B, T, head_size）は、学習されたK、Q、Vの射影に基づいて、シーケンス内の他の関連トークンから集約された情報を各トークンごとに含んでいます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#multi-head-attention多角的な視点",
    "href": "posts/transformer-attention-jp/index.html#multi-head-attention多角的な視点",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Multi-Head Attention：多角的な視点",
    "text": "Multi-Head Attention：多角的な視点\n単一のAttention Headは、ある特定タイプの関係性（例：名詞と動詞の一致）に焦点を当てるかもしれません。多様な関係性を捉えるために、TransformerはMulti-Head Attentionを使用します。\nclass Head(nn.Module):\n    \"\"\" self-attentionの単一ヘッド \"\"\"\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        # trilをバッファとして登録（パラメータではない）\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        self.dropout = nn.Dropout(dropout) # Dropoutを追加\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,head_size)\n        q = self.query(x) # (B,T,head_size)\n        # 注意スコア（\"affinities\"）を計算\n        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # head_sizeでスケーリング\n        # Tに基づいて動的にマスクを適用\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        wei = F.softmax(wei, dim=-1)\n        wei = self.dropout(wei) # 注意の重みにDropoutを適用\n        # Valueの重み付き集約を実行\n        v = self.value(x) # (B,T,head_size)\n        out = wei @ v\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" self-attentionの複数ヘッドを並列に実行 \"\"\"\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        # 複数のHeadインスタンスを作成\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        # 連結後の射影層\n        self.proj = nn.Linear(num_heads * head_size, n_embd) # n_embd = num_heads * head_size\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # 各ヘッドを並列に実行し、結果をチャネル次元で連結\n        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, num_heads * head_size)\n        # 連結された出力を元のn_embd次元に再射影\n        out = self.dropout(self.proj(out)) # (B, T, n_embd)\n        return out\nこれは単純に複数のHeadモジュールを並列に実行し、それぞれが異なる学習済みK、Q、V射影を持つ可能性があります。各ヘッドの出力（それぞれ B, T, head_size）は連結され（B, T, num_heads * head_size）、その後、別の線形層（self.proj）を用いて元の埋め込み次元（B, T, n_embd）に再射影されます。これにより、モデルは異なる表現部分空間からの情報に同時に注意を向けることができます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#attentionの応用self-attention-cross-attention-encoderdecoderブロック",
    "href": "posts/transformer-attention-jp/index.html#attentionの応用self-attention-cross-attention-encoderdecoderブロック",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Attentionの応用：Self-Attention, Cross-Attention, Encoder/Decoderブロック",
    "text": "Attentionの応用：Self-Attention, Cross-Attention, Encoder/Decoderブロック\nこれまで解説してきたAttentionの基本的な仕組みは、Self-Attentionと呼ばれるものでした。これはQuery(Q), Key(K), Value(V)のベクトルがすべて同じ入力シーケンス（x）から生成され、シーケンス内のトークンが相互に注意を向け合うものでした。しかし、このSelf-Attentionの使われ方や、Attentionメカニズム全体にはいくつかの重要なバリエーションが存在します。\nまず、Self-Attention自体の使われ方によって、それがEncoderブロックの一部として機能するのか、Decoderブロックの一部として機能するのかが変わってきます。この違いを生む主な要因は、Attentionスコア計算におけるマスキングの有無です。\nDecoderブロックで使われるSelf-Attentionでは、未来の情報を参照しないようにするための因果マスキング（causal masking）、つまり三角マスクが適用されます。これは、GPTのような自己回帰（autoregressive）モデルや、機械翻訳のデコーダー部分のように、過去の情報のみに基づいて次のトークンを生成する必要があるタスクで不可欠です。Karpathy氏の動画で構築されたnanogptは、まさしくこのDecoderブロックのみで構成されるモデルです。\n一方、Encoderブロックで使われるSelf-Attentionでは、この因果マスキングは適用されません。シーケンス内のすべてのトークンが、他のすべてのトークン（過去も未来も含む）に自由に注意を向けることができます。これは、BERTのように入力テキスト全体の文脈理解を目的とするモデルや、機械翻訳におけるエンコーダー部分（入力文全体の情報を符号化する役割）などで用いられます。入力シーケンス全体の双方向の文脈を捉えるのに適しています。\n次に、Attentionメカニズムのもう一つの重要な形態がCross-Attentionです。これはSelf-Attention（マスキングの有無に関わらず）とは異なり、Query、Key、Valueの由来が異なります。Cross-Attentionでは、Query(Q)はあるソース（例えばデコーダー側の状態）から生成されますが、Key(K)とValue(V)は別のソース（例えばエンコーダーの最終出力）から提供されます。\nこのCross-Attentionは、主にEncoder-Decoderアーキテクチャにおいて、EncoderとDecoderを接続する役割を果たします。デコーダーが出力トークンを生成する際に、Cross-Attentionを通じてエンコーダーが符号化した入力情報全体を常に参照できるようにします。機械翻訳タスクで、翻訳先の言語を生成しながら常に翻訳元の文章の意味を考慮する、といったことを可能にするメカニズムです。\nnanogptのようなdecoder-onlyモデルでは、外部の入力シーケンスを処理するEncoder部分が存在しないため、EncoderブロックやCross-Attentionは必要なく、因果マスキングを用いたSelf-Attention（Decoderブロック）のみで構成されている、というわけです。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#transformerブロック通信と計算",
    "href": "posts/transformer-attention-jp/index.html#transformerブロック通信と計算",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "Transformerブロック：通信と計算",
    "text": "Transformerブロック：通信と計算\nAttentionは通信メカニズムを提供します。しかし、モデルは集約された情報を処理するための計算も必要です。標準的なTransformerブロックは、Multi-Head Self-Attentionと、単純な位置ごとのFeedForwardネットワークを組み合わせます。\n重要な点として、各サブレイヤー（AttentionとFeedForward）の周囲にResidual Connections（残差接続）とLayer Normalization（層正規化）が追加されます。\n\nResidual Connections: x = x + sublayer(norm(x))。サブレイヤーの入力xが、サブレイヤーの出力に加算されます。これにより、深いネットワークでの逆伝播時に勾配が流れやすくなり、学習の安定性と性能が大幅に向上します。\nLayer Normalization: 各トークンについて、特徴量をチャネル次元にわたって独立に正規化します。Batch Normalizationとは異なり、バッチ統計に依存しないため、シーケンスデータに適しています。これも学習を安定させます。Karpathy氏は、サブレイヤーの前にLayerNormを適用する一般的な「pre-norm」形式を実装しています。\n\nclass FeedFoward(nn.Module):\n    \"\"\" 単純な線形層と非線形活性化関数 \"\"\"\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd), # 中間層は通常4倍大きい\n            nn.ReLU(),                    # ReLU活性化関数\n            nn.Linear(4 * n_embd, n_embd), # n_embdに再射影\n            nn.Dropout(dropout),           # 正則化のためのDropout\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \"\"\" Transformerブロック：通信の後に計算 \"\"\"\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size) # 通信 (Communication)\n        self.ffwd = FeedFoward(n_embd)                 # 計算 (Computation)\n        self.ln1 = nn.LayerNorm(n_embd)                # Attention前のLayerNorm\n        self.ln2 = nn.LayerNorm(n_embd)                # FeedForward前のLayerNorm\n\n    def forward(self, x):\n        # Pre-norm形式と残差接続\n        # LayerNorm適用 -&gt; Self-Attention -&gt; 残差を加算\n        x = x + self.sa(self.ln1(x))\n        # LayerNorm適用 -&gt; FeedForward -&gt; 残差を加算\n        x = x + self.ffwd(self.ln2(x))\n        return x\n完全なGPTモデルは、これらのBlockレイヤーを複数、順番に積み重ねます。すべてのブロックを通過した後、最終的なLayerNormが適用され、その後、最終的なトークン表現を語彙サイズに射影する線形層が続き、次のトークンを予測するためのロジットが得られます。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#最終的なgptモデルの構築",
    "href": "posts/transformer-attention-jp/index.html#最終的なgptモデルの構築",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "最終的なGPTモデルの構築",
    "text": "最終的なGPTモデルの構築\nこれまで解説してきたコンポーネントを統合し、最終的なGPTスタイルの言語モデルGPTLanguageModelを構築します。以下に示すコードは、Karpathy氏の動画における完成形であり、先に説明したBlock（MultiHeadAttentionとFeedForwardを含む）などを組み合わせています。\n# (主要なハイパーパラメータを再掲)\n# hyperparameters\nbatch_size = 64 # 並列処理する独立したシーケンス数\nblock_size = 256 # 予測のための最大コンテキスト長\nmax_iters = 5000\neval_interval = 500\nlearning_rate = 3e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 384     # 埋め込み次元数\nn_head = 6       # Attentionヘッドの数\nn_layer = 6      # Transformerブロックの層数\ndropout = 0.2    # ドロップアウト率\n# ------------\n\nclass GPTLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # トークン埋め込みと位置埋め込みのテーブル\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        # n_layer個のTransformerブロックを積み重ねる\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # 最終LayerNorm\n        self.lm_head = nn.Linear(n_embd, vocab_size) # 出力層（線形層）\n\n        # （動画本編では触れられていないが重要な）重み初期化\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        # （重み初期化の詳細は省略）\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C) Transformerブロックを通過\n        x = self.ln_f(x) # (B,T,C) 最終LayerNormを適用\n        logits = self.lm_head(x) # (B,T,vocab_size) LMヘッドでロジットを計算\n\n        if targets is None:\n            loss = None\n        else:\n            # 損失計算のために形状を変更\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idxは現在の文脈におけるインデックスの(B, T)配列\n        for _ in range(max_new_tokens):\n            # Position Embeddingのサイズ制限のため、idxを最後のblock_sizeトークンに切り詰める\n            idx_cond = idx[:, -block_size:]\n            # 予測を取得\n            logits, loss = self(idx_cond) # forwardパスを実行\n            # 最後のタイムステップのみに注目\n            logits = logits[:, -1, :] # (B, C) になる\n            # softmaxを適用して確率を取得\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # 分布からサンプリング\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # サンプリングされたインデックスを実行中のシーケンスに追加\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\nこのGPTLanguageModelクラスでは、__init__メソッドで、これまで説明してきたトークン埋め込みと位置埋め込みテーブル(token_embedding_table, position_embedding_table)を定義した後、n_layer個のBlockをnn.Sequentialで積み重ねています。これがTransformerの中核部であり、入力ベクトルはここを通過することで段階的にリッチな表現へと変換されます。その後、最終的なLayerNorm (ln_f)を経て、出力用の線形層lm_headによって語彙数次元のロジットへと変換されます。また、安定した学習のための重み初期化メソッド_init_weightsも含まれています。\nforwardメソッドは、この一連の流れを実装しており、トークン埋め込みと位置埋め込みを加算したベクトルをblocksに通し、正規化と線形変換を経て最終的なロジットを出力します。\nテキスト生成を行うgenerateメソッドでは、自己回帰的にトークンを生成していきますが、ここで重要なのはidx_cond = idx[:, -block_size:]の部分です。位置埋め込みテーブルposition_embedding_tableのサイズがblock_sizeに固定されているため、モデルに入力できるのは直近block_size個のトークンまでとなります。この制約のもとでforwardパスを実行し、最後のタイムステップのロジットから次のトークンをサンプリングし、シーケンスを伸長していく処理を繰り返します。\nコード全体を見ると、これらのモデル定義に加えて、学習を制御するハイパーパラメータ群（batch_sizeやlearning_rateなど）や、AdamWオプティマイザ、そしてestimate_loss関数を用いた評価を含む標準的な学習ループが組み合わされていることがわかります。これらが一体となってGPTモデルの学習と推論を実現しています。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#スケールアップと結果",
    "href": "posts/transformer-attention-jp/index.html#スケールアップと結果",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "スケールアップと結果",
    "text": "スケールアップと結果\nKarpathy氏は上のGPTLanguageModel（n_layer=6, n_head=6, n_embd=384, dropout=0.2）でTiny Shakespeareを学習させます。結果として得られるモデルは、はるかに一貫性のある（ただし、まだ意味をなさない）シェイクスピア風のテキストを生成し、十分なモデル容量と組み合わされたAttentionの力を示しています。\n# GPTLanguageModelからのサンプル出力\nFlY BOLINGLO:\nThem thrumply towiter arts the\nmuscue rike begatt the sea it\nWhat satell in rowers that some than othis Marrity.\n\nLUCENTVO:\nBut userman these that, where can is not diesty rege;\nWhat and see to not. But's eyes. What?\nこのアーキテクチャ、すなわちdecoder-only Transformer（causal maskを使用）は、基本的にGPT-2やGPT-3のようなモデルで使用されているものと同じですが、パラメータ数、層数、埋め込みサイズ、そして学習データ（シェイクスピアだけでなく膨大なインターネットテキスト）の点で、はるかに大規模になっています。"
  },
  {
    "objectID": "posts/transformer-attention-jp/index.html#まとめ",
    "href": "posts/transformer-attention-jp/index.html#まとめ",
    "title": "コードで理解するTransformer：AttentionとGPTモデル入門",
    "section": "まとめ",
    "text": "まとめ\nAttentionメカニズム、特にScaled dot-product self-attentionは、Transformerの能力を飛躍的に向上させた革新的な技術です。これにより、シーケンス内のトークンが動的にお互いを参照し、学習されたQuery-Keyの相互作用に基づいて関連性スコア（アフィニティ）を計算し、関連するトークンのValueベクトルからの情報を重み付きで集約することが可能になります。Multi-Head Attention、Residual Connections、Layer Normalization、そして位置ごとのFeedForwardネットワークと組み合わせることで、ChatGPTのようなAIに革命をもたらしているモデルの基本的な構成要素であるTransformerブロックが形成されます。\nKarpathy氏のように段階的に構築することで、強力でありながらも、その中心的なアイデアは把握可能であり、比較的簡潔なコードで実装できることがわかります。\n\nこの記事は、Andrej Karpathy氏のYouTube動画「Let’s build GPT: from scratch, in code, spelled out.」に基づいています。完全なコードやより深い洞察については、ぜひ動画と彼のnanogptリポジトリをご覧ください。 この記事が、TransformerとAttentionの理解の一助となれば幸いです。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html",
    "href": "posts/latent-dharmesh-shah/index.html",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "",
    "text": "HubSpotの共同創業者兼CTOであり、近年はAgent.aiの創設者としても注目を集めるDharmesh Shah。インバウンドマーケティングのパイオニアとして名を馳せた彼が今、情熱を注ぐのは人工知能（AI）、とりわけAIエージェントの世界である。単なるバズワードとしてではなく、ビジネスの根幹を変革しうる力としてAIを見据える彼の洞察は、Latent Space podcastでのインタビューからも鮮明に浮かび上がる。本稿では、Shah氏が描くAIエージェントの未来像、特に「ハイブリッドチーム」という概念、新たなビジネスモデル「WaaS/RaaS」、そして彼が手掛けるAgent.aiの野心的なビジョンについて深く掘り下げていく。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#エージェントの再定義ツールからチームメイトへ",
    "href": "posts/latent-dharmesh-shah/index.html#エージェントの再定義ツールからチームメイトへ",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "エージェントの再定義：ツールから「チームメイト」へ",
    "text": "エージェントの再定義：ツールから「チームメイト」へ\nShah氏は、AIエージェントを「AIを活用し目標を達成するソフトウェア」と極めて広範に定義する。この定義は一部で「曖昧すぎる」との批判も招くが、彼の意図は既存の枠組みに囚われず、AIの可能性を最大限に捉えようとするところにあるのだろう。podcastで彼が語ったように、エージェントは自律性の度合い、ワークフローの決定性、同期/非同期性、インタラクションモード（チャット型、ワークフロー型など）によって多様な形態を取りうる。重要なのは、特定の技術実装ではなく、AIが「何かを成し遂げる」という本質なのである。\nさらにShah氏は、「ツールすらも原子的なエージェントと見なせるのではないか」という、より刺激的な視点を提供する。LLMがツールを呼び出す現在の主流アプローチに対し、彼は「すべてがエージェントであり、ツール呼び出しはエージェント間の連携に過ぎない」と考えれば、よりエレガントな設計思想に至る可能性を示唆する。この「万物エージェント論」とも言える発想は、彼がAgent.aiで目指す「AIエージェントのためのプロフェッショナルネットワーク」構想と深く結びついている。\nAgent.aiは、単なるAIツールのマーケットプレイスではない。Shah氏が語るように、それは「AIエージェント版LinkedIn」であり、様々な能力を持つAIエージェントが発見され、評価され、「雇用」されるプラットフォームを目指す。驚異的なスピードでユーザー数を増やし（2025年初頭の25万人から3月には110万人超へ）、1,000以上の公開エージェントを擁するに至った現状は、市場がいかに実用的なAIソリューションを渇望しているかの証左であろう。Shah氏自身が「好奇心こそが重要」と語るように、ローコード/ノーコードのビルダー機能は、専門家でなくとも独自のAIエージェントを構築できる民主化の波を後押ししている。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#ハイブリッドチーム次世代の働き方",
    "href": "posts/latent-dharmesh-shah/index.html#ハイブリッドチーム次世代の働き方",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "ハイブリッドチーム：次世代の働き方",
    "text": "ハイブリッドチーム：次世代の働き方\nShah氏が提唱する最も興味深い概念の一つが「ハイブリッドチーム」である。これは、従来の「リモート vs オフィス」「正社員 vs 契約社員」といったハイブリッドモデルの次に来る、人間とAIエージェントが文字通り「チームメイト」として協働する組織形態を指す。AIが単なるツールではなく、主体性を持った協力者としてチームに加わる未来像だ。\nこのビジョンの核心は、AIエージェントがデータ入力や定型レポート作成といった「退屈な（mundane）」タスクを引き受け、人間は戦略立案、創造性、共感、複雑な人間関係構築といった、より高度で人間的な能力（Shah氏の言葉を借りれば「魔法（magic）」）の発揮に集中できるようになるという点にある。AIによる雇用喪失の懸念に対し、彼はあくまで人間の能力を「拡張（augmentation）」するものであり、「皆さんの仕事は安全だ」と断言する。\nしかし、このハイブリッドチームの実現は、新たなマネジメントの課題も提起する。人間とAIの間でいかに信頼を構築し、タスクを効果的に委任し、円滑なコミュニケーションを確立するか。AIエージェントのパフォーマンスをどう評価し、チーム全体のダイナミクスをどう最適化していくか。これらの問いに対する答えはまだ模索段階であり、新たな組織論やリーダーシップ論が必要となることは想像に難くない。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#価値提供の進化saasからwaasそしてraasへ",
    "href": "posts/latent-dharmesh-shah/index.html#価値提供の進化saasからwaasそしてraasへ",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "価値提供の進化：SaaSからWaaS、そしてRaaSへ",
    "text": "価値提供の進化：SaaSからWaaS、そしてRaaSへ\nAIアプリケーションの普及に伴い、ビジネスモデルも進化を迫られる。Shah氏は、従来のSoftware as a Service (SaaS)に加え、Work as a Service (WaaS)とResults as a Service (RaaS)という新たなモデルの重要性を指摘する。\nRaaSは、ソフトウェアが提供した具体的な「結果」に対して対価を支払うモデルである。例えば、解決されたサポートチケット数に応じて課金されるケースなどが該当する。成果が明確で測定可能な場合に有効だが、シャー氏は現状、このRaaSが「過度に重視されている（over-indexed）」可能性があると警鐘を鳴らす。なぜなら、すべてのAIタスクの成果が客観的に測定可能とは限らず、また成果に対する責任が人間とAIの間で共有されるケースも多いからだ。例えば、AIが生成したデザイン案の良し悪しをどう客観的に評価し、誰に最終的な責任を帰属させるのか、といった問題である。\nそこでShah氏が中間的なモデルとして提唱するのがWaaSである。これは、AIが実行した「作業」そのものに対して対価を支払うモデルだ。最終的な成果が主観的であったり、測定困難であったりする場合でも、AIが行ったプロセスや費やしたリソースに基づいて価値を評価する。これは、人間の労働がしばしば時間や労力で評価される現状とも整合性が高い。\nShah氏は、SaaS、WaaS、RaaSの3つのモデルが、ユースケースに応じて併用される未来を予測する。SaaSは依然として人間を支援・強化するツールとして有効であり、RaaSは成果が明確な定型タスクに、そしてWaaSは成果保証が難しい複雑なタスクや、人間とAIが協働するハイブリッドチームの文脈で、その真価を発揮するだろう。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#エコシステム実現への道メモリと認証の壁",
    "href": "posts/latent-dharmesh-shah/index.html#エコシステム実現への道メモリと認証の壁",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "エコシステム実現への道：メモリと認証の壁",
    "text": "エコシステム実現への道：メモリと認証の壁\nShah氏が描くような、多数のAIエージェントが連携し合うエコシステムの実現には、乗り越えるべき技術的なハードルが存在する。podcastでも強調されていたのが、「メモリ」と「認証」の問題である。\n現在のチャットボットの多くが長時間の対話で文脈を維持できないように、AIエージェントが複雑なタスクを遂行するには、永続的で信頼性の高いメモリが不可欠となる。特にShah氏が重要視するのは「エージェント間のメモリ共有（cross-agent memory sharing）」である。あるエージェントが学習した情報を、許可された他のエージェントが安全に利用できなければ、真の連携は実現しない。\n同様に、データアクセス制御も大きな課題だ。現状のOAuthのような仕組みでは不十分であり、ユーザーが特定のデータ（例えば、特定のラベルが付いたメールのみ、特定の期間のデータのみなど）を選択的に、異なるエージェントに対して許可できるような、より詳細な（granular）認証メカニズムが必要だとShah氏は主張する。これが実現しなければ、セキュリティやプライバシーへの懸念から、企業や個人がAIエージェントに重要なタスクや広範なデータアクセスを委ねることは難しいだろう。\nこれらのメモリと認証の課題は、単なる技術的な問題ではなく、AIエージェントに対する「信頼」をいかに構築するかという根源的な問いに繋がっている。Meta Agent Communication Protocol (MCP)のような標準規格の登場は、相互運用性の一助となる可能性はあるが、根本的なインフラ整備はまだ道半ばである。これらの課題解決こそが、Agent.aiのようなプラットフォーム、そしてハイブリッドチームという未来像の実現に向けた鍵となるのである。"
  },
  {
    "objectID": "posts/latent-dharmesh-shah/index.html#結論dharmesh-shahが拓く未来",
    "href": "posts/latent-dharmesh-shah/index.html#結論dharmesh-shahが拓く未来",
    "title": "HubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来",
    "section": "結論：Dharmesh Shahが拓く未来",
    "text": "結論：Dharmesh Shahが拓く未来\nDharmesh Shah氏は、HubSpotでの成功体験を基盤としながら、AIエージェントという新たな領域で再びイノベーションを牽引しようとしている。彼が提示するハイブリッドチームという働き方の未来像、WaaS/RaaSという新たな価値交換の形、そしてそれらを実現するためのプラットフォームとしてのAgent.aiは、単なる技術トレンドの追随ではなく、仕事の本質そのものを問い直す野心的な試みと言えるだろう。\n技術的な課題は残るものの、Shah氏のビジョンと実行力は、AIが社会やビジネスに浸透していくプロセスにおいて、重要な羅針盤となる可能性を秘めている。彼がpodcastで語ったように、AIエージェントとの協働はもはや避けられない未来であり、重要なのはそれを脅威と捉えるのではなく、いかにして人間の能力を拡張し、より良い働き方を実現するかという視点を持つことなのだろう。Agent.aiの急速な成長と、Shah氏の発信するメッセージは、その未来に向けた確かな一歩を示している。"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Junichiro Iwasawa",
    "section": "",
    "text": "個人ページ: jiwasawa.github.io/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ブログ",
    "section": "",
    "text": "拡散モデル入門：基本概念から応用まで\n\n\n\n\n\n\nMachine Learning\n\n\nDiffusion models\n\n\n\n\n\n\n\n\n\nApr 17, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nHubSpot共同創業者が見据えるAIエージェント新時代：ハイブリッドチームと仕事の未来\n\n\n\n\n\n\nAI\n\n\nPodcast\n\n\nLatent Space Podcast\n\n\n\n\n\n\n\n\n\nApr 16, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nAI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』\n\n\n\n\n\n\nLLM\n\n\nPodcast\n\n\nAI\n\n\n\n\n\n\n\n\n\nApr 15, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\n\n\n\n\n\n\nコードで理解するTransformer：AttentionとGPTモデル入門\n\n\n\n\n\n\nMachine Learning\n\n\nTransformer\n\n\nPython\n\n\nLLM\n\n\n\n\n\n\n\n\n\nApr 11, 2025\n\n\nJunichiro Iwasawa\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html",
    "href": "posts/cognitive-aime-coscientist/index.html",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "",
    "text": "Google DeepMindから発表された二つの研究プロジェクト、AMIE (Articulate Medical Intelligence Explorer) とAI co-scientistは、AIの能力が新たな段階に到達しつつあることを示唆している。先日配信されたポッドキャスト「The Cognitive Revolution」では、開発担当者のVivek Natarajan氏とAnil Palepu氏がこれらのプロジェクトについて語り、AIが高度な専門知識を要する領域で人間と肩を並べ、あるいは特定のタスクにおいては凌駕し始めている現状が浮き彫りとなった。本稿では、これらの研究内容とその意味合いについて、ポッドキャストでの議論も踏まえつつ、やや距離を置いた視点から分析を試みる。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#診断対話aiamie医師との比較で見えた可能性と課題",
    "href": "posts/cognitive-aime-coscientist/index.html#診断対話aiamie医師との比較で見えた可能性と課題",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "診断対話AI『AMIE』：医師との比較で見えた可能性と課題",
    "text": "診断対話AI『AMIE』：医師との比較で見えた可能性と課題\nAMIEとは、診断における医師と患者の対話をAIで支援、あるいは代替することを目論む大規模言語モデル（LLM）ベースのシステムである。医療の核心とも言えるこの対話プロセスにおいて、AIがどこまで人間の医師の能力に近づけるかは、長らく大きな挑戦とされてきた代物だ。\nAMIEの開発では、多様な疾患や専門分野、文脈に対応できるよう、自己対戦（self-play）に基づいたシミュレーション環境と自動フィードバック機構が用いられた。これにより、モデルは様々な状況下での対話を通じて学習を深めることが可能となる。推論時には、対話の文脈を踏まえながら段階的に思考を深める「Chain-of-Reasoning」戦略を採用し、応答の正確性と質を高めているという。\nその性能を評価するため、客観的臨床能力試験（OSCE）を模した形式で、訓練を受けた模擬患者とAMIE、そして比較対象として現役のプライマリケア医（PCP）が、テキストチャットで診察を行うランダム化比較試験が実施された。この試験では、病歴聴取、診断精度、治療方針の妥当性、コミュニケーションスキル、共感力といった複数の軸で評価が行われた。\n結果を見ると、専門医評価では32項目中28項目、模擬患者評価では26項目中24項目において、AMIEがPCPを上回る評価を獲得したという。特に診断精度においては、AMIEがPCPよりも高い精度を示した点が注目される。さらに、ポッドキャストで触れられていた後続研究では、心臓病学や腫瘍学といった専門分野においても、AMIEがフェロー（専門研修医）を上回り、指導医レベルに迫る性能を示し始めていることが示唆された。\nただし、これらの結果を鵜呑みにするのは早計である。最大の注意点は、評価がテキストチャットという、実際の臨床現場とは異なる限定的な環境で行われたことだ。医師は通常、対面や電話、ビデオ通話で患者と対話するため、テキストチャット形式は不慣れであった可能性が高い。また、対話相手も実際の患者ではなく、特定のシナリオに基づいて演技する模擬患者であった。\nとはいえ、特定の条件下においてAIが高い診断能力と対話能力を示した事実は無視できない。ポッドキャストで語られていたように、AIが人間の医師を補完する形で活用される可能性、例えば、診断の網羅性を高めたり、より共感的で構造化された応答を提案したりする未来は十分に考えられる。事実、心臓専門医がAMIEを利用した場合、単独の場合と比較してほぼ全ての評価指標でパフォーマンスが向上したという結果は、人間とAIの協調の可能性を示唆するものだろう。現在、AMIEはハーバード大学医学部付属病院であるベス・イスラエル・ディーコネス医療センターとの提携を通じて、実世界での検証、いわば臨床試験に近い段階へと進められている模様だ。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#co-scientist科学的発見プロセスを支援するai",
    "href": "posts/cognitive-aime-coscientist/index.html#co-scientist科学的発見プロセスを支援するai",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "『Co-Scientist』：科学的発見プロセスを支援するAI",
    "text": "『Co-Scientist』：科学的発見プロセスを支援するAI\n一方、Co-Scientistは、科学者が新たな知識を発見し、独創的な研究仮説を立てるプロセスを支援するために設計されたマルチエージェントシステムである。このシステムは、研究目標やガイダンスに基づいて先行研究を調査・統合し、実証可能な仮説や研究提案を生成することを目的とする。\nCo-Scientistの設計は、科学的手法に着想を得た「生成・討論・進化（generate, debate, evolve）」アプローチを採用している。複数の専門エージェント（生成、反省、ランキング、進化など）が連携し、トーナメント形式のフレームワーク内で仮説を継続的に生成、評価、改善していく。この自己改善ループにより、仮説の質が向上していくことが期待されるわけだ。また、ウェブ検索や専門的なAIモデル（論文中ではAlphaFoldへの言及もあった）といったツールを活用し、生成される仮説の根拠付けや質を高めている。\nその有効性を検証するため、3つの異なる複雑さを持つ生物医学分野での評価が行われた。第一に、比較的探索空間が限定される「既存薬の再開発（ドラッグリパーパシング）」では、急性骨髄性白血病（AML）に対して有望な候補薬を提案し、その一部は臨床的に適用可能な濃度で腫瘍抑制効果を示すことがin vitro実験で確認された。\n第二に、より複雑な「新規治療標的の発見」では、肝線維症に対する新たなエピジェネティックな標的を提案し、ヒト肝オルガノイドを用いた実験で抗線維化活性が検証された。\nそして第三に、最も挑戦的とも言える「細菌の薬剤耐性獲得メカニズムの解明」という完全にオープンエンドな課題である。この検証では、共同研究者である科学者グループが実験的に発見し、まだ公表していなかった特定の遺伝子伝達メカニズム（cf-PICIが多様なファージ尾部と相互作用することで宿主域を拡大する）と全く同じ仮説を、Co-Scientistが独立して最有力候補として提案するという、にわかには信じがたい結果が得られた。これは、AIが既存知識を単に再構成するだけでなく、点在する情報を結びつけ、人間にとっても新規性のある洞察を生み出す能力を持ち始めていることを強く示唆する事例と言えよう。\nCo-Scientistは、あくまで科学者を支援する「共同研究者」として設計されており、プロセスのどの段階でも人間の専門家が介入し、フィードバックを与えることが可能だ。現在、このシステムは「Trusted Tester Program」を通じて、より多くの研究者に利用機会を提供し、実世界での有用性や課題に関するフィードバックを収集する段階に進んでいる。"
  },
  {
    "objectID": "posts/cognitive-aime-coscientist/index.html#専門知のai化見えてきた共通項と今後の展望",
    "href": "posts/cognitive-aime-coscientist/index.html#専門知のai化見えてきた共通項と今後の展望",
    "title": "AI、専門家の領域へ：診断支援『AMIE』と科学的発見『AI co-scientist』",
    "section": "専門知のAI化：見えてきた共通項と今後の展望",
    "text": "専門知のAI化：見えてきた共通項と今後の展望\nAMIEとCo-Scientistの研究は、AIが人間の高度な知的活動領域へと進出している現状を示すものである。これらの研究からは、いくつかの共通した技術的アプローチが見て取れる。一つは、特定のタスクに対するモデルのファインチューニング（追加学習）よりも、汎用的な基盤モデルの能力を高度なプロンプティングやエージェント設計によって引き出す方向性へのシフト。二つ目は、長文脈処理能力と推論時の計算資源（Test-time Compute）を潤沢に使うことで、より深い思考や複雑なタスクの実行を可能にしている点。そして三つ目は、自己対戦やトーナメント形式の評価、外部ツール（特にウェブ検索）からの情報（エントロピー）注入といった仕組みを取り入れることで、システムの自己改善能力や生成物の質を高めている点である。\nポッドキャストで議論されていたように、「AIが人間より賢くなった」と結論づけるのは時期尚早であろう。しかし、特定の定義されたタスクにおいて、AIがトップレベルの人間の専門家と同等、あるいはそれ以上のパフォーマンスを発揮し始めていることは否定できない。Co-Scientistが未発表の科学的発見を再現した事例は、その好例だ。\nこれらのAIシステムは、単に既存の情報を検索・要約するだけでなく、複数の情報源を統合し、新たな仮説を生成するという、より高度な知的作業を可能にしつつある。もちろん、現実世界の複雑さへの対応、真に独創的な問いを発する能力、倫理的な課題など、克服すべき点は山積している。しかし、AMIEの臨床応用への模索やCo-Scientistの研究コミュニティへの提供開始は、AIが専門家の「思考パートナー」となる未来が、もはやSFの領域ではなくなりつつあることを物語っている。\n肝要なのは、これらの技術をいかに責任ある形で社会実装していくかという点に尽きる。特に医療や科学研究といった分野では、人間の専門家による監督と検証が不可欠であり、AIはあくまで人間を支援し、その能力を拡張するためのツールとして位置づけられるべきなのだ。Google DeepMindの取り組みは、その可能性と課題の両方を我々に突きつけており、今後の動向から目が離せない。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html",
    "href": "posts/diffusion-basics/index.html",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "",
    "text": "近年、特に画像生成分野で目覚ましい成果を上げている拡散モデル（Diffusion Models）について、基本的な仕組みから応用技術までを解説します。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#拡散モデルとは",
    "href": "posts/diffusion-basics/index.html#拡散モデルとは",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "拡散モデルとは？",
    "text": "拡散モデルとは？\n拡散モデルは、生成モデルの一種です。他の代表的な生成モデルとしてGAN、VAE、Flowベースモデルがありますが、GANは学習の不安定さ、VAEは代理損失への依存、Flowモデルは可逆変換のためのアーキテクチャ制約といった課題がありました。\n拡散モデルは、非平衡熱力学に着想を得ており、データの分布を学習するための独自のアプローチを取ります。\n\n順方向プロセス（Forward Process / Diffusion Process）： 元のデータに段階的に微小なランダムノイズを加えていき、最終的には既知の単純な分布（通常は標準正規分布）に変換します。\n逆方向プロセス（Reverse Process / Denoising Process）： 上記の過程を逆向きに辿り、単純なノイズ分布からスタートして、段階的にノイズを除去していくことで元のデータ分布に属する新しいサンプルを生成します。\n\nこの「ノイズ除去」ステップを学習したニューラルネットワークが、実質的な生成モデルとなります。拡散モデルは、学習プロセスが固定されており、VAEやFlowモデルと異なり、潜在変数が元データと同じ次元を持つという特徴があります。\n\n順方向プロセス：データをノイズへ\n元のデータ \\(\\mathbf{x}_0 \\sim q(\\mathbf{x})\\) から出発し、\\(T\\) ステップかけて徐々にGaussianノイズを加えていくマルコフ連鎖として定義されます。各ステップ \\(t\\) での遷移は次のように定義されます。\n\\[q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t\\mathbf{I})\\]\nここで、\\(\\\\{\\beta_t \\in (0, 1)\\\\}_{t=1}^T\\) は分散スケジュールと呼ばれるハイパーパラメータで、各ステップで加えるノイズの大きさを制御します。\\(\\beta_t\\) は通常、\\(t\\) が大きくなるにつれて増加するように設定されます（例：linear スケジュール、cosine スケジュール[Nichol & Dhariwal, 2021]）。\\(\\mathbf{I}\\) は単位行列です。\n全ステップの同時分布は次のようになります。\n\\[q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0) = \\prod^T_{t=1} q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1})\\]\nこのプロセスの重要な特性は、任意のステップ \\(t\\) におけるノイズ付きデータ \\(\\mathbf{x}_t\\) を、元のデータ \\(\\mathbf{x}_0\\) から閉じた式で直接計算できることです。\\(\\alpha_t = 1 - \\beta_t\\) および \\(\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i\\) と定義すると、\\(\\mathbf{x}_t\\) の分布は次のように表せます。\n\\[q(\\mathbf{x}_t \\vert \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I})\\]\nこれは、\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}\\) （ただし \\(\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\)）と書くこともできます。つまり、\\(\\mathbf{x}_t\\) は、元のデータ \\(\\mathbf{x}_0\\) をスケールしたものと、それに加わるノイズ項の和で表されるわけです。\\(T\\) が十分に大きいと、\\(\\bar{\\alpha}_T \\approx 0\\) となり、\\(\\mathbf{x}_T\\) は元のデータ \\(\\mathbf{x}_0\\) からほぼ独立したGaussianノイズ \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) になります。\n\n\n逆方向プロセス：ノイズからデータへ\n生成プロセスは、この順方向プロセスを逆に辿ります。つまり、まずGaussianノイズ \\(\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) をサンプリングし、そこから \\(t=T, T-1, \\dots, 1\\) とステップを遡って \\(\\mathbf{x}_{T-1}, \\mathbf{x}_{T-2}, \\dots, \\mathbf{x}_0\\) を逐次的にサンプリングします。\nこのためには、逆方向の遷移確率 \\(q(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) を知る必要がありますが、これはデータセット全体の情報が必要となるため計算が困難（intractable）です。そこで、この遷移確率をニューラルネットワーク（パラメータ \\(\\theta\\) を持つ）で近似します。この近似された遷移確率を \\(p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) と書きます。\n逆方向プロセス全体は次のように表されます。\n\\[p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\]\nここで \\(p(\\mathbf{x}_T) = \\mathcal{N}(\\mathbf{x}_T; \\mathbf{0}, \\mathbf{I})\\) です。各逆方向ステップの遷移 \\(p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t)\\) もガウス分布であると仮定するのが一般的です。\n\\[p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))\\]\nモデルの目標は、この平均 \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) と共分散 \\(\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)\\) を学習することです。 共分散 \\(\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)\\) は、しばしば学習せず、\\(\\sigma_t^2 \\mathbf{I}\\) という形の固定値（またはスケジュールに従う値）が用いられます。\\(\\sigma_t^2\\) としては、順方向プロセスの \\(\\beta_t\\) や、理論的に導かれる \\(\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\beta_t\\) が使われます。[Nichol & Dhariwal, 2021] では、\\(\\beta_t\\) と \\(\\tilde{\\beta}_t\\) の間の補間として学習する手法も提案されていますが、不安定になる可能性も指摘されています。\n\n\n学習の目標：ノイズを予測する\nでは、どのようにして \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) を学習するのでしょうか？ 完全な導出は変分下限（Variational Lower Bound, VLB）の最大化に基づきますが、DDPM [Ho et al., 2020] では、より直感的で効果的な目的関数が用いられています。\nその中心的なアイデアは、逆方向ステップの平均 \\(\\boldsymbol{\\mu}_\\theta\\) を直接予測するのではなく、順方向プロセスでステップ \\(t\\) においてデータ \\(\\mathbf{x}_0\\) に加えられたノイズ \\(\\boldsymbol{\\epsilon}\\) を予測することです。モデルを \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と書きます。\n\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}\\) の関係を使うと、逆方向ステップの（真の）平均 \\(\\tilde{\\boldsymbol{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0)\\) （これは \\(\\mathbf{x}_0\\) が既知の場合に計算可能）は、このノイズ \\(\\boldsymbol{\\epsilon}\\) を使って表現できます。そして、学習する平均 \\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) がこの真の平均に近くなるように、モデル \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) が真のノイズ \\(\\boldsymbol{\\epsilon}\\) を予測するように学習させます。\n具体的には、\\(\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)\\) は、予測されたノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) を用いて次のようにパラメータ化されます。\n\\[\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right)\\]\nこの式を見ると、モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) が学習できれば、逆方向ステップの平均 \\(\\boldsymbol{\\mu}_\\theta\\) が決まることがわかります。\nそして、DDPMで提案された単純化された学習目的関数（損失関数）は、以下のように、予測ノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と、実際に加えられたノイズ \\(\\boldsymbol{\\epsilon}\\) との間の平均二乗誤差（Mean Squared Error, MSE）を最小化することになります。\n\\[L_\\text{simple} = \\mathbb{E}_{t \\sim \\mathcal{U}(1, T), \\mathbf{x}_0 \\sim q(\\mathbf{x}_0), \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left[\\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}, t)\\|^2 \\right]\\]\n訓練時には、データ \\(\\mathbf{x}_0\\) をサンプリングし、ランダムなステップ \\(t\\) を選び、Gaussianノイズ \\(\\boldsymbol{\\epsilon}\\) を生成し、\\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}\\) を計算します。そして、モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) に \\(\\mathbf{x}_t\\) と \\(t\\) を入力し、予測されたノイズ \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) と元のノイズ \\(\\boldsymbol{\\epsilon}\\) とのMSEを計算し、これを損失としてモデルパラメータ \\(\\theta\\) を更新します。\nスコア関数との関連: このノイズ予測 \\(\\boldsymbol{\\epsilon}_\\theta\\) は、実はデータの対数確率密度勾配、すなわちスコア関数 \\(\\nabla_{\\mathbf{x}_t} \\log q(\\mathbf{x}_t)\\) と密接に関連しています。具体的には、\\(\\mathbf{s}_\\theta(\\mathbf{x}_t, t) \\approx \\nabla_{\\mathbf{x}_t} \\log q(\\mathbf{x}_t) \\approx - \\frac{\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)}{\\sqrt{1 - \\bar{\\alpha}_t}}\\) という関係があります。これは、拡散モデルがスコアベース生成モデル（NCSN [Song & Ermon, 2019] など）と深いつながりを持つことを示唆しています。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#拡散モデルの進化と応用",
    "href": "posts/diffusion-basics/index.html#拡散モデルの進化と応用",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "拡散モデルの進化と応用",
    "text": "拡散モデルの進化と応用\nDDPMの成功を受けて、拡散モデルの性能向上や応用範囲拡大のための様々な研究が行われています。\n\n条件付き生成（Conditional Generation）\n特定の情報（クラスラベル、テキスト記述、他の画像など）に基づいて画像を生成する技術です。\n\nClassifier Guidance: [Dhariwal & Nichol, 2021] で提案。ノイズ付き画像 \\(\\mathbf{x}_t\\) を入力として目的の条件 \\(y\\) の対数尤度 \\(\\log f_\\phi(y \\vert \\mathbf{x}_t)\\) を計算する別の分類器 \\(f_\\phi\\) を訓練します。生成時には、通常のノイズ予測 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\) に、この分類器の勾配 \\(\\nabla_{\\mathbf{x}_t} \\log f_\\phi(y \\vert \\mathbf{x}_t)\\) を加味して予測を修正します。 \\[\\bar{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{x}_t, t) = \\boldsymbol{\\epsilon}_\\theta(x_t, t) - w \\sqrt{1 - \\bar{\\alpha}_t} \\nabla_{\\mathbf{x}_t} \\log f_\\phi(y \\vert \\mathbf{x}_t)\\] ここで \\(w\\) はガイダンスの強さを制御する係数です。ADM (Ablated Diffusion Model) や ADM-G (ADM with Guidance) で高い性能が示されました。\nClassifier-Free Guidance: [Ho & Salimans, 2021] で提案。拡散モデル \\(\\boldsymbol{\\epsilon}_\\theta\\) 自身を、条件 \\(y\\) が与えられた場合 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y)\\) と、条件がない（\\(y=\\varnothing\\) とする）場合 \\(\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing)\\) の両方で学習します。これは訓練中に一定の確率で条件 \\(y\\) を無視（空の条件 \\(\\varnothing\\) に置き換える）ことで実現されます。生成時には、この二つの予測を組み合わせてガイダンスを行います。 \\[\\bar{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{x}_t, t, y) = \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing) + w (\\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y) - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing))\\] これは \\((w+1) \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, y) - w \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t, \\varnothing)\\) とも書けます（元のブログ記事の式と一致）。この手法は追加の分類器が不要であり、近年の多くの高性能モデル（Imagen, Stable Diffusion, GLIDEなど）で広く採用されています。GLIDE [Nichol et al., 2022] では、CLIPを用いたガイダンスよりもClassifier-Freeガイダンスの方が好ましい結果が得られたと報告されています。\n\n\n\n高速化（Speeding Up Sampling）\nDDPMの最大の課題であった生成速度を改善するための研究が活発に行われています。\n\nDDIM (Denoising Diffusion Implicit Models): [Song et al., 2020] で提案。DDPMはマルコフ連鎖的な確率過程でしたが、DDIMは同じ順方向プロセスを持ちながら、非マルコフ的な（より大きなステップを許容する）決定論的な生成プロセスを定義します。これにより、サンプリングステップ数を大幅に（例：1000ステップから20～50ステップへ）削減しても高品質な生成が可能になりました。DDIMはパラメータ \\(\\eta\\) を持ち、\\(\\eta=0\\) で決定論的（DDIM）、\\(\\eta=1\\) でDDPMに近い確率的なサンプリングになります。決定論的であるため、同じ初期ノイズからは同じ画像が生成される「一貫性」を持ち、潜在空間での補間なども可能になります。\nProgressive Distillation: [Salimans & Ho, 2022] で提案。訓練済みの決定論的サンプラー（例：DDIM）を「教師」とし、より少ないステップ数で同じ結果を出す「生徒」モデルを訓練する蒸留手法です。具体的には、生徒モデルの1ステップが教師モデルの2ステップに対応するように学習させます。これを繰り返すことで、サンプリングステップ数を指数関数的に削減できます。\nConsistency Models: [Song et al., 2023] で提案。拡散過程の途中の任意のノイズ付きデータ \\(\\mathbf{x}_t\\) から、直接元のデータ \\(\\mathbf{x}_0\\) （またはそれに近い \\(\\mathbf{x}_\\epsilon\\)）を予測する関数 \\(f(\\mathbf{x}_t, t) \\approx \\mathbf{x}_0\\) を学習します。同じ軌道上の点はすべて同じ出力にマッピングされるという「自己一貫性」を持ちます。事前学習済みの拡散モデルから蒸留する方法（Consistency Distillation, CD）と、直接学習する方法（Consistency Training, CT）があります。これにより、理論的には1ステップでの高品質な生成が可能になります。\nLatent Diffusion Models (LDM): [Rombach et al., 2022] で提案。画像を直接扱うのではなく、まず強力なAutoencoder（Encoder \\(\\mathcal{E}\\) と Decoder \\(\\mathcal{D}\\)）を用いて画像を低次元の潜在表現 \\(\\mathbf{z} = \\mathcal{E}(\\mathbf{x})\\) に圧縮します。そして、この潜在空間 \\(\\mathbf{z}\\) 上で拡散モデル（通常はU-Netベース）を学習・実行します。生成時には、潜在空間でノイズから潜在表現 \\(\\mathbf{z}\\) を生成し、最後にDecoder \\(\\mathcal{D}\\) を使って画像 \\(\\tilde{\\mathbf{x}} = \\mathcal{D}(\\mathbf{z})\\) に戻します。計算量を大幅に削減できるため、Stable Diffusionなどの高解像度画像生成モデルの基盤技術となっています。潜在空間の正則化にはKLペナルティ（VAEライク）やVQ正則化（VQ-VAEライク）が用いられます。条件付けは、潜在空間上のU-NetにCross-Attention機構を導入して行われることが多いです。\n\n\n\n高解像度・高品質化\n\nCascaded Models: [Ho et al., 2021] など。まず低解像度の画像を生成し、次にその低解像度画像を条件として、より高解像度の画像を生成する超解像拡散モデルを適用する、というパイプライン方式です。高品質な高解像度画像を生成するために有効です。この際、低解像度の条件画像に意図的にノイズを加える「Noise Conditioning Augmentation」が、誤差の蓄積を防ぎ品質を向上させる上で重要であることが示されています（低解像度ではGaussianノイズ、高解像度ではガウスぼかしが有効）。\nunCLIP / DALL-E 2: [Ramesh et al., 2022] で提案。CLIPモデルを活用し、テキスト記述から高品質な画像を生成します。2段階のプロセスからなります：(1) Priorモデルがテキスト \\(y\\) から対応するCLIP画像埋め込み \\(\\mathbf{c}^i\\) を生成する (\\(P(\\mathbf{c}^i \\vert y)\\))。(2) Decoderモデルが、生成された画像埋め込み \\(\\mathbf{c}^i\\) （と、任意で元のテキスト \\(y\\)）を条件として、最終的な画像 \\(\\mathbf{x}\\) を生成する (\\(P(\\mathbf{x} \\vert \\mathbf{c}^i, [y])\\))。Decoderには拡散モデルが用いられます。\nImagen: [Saharia et al., 2022] で提案。CLIPの代わりに、大規模な事前学習済み言語モデル（凍結されたT5-XXL）をテキストエンコーダとして使用します。テキストエンコーダの規模がU-Netの規模よりも重要であることが示されました。Classifier-Free Guidanceのスケール \\(w\\) を大きくした際の画像忠実度低下を防ぐために、予測値をクリッピングする「Dynamic Thresholding」という手法を導入しました。また、U-Netアーキテクチャを改良した「Efficient U-Net」（低解像度ブロックにパラメータを集中、スキップ接続のスケーリング、畳み込みとプーリングの順序変更など）も提案されました。\nアーキテクチャの進化 (U-Net, DiT, ControlNet):\n\nU-Net: ダウンサンプリングパスとアップサンプリングパスを持ち、対応する層間をスキップ接続で繋いだ構造は、拡散モデル（特に画像）の標準的なバックボーンとして広く使われています。\nDiT (Diffusion Transformer): [Peebles & Xie, 2023] で提案。LDMと同様に潜在空間上で動作しますが、バックボーンとしてU-Netの代わりにTransformerを使用します。潜在表現をパッチに分割し、シーケンスとしてTransformerブロックに入力します。タイムステップ \\(t\\) やクラスラベル \\(c\\) などの条件は、Layer Normalizationのパラメータを適応的に変化させる adaLN (Adaptive Layer Norm) -Zero という方式で埋め込むのが効果的でした。Transformerのスケーラビリティの恩恵を受け、モデルサイズと計算量を増やすことで性能が向上することが示されています。\nControlNet: [Zhang et al., 2023] で提案。事前学習済みの強力な拡散モデル（例：Stable Diffusion）の重みを凍結したまま、そこに新たな条件（例：人物の骨格、線画、深度マップなど）を追加制御できるようにする手法です。元のモデルの各ブロックをコピーし、そのコピーのみを訓練可能にします。元のブロックとコピーの間を「Zero Convolution」（重みとバイアスがゼロで初期化された1x1畳み込み）で接続することで、元のモデルの性能を損なわずに、かつ安定して新たな制御を追加学習できます。式で書くと \\(\\mathbf{y}_c = \\mathcal{F}_\\theta(\\mathbf{x}) + \\mathcal{Z}_{\\theta_{z2}}(\\mathcal{F}_{\\theta_c}(\\mathbf{x} + \\mathcal{Z}_{\\theta_{z1}}(\\mathbf{c})))\\) となります。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#まとめ",
    "href": "posts/diffusion-basics/index.html#まとめ",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "まとめ",
    "text": "まとめ\n拡散モデルは、データをノイズに変換する順方向プロセスと、その逆を学習してノイズからデータを生成する逆方向プロセスに基づく、強力かつ柔軟な生成モデルです。\n\n利点: 理論的な扱いやすさ（Tractability）と表現力の高さ（Flexibility）を両立しています。特に画像生成においては、GANを凌駕する非常に高品質で多様なサンプルを生成できます。学習も比較的安定しています。\n欠点: 元々はサンプリング（生成）に非常に時間がかかるという問題がありましたが、DDIM、LDM、蒸留技術、Consistency Modelsなどの登場により大幅に改善され、実用性が大きく向上しました。それでも、応用によってはまだGANなど他の手法に比べて速度面で課題が残る場合もあります。\n\nClassifier-Free Guidance、Latent Diffusion、Transformerアーキテクチャの採用、ControlNetのような制御技術など、数々の技術革新により、拡散モデルはテキストからの画像生成、画像編集、動画生成など、多くの応用分野で最先端の成果を上げており、現在の生成AIの発展を牽引する重要な技術となっています。"
  },
  {
    "objectID": "posts/diffusion-basics/index.html#参考文献",
    "href": "posts/diffusion-basics/index.html#参考文献",
    "title": "拡散モデル入門：基本概念から応用まで",
    "section": "参考文献",
    "text": "参考文献\n\nWeng, Lilian. (Jul 2021). What are diffusion models? Lil’Log. https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\nHo, Jonathan, Ajay Jain, and Pieter Abbeel. “Denoising diffusion probabilistic models.” NeurIPS 2020. (DDPM)\nSong, Jiaming, Chenlin Meng, and Stefano Ermon. “Denoising diffusion implicit models.” ICLR 2021. (DDIM)\nRombach, Robin, et al. “High-resolution image synthesis with latent diffusion models.” CVPR 2022. (Latent Diffusion / Stable Diffusionの基盤)\nNichol, Alex, and Prafulla Dhariwal. “Improved denoising diffusion probabilistic models.” ICML 2021.\nDhariwal, Prafulla, and Alex Nichol. “Diffusion models beat gans on image synthesis.” NeurIPS 2021.\nHo, Jonathan, and Tim Salimans. “Classifier-free diffusion guidance.” NeurIPS 2021 Workshop.\nSalimans, Tim, and Jonathan Ho. “Progressive distillation for fast sampling of diffusion models.” ICLR 2022.\nSong, Yang, et al. “Consistency models.” ICML 2023.\nHo, Jonathan, et al. “Cascaded diffusion models for high fidelity image generation.” JMLR 2022.\nRamesh, Aditya, et al. “Hierarchical text-conditional image generation with clip latents.” arXiv 2022. (unCLIP / DALL-E 2)\nSaharia, Chitwan, et al. “Photorealistic text-to-image diffusion models with deep language understanding.” NeurIPS 2022. (Imagen)\nPeebles, William, and Saining Xie. “Scalable diffusion models with transformers.” ICCV 2023. (DiT)\nZhang, Lvmin, and Maneesh Agrawala. “Adding conditional control to text-to-image diffusion models.” ICCV 2023. (ControlNet)"
  }
]