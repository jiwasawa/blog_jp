---
title: "John Schulmanの「解像度」：OpenAI創設者が語る強化学習の現在地と、Thinking Machinesの野心"
description: "OpenAI共同創業者John Schulmanが明かす、初期の「正しすぎる失敗」や強化学習の不都合な真実、そしてAGIへの冷徹な視点から、新天地Thinking Machinesで彼が仕掛ける次世代のAI開発戦略までを分析する"
author: "Junichiro Iwasawa"
date: "2025-12-21"
categories: [LLM, AI]
image: https://picsum.photos/id/134/200
---

John SchulmanがOpenAIを去り、Anthropicを経て自らの新天地Thinking Machinesへと居を移してからしばらくが経つ。

ChatGPTのリードアーキテクトであり、PPO（Proximal Policy Optimization）の生みの親でもある彼が、CursorのMichael Truellとのやりとりの中でOpenAI初期の狂乱と、現在のReinforcement Learning（RL）における「不都合な真実」を淡々と、しかし極めて高い解像度で語っている。

今回のブログでは、[彼のインタビュー](https://youtu.be/29BYxvvF1iM?si=avB1uybraWM3DxF_)から見えてくるAI開発の「泥臭い真実」と、彼が次に仕掛けるTinkerの勝算について、独自の視点で分析してみたい。

## 「Universe」という正しすぎる失敗

OpenAIの初期がいかに「Rag-tag（寄せ集め）」な集団であったか。今や時価総額が国家予算レベルに達しようとしている巨人の、かつての姿をSchulmanは懐かしむように語る。

当時は現代のような「スケーリング則への狂信」はなく、アカデミアに近い自由な雰囲気が漂っていたという。そこで生まれた大きな挫折の一つが、Universeプロジェクトだ。

Universeは、あらゆるコンピューター上のタスク（ビデオゲームやウェブナビゲーション）をRLの環境として統合し、汎用エージェントを育てようという壮大な試みだった。Schulmanはこれを「深く正しいアイデア（Deeply correct idea）だったが、10年早すぎた」と評している。

当時のインフラではシステムの複雑さに耐えきれず、モデルの汎化性能も追いつかなかった。結局、OpenAIはこの広すぎる野心を一旦捨て、Dota 2というスコープを絞ったプロジェクトで「大規模なエンジニアリング」の筋肉を鍛えることになる。

この「正しいが早すぎるアイデア」を捨てる勇気こそが、後のOpenAIを成功に導いた。ロボティクス部門の閉鎖も同様だ。それらは「デッドエンド」だったかもしれないが、そこで培われた大規模学習のノウハウが、後のGPTシリーズの血肉となっている。

## なぜ今、Value Functionは「オワコン」なのか

インタビューの中で、筆者が最も興味を惹かれたのが、強化学習におけるValue Function（価値関数）の現状に関するSchulmanの分析だ。

伝統的なRLにおいて、Value FunctionはVariance Reduction（分散低減）のために不可欠な要素だった。しかし、現在のLLMに対するRL（特にRLHFや検証可能な報酬を用いた学習）において、Value Functionはそれほど大きな役割を果たしていないという。

> **John Schulman:** 「なぜ価値関数が現在のタスクでそれほど役立たないのか、その理由ははっきりとは分かりません。おそらく、分散低減の効果が期待したほど得られていないのでしょう。ただ、いつかValue Functionが返り咲く時は来ると予想しています。」

この発言は非常に示唆に富んでいる。現在のLLMの学習が、ある種「短いタイムホライズン（時間軸）」の最適化に終始している可能性を示唆しているからだ。数万トークンをサンプリングする今のLLMは一見「長い時間軸」を扱っているように見えるが、RLの構造としてはまだ深みに欠けているのかもしれない。

## AGIタイムラインに潜む「エンジニアのバイアス」

Schulmanは、巷で囁かれるAGI（人工汎用知能）のタイムラインに対しても、極めて現実的な、あるいは冷ややかな視点を持っている。

彼は、エンジニアや研究者がプロジェクトの完了時間を常に見誤る「計画の錯誤」に触れ、世の中のAGI予測には「3倍の係数（3x factor）」をかけるべきだと示唆している。自動運転車（Self-driving cars）が「あと数年」と言われ続けてから久しいのと同様に、AGIもまた、最後の数パーセントの精度を埋めるために膨大な時間がかかるという見立てだ。

一方で、AIがAI自身の開発を加速させる「ポジティブ・フィードバック・ループ」の存在も認めており、直感に反するスピードで進化が起こる可能性についても留保を置いている。この「慎重な楽観主義」こそが、狂騒のAI業界で彼が信頼され続ける理由だろう。

## Thinking Machinesと「Tinker」の狙い

Schulmanが現在取り組んでいるThinking Machinesの旗艦プロダクトがTinkerだ。

これは、低レイヤーのFine-tuning APIであり、GPUや分散システムの複雑さを意識することなく、独自のPost-trainingアルゴリズムを実装できるプラットフォームだという。

OpenAIやAnthropicが、高度にパッケージ化された「推論API」を提供する「プラットフォームの巨人」へと進化する中で、Schulmanはあえて「モデルの裏側を弄りたい」という玄人志向の開発者、あるいは研究者たちのニーズに賭けている。

> **John Schulman:** 「Tinkerは、MLの知識があり、細部にこだわりたい人たちのためのものです。GPUボックスを自前で立てる必要なく、Pythonスクリプトを書くだけで大規模なトレーニングが可能になります。」

これは、前述のサンプルブログで指摘されていたOpenAIの「アンチプラットフォーム性（外部開発者の軽視）」に対する、Schulmanなりのアンサーのようにも聞こえる。

## 今でも研究者に必要なのは「コーヒーとノート」

最後に、Schulmanの日常が語られている。意外にも、彼は今でもノートを手に喫茶店へ行き、雑音の中で思考を巡らせることを好むという。

GPT-5 Proを使って文献調査を行い、自分の曖昧なアイデアをモデルに肉付けさせる。一方で、コードの1行1行を完全に把握し、シンプルな実装を保つことの重要性を説く。

AIの進化を最前線でリードしてきた男が、最終的には「コーヒーとノート」という極めてアナログな環境を思考のベースに置いている事実は、技術に溺れがちな我々への警鐘のようにも響く。

Thinking Machinesが次に何を打ち出すのか。Tinkerがどこまで開発者の筋肉を加速させるのか。John Schulmanの第2章は、まだ始まったばかりだ。
