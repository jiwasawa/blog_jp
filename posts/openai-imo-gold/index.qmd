---
title: "AIが数学オリンピックを制覇した日：OpenAIのIMO金メダル獲得と、その先にある「超知能」への道筋"
description: "OpenAIによる国際数学オリンピック金メダル獲得という歴史的快挙を題材に、AIが到達した新たな思考レベルと、Googleとの競争が加速させる「超知能」への道筋を分析する。"
author: "Junichiro Iwasawa"
date: "2025-08-01"
categories: [LLM, AI, Podcast]
image: https://picsum.photos/id/107/200
---

OpenAIが、ついにAI研究における長年の悲願であった国際数学オリンピック（IMO）での金メダル性能を達成したと発表した。Sam Altmanが数年前から目標として掲げていたこのマイルストーンは、単なる計算能力の向上ではなく、人間のトップレベルの創造性やひらめきが求められる領域へのAIの進出を意味する。

驚くべきことに、この歴史的快挙を成し遂げたコアチームは、Alexander Wei氏、Sheryl Hsu氏、Noam Brown氏というわずか3人の研究者による、ここ数ヶ月の「スプリント」だったという。多くの人が「2025年中の達成は無理だろう」と懐疑的だった中、彼らは一体どのようにしてこの偉業を成し遂げたのか。[7/30に公開されたSequoia Capitalのインタビュー](https://www.youtube.com/watch?v=EEIPtofVe2Q)からそのアプローチと舞台裏に迫る。

## 「IMO金メダル」の何がそんなに凄いのか？

まず、この成果の画期的な点を整理しよう。

* **人間のトップ頭脳と同じ土俵での勝負：** AIは、人間の参加者と全く同じルール（4.5時間の試験を2回、ツールやインターネットは使用不可）で、2025年のIMO問題に挑戦した。
* **圧倒的なスコア：** 6問中5問を正答し、合計42点満点中35点を獲得。このスコアは、人間の参加者であれば余裕で金メダルに相当する。採点は3名の元IMOメダリストが担当し、満場一致で正答と認められた。
* **思考の持続時間が桁違い：** これまでの数学ベンチマークは、トップレベルの人間でも数秒〜数分で解けるものが大半だった。しかしIMOの問題は、平均して1問あたり100分以上の持続的かつ創造的な思考を必要とする。AIの推論能力が、この時間軸に到達したことの意義は計り知れない。

インタビューでNoam Brown氏が語ったように、AIの数学能力の進歩は凄まじい。数年前は小学生レベルの算数で苦戦していたモデルが、GSM8K（小学校レベル）、MATHベンチマーク（高校レベル）、AIME（トップ高校レベル）、そしてついにIMOという最高峰の壁を、わずか数年で次々と突破してしまったのだ。この速度感こそが、今回のニュースの核心である。

## 汎用技術という「異端」のアプローチ

今回のIMOモデルがさらに興味深いのは、その開発アプローチだ。チェスのDeep Blueや囲碁のAlphaGoのように、特定のタスクに特化した「特化型AI」を開発したわけではない。チームが優先したのは、（以前Alexander Wei氏とNoam Brown氏が開発に携わったCICEROと同じく）あらゆるタスクに応用可能な「汎用技術」だった。

具体的には、以下の2点が挙げられる。

1.  **検証困難なタスクに対する強化学習：** IMOの証明問題には、ゲームのように明確で検証しやすい報酬（勝ち/負け）が存在しない。AIが出力した数ページにわたる証明が「本当に正しいか」を判断するのは非常に難しい。チームは、このような「検証困難なタスク（Hard-to-verify problem）」をうまく扱うための、新しい強化学習の地平を切り拓いた。
2.  **自然言語による推論へのこだわり：** 数学の証明には「Lean」のような形式的検証言語を用いるアプローチもある。しかしチームは、より汎用性の高い**自然言語**による証明にこだわった。Alex Wei氏が言うように、「世界の多くの問題は、形式化できるものよりも、非形式的な推論でアプローチできるものの方が多い」からだ。

このアプローチの結果、AIが出力する証明は「お世辞にも読みやすいとは言えないひどい（atrociousな）もの」になったという。しかし、その論理は完璧であり、AIの思考の「生」の状態を我々に見せつけている。ちなみに、この証明をChatGPTに食わせて「もっと読みやすく書き直して」と頼むこともできたが、チームは透明性を重視し、あえて生の出力のまま公開したそうだ。

## 解けなかった「第6問」とAIの自己認識

このモデルは5問を解いたが、伝統的に最難関とされる第6問（この年は組合せ論の問題）には手も足も出なかった。大量の計算リソースを投入したにもかかわらず、最終的な出力は「解答なし（no answer）」だった。

一見すると残念な結果だが、チームはこの結果にこそ希望を見出している。なぜなら、これはAIが**自らの能力の限界を認識している**ことを示唆しているからだ。

数年前のモデルであれば、解けない問題に対してもっともらしい嘘の解答を平気で生成（ハルシネーション）していただろう。しかし今回のモデルは、膨大な思考の末に「これは無理だ」と白旗を上げた。インタビュー中に明かされた、モデルが思考の途中で「難しそうだ（seems hard）」と呟いていたというエピソードは、AIが新たなレベルの自己認識を獲得しつつあることを示す面白い証拠と言える。

## 次の戦場はどこか？

IMOを制覇した今、AIの数学能力における次のフロンティアはどこになるのか。チームは「コンペ数学の時代は終わった」と断言する。次の目標は、数ヶ月、数年単位の思考を必要とする「未解決の数学研究」だ。IMOが1.5時間の思考だとすれば、研究レベルの数学は1500時間以上の思考を要する。まだ1000倍の隔たりがあるが、この数年の進歩のペースを考えれば、それも決して夢物語ではないだろう。

そして、この物語はOpenAIだけで終わらない。奇しくも同じ2025年のIMOで、Googleのモデル（8/1に[Gemini 2.5 Deep Thinkとして公開](https://blog.google/products/gemini/gemini-2-5-deep-think/)）も同様に金メダル性能に到達していたことが明らかになった。

AIによる科学的発見の時代は、我々の想像を遥かに超えるスピードで近づいている。一つの山頂が見えたと思ったら、そこは次の巨大な山脈の麓に過ぎなかった。AI開発のレースは、新たなステージに突入したのだ。
