---
title: "SETA: 端末操作エージェントのためのスケーラブルな環境構築とLLM能力の拡張"
description: "SETAプロジェクトは、LLMがターミナル操作エージェントとしてSOTA性能を達成するための高度なツールキット設計とスケーラブルなRL学習パイプラインを提案し、LLMの応用可能性を大きく広げる。"
author: "Junichiro Iwasawa"
date: "2026-01-11"
categories: [LLM, AI, Podcast]
image: https://picsum.photos/id/146/200
---

近年、AI技術の進化は目覚ましく、Large Language Model (LLM) は単なるテキスト生成ツールから、複雑なタスクを自律的に遂行する「エージェント」へと変貌を遂げつつある。その中でも、開発者やシステム管理者にとって最も強力かつ複雑なインターフェースである「ターミナル（コマンドライン）」をLLMに操作させる試みは、大きな課題であり続けてきた。

本記事では、この課題に対してState-of-the-Art (SOTA) の性能を達成したプロジェクト「[SETA (Scaling Environments for Terminal Agents)](https://x.com/camelaiorg/status/2009675880503599571)」について、その技術的背景、アーキテクチャ、および学習パイプラインの詳細を解説する。

## SETAとは何か？

SETAは、CAMELフレームワーク上に構築された、ターミナル操作エージェントのための包括的な環境およびツールキットである。従来のLLMエージェントは、複雑な環境下での計画能力や、ステートフル（状態を持つ）なプロセスとの相互作用において限界を抱えていた。

SETAはこの問題を解決するために、以下の3つの主要な柱を掲げている。

1.  **高度なツールキット設計:** 安全かつ柔軟なコマンド実行とメモリ管理を実現するAPIの提供。
2.  **SOTAエージェントの実現:** Claude Sonnet 4.5やGPT-4.1を用いたエージェントによる、ベンチマーク（Terminal-Bench）での最高性能の達成。
3.  **スケーラブルなRL学習パイプライン:** 合成環境生成によるデータセット構築と、それを用いたReinforcement Learning (RL) によるモデルのファインチューニング。

## アーキテクチャ：エージェントを支える2つのツールキット

ターミナル操作は単発のコマンド実行で完結するものではない。長時間実行されるジョブの管理、対話的なプログラムへの入力、エラーからの回復など、多岐にわたる制御が求められる。SETAはこれを実現するために、特化した2つのツールキットを導入している。

### 1. Terminal Toolkit：実行制御とプロセス間通信

単純に `os.system()` を叩かせるだけでは、複雑なワークフローは実現できない。Terminal Toolkitは、エージェントに対し、以下のような高レベルなプリミティブを提供する。

*   **制御されたコマンド実行:**
    *   `shell_exec`: コマンドをブロッキング（完了を待つ）またはノンブロッキング（バックグラウンド実行）モードで実行する。これにより、サーバーの起動や長時間のビルドプロセスを裏で走らせながら、別の作業を行うことが可能になる。
    *   `shell_write_content_to_file`: 複雑な `echo` コマンドやエスケープシーケンスに頼ることなく、安全にファイルを作成・編集する。

*   **実行中プロセスとの対話:**
    *   `shell_write_to_process`: 実行中のプロセス（例：REPL、デバッガ、インストーラーのプロンプト）に対して入力を送信する。例えば、テキストアドベンチャーゲーム（Zorkなど）のような対話型アプリケーションの操作も可能にする。
    *   `shell_view` / `shell_wait`: バックグラウンドプロセスの出力を確認したり、特定のイベントを待機したりする。
    *   `shell_kill_process`: 不要になったり暴走したりしたプロセスを確実に終了させる。

### 2. Note-Taking Toolkit：長期的記憶の外部化

複雑なタスク（例：大規模なリファクタリングやデバッグ）では、LLMのコンテキストウィンドウがすぐに埋まってしまう。Note-Taking Toolkitは、エージェントに「構造化された永続メモリ」を提供することでこの問題を解決する。

*   `create_note`, `append_note`, `read_note`: 調査結果、計画、現在直面しているエラーなどを記録し、必要に応じて参照する。

これにより、エージェントは「今何をしようとしていたか」を見失うことなく、マルチステップの推論と実行を一貫して行うことができる。

## パフォーマンス分析：Terminal-Benchにおける成果

SETAの研究チームは、これらのツールキットを用いて構築されたエージェントの性能を詳細に分析している。

### Claude Sonnet 4.5の躍進

Terminal-Bench 2.0において、Claude Sonnet 4.5を搭載したエージェントは**46.5%の正解率**を記録し、SOTAを達成した。特に以下の領域で高い能力を示している。

*   **Git操作 (80%):** ブランチ管理や競合解決など。
*   **DevOps (83%):** サーバー設定やログ管理。
*   **セキュリティ分析 (75%):** コードの脆弱性修正など。

成功したタスクにおける平均ツール呼び出し回数は79.8回であったのに対し、失敗したタスクでは128.8回に達しており、失敗時には非効率なループに陥る傾向が見られた。

### 課題：ドメイン知識の欠如

一方で、専門性が極めて高い領域では苦戦を強いられている。

*   **暗号技術 (Cryptography):** 特殊なアルゴリズムの実装や解読。
*   **低レベルコンパイル:** 特殊なアーキテクチャ向けのビルド。
*   **高度なMLインフラ:** 分散学習の設定など。

これらは、LLMの学習データに含まれる一般的な知識分布（Out-of-Distribution）の外側にある知識を要求するためである。これに対処するため、SETAチームは外部知識へアクセスするための**Browser Toolkit**の統合を計画している。

## 合成環境生成とRLによる能力拡張

SETAの最も技術的に興味深い貢献の一つは、Reinforcement Learning (RL) のための合成データ生成パイプラインである。高品質なターミナル操作データは収集が困難であるため、彼らは以下のアプローチを採用した。

### 1. データ生成パイプライン

1.  **Idea Generation Agent:** シードとなるQ&Aデータから、多様な技術要素（言語、ツール、問題タイプ）を含むタスクの仕様書を作成する。
2.  **Datapoint Creation Agent:** 仕様書に基づき、実際に実行可能なTerminal-Bench形式のタスク（Docker環境、解答スクリプト、検証スクリプト）を生成する。
3.  **Validation:** 生成されたタスクが正しく動作するかを、Oracleエージェントを用いて検証する。

### 2. RLファインチューニングの効果

このパイプラインによって生成された400の合成タスク（そのうち260タスクを学習に使用）を用いて、オープンソースモデルである**Qwen3-8B**のRLファインチューニングが行われた。

結果として、RL適用後のモデルはベースラインと比較して以下の改善を示した。

*   **未知のタスクへの適応:** 学習データに含まれない新しいタスクの解決能力が向上。
*   **ユニットテスト通過率:** 実行過程での中間チェック（ユニットテスト）の通過率が平均20.2%向上。
*   **エラー回復:** 明示的なエラーメッセージや実行結果を受け取り、複数ステップにわたって修正を試みる粘り強さが獲得された。

## 結論と展望

SETAは、LLMが単なる「コード生成器」を超え、実際の計算環境で自律的に動作する「システムオペレーター」へと進化するための重要なステップを示した。特に、制御可能なTerminal Toolkitの設計と、RLを用いた合成環境でのトレーニング手法は、今後のエージェント開発における標準的なアプローチとなる可能性がある。

今後はBrowser Toolkitによる外部知識の補完や、より大規模な合成データセットによる学習が進むことで、バイオインフォマティクスや低レイヤープログラミングといった専門領域においても、人間のエンジニアを強力に支援するエージェントの登場が期待される。

---
**参考文献:**
*   CAMEL-AI.org. "[SETA: Scaling Environments for Terminal Agents](https://x.com/camelaiorg/status/2009675880503599571)".
