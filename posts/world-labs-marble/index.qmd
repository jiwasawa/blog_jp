---
title: "ポストLLM時代の「空間知能」：World Labsが描く脱・言語偏重の未来"
description: "World LabsのFei-Fei LiとJustin Johnsonの対談から、LLMの言語偏重から脱却し、物理世界を理解する「空間知能」へと進化するAIの未来と、その先駆者たるMarbleについて解説する。"
author: "Junichiro Iwasawa"
date: "2025-12-09"
categories: [AI, Latent Space Podcast]
image: https://picsum.photos/id/125/200
---

Large Language Model (LLM) の熱狂が冷めやらぬ中、シリコンバレーの賢人たちの視線はすでに「次」へと向いている。テキストや2次元の画像生成を超え、物理世界を真に理解し、生成し、そして操作できるAI――それが「Spatial Intelligence（空間知能）」だ。

[先日公開されたLatent Space podcastのエピソード](https://youtu.be/60iW8FZ7MJU?si=gtyhR3ahggNB7Sq5)では、この分野のパイオニアであるWorld Labsの創業者チーム、Fei-Fei Li氏とJustin Johnson氏が登場し、彼らが描く未来の青写真と、その第一歩となるプロダクト「Marble」について語った。彼らの議論は、単なる新製品の宣伝にとどまらず、AIがどのようにして「言葉」の限界を超え、物理的な実在感を伴う「世界」を構築するかという、極めて本質的な問いに満ちていた。

LLM全盛の今、なぜ彼らはあえて「空間」に賭けるのか。そして、Justin Johnson氏が熱っぽく語った「Gaussian Splats」という技術的アプローチは何を示唆しているのか。今回はWorld Labsの挑戦を通じて、生成AIの次なるパラダイムを読み解く。

## ImageNetからSpatial Intelligenceへ：計算資源とデータの大いなる旅

Fei-Fei Li氏といえば、現在のDeep Learningブームの火付け役とも言えるImageNetの生みの親である。彼女のキャリアは、AIに「視覚」を与えること、つまりコンピュータビジョンの進化と共にあった。ポッドキャストの中で彼女は、Deep Learningの歴史を「Scaling up compute（計算能力の拡大）」の歴史であると総括した。AlexNetが登場した2012年、GPUによる計算資源の爆発的な増加がブレイクスルーを生んだように、現在もまた、より大規模なモデルとデータが次なる知能への鍵を握っている。

しかし、World Labsが見据えるのは、単にパラメータ数の多いLLMではない。彼らが提唱する「Spatial Intelligence」とは、AIが3次元空間の中で推論し、移動し、相互作用する能力のことだ。

考えてみてほしい。人間がマグカップを手に取る時、私たちはカップの形状、取っ手の位置、そこまでの距離、そして自分の手の動きを、言語化することなく瞬時に、かつ空間的に理解している。LLMはシェイクスピアのような文章を書けるかもしれないが、物理法則に従って積み木を崩さないように動かすという、幼児でもできるタスクには依然として苦戦する。これは、LLMが本質的にシーケンシャルなデータ（単語の列）を処理するものであり、深遠な空間的理解を欠いているからに他ならない。

## World Modelの構成要素：なぜGaussian Splatsなのか？

今回の対談で最も技術的な深みを感じさせたのが、Justin Johnson氏によるモデリング手法に関する議論だ。とりわけ、World Labsのプロダクト「Marble」が採用している「Gaussian Splats」への言及は、3D生成AIの未来を占う上で非常に示唆に富んでいる。

従来の3Dグラフィックスでは、ポリゴンメッシュやボクセルが標準的な表現手法だった。しかし、生成モデルにおいて「世界」を表現するための最小単位（Atomic Unit）は何であるべきか？ Justin氏は、現在の最適解としてGaussian Splatsを挙げている。

Gaussian Splatsは、空間上の位置、色、不透明度、そして方向を持った無数の「楕円体（スプラット）」の集合としてシーンを表現する。これが画期的なのは、そのレンダリング効率の高さと、微分可能性（Differentiable）にある。つまり、ニューラルネットワークの学習プロセスに3D表現を直接組み込み、勾配降下法で最適化できるのだ。

Justin氏の洞察で特に興味深かったのは、「Transformerは実はシーケンスモデルではなく、集合（Set）のモデルである」という指摘だ。通常、LLMではPositional Embeddingによって無理やり順序を与えているが、Transformerのアーキテクチャ自体は本来、順序のない要素の集まり（Set）を処理するのに向いている。そして、Gaussian Splatsもまた、順序を持たない粒子の集合体である。この「Set of Tokens」と「Set of Splats」の親和性こそが、World Labsが目指すスケーラブルなWorld Modelの根幹を成している可能性がある。

従来のビデオ生成モデル（例えばSoraなど）が、あくまで2次元のピクセルをフレームごとに予測しているのに対し、Marbleはネイティブな3D表現（Splats）を生成する。これにより、生成された世界の中を自由にカメラ移動したり、オブジェクトを配置換えしたりといった「インタラクション」が可能になる。これは、単なる動画生成とは次元の異なる体験だ。

## Marble：生成された世界を「編集」する

World Labsが発表した「Marble」は、テキストや画像を入力として3D世界を生成するGenerative World Modelだ。しかし、その真価は「生成」よりも「編集と相互作用」にある。

デモで示されたように、ユーザーは生成されたシーンに対し、「このテーブルを削除して」「照明を変えて」「視点を変えて」といった指示を出し、リアルタイムにその結果を確認できる。これは、従来のVFXやゲーム制作のパイプラインを根底から覆す可能性を秘めている。

Justin氏が指摘するように、Soraのような動画生成モデルでは「カメラを北に63度パンして」といった正確な制御は極めて難しい。なぜなら、モデルは「北」や「63度」という空間的な概念を、ピクセルの並びとしてあやふやにしか理解していないからだ。対して、3D表現を内在するMarbleであれば、カメラワークやオブジェクトの配置を数学的に正確に制御できる。

これはクリエイターにとって強力なツールとなるだけでなく、さらにその先にある「Robotics」への布石でもある。

## 仮想から具象へ：データ欠乏問題への処方箋

Fei-Fei Li氏が長年指摘してきた課題の一つに、ロボティクスにおける「Data Starvation（データ飢餓）」がある。インターネット上にはテキストや画像データは溢れているが、ロボットが物理世界で学習するための「物理法則に基づいたインタラクションデータ」は圧倒的に不足している。

MarbleのようなGenerative World Modelは、この問題を解決する「Synthetic Data（合成データ）」の供給源になり得る。シミュレーションの中で無限に多様な環境を生成し、そこでロボット（Embodied AI）をトレーニングさせる。Fei-Fei氏は、この仮想空間での知能の育成が、やがて物理世界で動作するロボットへと転移（Transfer）していく未来を描いている。

## 言語は必要か？：Multimodal AIの行方

議論の終盤、AIにおける「言語」の役割についての哲学的な問いが投げかけられた。「F=ma」のような物理法則を理解するのに、言語による形式化は不可欠なのか、それとも純粋な観察と経験（Spatial Intelligence）だけで到達できるのか。

Fei-Fei氏のスタンスは明確だ。空間知能と言語知能は対立するものではなく、補完的なものである。人間は進化の過程で、まず空間的な知能を獲得し、その上に言語という抽象化レイヤーを築き上げた。LLMはいきなり抽象化の頂点（言語）に飛びついてしまったが、World Labsのアプローチは、その土台となる空間的・身体的な理解をAIに取り戻そうとする試みとも言える。

Dario Amodeiの言う「データセンターいっぱいのEinstein」を作るのも良いが、コップの水をこぼさずに運べるAIを作るには、Einsteinの頭脳だけでなく、物理世界への深い洞察が必要だ。World Labsの挑戦は、AIが「脳」だけでなく「身体性」を獲得するための、重要なミッシングリンクを埋めるものになるだろう。

彼らの旅はまだ始まったばかりだ。しかし、Gaussian Splatsという筆で描かれるその世界は、スクリーンの中のピクセルを超え、私たちの現実へと確実に近づいている。
