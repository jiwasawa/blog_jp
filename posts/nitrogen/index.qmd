---
title: "NitroGen：汎用ゲーミングエージェントのための基盤モデル"
description: "40,000時間以上のゲームプレイ動画から学習した行動ラベル付きデータとTransformerベースの基盤モデルにより、未知のゲーム環境でも適応可能な汎用ゲーミングエージェントの実現を目指すNVIDIAのNitroGenを紹介する"
author: "Junichiro Iwasawa"
date: "2025-12-22"
categories: [LLM, AI]
image: https://picsum.photos/id/135/200
---

近年、大規模言語モデル（LLM）やVision Foundation Modelの台頭により、AIはテキストや画像の理解において飛躍的な進化を遂げた。しかし、多様な環境下で自律的に行動し、タスクを遂行する「Embodied AI（身体性AI）」、特に汎用的なエージェントの構築は、依然としてAI研究における聖杯（Holy Grail）であり続けている。

その最大の障壁となっていたのが、**「行動ラベル付きデータ（Labeled Action Data）」の圧倒的な不足**である。インターネット上にはテキストや画像は溢れているが、"ある状況下でどのような行動をとるべきか"を示したデータは極めて稀少である。

NVIDIA等の研究チームが発表した **[NitroGen](https://nitrogen.minedojo.org)** は、この課題に対して「規模」と「基盤モデル」のアプローチで挑んだ意欲的な研究である。本稿では、1000以上のゲーム、4万時間に及ぶプレイデータから学習されたこの基盤モデルについて、その技術的革新性、アーキテクチャ、そして汎用エージェント研究への示唆を解説する。

## NitroGenとは何か：Embodied AIへの新たなアプローチ

NitroGenは、未知のゲーム環境においても適応可能な「汎用ゲーミングエージェント（Generalist Gaming Agent）」を目指したオープンな基盤モデルである。

従来、ゲームAIといえば強化学習（Reinforcement Learning: RL）が主流であった（AlphaGoやOpenAI Fiveなど）。しかし、RLは特定の環境（特定のゲーム）に特化しており、新たなゲームに対応するにはゼロからの学習が必要となる。また、Behavior Cloning（BC: 行動模倣）を用いる場合でも、人間によるデモンストレーションデータの収集コストがボトルネックとなり、対象はMinecraftなどの一部のゲームに限定されていた。

NitroGenは、以下の3つのコアコンポーネントによってこれらの制約を突破しようとしている。

1.  **インターネットスケールのビデオ-アクション・データセット:** YouTube等の公開動画から自動的に「行動（コントローラ入力）」を抽出・生成。
2.  **マルチゲーム評価ベンチマーク:** あらゆるゲームをGymnasium APIでラップする「Universal Simulator」。
3.  **大規模Behavior Cloning事前学習:** Vision TransformerとDiffusion Transformerを組み合わせたモデルによる、スケーラブルな学習。

これは、Richard Suttonが提唱した「The Bitter Lesson（苦い教訓）」—すなわち、手作業による設計よりも、計算量とデータ量によるスケーリングが長期的には勝利する—を、Embodied AIの領域で実践したものと言える。

### 1. データの錬金術：Input Overlayからの行動抽出

NitroGenの最大の貢献は、データの収集方法にある。研究チームは、ゲーム実況動画などでプレイヤーの手元操作を画面上に表示する「[Input Overlay](https://github.com/univrsal/input-overlay)」に着目した。

通常、ゲームプレイ動画には映像（ピクセル）しか含まれておらず、プレイヤーがどのボタンを押したかという正解ラベルは存在しない。NitroGenは以下のパイプラインにより、既存の動画から高品質な学習データを生成（マイニング）している。

1.  **テンプレートマッチング:** SIFTやXFeatといった特徴点抽出アルゴリズムを用い、動画内からゲームパッドのオーバーレイ表示を検出・特定する。
2.  **セグメンテーションによる行動解析:** 特定された領域に対し、学習済みのセグメンテーションモデル（SegFormer）を適用。ジョイスティックの位置（アナログ値）やボタンのOn/Off（デジタル値）をフレーム単位で高精度に抽出する。
3.  **品質フィルタリング:** 抽出されたアクションの密度や整合性をチェックし、学習に適したクリップのみを選別する。

このプロセスにより、**1,000以上のゲームタイトル**にまたがる**40,000時間**という、前例のない規模の行動ラベル付きデータセットが構築された。これにより、RPG、プラットフォーマー、レース、FPSなど、多種多様な物理法則と操作体系を持つ「マルチバース」な環境での学習が可能となった。

### 2. 基盤モデルのアーキテクチャ：Vision & Diffusion

NitroGenのモデルアーキテクチャは、ロボティクス向けの基盤モデル「[GR00T](https://arxiv.org/abs/2503.14734)」の設計思想を受け継いでいる。基本的には、視覚情報を処理するエンコーダと、行動を生成するデコーダから成る。

*   **Vision Encoder:** 画像入力（$256 \times 256$）を処理するために、[SigLIP](https://arxiv.org/abs/2502.14786)を採用。
*   **Action Generator:** 行動生成部には **Diffusion Transformer (DiT)** を採用し、**[Flow Matching](https://arxiv.org/abs/2210.02747)** アルゴリズムによって学習を行う。

#### Flow Matchingによる行動生成

NitroGenでは、従来の単純な回帰問題としてのBehavior Cloningではなく、生成モデルのアプローチを採用している。具体的には、条件付きFlow Matchingを用い、観測画像 $o$ を条件として、未来の行動チャンク（一連のアクションシーケンス） $a$ を生成する。

学習目的関数は、条件付きベクトル場（Conditional Vector Field）の回帰として定式化される。時刻 $t \in [0, 1]$、ガウスノイズ $\epsilon \sim \mathcal{N}(0, I)$ としたとき、損失関数は以下のように表現される。

$$ \mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t, a, \epsilon} \left[ \| v_\theta(\psi(o), x_t, t) - (a - \epsilon) \|^2 \right] $$

ここで、$x_t = (1-t)\epsilon + t a$ はノイズと正解アクションの補間であり、$v_\theta$ はモデルが予測するベクトル場（Velocity Field）である。推論時には、ノイズからスタートし、常微分方程式（ODE）ソルバーを用いて決定論的、あるいは確率的にアクションを生成する。
また、単一のステップではなく**16ステップ分の行動チャンク**を一度に生成することで、時間的な整合性（Temporal Consistency）を保ち、高速な動作に対応している。

### 3. 評価と成果：転移学習の威力

評価のために、任意のWindowsゲーム実行バイナリをラップし、強化学習の標準インターフェースである[Gymnasium API](https://arxiv.org/abs/2407.17032)として扱えるようにする「Universal Simulator」が開発された。これにより、システムクロックを制御し、フレーム単位での厳密な評価が可能となっている。

10の未見の商用ゲーム（30タスク）で行われた評価実験では、以下の点が明らかになった。

*   **ゼロショット能力:** 完全に未知のゲームであっても、事前学習済みモデルはある程度の操作が可能である。
*   **ファインチューニングの効率化:** 最も重要な成果は、**「事前学習済みモデルを初期値として、新しいゲームで少量のデータを用いてファインチューニングした場合」**の性能向上である。スクラッチから学習する場合と比較し、タスク成功率において最大 **52%の相対的改善** が確認された。

これは、NitroGenが特定のゲームの攻略法を丸暗記したのではなく、"ゲームにおける一般的な身体操作（カメラ操作、移動、ジャンプのタイミングなど）" という汎用的なスキルを獲得していることを示唆している。

## 議論：System 1 AIと今後の課題

### System 1 vs System 2
NVIDIAの研究者であるJim Fan氏は、NitroGenを**「System 1（直感的な速い思考）」**のエージェントであると位置づけている。
人間がゲームをプレイする際、瞬時の反射神経やコントローラ操作（System 1）と、長期的な戦略立案やパズル解法（System 2）を使い分けている。現在のNitroGenは、視覚入力から即座に行動を生成する「ゲーマーの直感（Motor Control）」に特化しており、長期的な計画能力や、自然言語による指示従属能力（Instruction Following）は持っていない。これらは今後の課題であり、LLMとの統合や階層的な強化学習が必要となる領域である。

### Behavior Cloning (BC) の限界
また、NitroGenはBehavior Cloning（模倣学習）に基づいているため、原理的な限界も存在する。
BCにおける最大の課題は **「分布シフト（Distribution Shift）」** である。学習データ（熟練者のプレイ）にある状態分布から、エージェントが少しでも外れる（ミスをする）と、見たことのない状態に陥り、そこから復帰できずにエラーが累積していく問題である。
NitroGenは、インターネット上の多様（かつノイズの多い）データを大量に学習することで、分布のカバー範囲を広げ、ロバスト性を高めているが、本質的なリカバリー能力を獲得するには、オンラインでの相互作用や強化学習による自己改善（Trial and Error）の導入が待たれる。

## まとめ

NitroGenは、Embodied AIにおける「GPT-3モーメント」に向けた重要な一歩である。
40,000時間という圧倒的なデータ規模と、それを処理するTransformerベースの基盤モデルにより、ゲームという仮想空間における「身体性」の獲得に成功した。

NitroGenが示した「インターネット動画から行動を学習する」というパラダイムは、今後、物理シミュレーションや実世界ロボティクス（Physical AI）へと応用範囲を広げ、真に汎用的なエージェントの実現を加速させるだろう。

## 参考文献

1. Magne, L., Awadalla, A., Wang, G., et al. (2025). *NitroGen: An Open Foundation Model for Generalist Gaming Agents*. [PDF](https://nitrogen.minedojo.org/assets/documents/nitrogen.pdf) [Project](https://nitrogen.minedojo.org)
2. Fan, L. (2024). [Twitter/X Post regarding NitroGen release and context].
3. Baker, B., et al. (2022). *Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos*. NeurIPS.
4. Bjorck, J., et al. (2025). *GR00T N1: An Open Foundation Model for Generalist Humanoid Robots*. [arXiv](https://arxiv.org/abs/2503.14734)
5. Lipman, Y., et al. (2023). *Flow Matching for Generative Modeling*. ICLR. [arXiv](https://arxiv.org/abs/2210.02747)
