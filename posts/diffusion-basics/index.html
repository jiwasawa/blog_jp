<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Junichiro Iwasawa">
<meta name="dcterms.date" content="2025-04-17">

<title>拡散モデル入門：基本概念から応用まで – jiwasawa のブログ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8647a4a42273f773479d27c00df3f9ed.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8BXHXPDSCJ"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-8BXHXPDSCJ', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">jiwasawa のブログ</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Junichiro Iwasawa</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/jiwasawa"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/junichiro-iwasawa-875b37130/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jiwasawa"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">拡散モデル入門：基本概念から応用まで</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Diffusion models</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Junichiro Iwasawa </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 17, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>近年、特に画像生成分野で目覚ましい成果を上げている拡散モデル（Diffusion Models）について、基本的な仕組みから応用技術までを解説します。</p>
<section id="拡散モデルとは" class="level2">
<h2 class="anchored" data-anchor-id="拡散モデルとは">拡散モデルとは？</h2>
<p>拡散モデルは、生成モデルの一種です。他の代表的な生成モデルとしてGAN、VAE、Flowベースモデルがありますが、GANは学習の不安定さ、VAEは代理損失への依存、Flowモデルは可逆変換のためのアーキテクチャ制約といった課題がありました。</p>
<p>拡散モデルは、非平衡熱力学に着想を得ており、データの分布を学習するための独自のアプローチを取ります。</p>
<ol type="1">
<li><strong>順方向プロセス（Forward Process / Diffusion Process）：</strong> 元のデータに段階的に微小なランダムノイズを加えていき、最終的には既知の単純な分布（通常は標準正規分布）に変換します。</li>
<li><strong>逆方向プロセス（Reverse Process / Denoising Process）：</strong> 上記の過程を逆向きに辿り、単純なノイズ分布からスタートして、段階的にノイズを除去していくことで元のデータ分布に属する新しいサンプルを生成します。</li>
</ol>
<p>この「ノイズ除去」ステップを学習したニューラルネットワークが、実質的な生成モデルとなります。拡散モデルは、学習プロセスが固定されており、VAEやFlowモデルと異なり、潜在変数が元データと同じ次元を持つという特徴があります。</p>
<section id="順方向プロセスデータをノイズへ" class="level3">
<h3 class="anchored" data-anchor-id="順方向プロセスデータをノイズへ">順方向プロセス：データをノイズへ</h3>
<p>元のデータ <span class="math inline">\(\mathbf{x}_0 \sim q(\mathbf{x})\)</span> から出発し、<span class="math inline">\(T\)</span> ステップかけて徐々にGaussianノイズを加えていくマルコフ連鎖として定義されます。各ステップ <span class="math inline">\(t\)</span> での遷移は次のように定義されます。</p>
<p><span class="math display">\[q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I})\]</span></p>
<p>ここで、<span class="math inline">\(\\{\beta_t \in (0, 1)\\}_{t=1}^T\)</span> は<strong>分散スケジュール</strong>と呼ばれるハイパーパラメータで、各ステップで加えるノイズの大きさを制御します。<span class="math inline">\(\beta_t\)</span> は通常、<span class="math inline">\(t\)</span> が大きくなるにつれて増加するように設定されます（例：linear スケジュール、cosine スケジュール[Nichol &amp; Dhariwal, 2021]）。<span class="math inline">\(\mathbf{I}\)</span> は単位行列です。</p>
<p>全ステップの同時分布は次のようになります。</p>
<p><span class="math display">\[q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})\]</span></p>
<p>このプロセスの重要な特性は、任意のステップ <span class="math inline">\(t\)</span> におけるノイズ付きデータ <span class="math inline">\(\mathbf{x}_t\)</span> を、元のデータ <span class="math inline">\(\mathbf{x}_0\)</span> から閉じた式で直接計算できることです。<span class="math inline">\(\alpha_t = 1 - \beta_t\)</span> および <span class="math inline">\(\bar{\alpha}_t = \prod_{i=1}^t \alpha_i\)</span> と定義すると、<span class="math inline">\(\mathbf{x}_t\)</span> の分布は次のように表せます。</p>
<p><span class="math display">\[q(\mathbf{x}_t \vert \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})\]</span></p>
<p>これは、<span class="math inline">\(\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}\)</span> （ただし <span class="math inline">\(\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</span>）と書くこともできます。つまり、<span class="math inline">\(\mathbf{x}_t\)</span> は、元のデータ <span class="math inline">\(\mathbf{x}_0\)</span> をスケールしたものと、それに加わるノイズ項の和で表されるわけです。<span class="math inline">\(T\)</span> が十分に大きいと、<span class="math inline">\(\bar{\alpha}_T \approx 0\)</span> となり、<span class="math inline">\(\mathbf{x}_T\)</span> は元のデータ <span class="math inline">\(\mathbf{x}_0\)</span> からほぼ独立したGaussianノイズ <span class="math inline">\(\mathcal{N}(\mathbf{0}, \mathbf{I})\)</span> になります。</p>
</section>
<section id="逆方向プロセスノイズからデータへ" class="level3">
<h3 class="anchored" data-anchor-id="逆方向プロセスノイズからデータへ">逆方向プロセス：ノイズからデータへ</h3>
<p>生成プロセスは、この順方向プロセスを逆に辿ります。つまり、まずGaussianノイズ <span class="math inline">\(\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</span> をサンプリングし、そこから <span class="math inline">\(t=T, T-1, \dots, 1\)</span> とステップを遡って <span class="math inline">\(\mathbf{x}_{T-1}, \mathbf{x}_{T-2}, \dots, \mathbf{x}_0\)</span> を逐次的にサンプリングします。</p>
<p>このためには、逆方向の遷移確率 <span class="math inline">\(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\)</span> を知る必要がありますが、これはデータセット全体の情報が必要となるため計算が困難（intractable）です。そこで、この遷移確率をニューラルネットワーク（パラメータ <span class="math inline">\(\theta\)</span> を持つ）で近似します。この近似された遷移確率を <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\)</span> と書きます。</p>
<p>逆方向プロセス全体は次のように表されます。</p>
<p><span class="math display">\[p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod^T_{t=1} p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\]</span></p>
<p>ここで <span class="math inline">\(p(\mathbf{x}_T) = \mathcal{N}(\mathbf{x}_T; \mathbf{0}, \mathbf{I})\)</span> です。各逆方向ステップの遷移 <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\)</span> もガウス分布であると仮定するのが一般的です。</p>
<p><span class="math display">\[p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))\]</span></p>
<p>モデルの目標は、この平均 <span class="math inline">\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)\)</span> と共分散 <span class="math inline">\(\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)\)</span> を学習することです。 共分散 <span class="math inline">\(\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)\)</span> は、しばしば学習せず、<span class="math inline">\(\sigma_t^2 \mathbf{I}\)</span> という形の固定値（またはスケジュールに従う値）が用いられます。<span class="math inline">\(\sigma_t^2\)</span> としては、順方向プロセスの <span class="math inline">\(\beta_t\)</span> や、理論的に導かれる <span class="math inline">\(\tilde{\beta}_t = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t\)</span> が使われます。[Nichol &amp; Dhariwal, 2021] では、<span class="math inline">\(\beta_t\)</span> と <span class="math inline">\(\tilde{\beta}_t\)</span> の間の補間として学習する手法も提案されていますが、不安定になる可能性も指摘されています。</p>
</section>
<section id="学習の目標ノイズを予測する" class="level3">
<h3 class="anchored" data-anchor-id="学習の目標ノイズを予測する">学習の目標：ノイズを予測する</h3>
<p>では、どのようにして <span class="math inline">\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)\)</span> を学習するのでしょうか？ 完全な導出は変分下限（Variational Lower Bound, VLB）の最大化に基づきますが、DDPM [Ho et al., 2020] では、より直感的で効果的な目的関数が用いられています。</p>
<p>その中心的なアイデアは、逆方向ステップの平均 <span class="math inline">\(\boldsymbol{\mu}_\theta\)</span> を直接予測するのではなく、<strong>順方向プロセスでステップ <span class="math inline">\(t\)</span> においてデータ <span class="math inline">\(\mathbf{x}_0\)</span> に加えられたノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> を予測する</strong>ことです。モデルを <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> と書きます。</p>
<p><span class="math inline">\(\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}\)</span> の関係を使うと、逆方向ステップの（真の）平均 <span class="math inline">\(\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0)\)</span> （これは <span class="math inline">\(\mathbf{x}_0\)</span> が既知の場合に計算可能）は、このノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> を使って表現できます。そして、学習する平均 <span class="math inline">\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)\)</span> がこの真の平均に近くなるように、モデル <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> が真のノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> を予測するように学習させます。</p>
<p>具体的には、<span class="math inline">\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)\)</span> は、予測されたノイズ <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> を用いて次のようにパラメータ化されます。</p>
<p><span class="math display">\[\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right)\]</span></p>
<p>この式を見ると、モデル <span class="math inline">\(\boldsymbol{\epsilon}_\theta\)</span> が学習できれば、逆方向ステップの平均 <span class="math inline">\(\boldsymbol{\mu}_\theta\)</span> が決まることがわかります。</p>
<p>そして、DDPMで提案された単純化された学習目的関数（損失関数）は、以下のように、予測ノイズ <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> と、実際に加えられたノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> との間の平均二乗誤差（Mean Squared Error, MSE）を最小化することになります。</p>
<p><span class="math display">\[L_\text{simple} = \mathbb{E}_{t \sim \mathcal{U}(1, T), \mathbf{x}_0 \sim q(\mathbf{x}_0), \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left[\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}, t)\|^2 \right]\]</span></p>
<p>訓練時には、データ <span class="math inline">\(\mathbf{x}_0\)</span> をサンプリングし、ランダムなステップ <span class="math inline">\(t\)</span> を選び、Gaussianノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> を生成し、<span class="math inline">\(\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}\)</span> を計算します。そして、モデル <span class="math inline">\(\boldsymbol{\epsilon}_\theta\)</span> に <span class="math inline">\(\mathbf{x}_t\)</span> と <span class="math inline">\(t\)</span> を入力し、予測されたノイズ <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> と元のノイズ <span class="math inline">\(\boldsymbol{\epsilon}\)</span> とのMSEを計算し、これを損失としてモデルパラメータ <span class="math inline">\(\theta\)</span> を更新します。</p>
<p><strong>スコア関数との関連:</strong> このノイズ予測 <span class="math inline">\(\boldsymbol{\epsilon}_\theta\)</span> は、実はデータの対数確率密度勾配、すなわちスコア関数 <span class="math inline">\(\nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t)\)</span> と密接に関連しています。具体的には、<span class="math inline">\(\mathbf{s}_\theta(\mathbf{x}_t, t) \approx \nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t) \approx - \frac{\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)}{\sqrt{1 - \bar{\alpha}_t}}\)</span> という関係があります。これは、拡散モデルがスコアベース生成モデル（NCSN [Song &amp; Ermon, 2019] など）と深いつながりを持つことを示唆しています。</p>
</section>
</section>
<section id="拡散モデルの進化と応用" class="level2">
<h2 class="anchored" data-anchor-id="拡散モデルの進化と応用">拡散モデルの進化と応用</h2>
<p>DDPMの成功を受けて、拡散モデルの性能向上や応用範囲拡大のための様々な研究が行われています。</p>
<section id="条件付き生成conditional-generation" class="level3">
<h3 class="anchored" data-anchor-id="条件付き生成conditional-generation">条件付き生成（Conditional Generation）</h3>
<p>特定の情報（クラスラベル、テキスト記述、他の画像など）に基づいて画像を生成する技術です。</p>
<ul>
<li><p><strong>Classifier Guidance:</strong> [Dhariwal &amp; Nichol, 2021] で提案。ノイズ付き画像 <span class="math inline">\(\mathbf{x}_t\)</span> を入力として目的の条件 <span class="math inline">\(y\)</span> の対数尤度 <span class="math inline">\(\log f_\phi(y \vert \mathbf{x}_t)\)</span> を計算する別の分類器 <span class="math inline">\(f_\phi\)</span> を訓練します。生成時には、通常のノイズ予測 <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\)</span> に、この分類器の勾配 <span class="math inline">\(\nabla_{\mathbf{x}_t} \log f_\phi(y \vert \mathbf{x}_t)\)</span> を加味して予測を修正します。 <span class="math display">\[\bar{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t) = \boldsymbol{\epsilon}_\theta(x_t, t) - w \sqrt{1 - \bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log f_\phi(y \vert \mathbf{x}_t)\]</span> ここで <span class="math inline">\(w\)</span> はガイダンスの強さを制御する係数です。ADM (Ablated Diffusion Model) や ADM-G (ADM with Guidance) で高い性能が示されました。</p></li>
<li><p><strong>Classifier-Free Guidance:</strong> [Ho &amp; Salimans, 2021] で提案。拡散モデル <span class="math inline">\(\boldsymbol{\epsilon}_\theta\)</span> 自身を、条件 <span class="math inline">\(y\)</span> が与えられた場合 <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y)\)</span> と、条件がない（<span class="math inline">\(y=\varnothing\)</span> とする）場合 <span class="math inline">\(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing)\)</span> の両方で学習します。これは訓練中に一定の確率で条件 <span class="math inline">\(y\)</span> を無視（空の条件 <span class="math inline">\(\varnothing\)</span> に置き換える）ことで実現されます。生成時には、この二つの予測を組み合わせてガイダンスを行います。 <span class="math display">\[\bar{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, y) = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing) + w (\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing))\]</span> これは <span class="math inline">\((w+1) \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - w \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing)\)</span> とも書けます（元のブログ記事の式と一致）。この手法は追加の分類器が不要であり、近年の多くの高性能モデル（Imagen, Stable Diffusion, GLIDEなど）で広く採用されています。GLIDE [Nichol et al., 2022] では、CLIPを用いたガイダンスよりもClassifier-Freeガイダンスの方が好ましい結果が得られたと報告されています。</p></li>
</ul>
</section>
<section id="高速化speeding-up-sampling" class="level3">
<h3 class="anchored" data-anchor-id="高速化speeding-up-sampling">高速化（Speeding Up Sampling）</h3>
<p>DDPMの最大の課題であった生成速度を改善するための研究が活発に行われています。</p>
<ul>
<li><p><strong>DDIM (Denoising Diffusion Implicit Models):</strong> [Song et al., 2020] で提案。DDPMはマルコフ連鎖的な確率過程でしたが、DDIMは同じ順方向プロセスを持ちながら、非マルコフ的な（より大きなステップを許容する）決定論的な生成プロセスを定義します。これにより、サンプリングステップ数を大幅に（例：1000ステップから20～50ステップへ）削減しても高品質な生成が可能になりました。DDIMはパラメータ <span class="math inline">\(\eta\)</span> を持ち、<span class="math inline">\(\eta=0\)</span> で決定論的（DDIM）、<span class="math inline">\(\eta=1\)</span> でDDPMに近い確率的なサンプリングになります。決定論的であるため、同じ初期ノイズからは同じ画像が生成される「一貫性」を持ち、潜在空間での補間なども可能になります。</p></li>
<li><p><strong>Progressive Distillation:</strong> [Salimans &amp; Ho, 2022] で提案。訓練済みの決定論的サンプラー（例：DDIM）を「教師」とし、より少ないステップ数で同じ結果を出す「生徒」モデルを訓練する蒸留手法です。具体的には、生徒モデルの1ステップが教師モデルの2ステップに対応するように学習させます。これを繰り返すことで、サンプリングステップ数を指数関数的に削減できます。</p></li>
<li><p><strong>Consistency Models:</strong> [Song et al., 2023] で提案。拡散過程の途中の任意のノイズ付きデータ <span class="math inline">\(\mathbf{x}_t\)</span> から、直接元のデータ <span class="math inline">\(\mathbf{x}_0\)</span> （またはそれに近い <span class="math inline">\(\mathbf{x}_\epsilon\)</span>）を予測する関数 <span class="math inline">\(f(\mathbf{x}_t, t) \approx \mathbf{x}_0\)</span> を学習します。同じ軌道上の点はすべて同じ出力にマッピングされるという「自己一貫性」を持ちます。事前学習済みの拡散モデルから蒸留する方法（Consistency Distillation, CD）と、直接学習する方法（Consistency Training, CT）があります。これにより、理論的には1ステップでの高品質な生成が可能になります。</p></li>
<li><p><strong>Latent Diffusion Models (LDM):</strong> [Rombach et al., 2022] で提案。画像を直接扱うのではなく、まず強力なAutoencoder（Encoder <span class="math inline">\(\mathcal{E}\)</span> と Decoder <span class="math inline">\(\mathcal{D}\)</span>）を用いて画像を低次元の潜在表現 <span class="math inline">\(\mathbf{z} = \mathcal{E}(\mathbf{x})\)</span> に圧縮します。そして、この潜在空間 <span class="math inline">\(\mathbf{z}\)</span> 上で拡散モデル（通常はU-Netベース）を学習・実行します。生成時には、潜在空間でノイズから潜在表現 <span class="math inline">\(\mathbf{z}\)</span> を生成し、最後にDecoder <span class="math inline">\(\mathcal{D}\)</span> を使って画像 <span class="math inline">\(\tilde{\mathbf{x}} = \mathcal{D}(\mathbf{z})\)</span> に戻します。計算量を大幅に削減できるため、Stable Diffusionなどの高解像度画像生成モデルの基盤技術となっています。潜在空間の正則化にはKLペナルティ（VAEライク）やVQ正則化（VQ-VAEライク）が用いられます。条件付けは、潜在空間上のU-NetにCross-Attention機構を導入して行われることが多いです。</p></li>
</ul>
</section>
<section id="高解像度高品質化" class="level3">
<h3 class="anchored" data-anchor-id="高解像度高品質化">高解像度・高品質化</h3>
<ul>
<li><p><strong>Cascaded Models:</strong> [Ho et al., 2021] など。まず低解像度の画像を生成し、次にその低解像度画像を条件として、より高解像度の画像を生成する超解像拡散モデルを適用する、というパイプライン方式です。高品質な高解像度画像を生成するために有効です。この際、低解像度の条件画像に意図的にノイズを加える「Noise Conditioning Augmentation」が、誤差の蓄積を防ぎ品質を向上させる上で重要であることが示されています（低解像度ではGaussianノイズ、高解像度ではガウスぼかしが有効）。</p></li>
<li><p><strong>unCLIP / DALL-E 2:</strong> [Ramesh et al., 2022] で提案。CLIPモデルを活用し、テキスト記述から高品質な画像を生成します。2段階のプロセスからなります：(1) Priorモデルがテキスト <span class="math inline">\(y\)</span> から対応するCLIP画像埋め込み <span class="math inline">\(\mathbf{c}^i\)</span> を生成する (<span class="math inline">\(P(\mathbf{c}^i \vert y)\)</span>)。(2) Decoderモデルが、生成された画像埋め込み <span class="math inline">\(\mathbf{c}^i\)</span> （と、任意で元のテキスト <span class="math inline">\(y\)</span>）を条件として、最終的な画像 <span class="math inline">\(\mathbf{x}\)</span> を生成する (<span class="math inline">\(P(\mathbf{x} \vert \mathbf{c}^i, [y])\)</span>)。Decoderには拡散モデルが用いられます。</p></li>
<li><p><strong>Imagen:</strong> [Saharia et al., 2022] で提案。CLIPの代わりに、大規模な事前学習済み言語モデル（凍結されたT5-XXL）をテキストエンコーダとして使用します。テキストエンコーダの規模がU-Netの規模よりも重要であることが示されました。Classifier-Free Guidanceのスケール <span class="math inline">\(w\)</span> を大きくした際の画像忠実度低下を防ぐために、予測値をクリッピングする「Dynamic Thresholding」という手法を導入しました。また、U-Netアーキテクチャを改良した「Efficient U-Net」（低解像度ブロックにパラメータを集中、スキップ接続のスケーリング、畳み込みとプーリングの順序変更など）も提案されました。</p></li>
<li><p><strong>アーキテクチャの進化 (U-Net, DiT, ControlNet):</strong></p>
<ul>
<li><em>U-Net:</em> ダウンサンプリングパスとアップサンプリングパスを持ち、対応する層間をスキップ接続で繋いだ構造は、拡散モデル（特に画像）の標準的なバックボーンとして広く使われています。</li>
<li><em>DiT (Diffusion Transformer):</em> [Peebles &amp; Xie, 2023] で提案。LDMと同様に潜在空間上で動作しますが、バックボーンとしてU-Netの代わりにTransformerを使用します。潜在表現をパッチに分割し、シーケンスとしてTransformerブロックに入力します。タイムステップ <span class="math inline">\(t\)</span> やクラスラベル <span class="math inline">\(c\)</span> などの条件は、Layer Normalizationのパラメータを適応的に変化させる adaLN (Adaptive Layer Norm) -Zero という方式で埋め込むのが効果的でした。Transformerのスケーラビリティの恩恵を受け、モデルサイズと計算量を増やすことで性能が向上することが示されています。</li>
<li><em>ControlNet:</em> [Zhang et al., 2023] で提案。事前学習済みの強力な拡散モデル（例：Stable Diffusion）の重みを凍結したまま、そこに新たな条件（例：人物の骨格、線画、深度マップなど）を追加制御できるようにする手法です。元のモデルの各ブロックをコピーし、そのコピーのみを訓練可能にします。元のブロックとコピーの間を「Zero Convolution」（重みとバイアスがゼロで初期化された1x1畳み込み）で接続することで、元のモデルの性能を損なわずに、かつ安定して新たな制御を追加学習できます。式で書くと <span class="math inline">\(\mathbf{y}_c = \mathcal{F}_\theta(\mathbf{x}) + \mathcal{Z}_{\theta_{z2}}(\mathcal{F}_{\theta_c}(\mathbf{x} + \mathcal{Z}_{\theta_{z1}}(\mathbf{c})))\)</span> となります。</li>
</ul></li>
</ul>
</section>
</section>
<section id="まとめ" class="level2">
<h2 class="anchored" data-anchor-id="まとめ">まとめ</h2>
<p>拡散モデルは、データをノイズに変換する順方向プロセスと、その逆を学習してノイズからデータを生成する逆方向プロセスに基づく、強力かつ柔軟な生成モデルです。</p>
<ul>
<li><strong>利点:</strong> 理論的な扱いやすさ（Tractability）と表現力の高さ（Flexibility）を両立しています。特に画像生成においては、GANを凌駕する非常に高品質で多様なサンプルを生成できます。学習も比較的安定しています。</li>
<li><strong>欠点:</strong> 元々はサンプリング（生成）に非常に時間がかかるという問題がありましたが、DDIM、LDM、蒸留技術、Consistency Modelsなどの登場により大幅に改善され、実用性が大きく向上しました。それでも、応用によってはまだGANなど他の手法に比べて速度面で課題が残る場合もあります。</li>
</ul>
<p>Classifier-Free Guidance、Latent Diffusion、Transformerアーキテクチャの採用、ControlNetのような制御技術など、数々の技術革新により、拡散モデルはテキストからの画像生成、画像編集、動画生成など、多くの応用分野で最先端の成果を上げており、現在の生成AIの発展を牽引する重要な技術となっています。</p>
</section>
<section id="参考文献" class="level2">
<h2 class="anchored" data-anchor-id="参考文献">参考文献</h2>
<ol type="1">
<li>Weng, Lilian. (Jul 2021). What are diffusion models? Lil’Log. <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></li>
<li>Ho, Jonathan, Ajay Jain, and Pieter Abbeel. “<a href="https://arxiv.org/abs/2006.11239">Denoising diffusion probabilistic models</a>.” NeurIPS 2020. (DDPM)</li>
<li>Song, Jiaming, Chenlin Meng, and Stefano Ermon. “<a href="https://arxiv.org/abs/2010.02502">Denoising diffusion implicit models</a>.” ICLR 2021. (DDIM)</li>
<li>Rombach, Robin, et al.&nbsp;“<a href="https://arxiv.org/abs/2112.10752">High-resolution image synthesis with latent diffusion models</a>.” CVPR 2022. (Latent Diffusion / Stable Diffusionの基盤)</li>
<li>Nichol, Alex, and Prafulla Dhariwal. “<a href="https://arxiv.org/abs/2102.09672">Improved denoising diffusion probabilistic models</a>.” ICML 2021.</li>
<li>Dhariwal, Prafulla, and Alex Nichol. “<a href="https://arxiv.org/abs/2105.05233">Diffusion models beat gans on image synthesis</a>.” NeurIPS 2021.</li>
<li>Ho, Jonathan, and Tim Salimans. “<a href="https://arxiv.org/abs/2207.12598">Classifier-free diffusion guidance</a>.” NeurIPS 2021 Workshop.</li>
<li>Salimans, Tim, and Jonathan Ho. “<a href="https://arxiv.org/abs/2202.00512">Progressive distillation for fast sampling of diffusion models</a>.” ICLR 2022.</li>
<li>Song, Yang, et al.&nbsp;“<a href="https://arxiv.org/abs/2303.01469">Consistency models</a>.” ICML 2023.</li>
<li>Ho, Jonathan, et al.&nbsp;“<a href="https://arxiv.org/abs/2106.15282">Cascaded diffusion models for high fidelity image generation</a>.” JMLR 2022.</li>
<li>Ramesh, Aditya, et al.&nbsp;“<a href="https://arxiv.org/abs/2204.06125">Hierarchical text-conditional image generation with clip latents</a>.” arXiv 2022. (unCLIP / DALL-E 2)</li>
<li>Saharia, Chitwan, et al.&nbsp;“<a href="https://arxiv.org/abs/2205.11487">Photorealistic text-to-image diffusion models with deep language understanding</a>.” NeurIPS 2022. (Imagen)</li>
<li>Peebles, William, and Saining Xie. “<a href="https://arxiv.org/abs/2212.09748">Scalable diffusion models with transformers</a>.” ICCV 2023. (DiT)</li>
<li>Zhang, Lvmin, and Maneesh Agrawala. “<a href="https://arxiv.org/abs/2302.05543">Adding conditional control to text-to-image diffusion models</a>.” ICCV 2023. (ControlNet)</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jiwasawa\.github\.io\/blog_jp");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>