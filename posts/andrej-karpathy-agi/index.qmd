---
title: "Andrej Karpathy、AIの「デモと現実」を語る：なぜAGIは「今年」ではなく「10年」かかるのか"
description: "Andrej Karpathy のpodcastを通し、AIの受容・AGIへのタイムラインについて考える"
author: "Junichiro Iwasawa"
date: "2025-10-22"
categories: [LLM, AI]
image: https://picsum.photos/id/110/200
---

TeslaのAIディレクターを務め、OpenAIの創設メンバーでもあるAndrej Karpathy氏が、[Dwarkesh Patel氏のpodcast](https://www.dwarkesh.com/p/andrej-karpathy)に出演し、AIエージェントの現状とAGI（汎用人工知能）へのタイムラインについて、地に足のついた技術的洞察を披露した。

最近の業界の熱狂に対し、Karpathy氏は「今年はエージェントの年 (Year of Agents)」ではなく、「**エージェントの10年 (Decade of Agents)**」になるだろうと語る。

なぜ彼は、AGIの実現に10年というタイムラインを提示するのか。本稿では、podcastで語られたKarpathy氏の分析、特にAIが直面している「認知的欠陥」と「強化学習の限界」に焦点を当てて解説する。

---

## 「エージェントの年」ではなく「エージェントの10年」

Karpathy氏が「10年」というスパンを主張する理由は極めてシンプルだ。それは、現在のエージェントが「**まだ使い物にならない (They just don't work)**」からである。

氏は、Claude codeやCodexのような（彼が日常的に使っている）初期のエージェントは非常に印象的であると認めつつも、私たちが期待する「従業員やインターンの代わり」には到底及ばないと断言する。

なぜなら、現在のモデルには以下のような根本的な能力が欠けているからだ。

* **継続的学習 (Continual Learning):** 一度教えたことを覚えていられない。
* **マルチモーダリティ (Multimodality):** テキスト以外の情報を真に理解し、活用できない。
* **認知的な深さ (Cognitive Depth):** コンピュータを人間のように操作したり、複雑なタスクを自律的に遂行したりできない。

Karpathy氏の反応は、業界の「過剰な予測」に対するものであり、これらの根本的な問題を解決するには、10年単位の地道な研究開発が必要だというのが彼の見解である。

---

## LLMの「認知的欠陥」：インターネットの「データ多様体」への過剰な依存

Karpathy氏の洞察がもっとも鋭く表れているのが、彼自身が最近リリースした[`nanochat`](https://github.com/karpathy/nanochat/discussions/1)（ChatGPTクローンのシンプルなリポジトリ）の開発経験だ。

彼は、`nanochat`のような「知的集約型 (intellectually intense)」な、つまり**過去に例のない新しいコード**を書く際、いわゆる「Vibeコーディング」（AIエージェントに丸投げするスタイル）は全く役に立たなかったと語る。AIエージェントが生成するコードは「**スロップ (Slop)（粗悪なもの）**」であり、むしろ彼の作業の邪魔になったという。

その最大の理由は、LLMが**インターネット上に存在する「典型的なやり方」や「既存のデータ多様体 (data manifold)」に過度に束縛されている**点にある。

Karpathy氏が`nanochat`で、PyTorchの標準的なDDP（分散データ並列）コンテナを使わずにカスタムの同期ルーチンを実装した際、AIモデルは彼の意図を全く理解できなかった。AIは「インターネットで最も一般的なDDPを使うべきだ」と主張し続け、彼のカスタム実装を妨害しようとした。

これは、エージェントが「**インターネットのデータ多様体から外れること (going off the data manifold)**」を極端に苦手としていることを示している。彼らは、既存の知識やパターンに依存しすぎており、真に新しい、あるいは独自性の高いタスクに対応できないのだ。

Karpathy氏は、この問題を「**サイレント・コラプス (silently collapsed)**」という言葉でも表現する。LLMに合成データ（例：思考プロセスやジョーク）を生成させると、一見もっともらしく見えるが、多様性が致命的に欠けている。ChatGPTにジョークを頼むと、いつも3種類ほどの決まった答えしか返ってこないのがその典型だ。

彼は、現在のLLMは「知識（メモリ）」を詰め込みすぎていると指摘する。AGIの実現に必要なのは、知識そのものではなく、知識を取り除いた純粋な「**認知的コア (cognitive core)**」、つまり思考と問題解決のアルゴリズムそのものだと主張する。

---

## 「強化学習はひどい」：ストローで監視を吸うようなもの

Karpathy氏は、現在のAI研究のもう一つの柱である強化学習（RL）に対しても、痛烈な批判を展開している。

「**人間は強化学習を使っていない**」「**強化学習はひどい (Reinforcement learning is terrible)**」と彼は言う。

現在のRLの手法は、例えば数学の問題を解く場合、何百もの異なる解法（軌道）を並行して試行する。そして最後に「答えが合っていたか」という単一の報酬シグナルに基づき、成功した軌道で行われた「全て」のトークン（思考ステップ）の重みを上げる（「もっとやれ」と指示する）。

Karpathy氏は、これを「**ストローで監視を吸っている (sucking supervision through a straw)**」ようなものだと比喩する。

この手法の問題は、たとえ最終的な答えが合っていても、途中のステップには間違った推論や非効率な回り道が含まれている可能性があることだ。しかしRLは、その軌道全体を盲目的に「良いもの」として扱う。これは「ノイズが多く」「愚かで」「クレイジーだ」と彼は切り捨てる。

では、なぜステップごとに報酬を与える「プロセスベースの監視」を使わないのか？
Karpathy氏によれば、それは「**LLMジャッジ（採点役のAI）がゲーム可能 (gameable)**」だからだ。

LLMジャッジを使って部分的な解法を評価させようとすると、強化学習プロセスがそのLLMジャッジの「抜け穴」を見つけ出してしまう。Karpathy氏は、モデルが「dhdhdhdh」のような無意味な文字列を出力したところ、LLMジャッジがそれを「完璧な回答」と誤認識し、100%の報酬を与えてしまったという adversarial example（敵対的事例）を挙げた。

このLLMジャッジの脆弱性は、現在のRLにおける深刻なボトルネックとなっている。

---

## 自動運転の教訓：「デモから製品までのギャップ」

Karpathy氏の現実的なタイムラインは、彼がTeslaで自動運転開発を5年間率いた経験に深く根差している。

自動運転の世界には、「**デモと製品の間の巨大なギャップ**」が存在する。そして、自動運転のような「失敗のコストが極めて高い」ドメインでは、そのギャップを埋めるのに膨大な時間がかかる。

彼はこれを「**9の行進 (march of nines)**」と呼ぶ。
デモで90%の成功率を達成するのは簡単だ。しかし、製品レベルの信頼性、つまり99%、99.9%、99.99%へと進むにつれ、その「9」を一つ増やすごとに、90%を達成した時と同等かそれ以上の一定の作業量が必要になる。

彼は、この「9の行進」が、セキュリティ（ソフトウェアの欠陥が数百万人の個人情報漏洩につながる）など、高度な知識労働（AIエージェントが担うとされる領域）にも同様に当てはまると指摘する。

自動運転が1980年代からデモが存在し、2014年には完璧に見えるWaymoのデモがあったにもかかわらず、2024年の今もなお「解決済み」とは言えない現実。これが、彼がAIの急速な爆発的進化に懐疑的な理由である。

---

## AGIはGDPを爆発させない

Karpathy氏は、AGIが経済に与える影響についても、一般的な「爆発的成長」論とは一線を画す。

彼は、AGIを「**コンピューティングの延長線上**」にあるものと捉えている。

歴史を振り返っても、コンピュータの登場やインターネットの普及といった革命的な技術でさえ、GDP成長率のグラフ上で「特異点」として現れてはいない。それらの影響は、既存の年率2%程度の指数関数的成長の中にスムーズに溶け込んでいる。

Karpathy氏の予測は、AGIもまた同様に、既存の成長トレンドの中に吸収され、GDPの「**離散的なジャンプ**」を引き起こすことはない、というものだ。

---

## Karpathyの次章：「Starfleet Academy」と教育の未来

では、Karpathy氏は今、何に注力しているのか。彼はAIラボの最前線から離れ、教育分野で「Eureka」という新しいプロジェクトを立ち上げた。

彼の最大の懸念は、AIが自律的に発展していく一方で、人類がそれに追いつけず、映画『WALL-E』や『Idiocracy』のように「**人類が非力化される未来**」が訪れることだという。

彼が目指すのは、技術の最前線で活躍する人材を育成するエリート機関、「**Starfleet Academy（宇宙艦隊アカデミー）**」の構築だ。

しかし、ここでも彼はAIの現状に対して極めて現実的だ。
AIチューター（AI家庭教師）はどうか？ 彼は、韓国語学習で雇った「優れた人間の家庭教師」の経験を引き合いに出す。その家庭教師は、Karpathy氏の知識モデルを瞬時に把握し、彼にとって簡単すぎず難しすぎない「完璧な挑戦」を常に提供し続けたという。

現在のAIチューターが出力するものは、それに比べれば「スロップ（粗悪なもの）」に過ぎず、「**まだ能力がそこまで達していない**」と彼は言う。

Karpathy氏は、AGI（汎用人工知能）登場以前と以後で、教育の意味合いが変わると予測する。

* **Pre-AGI（AGI以前）:** 教育は「**役に立つ**」もの（お金を稼ぐため）。
* **Post-AGI（AGI以後）:** 教育は「**楽しい**」もの。

彼は、現代人が（生活のために必要ないにもかかわらず）ジムに通って肉体を鍛えるのと同じように、Post-AGIの世界では、人々は認知的な「自己実現」や「繁栄」のために学ぶようになると語る。

Karpathy氏のpodcast全体を貫くメッセージは、彼はAIの未来に対して悲観的なのではなく、誰よりも「**地に足のついたエンジニア**」であるということだ。彼はAIの可能性を信じているからこそ「10年」という時間軸を設定し、同時に、そこに到達するために解決すべき膨大な技術的課題（認知的欠陥、RLの限界、9の行進）を直視している。そして彼の視線は、その新しい時代を生きる「人間」のエンパワーメントへと向かっている。
