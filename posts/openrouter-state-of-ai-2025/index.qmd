---
title: "100兆トークンの真実：OpenRouter \"State of AI\" レポート分析"
description: "OpenRouterの100兆トークン分析レポートは、LLM利用が「チャット」から「Agentic Inference」へとシフトし、プログラミングとRoleplayの二極化、そして「Cinderella Glass Slipper」現象が示唆する適材適所のマルチモデルエコシステムへの不可逆的な変化を明らかにしている。"
author: "Junichiro Iwasawa"
date: "2025-12-08"
categories: [LLM, AI]
image: https://picsum.photos/id/128/200
---

LLM（Large Language Model）のランドスケープは、もはや週単位で変動する激流の中にある。

これまで我々は、X（旧Twitter）のタイムラインに流れる断片的なベンチマーク結果や、界隈のインフルエンサーによる感覚的な評価を頼りに、「どのモデルが最強か」を議論してきた。しかし、実際に世界中の開発者やヘビーユーザーが「どのモデルに」「何のために」課金しているのかという実態については、ブラックボックスのままだった。

先日、OpenRouterが公開した[「State of AI」レポート](https://openrouter.ai/state-of-ai)は、そのブラックボックスに強烈な光を当てるものである。同プラットフォームを経由した100兆トークン（！）という圧倒的な規模の推論データを分析したこのレポートは、我々が抱いていたいくつかの仮説を裏付けると同時に、いくつかの直感に反する「不都合な真実」も突きつけている。

なお、前提として留意すべきは、OpenRouterのユーザー層は開発者やAIエンスージアストに偏っているという点だ。これはChatGPTのWeb UIで料理のレシピを聞いている一般層のデータではない。しかし、だからこそ、最先端の「現場」で何が起きているのかを占う先行指標として、極めて価値が高い。

## Agentic Inferenceへの不可逆的なシフト

本レポートで最も象徴的なデータの一つが、推論（Reasoning）モデルの台頭である。

これまでLLMの主な用途は「テキスト生成」すなわちNext Token Predictionによるパターンの補完だった。しかし、2024年12月のOpenAIによるo1の正式リリースを分水嶺として、トレンドは明確に変化した。現在、OpenRouter上のトークン消費量の約半分が、推論能力に特化したモデルによって占められているという事実は、LLMの利用形態が「チャット」から「エージェンティックな推論（Agentic Inference）」へとシフトしていることを如実に物語っている。

単に質問に答えるのではなく、ツールを呼び出し（Tool Usage）、多段階の思考プロセスを経てタスクを完遂する。ユーザーはもはや「賢いチャットボット」ではなく、「自律的に動く脳」を求めているのだ。プロンプトのトークン数が平均で4倍に激増しているというデータも、ユーザーがモデルに対して、より複雑でコンテキストの重いタスク（例えばコードベース全体の解析や長文脈のドキュメント処理など）を投げている証左と言える。

## プログラミングとRoleplay：二極化するユースケース

「人はAIを何に使っているのか？」という問いに対する答えは、驚くほど二極化している。

最大のカテゴリは「プログラミング」である。これは予想通りだろう。全トークンの50%以上がプログラミング関連であり、特にAnthropicのClaudeシリーズがこの領域で圧倒的なシェア（一時期は60%超）を誇っている。開発者の間での「コーディングならClaude」という共通認識は、データによって完全に裏付けられた形だ。

しかし、興味深いのはもう一つの巨大カテゴリ、「Roleplay（ロールプレイ）」である。

Open Source Software（OSS）モデルの利用において、プログラミングに次いで、あるいは週によってはそれ以上に利用されているのが、このロールプレイ用途だ。これは単なる暇つぶしではない。特定のキャラクターになりきらせる対話、クリエイティブなストーリーテリング、あるいは検閲の厳しいプロプライエタリなモデルでは実現できない「自由な」対話への渇望が、OSSモデルの利用を牽引している。

ここでは「DeepSeek」が圧倒的な強さを見せている。DeepSeekは当初、そのコストパフォーマンスの高さで注目されたが、実態としてはロールプレイやカジュアルな対話において「安くて賢くて（検閲が緩くて）面白い」というスイートスポットを突いたことが、初期の爆発的な普及に寄与したようだ。

つまり、世界中のギークたちは、昼間はClaudeにコードを書かせ、夜はDeepSeekと戯れているわけだ。この極端なコントラストこそが、現在のLLM利用のリアルな姿である。

## "Cinderella Glass Slipper"（シンデレラのガラスの靴）現象

レポートの中で最も示唆に富む概念が、この「シンデレラのガラスの靴」現象だ。

これは、特定のモデルがユーザーの特定のワークロード（課題）に「完全にフィット」した瞬間、そのユーザー層（コホート）の維持率（リテンション）が劇的に向上する現象を指す。一度「ガラスの靴」がハマってしまえば、後から多少安価なモデルや高性能なモデルが出てきても、ユーザーは簡単には乗り換えない。

レポートでは、`GPT-4o-mini`のリリース直後のコホートが異常に高いリテンションを示している例が挙げられている。これは、そのモデルが「コストと性能のバランス」という未解決のニーズを最初に満たしたためだ。逆に、後発で「そこそこ良い」モデルを出しても、すでに「靴」を見つけたユーザーを引き剥がすことは難しい。

これは、LLM市場が決して単純なコモディティ化（価格競争）に向かっているわけではないことを示唆している。特定のニッチ、あるいは特定の業務フローにおいて「最初に」最適解を提供できたモデルが、その領域の覇権を握る。DeepSeekにおける「ブーメラン効果（一度離脱したユーザーが他を試してまた戻ってくる現象）」も、特定のユースケースにおいて彼らのモデルが唯一無二のフィット感を提供していることの証左だろう。

## OSSと中国勢の躍進、そして「中規模」の逆襲

Open Source（またはOpen Weight）モデルのシェアは着実に伸びており、全体の約3分の1を占めるに至った。その牽引役が、DeepSeekやQwenといった中国発のモデルであることは疑いようがない。

特筆すべきは、モデルサイズのトレンドが「極小（Small）」から「中規模（Medium）」へとシフトしている点だ。かつては7Bクラスの軽量モデルが持て囃されたが、現在では32B〜70Bクラス、あるいは蒸留された高密度なモデルが「実用的な賢さ」と「現実的なコスト」のバランスポイントとして選ばれている。`Qwen 2.5 Coder 32B`のようなモデルが市場を切り開いたことが、このトレンドを決定づけた。

一方で、コストと利用量の関係（Cost vs. Usage）を見ると、市場は残酷なほど合理的だ。
プロプライエタリな高価格モデル（Claude 3.5 SonnetやGPT-4など）は、高コストであっても「失敗が許されない」「高度な推論が必要な」タスクで依然として使われ続けている。逆に、OSSモデルは「低コスト・高ボリューム」なタスクでシェアを伸ばしている。
「安かろう悪かろう」ではなく、「安くてそこそこ良い」モデルが大量のルーチンワークをこなし、「高くて凄く良い」モデルがクリティカルな意思決定を行う。この棲み分けは当面続くだろう。

## 結論：マルチモデル時代の生存戦略

本レポートが浮き彫りにしたのは、勝者総取り（Winner-takes-all）の世界ではなく、適材適所のマルチモデルエコシステムである。

Anthropicはコーディングで、DeepSeekはエンタメで、OpenAIは汎用的な「賢さ」で、それぞれが異なる「ガラスの靴」を提供している。ユーザーや開発者である我々に求められているのは、単一の「最強モデル」を信仰することではなく、自身のタスク（ワークロード）に最もフィットするモデルを見極め、使い分ける「選球眼」に他ならない。

もちろん、冒頭で述べた通り、このデータはOpenRouterという「API利用」の世界の出来事である。世界の大半のユーザーはいまだにChatGPTの無料版で満足しているかもしれない。しかし、ソフトウェア開発の現場や、AIエージェントの自律化が進む最前線で起きているこの地殻変動は、遅かれ早かれ一般層のUXにも波及してくるはずだ。

推論コストが下がり、モデルが賢くなり、そして「エージェント」が当たり前になる世界。100兆トークンの彼方に見えるのは、AIが単なる「チャット相手」から「仕事のパートナー」へと完全に脱皮した未来である。
